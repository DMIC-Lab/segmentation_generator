
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2024-05-13 15:00:47.263911: do_dummy_2d_data_aug: True 
2024-05-13 15:00:47.284729: Creating new 5-fold cross-validation split... 
2024-05-13 15:00:47.315515: Desired fold for training: 0 
2024-05-13 15:00:47.315599: This split has 5978 training and 1495 validation cases. 
2024-05-13 15:00:51.631825: Using torch.compile... 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [48, 192, 256], 'median_image_size_in_voxels': [46.0, 200.0, 273.0], 'spacing': [1.0, 1.0, 1.0], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}, 'deep_supervision': True}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset027_COPD_ONLY_1', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [46, 200, 273], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 1.0, 'mean': 0.488230437040329, 'median': 0.5212292075157166, 'min': 0.00011610400542849675, 'percentile_00_5': 0.07475718334317208, 'percentile_99_5': 0.9121223616600034, 'std': 0.1583905816078186}}} 
 
2024-05-13 15:00:52.434218: unpacking dataset... 
2024-05-13 15:02:34.356120: unpacking done... 
2024-05-13 15:02:34.359420: Unable to plot network architecture: nnUNet_compile is enabled! 
2024-05-13 15:02:34.411014:  
2024-05-13 15:02:34.411105: Epoch 0 
2024-05-13 15:02:34.411240: Current learning rate: 0.01 
2024-05-13 15:04:00.252936: train_loss -0.2421 
2024-05-13 15:04:00.253099: val_loss -0.383 
2024-05-13 15:04:00.253176: Pseudo dice [0.6687] 
2024-05-13 15:04:00.253235: Epoch time: 85.84 s 
2024-05-13 15:04:00.253281: Yayy! New best EMA pseudo Dice: 0.6687 
2024-05-13 15:04:01.350963:  
2024-05-13 15:04:01.351072: Epoch 1 
2024-05-13 15:04:01.351156: Current learning rate: 0.00999 
2024-05-13 15:04:50.054824: train_loss -0.4104 
2024-05-13 15:04:50.054988: val_loss -0.4411 
2024-05-13 15:04:50.055048: Pseudo dice [0.6829] 
2024-05-13 15:04:50.055126: Epoch time: 48.7 s 
2024-05-13 15:04:50.055173: Yayy! New best EMA pseudo Dice: 0.6702 
2024-05-13 15:04:51.385268:  
2024-05-13 15:04:51.385370: Epoch 2 
2024-05-13 15:04:51.385493: Current learning rate: 0.00998 
2024-05-13 15:05:40.261092: train_loss -0.4802 
2024-05-13 15:05:40.261261: val_loss -0.5151 
2024-05-13 15:05:40.261320: Pseudo dice [0.747] 
2024-05-13 15:05:40.261379: Epoch time: 48.88 s 
2024-05-13 15:05:40.261425: Yayy! New best EMA pseudo Dice: 0.6778 
2024-05-13 15:05:41.629419:  
2024-05-13 15:05:41.629519: Epoch 3 
2024-05-13 15:05:41.629621: Current learning rate: 0.00997 
2024-05-13 15:06:30.603297: train_loss -0.4954 
2024-05-13 15:06:30.603472: val_loss -0.5151 
2024-05-13 15:06:30.603535: Pseudo dice [0.737] 
2024-05-13 15:06:30.603593: Epoch time: 48.97 s 
2024-05-13 15:06:30.603641: Yayy! New best EMA pseudo Dice: 0.6838 
2024-05-13 15:06:32.265296:  
2024-05-13 15:06:32.265424: Epoch 4 
2024-05-13 15:06:32.265507: Current learning rate: 0.00996 
2024-05-13 15:07:21.237692: train_loss -0.5511 
2024-05-13 15:07:21.237864: val_loss -0.5588 
2024-05-13 15:07:21.237924: Pseudo dice [0.7714] 
2024-05-13 15:07:21.237981: Epoch time: 48.97 s 
2024-05-13 15:07:21.238025: Yayy! New best EMA pseudo Dice: 0.6925 
2024-05-13 15:07:22.593544:  
2024-05-13 15:07:22.593653: Epoch 5 
2024-05-13 15:07:22.593752: Current learning rate: 0.00995 
2024-05-13 15:08:11.636610: train_loss -0.5411 
2024-05-13 15:08:11.637332: val_loss -0.565 
2024-05-13 15:08:11.637395: Pseudo dice [0.7647] 
2024-05-13 15:08:11.637447: Epoch time: 49.04 s 
2024-05-13 15:08:11.637487: Yayy! New best EMA pseudo Dice: 0.6997 
2024-05-13 15:08:12.927859:  
2024-05-13 15:08:12.927978: Epoch 6 
2024-05-13 15:08:12.928080: Current learning rate: 0.00995 
2024-05-13 15:09:01.887633: train_loss -0.5689 
2024-05-13 15:09:01.887794: val_loss -0.5981 
2024-05-13 15:09:01.887850: Pseudo dice [0.783] 
2024-05-13 15:09:01.887906: Epoch time: 48.96 s 
2024-05-13 15:09:01.887949: Yayy! New best EMA pseudo Dice: 0.7081 
2024-05-13 15:09:03.236592:  
2024-05-13 15:09:03.236692: Epoch 7 
2024-05-13 15:09:03.236788: Current learning rate: 0.00994 
2024-05-13 15:09:52.215121: train_loss -0.5908 
2024-05-13 15:09:52.215292: val_loss -0.5855 
2024-05-13 15:09:52.215372: Pseudo dice [0.759] 
2024-05-13 15:09:52.215455: Epoch time: 48.98 s 
2024-05-13 15:09:52.215538: Yayy! New best EMA pseudo Dice: 0.7132 
2024-05-13 15:09:53.572823:  
2024-05-13 15:09:53.572927: Epoch 8 
2024-05-13 15:09:53.573010: Current learning rate: 0.00993 
2024-05-13 15:10:42.663547: train_loss -0.5992 
2024-05-13 15:10:42.663715: val_loss -0.6178 
2024-05-13 15:10:42.663778: Pseudo dice [0.7893] 
2024-05-13 15:10:42.663840: Epoch time: 49.09 s 
2024-05-13 15:10:42.663887: Yayy! New best EMA pseudo Dice: 0.7208 
2024-05-13 15:10:44.085703:  
2024-05-13 15:10:44.085808: Epoch 9 
2024-05-13 15:10:44.085905: Current learning rate: 0.00992 
2024-05-13 15:11:33.189805: train_loss -0.6073 
2024-05-13 15:11:33.190675: val_loss -0.614 
2024-05-13 15:11:33.190933: Pseudo dice [0.7963] 
2024-05-13 15:11:33.191124: Epoch time: 49.1 s 
2024-05-13 15:11:33.191289: Yayy! New best EMA pseudo Dice: 0.7283 
2024-05-13 15:11:34.549023:  
2024-05-13 15:11:34.549126: Epoch 10 
2024-05-13 15:11:34.549224: Current learning rate: 0.00991 
2024-05-13 15:12:23.555644: train_loss -0.6326 
2024-05-13 15:12:23.555916: val_loss -0.6571 
2024-05-13 15:12:23.555978: Pseudo dice [0.8191] 
2024-05-13 15:12:23.556037: Epoch time: 49.01 s 
2024-05-13 15:12:23.556084: Yayy! New best EMA pseudo Dice: 0.7374 
2024-05-13 15:12:24.859917:  
2024-05-13 15:12:24.860155: Epoch 11 
2024-05-13 15:12:24.860258: Current learning rate: 0.0099 
2024-05-13 15:13:13.878263: train_loss -0.6494 
2024-05-13 15:13:13.878453: val_loss -0.6552 
2024-05-13 15:13:13.878513: Pseudo dice [0.8167] 
2024-05-13 15:13:13.878571: Epoch time: 49.02 s 
2024-05-13 15:13:13.878617: Yayy! New best EMA pseudo Dice: 0.7453 
2024-05-13 15:13:15.185774:  
2024-05-13 15:13:15.185891: Epoch 12 
2024-05-13 15:13:15.185973: Current learning rate: 0.00989 
2024-05-13 15:14:04.192054: train_loss -0.6373 
2024-05-13 15:14:04.192762: val_loss -0.6741 
2024-05-13 15:14:04.192824: Pseudo dice [0.8267] 
2024-05-13 15:14:04.192882: Epoch time: 49.01 s 
2024-05-13 15:14:04.192921: Yayy! New best EMA pseudo Dice: 0.7535 
2024-05-13 15:14:05.511804:  
2024-05-13 15:14:05.511910: Epoch 13 
2024-05-13 15:14:05.512008: Current learning rate: 0.00988 
2024-05-13 15:14:54.508843: train_loss -0.6592 
2024-05-13 15:14:54.509006: val_loss -0.6621 
2024-05-13 15:14:54.509064: Pseudo dice [0.8248] 
2024-05-13 15:14:54.509120: Epoch time: 49.0 s 
2024-05-13 15:14:54.509162: Yayy! New best EMA pseudo Dice: 0.7606 
2024-05-13 15:14:56.196448:  
2024-05-13 15:14:56.196571: Epoch 14 
2024-05-13 15:14:56.196671: Current learning rate: 0.00987 
2024-05-13 15:15:45.254604: train_loss -0.6771 
2024-05-13 15:15:45.254775: val_loss -0.6719 
2024-05-13 15:15:45.254832: Pseudo dice [0.8321] 
2024-05-13 15:15:45.254895: Epoch time: 49.06 s 
2024-05-13 15:15:45.254939: Yayy! New best EMA pseudo Dice: 0.7677 
2024-05-13 15:15:46.595076:  
2024-05-13 15:15:46.595312: Epoch 15 
2024-05-13 15:15:46.595402: Current learning rate: 0.00986 
2024-05-13 15:16:35.601295: train_loss -0.6912 
2024-05-13 15:16:35.601755: val_loss -0.6965 
2024-05-13 15:16:35.602057: Pseudo dice [0.8437] 
2024-05-13 15:16:35.602325: Epoch time: 49.01 s 
2024-05-13 15:16:35.602550: Yayy! New best EMA pseudo Dice: 0.7753 
2024-05-13 15:16:36.956481:  
2024-05-13 15:16:36.956706: Epoch 16 
2024-05-13 15:16:36.956844: Current learning rate: 0.00986 
2024-05-13 15:17:25.972821: train_loss -0.6807 
2024-05-13 15:17:25.973013: val_loss -0.6755 
2024-05-13 15:17:25.973074: Pseudo dice [0.826] 
2024-05-13 15:17:25.973132: Epoch time: 49.02 s 
2024-05-13 15:17:25.973182: Yayy! New best EMA pseudo Dice: 0.7804 
2024-05-13 15:17:27.339426:  
2024-05-13 15:17:27.339544: Epoch 17 
2024-05-13 15:17:27.339641: Current learning rate: 0.00985 
2024-05-13 15:18:16.345899: train_loss -0.6875 
2024-05-13 15:18:16.346054: val_loss -0.6791 
2024-05-13 15:18:16.346127: Pseudo dice [0.8219] 
2024-05-13 15:18:16.346184: Epoch time: 49.01 s 
2024-05-13 15:18:16.346235: Yayy! New best EMA pseudo Dice: 0.7845 
2024-05-13 15:18:17.706910:  
2024-05-13 15:18:17.707016: Epoch 18 
2024-05-13 15:18:17.707100: Current learning rate: 0.00984 
2024-05-13 15:19:06.658578: train_loss -0.6731 
2024-05-13 15:19:06.659258: val_loss -0.6972 
2024-05-13 15:19:06.659320: Pseudo dice [0.8329] 
2024-05-13 15:19:06.659374: Epoch time: 48.95 s 
2024-05-13 15:19:06.659415: Yayy! New best EMA pseudo Dice: 0.7894 
2024-05-13 15:19:08.067401:  
2024-05-13 15:19:08.067506: Epoch 19 
2024-05-13 15:19:08.067591: Current learning rate: 0.00983 
2024-05-13 15:19:57.108983: train_loss -0.6962 
2024-05-13 15:19:57.109148: val_loss -0.6878 
2024-05-13 15:19:57.109204: Pseudo dice [0.8351] 
2024-05-13 15:19:57.109277: Epoch time: 49.04 s 
2024-05-13 15:19:57.109321: Yayy! New best EMA pseudo Dice: 0.794 
2024-05-13 15:19:58.490636:  
2024-05-13 15:19:58.490937: Epoch 20 
2024-05-13 15:19:58.491112: Current learning rate: 0.00982 
2024-05-13 15:20:47.451393: train_loss -0.7086 
2024-05-13 15:20:47.451593: val_loss -0.7071 
2024-05-13 15:20:47.451654: Pseudo dice [0.8458] 
2024-05-13 15:20:47.451712: Epoch time: 48.96 s 
2024-05-13 15:20:47.451757: Yayy! New best EMA pseudo Dice: 0.7991 
2024-05-13 15:20:48.811385:  
2024-05-13 15:20:48.811596: Epoch 21 
2024-05-13 15:20:48.811702: Current learning rate: 0.00981 
2024-05-13 15:21:37.811133: train_loss -0.7079 
2024-05-13 15:21:37.811419: val_loss -0.721 
2024-05-13 15:21:37.811486: Pseudo dice [0.8548] 
2024-05-13 15:21:37.811545: Epoch time: 49.0 s 
2024-05-13 15:21:37.811591: Yayy! New best EMA pseudo Dice: 0.8047 
2024-05-13 15:21:39.118624:  
2024-05-13 15:21:39.118800: Epoch 22 
2024-05-13 15:21:39.118887: Current learning rate: 0.0098 
2024-05-13 15:22:28.137144: train_loss -0.7225 
2024-05-13 15:22:28.137317: val_loss -0.7181 
2024-05-13 15:22:28.137377: Pseudo dice [0.8522] 
2024-05-13 15:22:28.137434: Epoch time: 49.02 s 
2024-05-13 15:22:28.137477: Yayy! New best EMA pseudo Dice: 0.8095 
2024-05-13 15:22:29.456078:  
2024-05-13 15:22:29.456181: Epoch 23 
2024-05-13 15:22:29.456262: Current learning rate: 0.00979 
2024-05-13 15:23:18.453890: train_loss -0.7122 
2024-05-13 15:23:18.454052: val_loss -0.7234 
2024-05-13 15:23:18.454127: Pseudo dice [0.8551] 
2024-05-13 15:23:18.454183: Epoch time: 49.0 s 
2024-05-13 15:23:18.454229: Yayy! New best EMA pseudo Dice: 0.814 
2024-05-13 15:23:19.749958:  
2024-05-13 15:23:19.750133: Epoch 24 
2024-05-13 15:23:19.750218: Current learning rate: 0.00978 
2024-05-13 15:24:08.800656: train_loss -0.7195 
2024-05-13 15:24:08.800832: val_loss -0.726 
2024-05-13 15:24:08.800896: Pseudo dice [0.8569] 
2024-05-13 15:24:08.800955: Epoch time: 49.05 s 
2024-05-13 15:24:08.801001: Yayy! New best EMA pseudo Dice: 0.8183 
2024-05-13 15:24:10.607234:  
2024-05-13 15:24:10.607363: Epoch 25 
2024-05-13 15:24:10.607450: Current learning rate: 0.00977 
2024-05-13 15:24:59.613725: train_loss -0.7184 
2024-05-13 15:24:59.614455: val_loss -0.7136 
2024-05-13 15:24:59.614522: Pseudo dice [0.856] 
2024-05-13 15:24:59.614574: Epoch time: 49.01 s 
2024-05-13 15:24:59.614614: Yayy! New best EMA pseudo Dice: 0.8221 
2024-05-13 15:25:00.924780:  
2024-05-13 15:25:00.924901: Epoch 26 
2024-05-13 15:25:00.925001: Current learning rate: 0.00977 
2024-05-13 15:25:50.010676: train_loss -0.7357 
2024-05-13 15:25:50.010860: val_loss -0.7404 
2024-05-13 15:25:50.010929: Pseudo dice [0.8634] 
2024-05-13 15:25:50.010988: Epoch time: 49.09 s 
2024-05-13 15:25:50.011033: Yayy! New best EMA pseudo Dice: 0.8262 
2024-05-13 15:25:51.344851:  
2024-05-13 15:25:51.345070: Epoch 27 
2024-05-13 15:25:51.345311: Current learning rate: 0.00976 
2024-05-13 15:26:40.439354: train_loss -0.7375 
2024-05-13 15:26:40.439520: val_loss -0.7061 
2024-05-13 15:26:40.439607: Pseudo dice [0.8457] 
2024-05-13 15:26:40.439667: Epoch time: 49.1 s 
2024-05-13 15:26:40.439711: Yayy! New best EMA pseudo Dice: 0.8282 
2024-05-13 15:26:41.768898:  
2024-05-13 15:26:41.769000: Epoch 28 
2024-05-13 15:26:41.769113: Current learning rate: 0.00975 
2024-05-13 15:27:30.966907: train_loss -0.7386 
2024-05-13 15:27:30.967156: val_loss -0.73 
2024-05-13 15:27:30.967222: Pseudo dice [0.871] 
2024-05-13 15:27:30.967293: Epoch time: 49.2 s 
2024-05-13 15:27:30.967340: Yayy! New best EMA pseudo Dice: 0.8324 
2024-05-13 15:27:32.323101:  
2024-05-13 15:27:32.323210: Epoch 29 
2024-05-13 15:27:32.323295: Current learning rate: 0.00974 
2024-05-13 15:28:21.318735: train_loss -0.7242 
2024-05-13 15:28:21.318917: val_loss -0.7584 
2024-05-13 15:28:21.318980: Pseudo dice [0.8772] 
2024-05-13 15:28:21.319042: Epoch time: 49.0 s 
2024-05-13 15:28:21.319088: Yayy! New best EMA pseudo Dice: 0.8369 
2024-05-13 15:28:22.639472:  
2024-05-13 15:28:22.639578: Epoch 30 
2024-05-13 15:28:22.639659: Current learning rate: 0.00973 
2024-05-13 15:29:11.690750: train_loss -0.7467 
2024-05-13 15:29:11.690923: val_loss -0.7298 
2024-05-13 15:29:11.690987: Pseudo dice [0.8683] 
2024-05-13 15:29:11.691044: Epoch time: 49.05 s 
2024-05-13 15:29:11.691089: Yayy! New best EMA pseudo Dice: 0.8401 
2024-05-13 15:29:13.029186:  
2024-05-13 15:29:13.029311: Epoch 31 
2024-05-13 15:29:13.029396: Current learning rate: 0.00972 
2024-05-13 15:30:02.111462: train_loss -0.7351 
2024-05-13 15:30:02.111733: val_loss -0.7501 
2024-05-13 15:30:02.111814: Pseudo dice [0.8728] 
2024-05-13 15:30:02.111877: Epoch time: 49.08 s 
2024-05-13 15:30:02.111924: Yayy! New best EMA pseudo Dice: 0.8433 
2024-05-13 15:30:03.446742:  
2024-05-13 15:30:03.446845: Epoch 32 
2024-05-13 15:30:03.446941: Current learning rate: 0.00971 
2024-05-13 15:30:52.496649: train_loss -0.7379 
2024-05-13 15:30:52.496812: val_loss -0.7532 
2024-05-13 15:30:52.497039: Pseudo dice [0.8723] 
2024-05-13 15:30:52.497098: Epoch time: 49.05 s 
2024-05-13 15:30:52.497143: Yayy! New best EMA pseudo Dice: 0.8462 
2024-05-13 15:30:53.844130:  
2024-05-13 15:30:53.844367: Epoch 33 
2024-05-13 15:30:53.844452: Current learning rate: 0.0097 
2024-05-13 15:31:42.856262: train_loss -0.747 
2024-05-13 15:31:42.856437: val_loss -0.7489 
2024-05-13 15:31:42.856518: Pseudo dice [0.8757] 
2024-05-13 15:31:42.856575: Epoch time: 49.01 s 
2024-05-13 15:31:42.856633: Yayy! New best EMA pseudo Dice: 0.8492 
2024-05-13 15:31:44.178216:  
2024-05-13 15:31:44.178337: Epoch 34 
2024-05-13 15:31:44.178434: Current learning rate: 0.00969 
2024-05-13 15:32:33.162317: train_loss -0.7515 
2024-05-13 15:32:33.162503: val_loss -0.7379 
2024-05-13 15:32:33.162561: Pseudo dice [0.8665] 
2024-05-13 15:32:33.162615: Epoch time: 48.98 s 
2024-05-13 15:32:33.162659: Yayy! New best EMA pseudo Dice: 0.8509 
2024-05-13 15:32:34.851873:  
2024-05-13 15:32:34.852148: Epoch 35 
2024-05-13 15:32:34.852316: Current learning rate: 0.00968 
2024-05-13 15:33:23.950462: train_loss -0.7446 
2024-05-13 15:33:23.950638: val_loss -0.733 
2024-05-13 15:33:23.950699: Pseudo dice [0.8635] 
2024-05-13 15:33:23.950756: Epoch time: 49.1 s 
2024-05-13 15:33:23.950800: Yayy! New best EMA pseudo Dice: 0.8522 
2024-05-13 15:33:25.275835:  
2024-05-13 15:33:25.276040: Epoch 36 
2024-05-13 15:33:25.276143: Current learning rate: 0.00968 
2024-05-13 15:34:14.315531: train_loss -0.7418 
2024-05-13 15:34:14.316219: val_loss -0.7549 
2024-05-13 15:34:14.316289: Pseudo dice [0.8757] 
2024-05-13 15:34:14.316344: Epoch time: 49.04 s 
2024-05-13 15:34:14.316389: Yayy! New best EMA pseudo Dice: 0.8545 
2024-05-13 15:34:15.654514:  
2024-05-13 15:34:15.654621: Epoch 37 
2024-05-13 15:34:15.654701: Current learning rate: 0.00967 
2024-05-13 15:35:04.705302: train_loss -0.7627 
2024-05-13 15:35:04.705501: val_loss -0.7725 
2024-05-13 15:35:04.705565: Pseudo dice [0.8843] 
2024-05-13 15:35:04.705625: Epoch time: 49.05 s 
2024-05-13 15:35:04.705670: Yayy! New best EMA pseudo Dice: 0.8575 
2024-05-13 15:35:06.067890:  
2024-05-13 15:35:06.068157: Epoch 38 
2024-05-13 15:35:06.068262: Current learning rate: 0.00966 
2024-05-13 15:35:55.072444: train_loss -0.763 
2024-05-13 15:35:55.072603: val_loss -0.7425 
2024-05-13 15:35:55.072676: Pseudo dice [0.8722] 
2024-05-13 15:35:55.072731: Epoch time: 49.01 s 
2024-05-13 15:35:55.072775: Yayy! New best EMA pseudo Dice: 0.859 
2024-05-13 15:35:56.431682:  
2024-05-13 15:35:56.431785: Epoch 39 
2024-05-13 15:35:56.431881: Current learning rate: 0.00965 
2024-05-13 15:36:45.465033: train_loss -0.7546 
2024-05-13 15:36:45.465754: val_loss -0.7482 
2024-05-13 15:36:45.465820: Pseudo dice [0.8754] 
2024-05-13 15:36:45.465871: Epoch time: 49.03 s 
2024-05-13 15:36:45.465910: Yayy! New best EMA pseudo Dice: 0.8606 
2024-05-13 15:36:46.835014:  
2024-05-13 15:36:46.835122: Epoch 40 
2024-05-13 15:36:46.835204: Current learning rate: 0.00964 
2024-05-13 15:37:35.881542: train_loss -0.7527 
2024-05-13 15:37:35.881748: val_loss -0.755 
2024-05-13 15:37:35.881824: Pseudo dice [0.8705] 
2024-05-13 15:37:35.881901: Epoch time: 49.05 s 
2024-05-13 15:37:35.881962: Yayy! New best EMA pseudo Dice: 0.8616 
2024-05-13 15:37:37.245984:  
2024-05-13 15:37:37.246101: Epoch 41 
2024-05-13 15:37:37.246200: Current learning rate: 0.00963 
2024-05-13 15:38:26.272512: train_loss -0.7593 
2024-05-13 15:38:26.272695: val_loss -0.7553 
2024-05-13 15:38:26.272756: Pseudo dice [0.8769] 
2024-05-13 15:38:26.272814: Epoch time: 49.03 s 
2024-05-13 15:38:26.272861: Yayy! New best EMA pseudo Dice: 0.8631 
2024-05-13 15:38:27.570765:  
2024-05-13 15:38:27.570871: Epoch 42 
2024-05-13 15:38:27.570953: Current learning rate: 0.00962 
2024-05-13 15:39:16.616252: train_loss -0.7681 
2024-05-13 15:39:16.616908: val_loss -0.7677 
2024-05-13 15:39:16.616964: Pseudo dice [0.876] 
2024-05-13 15:39:16.617015: Epoch time: 49.05 s 
2024-05-13 15:39:16.617053: Yayy! New best EMA pseudo Dice: 0.8644 
2024-05-13 15:39:17.905032:  
2024-05-13 15:39:17.905136: Epoch 43 
2024-05-13 15:39:17.905232: Current learning rate: 0.00961 
2024-05-13 15:40:06.943171: train_loss -0.7614 
2024-05-13 15:40:06.943344: val_loss -0.7715 
2024-05-13 15:40:06.943404: Pseudo dice [0.8891] 
2024-05-13 15:40:06.943464: Epoch time: 49.04 s 
2024-05-13 15:40:06.943508: Yayy! New best EMA pseudo Dice: 0.8669 
2024-05-13 15:40:08.237352:  
2024-05-13 15:40:08.237603: Epoch 44 
2024-05-13 15:40:08.237706: Current learning rate: 0.0096 
2024-05-13 15:40:57.241456: train_loss -0.7728 
2024-05-13 15:40:57.241763: val_loss -0.7758 
2024-05-13 15:40:57.241825: Pseudo dice [0.8791] 
2024-05-13 15:40:57.241900: Epoch time: 49.0 s 
2024-05-13 15:40:57.241940: Yayy! New best EMA pseudo Dice: 0.8681 
2024-05-13 15:40:58.994729:  
2024-05-13 15:40:58.994854: Epoch 45 
2024-05-13 15:40:58.994940: Current learning rate: 0.00959 
2024-05-13 15:41:47.996409: train_loss -0.7714 
2024-05-13 15:41:47.996589: val_loss -0.7679 
2024-05-13 15:41:47.996649: Pseudo dice [0.8797] 
2024-05-13 15:41:47.996723: Epoch time: 49.0 s 
2024-05-13 15:41:47.996770: Yayy! New best EMA pseudo Dice: 0.8693 
2024-05-13 15:41:49.344062:  
2024-05-13 15:41:49.344443: Epoch 46 
2024-05-13 15:41:49.344530: Current learning rate: 0.00959 
2024-05-13 15:42:38.382573: train_loss -0.7716 
2024-05-13 15:42:38.383274: val_loss -0.7802 
2024-05-13 15:42:38.383355: Pseudo dice [0.8813] 
2024-05-13 15:42:38.383413: Epoch time: 49.04 s 
2024-05-13 15:42:38.383454: Yayy! New best EMA pseudo Dice: 0.8705 
2024-05-13 15:42:39.664737:  
2024-05-13 15:42:39.664980: Epoch 47 
2024-05-13 15:42:39.665081: Current learning rate: 0.00958 
2024-05-13 15:43:28.654956: train_loss -0.7698 
2024-05-13 15:43:28.655141: val_loss -0.7812 
2024-05-13 15:43:28.655204: Pseudo dice [0.8829] 
2024-05-13 15:43:28.655262: Epoch time: 48.99 s 
2024-05-13 15:43:28.655307: Yayy! New best EMA pseudo Dice: 0.8717 
2024-05-13 15:43:29.928871:  
2024-05-13 15:43:29.928972: Epoch 48 
2024-05-13 15:43:29.929084: Current learning rate: 0.00957 
2024-05-13 15:44:18.983748: train_loss -0.7736 
2024-05-13 15:44:18.983920: val_loss -0.7691 
2024-05-13 15:44:18.983979: Pseudo dice [0.8834] 
2024-05-13 15:44:18.984035: Epoch time: 49.06 s 
2024-05-13 15:44:18.984080: Yayy! New best EMA pseudo Dice: 0.8729 
2024-05-13 15:44:20.305828:  
2024-05-13 15:44:20.305938: Epoch 49 
2024-05-13 15:44:20.306021: Current learning rate: 0.00956 
2024-05-13 15:45:09.319147: train_loss -0.7676 
2024-05-13 15:45:09.319868: val_loss -0.8003 
2024-05-13 15:45:09.319927: Pseudo dice [0.895] 
2024-05-13 15:45:09.319977: Epoch time: 49.01 s 
2024-05-13 15:45:09.540086: Yayy! New best EMA pseudo Dice: 0.8751 
2024-05-13 15:45:10.807535:  
2024-05-13 15:45:10.807750: Epoch 50 
2024-05-13 15:45:10.807842: Current learning rate: 0.00955 
2024-05-13 15:45:59.846547: train_loss -0.7731 
2024-05-13 15:45:59.846721: val_loss -0.7691 
2024-05-13 15:45:59.846781: Pseudo dice [0.8779] 
2024-05-13 15:45:59.846839: Epoch time: 49.04 s 
2024-05-13 15:45:59.846884: Yayy! New best EMA pseudo Dice: 0.8754 
2024-05-13 15:46:01.210570:  
2024-05-13 15:46:01.210675: Epoch 51 
2024-05-13 15:46:01.210754: Current learning rate: 0.00954 
2024-05-13 15:46:50.236129: train_loss -0.7758 
2024-05-13 15:46:50.236338: val_loss -0.7808 
2024-05-13 15:46:50.236423: Pseudo dice [0.8909] 
2024-05-13 15:46:50.236513: Epoch time: 49.03 s 
2024-05-13 15:46:50.236573: Yayy! New best EMA pseudo Dice: 0.8769 
2024-05-13 15:46:51.556906:  
2024-05-13 15:46:51.557012: Epoch 52 
2024-05-13 15:46:51.557109: Current learning rate: 0.00953 
2024-05-13 15:47:40.564739: train_loss -0.7648 
2024-05-13 15:47:40.564977: val_loss -0.7727 
2024-05-13 15:47:40.565046: Pseudo dice [0.8848] 
2024-05-13 15:47:40.565124: Epoch time: 49.01 s 
2024-05-13 15:47:40.565173: Yayy! New best EMA pseudo Dice: 0.8777 
2024-05-13 15:47:41.904547:  
2024-05-13 15:47:41.904747: Epoch 53 
2024-05-13 15:47:41.904848: Current learning rate: 0.00952 
2024-05-13 15:48:30.950829: train_loss -0.7704 
2024-05-13 15:48:30.950986: val_loss -0.7797 
2024-05-13 15:48:30.951044: Pseudo dice [0.8835] 
2024-05-13 15:48:30.951104: Epoch time: 49.05 s 
2024-05-13 15:48:30.951148: Yayy! New best EMA pseudo Dice: 0.8783 
2024-05-13 15:48:32.245857:  
2024-05-13 15:48:32.245958: Epoch 54 
2024-05-13 15:48:32.246054: Current learning rate: 0.00951 
2024-05-13 15:49:21.217650: train_loss -0.7759 
2024-05-13 15:49:21.217825: val_loss -0.7774 
2024-05-13 15:49:21.217885: Pseudo dice [0.887] 
2024-05-13 15:49:21.217941: Epoch time: 48.97 s 
2024-05-13 15:49:21.218001: Yayy! New best EMA pseudo Dice: 0.8792 
2024-05-13 15:49:22.999923:  
2024-05-13 15:49:23.000049: Epoch 55 
2024-05-13 15:49:23.000133: Current learning rate: 0.0095 
2024-05-13 15:50:12.158993: train_loss -0.7809 
2024-05-13 15:50:12.159172: val_loss -0.7799 
2024-05-13 15:50:12.159251: Pseudo dice [0.8838] 
2024-05-13 15:50:12.159312: Epoch time: 49.16 s 
2024-05-13 15:50:12.159358: Yayy! New best EMA pseudo Dice: 0.8796 
2024-05-13 15:50:13.475729:  
2024-05-13 15:50:13.475843: Epoch 56 
2024-05-13 15:50:13.475925: Current learning rate: 0.00949 
2024-05-13 15:51:02.523566: train_loss -0.7804 
2024-05-13 15:51:02.523729: val_loss -0.7777 
2024-05-13 15:51:02.523787: Pseudo dice [0.8879] 
2024-05-13 15:51:02.523860: Epoch time: 49.05 s 
2024-05-13 15:51:02.523905: Yayy! New best EMA pseudo Dice: 0.8805 
2024-05-13 15:51:03.911350:  
2024-05-13 15:51:03.911588: Epoch 57 
2024-05-13 15:51:03.911679: Current learning rate: 0.00949 
2024-05-13 15:51:52.972596: train_loss -0.774 
2024-05-13 15:51:52.972839: val_loss -0.7757 
2024-05-13 15:51:52.972936: Pseudo dice [0.8819] 
2024-05-13 15:51:52.973027: Epoch time: 49.06 s 
2024-05-13 15:51:52.973099: Yayy! New best EMA pseudo Dice: 0.8806 
2024-05-13 15:51:54.282515:  
2024-05-13 15:51:54.282853: Epoch 58 
2024-05-13 15:51:54.282943: Current learning rate: 0.00948 
2024-05-13 15:52:43.321964: train_loss -0.7616 
2024-05-13 15:52:43.322695: val_loss -0.7658 
2024-05-13 15:52:43.322807: Pseudo dice [0.88] 
2024-05-13 15:52:43.322884: Epoch time: 49.04 s 
2024-05-13 15:52:44.362822:  
2024-05-13 15:52:44.362930: Epoch 59 
2024-05-13 15:52:44.363013: Current learning rate: 0.00947 
2024-05-13 15:53:33.438316: train_loss -0.776 
2024-05-13 15:53:33.438493: val_loss -0.7948 
2024-05-13 15:53:33.438553: Pseudo dice [0.8969] 
2024-05-13 15:53:33.438608: Epoch time: 49.08 s 
2024-05-13 15:53:33.438651: Yayy! New best EMA pseudo Dice: 0.8822 
2024-05-13 15:53:34.762573:  
2024-05-13 15:53:34.762678: Epoch 60 
2024-05-13 15:53:34.762759: Current learning rate: 0.00946 
2024-05-13 15:54:23.771020: train_loss -0.7775 
2024-05-13 15:54:23.771190: val_loss -0.778 
2024-05-13 15:54:23.771250: Pseudo dice [0.8755] 
2024-05-13 15:54:23.771309: Epoch time: 49.01 s 
2024-05-13 15:54:24.787796:  
2024-05-13 15:54:24.787902: Epoch 61 
2024-05-13 15:54:24.787987: Current learning rate: 0.00945 
2024-05-13 15:55:13.814750: train_loss -0.7874 
2024-05-13 15:55:13.815419: val_loss -0.7941 
2024-05-13 15:55:13.815479: Pseudo dice [0.8856] 
2024-05-13 15:55:13.815531: Epoch time: 49.03 s 
2024-05-13 15:55:14.797653:  
2024-05-13 15:55:14.797761: Epoch 62 
2024-05-13 15:55:14.797856: Current learning rate: 0.00944 
2024-05-13 15:56:03.761995: train_loss -0.7692 
2024-05-13 15:56:03.762172: val_loss -0.7921 
2024-05-13 15:56:03.762236: Pseudo dice [0.8947] 
2024-05-13 15:56:03.762303: Epoch time: 48.97 s 
2024-05-13 15:56:03.762374: Yayy! New best EMA pseudo Dice: 0.8832 
2024-05-13 15:56:05.066559:  
2024-05-13 15:56:05.066669: Epoch 63 
2024-05-13 15:56:05.066755: Current learning rate: 0.00943 
2024-05-13 15:56:54.021804: train_loss -0.7892 
2024-05-13 15:56:54.021984: val_loss -0.783 
2024-05-13 15:56:54.022048: Pseudo dice [0.8875] 
2024-05-13 15:56:54.022126: Epoch time: 48.96 s 
2024-05-13 15:56:54.022177: Yayy! New best EMA pseudo Dice: 0.8836 
2024-05-13 15:56:55.357405:  
2024-05-13 15:56:55.357514: Epoch 64 
2024-05-13 15:56:55.357599: Current learning rate: 0.00942 
2024-05-13 15:57:44.366501: train_loss -0.7765 
2024-05-13 15:57:44.367160: val_loss -0.7806 
2024-05-13 15:57:44.367219: Pseudo dice [0.8904] 
2024-05-13 15:57:44.367269: Epoch time: 49.01 s 
2024-05-13 15:57:44.367307: Yayy! New best EMA pseudo Dice: 0.8843 
2024-05-13 15:57:45.692253:  
2024-05-13 15:57:45.692374: Epoch 65 
2024-05-13 15:57:45.692461: Current learning rate: 0.00941 
2024-05-13 15:58:34.626119: train_loss -0.7887 
2024-05-13 15:58:34.626318: val_loss -0.8005 
2024-05-13 15:58:34.626384: Pseudo dice [0.894] 
2024-05-13 15:58:34.626442: Epoch time: 48.93 s 
2024-05-13 15:58:34.626488: Yayy! New best EMA pseudo Dice: 0.8853 
2024-05-13 15:58:36.492615:  
2024-05-13 15:58:36.492740: Epoch 66 
2024-05-13 15:58:36.492839: Current learning rate: 0.0094 
2024-05-13 15:59:25.451946: train_loss -0.7967 
2024-05-13 15:59:25.452128: val_loss -0.7892 
2024-05-13 15:59:25.452205: Pseudo dice [0.8908] 
2024-05-13 15:59:25.452263: Epoch time: 48.96 s 
2024-05-13 15:59:25.452309: Yayy! New best EMA pseudo Dice: 0.8858 
2024-05-13 15:59:26.790020:  
2024-05-13 15:59:26.790246: Epoch 67 
2024-05-13 15:59:26.790648: Current learning rate: 0.00939 
2024-05-13 16:00:15.751434: train_loss -0.7852 
2024-05-13 16:00:15.751625: val_loss -0.7886 
2024-05-13 16:00:15.751730: Pseudo dice [0.8918] 
2024-05-13 16:00:15.751814: Epoch time: 48.96 s 
2024-05-13 16:00:15.751880: Yayy! New best EMA pseudo Dice: 0.8864 
2024-05-13 16:00:17.211289:  
2024-05-13 16:00:17.211509: Epoch 68 
2024-05-13 16:00:17.211619: Current learning rate: 0.00939 
2024-05-13 16:01:06.282981: train_loss -0.7923 
2024-05-13 16:01:06.283654: val_loss -0.7865 
2024-05-13 16:01:06.283714: Pseudo dice [0.8897] 
2024-05-13 16:01:06.283764: Epoch time: 49.07 s 
2024-05-13 16:01:06.283803: Yayy! New best EMA pseudo Dice: 0.8868 
2024-05-13 16:01:07.638977:  
2024-05-13 16:01:07.639092: Epoch 69 
2024-05-13 16:01:07.639179: Current learning rate: 0.00938 
2024-05-13 16:01:56.667604: train_loss -0.7886 
2024-05-13 16:01:56.667776: val_loss -0.7882 
2024-05-13 16:01:56.667837: Pseudo dice [0.8963] 
2024-05-13 16:01:56.667910: Epoch time: 49.03 s 
2024-05-13 16:01:56.667956: Yayy! New best EMA pseudo Dice: 0.8877 
2024-05-13 16:01:58.091961:  
2024-05-13 16:01:58.092168: Epoch 70 
2024-05-13 16:01:58.092299: Current learning rate: 0.00937 
2024-05-13 16:02:47.046527: train_loss -0.789 
2024-05-13 16:02:47.046718: val_loss -0.7923 
2024-05-13 16:02:47.046777: Pseudo dice [0.894] 
2024-05-13 16:02:47.046836: Epoch time: 48.96 s 
2024-05-13 16:02:47.046880: Yayy! New best EMA pseudo Dice: 0.8883 
2024-05-13 16:02:48.407214:  
2024-05-13 16:02:48.407327: Epoch 71 
2024-05-13 16:02:48.407410: Current learning rate: 0.00936 
2024-05-13 16:03:37.449090: train_loss -0.7914 
2024-05-13 16:03:37.449789: val_loss -0.7862 
2024-05-13 16:03:37.449871: Pseudo dice [0.8899] 
2024-05-13 16:03:37.449943: Epoch time: 49.04 s 
2024-05-13 16:03:37.450004: Yayy! New best EMA pseudo Dice: 0.8885 
2024-05-13 16:03:38.805656:  
2024-05-13 16:03:38.805911: Epoch 72 
2024-05-13 16:03:38.806000: Current learning rate: 0.00935 
2024-05-13 16:04:27.788819: train_loss -0.787 
2024-05-13 16:04:27.788983: val_loss -0.797 
2024-05-13 16:04:27.789056: Pseudo dice [0.8933] 
2024-05-13 16:04:27.789114: Epoch time: 48.98 s 
2024-05-13 16:04:27.789158: Yayy! New best EMA pseudo Dice: 0.889 
2024-05-13 16:04:29.164925:  
2024-05-13 16:04:29.165170: Epoch 73 
2024-05-13 16:04:29.165261: Current learning rate: 0.00934 
2024-05-13 16:05:18.167797: train_loss -0.7935 
2024-05-13 16:05:18.167962: val_loss -0.8055 
2024-05-13 16:05:18.168055: Pseudo dice [0.8979] 
2024-05-13 16:05:18.168116: Epoch time: 49.0 s 
2024-05-13 16:05:18.168162: Yayy! New best EMA pseudo Dice: 0.8899 
2024-05-13 16:05:19.555115:  
2024-05-13 16:05:19.555311: Epoch 74 
2024-05-13 16:05:19.555399: Current learning rate: 0.00933 
2024-05-13 16:06:08.568400: train_loss -0.7938 
2024-05-13 16:06:08.569091: val_loss -0.7813 
2024-05-13 16:06:08.569155: Pseudo dice [0.8854] 
2024-05-13 16:06:08.569206: Epoch time: 49.01 s 
2024-05-13 16:06:09.573541:  
2024-05-13 16:06:09.573749: Epoch 75 
2024-05-13 16:06:09.573836: Current learning rate: 0.00932 
2024-05-13 16:06:58.565306: train_loss -0.7897 
2024-05-13 16:06:58.565523: val_loss -0.7917 
2024-05-13 16:06:58.565615: Pseudo dice [0.8938] 
2024-05-13 16:06:58.565673: Epoch time: 48.99 s 
2024-05-13 16:07:00.064146:  
2024-05-13 16:07:00.064467: Epoch 76 
2024-05-13 16:07:00.064655: Current learning rate: 0.00931 
2024-05-13 16:07:49.086019: train_loss -0.7932 
2024-05-13 16:07:49.086175: val_loss -0.7958 
2024-05-13 16:07:49.086233: Pseudo dice [0.8892] 
2024-05-13 16:07:49.086287: Epoch time: 49.02 s 
2024-05-13 16:07:50.095189:  
2024-05-13 16:07:50.095314: Epoch 77 
2024-05-13 16:07:50.095394: Current learning rate: 0.0093 
2024-05-13 16:08:39.158612: train_loss -0.7974 
2024-05-13 16:08:39.158801: val_loss -0.8026 
2024-05-13 16:08:39.158866: Pseudo dice [0.8938] 
2024-05-13 16:08:39.158926: Epoch time: 49.06 s 
2024-05-13 16:08:39.158974: Yayy! New best EMA pseudo Dice: 0.8902 
2024-05-13 16:08:40.552400:  
2024-05-13 16:08:40.552514: Epoch 78 
2024-05-13 16:08:40.552612: Current learning rate: 0.0093 
2024-05-13 16:09:29.559621: train_loss -0.7922 
2024-05-13 16:09:29.559787: val_loss -0.7536 
2024-05-13 16:09:29.559843: Pseudo dice [0.8816] 
2024-05-13 16:09:29.559898: Epoch time: 49.01 s 
2024-05-13 16:09:30.621363:  
2024-05-13 16:09:30.621574: Epoch 79 
2024-05-13 16:09:30.621659: Current learning rate: 0.00929 
2024-05-13 16:10:19.716076: train_loss -0.7883 
2024-05-13 16:10:19.716721: val_loss -0.8171 
2024-05-13 16:10:19.716777: Pseudo dice [0.9049] 
2024-05-13 16:10:19.716827: Epoch time: 49.1 s 
2024-05-13 16:10:19.716865: Yayy! New best EMA pseudo Dice: 0.8909 
2024-05-13 16:10:21.131259:  
2024-05-13 16:10:21.131370: Epoch 80 
2024-05-13 16:10:21.131468: Current learning rate: 0.00928 
2024-05-13 16:11:10.229291: train_loss -0.8062 
2024-05-13 16:11:10.229574: val_loss -0.7906 
2024-05-13 16:11:10.229638: Pseudo dice [0.8887] 
2024-05-13 16:11:10.229703: Epoch time: 49.1 s 
2024-05-13 16:11:11.335290:  
2024-05-13 16:11:11.335402: Epoch 81 
2024-05-13 16:11:11.335487: Current learning rate: 0.00927 
2024-05-13 16:12:00.421441: train_loss -0.7796 
2024-05-13 16:12:00.421621: val_loss -0.7912 
2024-05-13 16:12:00.421679: Pseudo dice [0.8946] 
2024-05-13 16:12:00.421735: Epoch time: 49.09 s 
2024-05-13 16:12:00.421783: Yayy! New best EMA pseudo Dice: 0.8911 
2024-05-13 16:12:01.807733:  
2024-05-13 16:12:01.807865: Epoch 82 
2024-05-13 16:12:01.807963: Current learning rate: 0.00926 
2024-05-13 16:12:50.834392: train_loss -0.7944 
2024-05-13 16:12:50.834562: val_loss -0.8108 
2024-05-13 16:12:50.834622: Pseudo dice [0.9034] 
2024-05-13 16:12:50.834679: Epoch time: 49.03 s 
2024-05-13 16:12:50.834729: Yayy! New best EMA pseudo Dice: 0.8923 
2024-05-13 16:12:52.130219:  
2024-05-13 16:12:52.130332: Epoch 83 
2024-05-13 16:12:52.130430: Current learning rate: 0.00925 
2024-05-13 16:13:41.266966: train_loss -0.7867 
2024-05-13 16:13:41.267666: val_loss -0.8058 
2024-05-13 16:13:41.267724: Pseudo dice [0.9017] 
2024-05-13 16:13:41.267773: Epoch time: 49.14 s 
2024-05-13 16:13:41.267817: Yayy! New best EMA pseudo Dice: 0.8932 
2024-05-13 16:13:42.568828:  
2024-05-13 16:13:42.568936: Epoch 84 
2024-05-13 16:13:42.569018: Current learning rate: 0.00924 
2024-05-13 16:14:31.594215: train_loss -0.8021 
2024-05-13 16:14:31.594424: val_loss -0.8045 
2024-05-13 16:14:31.594485: Pseudo dice [0.8936] 
2024-05-13 16:14:31.594545: Epoch time: 49.03 s 
2024-05-13 16:14:31.594591: Yayy! New best EMA pseudo Dice: 0.8933 
2024-05-13 16:14:32.881181:  
2024-05-13 16:14:32.881288: Epoch 85 
2024-05-13 16:14:32.881384: Current learning rate: 0.00923 
2024-05-13 16:15:21.903440: train_loss -0.789 
2024-05-13 16:15:21.903626: val_loss -0.8068 
2024-05-13 16:15:21.903686: Pseudo dice [0.9015] 
2024-05-13 16:15:21.903759: Epoch time: 49.02 s 
2024-05-13 16:15:21.903814: Yayy! New best EMA pseudo Dice: 0.8941 
2024-05-13 16:15:23.649732:  
2024-05-13 16:15:23.649964: Epoch 86 
2024-05-13 16:15:23.650049: Current learning rate: 0.00922 
2024-05-13 16:16:12.661083: train_loss -0.8023 
2024-05-13 16:16:12.661743: val_loss -0.7803 
2024-05-13 16:16:12.661797: Pseudo dice [0.8872] 
2024-05-13 16:16:12.661846: Epoch time: 49.01 s 
2024-05-13 16:16:13.640469:  
2024-05-13 16:16:13.640692: Epoch 87 
2024-05-13 16:16:13.640798: Current learning rate: 0.00921 
2024-05-13 16:17:02.707775: train_loss -0.8071 
2024-05-13 16:17:02.707941: val_loss -0.7972 
2024-05-13 16:17:02.708007: Pseudo dice [0.9021] 
2024-05-13 16:17:02.708083: Epoch time: 49.07 s 
2024-05-13 16:17:02.708133: Yayy! New best EMA pseudo Dice: 0.8943 
2024-05-13 16:17:04.015554:  
2024-05-13 16:17:04.015784: Epoch 88 
2024-05-13 16:17:04.015878: Current learning rate: 0.0092 
2024-05-13 16:17:53.125428: train_loss -0.7996 
2024-05-13 16:17:53.125600: val_loss -0.8138 
2024-05-13 16:17:53.125676: Pseudo dice [0.9] 
2024-05-13 16:17:53.125735: Epoch time: 49.11 s 
2024-05-13 16:17:53.125780: Yayy! New best EMA pseudo Dice: 0.8948 
2024-05-13 16:17:54.444621:  
2024-05-13 16:17:54.444741: Epoch 89 
2024-05-13 16:17:54.444836: Current learning rate: 0.0092 
2024-05-13 16:18:43.472820: train_loss -0.8074 
2024-05-13 16:18:43.472984: val_loss -0.8011 
2024-05-13 16:18:43.473043: Pseudo dice [0.9008] 
2024-05-13 16:18:43.473099: Epoch time: 49.03 s 
2024-05-13 16:18:43.473149: Yayy! New best EMA pseudo Dice: 0.8954 
2024-05-13 16:18:44.800574:  
2024-05-13 16:18:44.800693: Epoch 90 
2024-05-13 16:18:44.800802: Current learning rate: 0.00919 
2024-05-13 16:19:33.820380: train_loss -0.8054 
2024-05-13 16:19:33.820592: val_loss -0.773 
2024-05-13 16:19:33.820653: Pseudo dice [0.8896] 
2024-05-13 16:19:33.820721: Epoch time: 49.02 s 
2024-05-13 16:19:34.784196:  
2024-05-13 16:19:34.784309: Epoch 91 
2024-05-13 16:19:34.784392: Current learning rate: 0.00918 
2024-05-13 16:20:23.838719: train_loss -0.7938 
2024-05-13 16:20:23.839391: val_loss -0.8063 
2024-05-13 16:20:23.839453: Pseudo dice [0.8981] 
2024-05-13 16:20:23.839503: Epoch time: 49.06 s 
2024-05-13 16:20:24.795262:  
2024-05-13 16:20:24.795367: Epoch 92 
2024-05-13 16:20:24.795449: Current learning rate: 0.00917 
2024-05-13 16:21:13.815870: train_loss -0.7998 
2024-05-13 16:21:13.816023: val_loss -0.8183 
2024-05-13 16:21:13.816090: Pseudo dice [0.907] 
2024-05-13 16:21:13.816143: Epoch time: 49.02 s 
2024-05-13 16:21:13.816181: Yayy! New best EMA pseudo Dice: 0.8964 
2024-05-13 16:21:15.079352:  
2024-05-13 16:21:15.079463: Epoch 93 
2024-05-13 16:21:15.079548: Current learning rate: 0.00916 
2024-05-13 16:22:04.153261: train_loss -0.8043 
2024-05-13 16:22:04.153452: val_loss -0.819 
2024-05-13 16:22:04.153512: Pseudo dice [0.9006] 
2024-05-13 16:22:04.153571: Epoch time: 49.07 s 
2024-05-13 16:22:04.153617: Yayy! New best EMA pseudo Dice: 0.8968 
2024-05-13 16:22:05.488769:  
2024-05-13 16:22:05.488878: Epoch 94 
2024-05-13 16:22:05.488964: Current learning rate: 0.00915 
2024-05-13 16:22:54.602672: train_loss -0.8047 
2024-05-13 16:22:54.602957: val_loss -0.8144 
2024-05-13 16:22:54.603033: Pseudo dice [0.9072] 
2024-05-13 16:22:54.603097: Epoch time: 49.11 s 
2024-05-13 16:22:54.603148: Yayy! New best EMA pseudo Dice: 0.8978 
2024-05-13 16:22:55.923379:  
2024-05-13 16:22:55.923486: Epoch 95 
2024-05-13 16:22:55.923580: Current learning rate: 0.00914 
2024-05-13 16:23:44.964544: train_loss -0.7986 
2024-05-13 16:23:44.964725: val_loss -0.8027 
2024-05-13 16:23:44.964811: Pseudo dice [0.8976] 
2024-05-13 16:23:44.964873: Epoch time: 49.04 s 
2024-05-13 16:23:45.911769:  
2024-05-13 16:23:45.912038: Epoch 96 
2024-05-13 16:23:45.912126: Current learning rate: 0.00913 
2024-05-13 16:24:35.022933: train_loss -0.8065 
2024-05-13 16:24:35.023098: val_loss -0.8141 
2024-05-13 16:24:35.023160: Pseudo dice [0.9014] 
2024-05-13 16:24:35.023218: Epoch time: 49.11 s 
2024-05-13 16:24:35.023264: Yayy! New best EMA pseudo Dice: 0.8982 
2024-05-13 16:24:36.694579:  
2024-05-13 16:24:36.694700: Epoch 97 
2024-05-13 16:24:36.694784: Current learning rate: 0.00912 
2024-05-13 16:25:25.848656: train_loss -0.8085 
2024-05-13 16:25:25.849359: val_loss -0.8065 
2024-05-13 16:25:25.849429: Pseudo dice [0.9024] 
2024-05-13 16:25:25.849484: Epoch time: 49.15 s 
2024-05-13 16:25:25.849524: Yayy! New best EMA pseudo Dice: 0.8986 
2024-05-13 16:25:27.166063:  
2024-05-13 16:25:27.166195: Epoch 98 
2024-05-13 16:25:27.166278: Current learning rate: 0.00911 
2024-05-13 16:26:16.282776: train_loss -0.8109 
2024-05-13 16:26:16.282970: val_loss -0.8299 
2024-05-13 16:26:16.283036: Pseudo dice [0.9116] 
2024-05-13 16:26:16.283094: Epoch time: 49.12 s 
2024-05-13 16:26:16.283142: Yayy! New best EMA pseudo Dice: 0.8999 
2024-05-13 16:26:17.567875:  
2024-05-13 16:26:17.567998: Epoch 99 
2024-05-13 16:26:17.568166: Current learning rate: 0.0091 
2024-05-13 16:27:06.587309: train_loss -0.8144 
2024-05-13 16:27:06.587501: val_loss -0.827 
2024-05-13 16:27:06.587576: Pseudo dice [0.9083] 
2024-05-13 16:27:06.587633: Epoch time: 49.02 s 
2024-05-13 16:27:06.936437: Yayy! New best EMA pseudo Dice: 0.9007 
2024-05-13 16:27:08.285720:  
2024-05-13 16:27:08.285834: Epoch 100 
2024-05-13 16:27:08.285929: Current learning rate: 0.0091 
2024-05-13 16:27:57.393065: train_loss -0.815 
2024-05-13 16:27:57.393313: val_loss -0.8353 
2024-05-13 16:27:57.393418: Pseudo dice [0.9117] 
2024-05-13 16:27:57.393519: Epoch time: 49.11 s 
2024-05-13 16:27:57.393616: Yayy! New best EMA pseudo Dice: 0.9018 
2024-05-13 16:27:58.780133:  
2024-05-13 16:27:58.780245: Epoch 101 
2024-05-13 16:27:58.780341: Current learning rate: 0.00909 
2024-05-13 16:28:47.814062: train_loss -0.8162 
2024-05-13 16:28:47.814824: val_loss -0.8385 
2024-05-13 16:28:47.814973: Pseudo dice [0.9166] 
2024-05-13 16:28:47.815074: Epoch time: 49.03 s 
2024-05-13 16:28:47.815154: Yayy! New best EMA pseudo Dice: 0.9033 
2024-05-13 16:28:49.135220:  
2024-05-13 16:28:49.135334: Epoch 102 
2024-05-13 16:28:49.135418: Current learning rate: 0.00908 
2024-05-13 16:29:38.215246: train_loss -0.8092 
2024-05-13 16:29:38.215424: val_loss -0.8144 
2024-05-13 16:29:38.215490: Pseudo dice [0.9037] 
2024-05-13 16:29:38.215550: Epoch time: 49.08 s 
2024-05-13 16:29:38.215600: Yayy! New best EMA pseudo Dice: 0.9034 
2024-05-13 16:29:39.553065:  
2024-05-13 16:29:39.553176: Epoch 103 
2024-05-13 16:29:39.553259: Current learning rate: 0.00907 
2024-05-13 16:30:28.594995: train_loss -0.8195 
2024-05-13 16:30:28.595153: val_loss -0.8274 
2024-05-13 16:30:28.595213: Pseudo dice [0.9062] 
2024-05-13 16:30:28.595270: Epoch time: 49.04 s 
2024-05-13 16:30:28.595423: Yayy! New best EMA pseudo Dice: 0.9036 
2024-05-13 16:30:29.938666:  
2024-05-13 16:30:29.938776: Epoch 104 
2024-05-13 16:30:29.938860: Current learning rate: 0.00906 
2024-05-13 16:31:19.044604: train_loss -0.8054 
2024-05-13 16:31:19.045017: val_loss -0.8041 
2024-05-13 16:31:19.045089: Pseudo dice [0.9005] 
2024-05-13 16:31:19.045149: Epoch time: 49.11 s 
2024-05-13 16:31:20.006290:  
2024-05-13 16:31:20.006398: Epoch 105 
2024-05-13 16:31:20.006480: Current learning rate: 0.00905 
2024-05-13 16:32:09.116171: train_loss -0.8125 
2024-05-13 16:32:09.116359: val_loss -0.8097 
2024-05-13 16:32:09.116421: Pseudo dice [0.9021] 
2024-05-13 16:32:09.116480: Epoch time: 49.11 s 
2024-05-13 16:32:10.082415:  
2024-05-13 16:32:10.082522: Epoch 106 
2024-05-13 16:32:10.082605: Current learning rate: 0.00904 
2024-05-13 16:32:59.106488: train_loss -0.8172 
2024-05-13 16:32:59.106657: val_loss -0.8184 
2024-05-13 16:32:59.106716: Pseudo dice [0.9074] 
2024-05-13 16:32:59.106776: Epoch time: 49.02 s 
2024-05-13 16:33:00.082322:  
2024-05-13 16:33:00.082516: Epoch 107 
2024-05-13 16:33:00.082609: Current learning rate: 0.00903 
2024-05-13 16:33:49.160864: train_loss -0.8138 
2024-05-13 16:33:49.161039: val_loss -0.8278 
2024-05-13 16:33:49.161100: Pseudo dice [0.9119] 
2024-05-13 16:33:49.161163: Epoch time: 49.08 s 
2024-05-13 16:33:49.161211: Yayy! New best EMA pseudo Dice: 0.9045 
2024-05-13 16:33:50.879128:  
2024-05-13 16:33:50.879245: Epoch 108 
2024-05-13 16:33:50.879328: Current learning rate: 0.00902 
2024-05-13 16:34:39.937096: train_loss -0.8132 
2024-05-13 16:34:39.937261: val_loss -0.8237 
2024-05-13 16:34:39.937338: Pseudo dice [0.9071] 
2024-05-13 16:34:39.937397: Epoch time: 49.06 s 
2024-05-13 16:34:39.937443: Yayy! New best EMA pseudo Dice: 0.9047 
2024-05-13 16:34:41.261893:  
2024-05-13 16:34:41.262005: Epoch 109 
2024-05-13 16:34:41.262115: Current learning rate: 0.00901 
2024-05-13 16:35:30.304260: train_loss -0.8084 
2024-05-13 16:35:30.304501: val_loss -0.8054 
2024-05-13 16:35:30.304586: Pseudo dice [0.9023] 
2024-05-13 16:35:30.304646: Epoch time: 49.04 s 
2024-05-13 16:35:31.322457:  
2024-05-13 16:35:31.322578: Epoch 110 
2024-05-13 16:35:31.322670: Current learning rate: 0.009 
2024-05-13 16:36:20.341265: train_loss -0.8056 
2024-05-13 16:36:20.342076: val_loss -0.8152 
2024-05-13 16:36:20.342145: Pseudo dice [0.9021] 
2024-05-13 16:36:20.342198: Epoch time: 49.02 s 
2024-05-13 16:36:21.329121:  
2024-05-13 16:36:21.329359: Epoch 111 
2024-05-13 16:36:21.329448: Current learning rate: 0.009 
2024-05-13 16:37:10.424638: train_loss -0.8188 
2024-05-13 16:37:10.424817: val_loss -0.7835 
2024-05-13 16:37:10.424878: Pseudo dice [0.8898] 
2024-05-13 16:37:10.424950: Epoch time: 49.1 s 
2024-05-13 16:37:11.396166:  
2024-05-13 16:37:11.396284: Epoch 112 
2024-05-13 16:37:11.396366: Current learning rate: 0.00899 
2024-05-13 16:38:00.413779: train_loss -0.8158 
2024-05-13 16:38:00.413947: val_loss -0.8193 
2024-05-13 16:38:00.414006: Pseudo dice [0.9062] 
2024-05-13 16:38:00.414061: Epoch time: 49.02 s 
2024-05-13 16:38:01.387642:  
2024-05-13 16:38:01.387756: Epoch 113 
2024-05-13 16:38:01.387838: Current learning rate: 0.00898 
2024-05-13 16:38:50.487069: train_loss -0.7905 
2024-05-13 16:38:50.487808: val_loss -0.7796 
2024-05-13 16:38:50.487876: Pseudo dice [0.8896] 
2024-05-13 16:38:50.487939: Epoch time: 49.1 s 
2024-05-13 16:38:51.464148:  
2024-05-13 16:38:51.464256: Epoch 114 
2024-05-13 16:38:51.464352: Current learning rate: 0.00897 
2024-05-13 16:39:40.522549: train_loss -0.7878 
2024-05-13 16:39:40.522872: val_loss -0.783 
2024-05-13 16:39:40.522939: Pseudo dice [0.8881] 
2024-05-13 16:39:40.523004: Epoch time: 49.06 s 
2024-05-13 16:39:41.492970:  
2024-05-13 16:39:41.493167: Epoch 115 
2024-05-13 16:39:41.493256: Current learning rate: 0.00896 
2024-05-13 16:40:30.541171: train_loss -0.8016 
2024-05-13 16:40:30.541353: val_loss -0.8108 
2024-05-13 16:40:30.541414: Pseudo dice [0.9036] 
2024-05-13 16:40:30.541471: Epoch time: 49.05 s 
2024-05-13 16:40:31.557793:  
2024-05-13 16:40:31.558033: Epoch 116 
2024-05-13 16:40:31.558122: Current learning rate: 0.00895 
2024-05-13 16:41:20.584798: train_loss -0.7934 
2024-05-13 16:41:20.585042: val_loss -0.8113 
2024-05-13 16:41:20.585114: Pseudo dice [0.898] 
2024-05-13 16:41:20.585170: Epoch time: 49.03 s 
2024-05-13 16:41:21.572492:  
2024-05-13 16:41:21.572741: Epoch 117 
2024-05-13 16:41:21.572847: Current learning rate: 0.00894 
2024-05-13 16:42:10.590682: train_loss -0.8021 
2024-05-13 16:42:10.590860: val_loss -0.7961 
2024-05-13 16:42:10.590921: Pseudo dice [0.894] 
2024-05-13 16:42:10.590977: Epoch time: 49.02 s 
2024-05-13 16:42:12.036530:  
2024-05-13 16:42:12.036684: Epoch 118 
2024-05-13 16:42:12.036779: Current learning rate: 0.00893 
2024-05-13 16:43:01.092875: train_loss -0.8129 
2024-05-13 16:43:01.093045: val_loss -0.8069 
2024-05-13 16:43:01.093105: Pseudo dice [0.9028] 
2024-05-13 16:43:01.093163: Epoch time: 49.06 s 
2024-05-13 16:43:02.111680:  
2024-05-13 16:43:02.112042: Epoch 119 
2024-05-13 16:43:02.112178: Current learning rate: 0.00892 
2024-05-13 16:43:51.235932: train_loss -0.8074 
2024-05-13 16:43:51.236114: val_loss -0.8054 
2024-05-13 16:43:51.236212: Pseudo dice [0.9004] 
2024-05-13 16:43:51.236284: Epoch time: 49.13 s 
2024-05-13 16:43:52.243784:  
2024-05-13 16:43:52.244138: Epoch 120 
2024-05-13 16:43:52.244228: Current learning rate: 0.00891 
2024-05-13 16:44:41.271075: train_loss -0.8232 
2024-05-13 16:44:41.271774: val_loss -0.8166 
2024-05-13 16:44:41.271848: Pseudo dice [0.9058] 
2024-05-13 16:44:41.271906: Epoch time: 49.03 s 
2024-05-13 16:44:42.286806:  
2024-05-13 16:44:42.286924: Epoch 121 
2024-05-13 16:44:42.287007: Current learning rate: 0.0089 
2024-05-13 16:45:31.379995: train_loss -0.8127 
2024-05-13 16:45:31.380186: val_loss -0.8241 
2024-05-13 16:45:31.380248: Pseudo dice [0.9052] 
2024-05-13 16:45:31.380304: Epoch time: 49.09 s 
2024-05-13 16:45:32.388140:  
2024-05-13 16:45:32.388253: Epoch 122 
2024-05-13 16:45:32.388333: Current learning rate: 0.00889 
2024-05-13 16:46:21.471557: train_loss -0.8164 
2024-05-13 16:46:21.471734: val_loss -0.8262 
2024-05-13 16:46:21.471794: Pseudo dice [0.9076] 
2024-05-13 16:46:21.471851: Epoch time: 49.08 s 
2024-05-13 16:46:22.463524:  
2024-05-13 16:46:22.463669: Epoch 123 
2024-05-13 16:46:22.463877: Current learning rate: 0.00889 
2024-05-13 16:47:11.550557: train_loss -0.8153 
2024-05-13 16:47:11.550734: val_loss -0.8046 
2024-05-13 16:47:11.550793: Pseudo dice [0.896] 
2024-05-13 16:47:11.550854: Epoch time: 49.09 s 
2024-05-13 16:47:12.540347:  
2024-05-13 16:47:12.540478: Epoch 124 
2024-05-13 16:47:12.540562: Current learning rate: 0.00888 
2024-05-13 16:48:01.595907: train_loss -0.8167 
2024-05-13 16:48:01.596087: val_loss -0.8371 
2024-05-13 16:48:01.596146: Pseudo dice [0.9131] 
2024-05-13 16:48:01.596253: Epoch time: 49.06 s 
2024-05-13 16:48:02.585285:  
2024-05-13 16:48:02.585524: Epoch 125 
2024-05-13 16:48:02.585624: Current learning rate: 0.00887 
2024-05-13 16:48:51.580031: train_loss -0.8146 
2024-05-13 16:48:51.580697: val_loss -0.8082 
2024-05-13 16:48:51.580757: Pseudo dice [0.898] 
2024-05-13 16:48:51.580808: Epoch time: 49.0 s 
2024-05-13 16:48:52.611974:  
2024-05-13 16:48:52.612085: Epoch 126 
2024-05-13 16:48:52.612169: Current learning rate: 0.00886 
2024-05-13 16:49:41.660365: train_loss -0.8099 
2024-05-13 16:49:41.660634: val_loss -0.8206 
2024-05-13 16:49:41.660699: Pseudo dice [0.9071] 
2024-05-13 16:49:41.660762: Epoch time: 49.05 s 
2024-05-13 16:49:42.663928:  
2024-05-13 16:49:42.664036: Epoch 127 
2024-05-13 16:49:42.664135: Current learning rate: 0.00885 
2024-05-13 16:50:31.715716: train_loss -0.8221 
2024-05-13 16:50:31.715882: val_loss -0.8105 
2024-05-13 16:50:31.715955: Pseudo dice [0.9037] 
2024-05-13 16:50:31.716011: Epoch time: 49.05 s 
2024-05-13 16:50:32.746729:  
2024-05-13 16:50:32.746961: Epoch 128 
2024-05-13 16:50:32.747047: Current learning rate: 0.00884 
2024-05-13 16:51:21.748742: train_loss -0.8234 
2024-05-13 16:51:21.749001: val_loss -0.8227 
2024-05-13 16:51:21.749068: Pseudo dice [0.9037] 
2024-05-13 16:51:21.749126: Epoch time: 49.0 s 
2024-05-13 16:51:23.150478:  
2024-05-13 16:51:23.150613: Epoch 129 
2024-05-13 16:51:23.150693: Current learning rate: 0.00883 
2024-05-13 16:52:12.174288: train_loss -0.8185 
2024-05-13 16:52:12.174488: val_loss -0.8194 
2024-05-13 16:52:12.174556: Pseudo dice [0.9017] 
2024-05-13 16:52:12.174617: Epoch time: 49.02 s 
2024-05-13 16:52:13.179331:  
2024-05-13 16:52:13.179463: Epoch 130 
2024-05-13 16:52:13.179548: Current learning rate: 0.00882 
2024-05-13 16:53:02.215753: train_loss -0.8224 
2024-05-13 16:53:02.215932: val_loss -0.8152 
2024-05-13 16:53:02.216009: Pseudo dice [0.905] 
2024-05-13 16:53:02.216069: Epoch time: 49.04 s 
2024-05-13 16:53:03.211035:  
2024-05-13 16:53:03.211297: Epoch 131 
2024-05-13 16:53:03.211387: Current learning rate: 0.00881 
2024-05-13 16:53:52.243215: train_loss -0.8212 
2024-05-13 16:53:52.243491: val_loss -0.8159 
2024-05-13 16:53:52.243561: Pseudo dice [0.9044] 
2024-05-13 16:53:52.243621: Epoch time: 49.03 s 
2024-05-13 16:53:53.249048:  
2024-05-13 16:53:53.249354: Epoch 132 
2024-05-13 16:53:53.249497: Current learning rate: 0.0088 
2024-05-13 16:54:42.298659: train_loss -0.8162 
2024-05-13 16:54:42.298833: val_loss -0.8206 
2024-05-13 16:54:42.298892: Pseudo dice [0.9049] 
2024-05-13 16:54:42.298950: Epoch time: 49.05 s 
2024-05-13 16:54:43.322785:  
2024-05-13 16:54:43.322905: Epoch 133 
2024-05-13 16:54:43.322989: Current learning rate: 0.00879 
2024-05-13 16:55:32.473449: train_loss -0.817 
2024-05-13 16:55:32.473770: val_loss -0.8234 
2024-05-13 16:55:32.473840: Pseudo dice [0.9061] 
2024-05-13 16:55:32.473916: Epoch time: 49.15 s 
2024-05-13 16:55:33.500625:  
2024-05-13 16:55:33.500739: Epoch 134 
2024-05-13 16:55:33.500821: Current learning rate: 0.00879 
2024-05-13 16:56:22.510662: train_loss -0.8074 
2024-05-13 16:56:22.511341: val_loss -0.8061 
2024-05-13 16:56:22.511406: Pseudo dice [0.8983] 
2024-05-13 16:56:22.511455: Epoch time: 49.01 s 
2024-05-13 16:56:23.522744:  
2024-05-13 16:56:23.522949: Epoch 135 
2024-05-13 16:56:23.523035: Current learning rate: 0.00878 
2024-05-13 16:57:12.617055: train_loss -0.8004 
2024-05-13 16:57:12.617227: val_loss -0.7908 
2024-05-13 16:57:12.617286: Pseudo dice [0.8881] 
2024-05-13 16:57:12.617343: Epoch time: 49.1 s 
2024-05-13 16:57:13.654056:  
2024-05-13 16:57:13.654182: Epoch 136 
2024-05-13 16:57:13.654268: Current learning rate: 0.00877 
2024-05-13 16:58:02.716259: train_loss -0.8089 
2024-05-13 16:58:02.716448: val_loss -0.8308 
2024-05-13 16:58:02.716507: Pseudo dice [0.9112] 
2024-05-13 16:58:02.716564: Epoch time: 49.06 s 
2024-05-13 16:58:03.788682:  
2024-05-13 16:58:03.788976: Epoch 137 
2024-05-13 16:58:03.789165: Current learning rate: 0.00876 
2024-05-13 16:58:52.868824: train_loss -0.8204 
2024-05-13 16:58:52.869000: val_loss -0.8164 
2024-05-13 16:58:52.869095: Pseudo dice [0.9092] 
2024-05-13 16:58:52.869164: Epoch time: 49.08 s 
2024-05-13 16:58:53.919524:  
2024-05-13 16:58:53.919630: Epoch 138 
2024-05-13 16:58:53.919714: Current learning rate: 0.00875 
2024-05-13 16:59:42.982929: train_loss -0.8291 
2024-05-13 16:59:42.983181: val_loss -0.8136 
2024-05-13 16:59:42.983266: Pseudo dice [0.8965] 
2024-05-13 16:59:42.983346: Epoch time: 49.06 s 
2024-05-13 16:59:43.994848:  
2024-05-13 16:59:43.994976: Epoch 139 
2024-05-13 16:59:43.995073: Current learning rate: 0.00874 
2024-05-13 17:00:33.012800: train_loss -0.818 
2024-05-13 17:00:33.012983: val_loss -0.8227 
2024-05-13 17:00:33.013053: Pseudo dice [0.9077] 
2024-05-13 17:00:33.013109: Epoch time: 49.02 s 
2024-05-13 17:00:34.531691:  
2024-05-13 17:00:34.531809: Epoch 140 
2024-05-13 17:00:34.531908: Current learning rate: 0.00873 
2024-05-13 17:01:23.572034: train_loss -0.8265 
2024-05-13 17:01:23.572232: val_loss -0.8201 
2024-05-13 17:01:23.572292: Pseudo dice [0.9084] 
2024-05-13 17:01:23.572351: Epoch time: 49.04 s 
2024-05-13 17:01:24.597961:  
2024-05-13 17:01:24.598229: Epoch 141 
2024-05-13 17:01:24.598325: Current learning rate: 0.00872 
2024-05-13 17:02:13.695193: train_loss -0.8288 
2024-05-13 17:02:13.695460: val_loss -0.8242 
2024-05-13 17:02:13.695525: Pseudo dice [0.9089] 
2024-05-13 17:02:13.695581: Epoch time: 49.1 s 
2024-05-13 17:02:14.718809:  
2024-05-13 17:02:14.719055: Epoch 142 
2024-05-13 17:02:14.719144: Current learning rate: 0.00871 
2024-05-13 17:03:03.787278: train_loss -0.8303 
2024-05-13 17:03:03.787448: val_loss -0.8294 
2024-05-13 17:03:03.787506: Pseudo dice [0.9093] 
2024-05-13 17:03:03.787565: Epoch time: 49.07 s 
2024-05-13 17:03:04.832670:  
2024-05-13 17:03:04.832792: Epoch 143 
2024-05-13 17:03:04.832874: Current learning rate: 0.0087 
2024-05-13 17:03:53.933063: train_loss -0.8094 
2024-05-13 17:03:53.933241: val_loss -0.8146 
2024-05-13 17:03:53.933302: Pseudo dice [0.8995] 
2024-05-13 17:03:53.933359: Epoch time: 49.1 s 
2024-05-13 17:03:54.960894:  
2024-05-13 17:03:54.961201: Epoch 144 
2024-05-13 17:03:54.961457: Current learning rate: 0.00869 
2024-05-13 17:04:44.045883: train_loss -0.8239 
2024-05-13 17:04:44.046085: val_loss -0.8219 
2024-05-13 17:04:44.046180: Pseudo dice [0.913] 
2024-05-13 17:04:44.046241: Epoch time: 49.09 s 
2024-05-13 17:04:44.046286: Yayy! New best EMA pseudo Dice: 0.905 
2024-05-13 17:04:45.460689:  
2024-05-13 17:04:45.460801: Epoch 145 
2024-05-13 17:04:45.460898: Current learning rate: 0.00868 
2024-05-13 17:05:34.494375: train_loss -0.8308 
2024-05-13 17:05:34.494626: val_loss -0.8293 
2024-05-13 17:05:34.494695: Pseudo dice [0.9122] 
2024-05-13 17:05:34.494753: Epoch time: 49.03 s 
2024-05-13 17:05:34.494798: Yayy! New best EMA pseudo Dice: 0.9057 
2024-05-13 17:05:35.847249:  
2024-05-13 17:05:35.847440: Epoch 146 
2024-05-13 17:05:35.847526: Current learning rate: 0.00868 
2024-05-13 17:06:24.916475: train_loss -0.8351 
2024-05-13 17:06:24.916658: val_loss -0.8422 
2024-05-13 17:06:24.916719: Pseudo dice [0.9188] 
2024-05-13 17:06:24.916779: Epoch time: 49.07 s 
2024-05-13 17:06:24.916824: Yayy! New best EMA pseudo Dice: 0.907 
2024-05-13 17:06:26.317174:  
2024-05-13 17:06:26.317286: Epoch 147 
2024-05-13 17:06:26.317369: Current learning rate: 0.00867 
2024-05-13 17:07:15.326560: train_loss -0.8354 
2024-05-13 17:07:15.326726: val_loss -0.8272 
2024-05-13 17:07:15.326787: Pseudo dice [0.9081] 
2024-05-13 17:07:15.326845: Epoch time: 49.01 s 
2024-05-13 17:07:15.326890: Yayy! New best EMA pseudo Dice: 0.9071 
2024-05-13 17:07:16.673409:  
2024-05-13 17:07:16.673525: Epoch 148 
2024-05-13 17:07:16.673619: Current learning rate: 0.00866 
2024-05-13 17:08:05.770895: train_loss -0.8228 
2024-05-13 17:08:05.771054: val_loss -0.8346 
2024-05-13 17:08:05.771113: Pseudo dice [0.9166] 
2024-05-13 17:08:05.771169: Epoch time: 49.1 s 
2024-05-13 17:08:05.771213: Yayy! New best EMA pseudo Dice: 0.9081 
2024-05-13 17:08:07.187409:  
2024-05-13 17:08:07.187521: Epoch 149 
2024-05-13 17:08:07.187618: Current learning rate: 0.00865 
2024-05-13 17:08:56.226678: train_loss -0.8238 
2024-05-13 17:08:56.226903: val_loss -0.8318 
2024-05-13 17:08:56.227006: Pseudo dice [0.9143] 
2024-05-13 17:08:56.227104: Epoch time: 49.04 s 
2024-05-13 17:08:56.534172: Yayy! New best EMA pseudo Dice: 0.9087 
2024-05-13 17:08:58.219877:  
2024-05-13 17:08:58.220112: Epoch 150 
2024-05-13 17:08:58.220202: Current learning rate: 0.00864 
2024-05-13 17:09:47.344089: train_loss -0.8267 
2024-05-13 17:09:47.344915: val_loss -0.8158 
2024-05-13 17:09:47.345012: Pseudo dice [0.9084] 
2024-05-13 17:09:47.345080: Epoch time: 49.13 s 
2024-05-13 17:09:48.390777:  
2024-05-13 17:09:48.390907: Epoch 151 
2024-05-13 17:09:48.390991: Current learning rate: 0.00863 
2024-05-13 17:10:37.422821: train_loss -0.8199 
2024-05-13 17:10:37.422996: val_loss -0.8241 
2024-05-13 17:10:37.423055: Pseudo dice [0.9083] 
2024-05-13 17:10:37.423111: Epoch time: 49.03 s 
2024-05-13 17:10:38.444177:  
2024-05-13 17:10:38.444299: Epoch 152 
2024-05-13 17:10:38.444398: Current learning rate: 0.00862 
2024-05-13 17:11:27.532031: train_loss -0.8175 
2024-05-13 17:11:27.532208: val_loss -0.8139 
2024-05-13 17:11:27.532267: Pseudo dice [0.9069] 
2024-05-13 17:11:27.532341: Epoch time: 49.09 s 
2024-05-13 17:11:28.552362:  
2024-05-13 17:11:28.552495: Epoch 153 
2024-05-13 17:11:28.552598: Current learning rate: 0.00861 
2024-05-13 17:12:17.569768: train_loss -0.8208 
2024-05-13 17:12:17.570611: val_loss -0.8381 
2024-05-13 17:12:17.570836: Pseudo dice [0.9159] 
2024-05-13 17:12:17.571003: Epoch time: 49.02 s 
2024-05-13 17:12:17.571153: Yayy! New best EMA pseudo Dice: 0.9092 
2024-05-13 17:12:18.960670:  
2024-05-13 17:12:18.960805: Epoch 154 
2024-05-13 17:12:18.960889: Current learning rate: 0.0086 
2024-05-13 17:13:08.008188: train_loss -0.8167 
2024-05-13 17:13:08.008371: val_loss -0.8243 
2024-05-13 17:13:08.008447: Pseudo dice [0.9116] 
2024-05-13 17:13:08.008509: Epoch time: 49.05 s 
2024-05-13 17:13:08.008554: Yayy! New best EMA pseudo Dice: 0.9094 
2024-05-13 17:13:09.367594:  
2024-05-13 17:13:09.367707: Epoch 155 
2024-05-13 17:13:09.367801: Current learning rate: 0.00859 
2024-05-13 17:13:58.501113: train_loss -0.8234 
2024-05-13 17:13:58.501280: val_loss -0.8295 
2024-05-13 17:13:58.501337: Pseudo dice [0.9112] 
2024-05-13 17:13:58.501414: Epoch time: 49.13 s 
2024-05-13 17:13:58.501459: Yayy! New best EMA pseudo Dice: 0.9096 
2024-05-13 17:13:59.885706:  
2024-05-13 17:13:59.885832: Epoch 156 
2024-05-13 17:13:59.885929: Current learning rate: 0.00858 
2024-05-13 17:14:48.901721: train_loss -0.8255 
2024-05-13 17:14:48.902619: val_loss -0.8204 
2024-05-13 17:14:48.902915: Pseudo dice [0.9036] 
2024-05-13 17:14:48.903130: Epoch time: 49.02 s 
2024-05-13 17:14:49.944924:  
2024-05-13 17:14:49.945041: Epoch 157 
2024-05-13 17:14:49.945127: Current learning rate: 0.00858 
2024-05-13 17:15:38.993380: train_loss -0.8236 
2024-05-13 17:15:38.993555: val_loss -0.8175 
2024-05-13 17:15:38.993615: Pseudo dice [0.9049] 
2024-05-13 17:15:38.993672: Epoch time: 49.05 s 
2024-05-13 17:15:40.073964:  
2024-05-13 17:15:40.074194: Epoch 158 
2024-05-13 17:15:40.074282: Current learning rate: 0.00857 
2024-05-13 17:16:29.140919: train_loss -0.8202 
2024-05-13 17:16:29.141094: val_loss -0.8383 
2024-05-13 17:16:29.141169: Pseudo dice [0.9146] 
2024-05-13 17:16:29.141227: Epoch time: 49.07 s 
2024-05-13 17:16:30.213732:  
2024-05-13 17:16:30.213850: Epoch 159 
2024-05-13 17:16:30.213953: Current learning rate: 0.00856 
2024-05-13 17:17:19.325418: train_loss -0.8226 
2024-05-13 17:17:19.326088: val_loss -0.8369 
2024-05-13 17:17:19.326146: Pseudo dice [0.9181] 
2024-05-13 17:17:19.326196: Epoch time: 49.11 s 
2024-05-13 17:17:19.326234: Yayy! New best EMA pseudo Dice: 0.9101 
2024-05-13 17:17:21.073452:  
2024-05-13 17:17:21.073600: Epoch 160 
2024-05-13 17:17:21.073706: Current learning rate: 0.00855 
2024-05-13 17:18:10.053626: train_loss -0.8238 
2024-05-13 17:18:10.053795: val_loss -0.8259 
2024-05-13 17:18:10.053847: Pseudo dice [0.9072] 
2024-05-13 17:18:10.053896: Epoch time: 48.98 s 
2024-05-13 17:18:11.101064:  
2024-05-13 17:18:11.101215: Epoch 161 
2024-05-13 17:18:11.101298: Current learning rate: 0.00854 
2024-05-13 17:19:00.198102: train_loss -0.8237 
2024-05-13 17:19:00.198277: val_loss -0.8231 
2024-05-13 17:19:00.198366: Pseudo dice [0.9062] 
2024-05-13 17:19:00.198427: Epoch time: 49.1 s 
2024-05-13 17:19:01.250362:  
2024-05-13 17:19:01.250485: Epoch 162 
2024-05-13 17:19:01.250572: Current learning rate: 0.00853 
2024-05-13 17:19:50.327356: train_loss -0.8171 
2024-05-13 17:19:50.327790: val_loss -0.8133 
2024-05-13 17:19:50.328031: Pseudo dice [0.9049] 
2024-05-13 17:19:50.328197: Epoch time: 49.08 s 
2024-05-13 17:19:51.379475:  
2024-05-13 17:19:51.379592: Epoch 163 
2024-05-13 17:19:51.379676: Current learning rate: 0.00852 
2024-05-13 17:20:40.395483: train_loss -0.8113 
2024-05-13 17:20:40.395687: val_loss -0.8046 
2024-05-13 17:20:40.395748: Pseudo dice [0.9008] 
2024-05-13 17:20:40.395809: Epoch time: 49.02 s 
2024-05-13 17:20:41.468156:  
2024-05-13 17:20:41.468271: Epoch 164 
2024-05-13 17:20:41.468368: Current learning rate: 0.00851 
2024-05-13 17:21:30.507050: train_loss -0.8257 
2024-05-13 17:21:30.507213: val_loss -0.8277 
2024-05-13 17:21:30.507273: Pseudo dice [0.9094] 
2024-05-13 17:21:30.507330: Epoch time: 49.04 s 
2024-05-13 17:21:31.522401:  
2024-05-13 17:21:31.522717: Epoch 165 
2024-05-13 17:21:31.522861: Current learning rate: 0.0085 
2024-05-13 17:22:20.610682: train_loss -0.8287 
2024-05-13 17:22:20.610934: val_loss -0.8259 
2024-05-13 17:22:20.611000: Pseudo dice [0.9066] 
2024-05-13 17:22:20.611059: Epoch time: 49.09 s 
2024-05-13 17:22:21.607320:  
2024-05-13 17:22:21.607440: Epoch 166 
2024-05-13 17:22:21.607524: Current learning rate: 0.00849 
2024-05-13 17:23:10.622325: train_loss -0.825 
2024-05-13 17:23:10.622517: val_loss -0.8288 
2024-05-13 17:23:10.622576: Pseudo dice [0.9077] 
2024-05-13 17:23:10.622637: Epoch time: 49.02 s 
2024-05-13 17:23:11.659131:  
2024-05-13 17:23:11.659242: Epoch 167 
2024-05-13 17:23:11.659323: Current learning rate: 0.00848 
2024-05-13 17:24:00.680753: train_loss -0.8264 
2024-05-13 17:24:00.680920: val_loss -0.84 
2024-05-13 17:24:00.680987: Pseudo dice [0.9154] 
2024-05-13 17:24:00.681080: Epoch time: 49.02 s 
2024-05-13 17:24:01.699169:  
2024-05-13 17:24:01.699389: Epoch 168 
2024-05-13 17:24:01.699479: Current learning rate: 0.00847 
2024-05-13 17:24:50.700325: train_loss -0.8205 
2024-05-13 17:24:50.700585: val_loss -0.8178 
2024-05-13 17:24:50.700659: Pseudo dice [0.9017] 
2024-05-13 17:24:50.700720: Epoch time: 49.0 s 
2024-05-13 17:24:51.768911:  
2024-05-13 17:24:51.769016: Epoch 169 
2024-05-13 17:24:51.769098: Current learning rate: 0.00847 
2024-05-13 17:25:40.824150: train_loss -0.8239 
2024-05-13 17:25:40.824317: val_loss -0.8448 
2024-05-13 17:25:40.824378: Pseudo dice [0.9164] 
2024-05-13 17:25:40.824436: Epoch time: 49.06 s 
2024-05-13 17:25:42.215026:  
2024-05-13 17:25:42.215191: Epoch 170 
2024-05-13 17:25:42.215282: Current learning rate: 0.00846 
2024-05-13 17:26:31.166948: train_loss -0.8108 
2024-05-13 17:26:31.167139: val_loss -0.8211 
2024-05-13 17:26:31.167223: Pseudo dice [0.9073] 
2024-05-13 17:26:31.167297: Epoch time: 48.95 s 
2024-05-13 17:26:32.189037:  
2024-05-13 17:26:32.189292: Epoch 171 
2024-05-13 17:26:32.189379: Current learning rate: 0.00845 
2024-05-13 17:27:21.249989: train_loss -0.8178 
2024-05-13 17:27:21.250256: val_loss -0.8086 
2024-05-13 17:27:21.250340: Pseudo dice [0.9079] 
2024-05-13 17:27:21.250402: Epoch time: 49.06 s 
2024-05-13 17:27:22.299470:  
2024-05-13 17:27:22.299779: Epoch 172 
2024-05-13 17:27:22.299874: Current learning rate: 0.00844 
2024-05-13 17:28:11.330453: train_loss -0.8259 
2024-05-13 17:28:11.330622: val_loss -0.8299 
2024-05-13 17:28:11.330697: Pseudo dice [0.9035] 
2024-05-13 17:28:11.330773: Epoch time: 49.03 s 
2024-05-13 17:28:12.354006:  
2024-05-13 17:28:12.354122: Epoch 173 
2024-05-13 17:28:12.354219: Current learning rate: 0.00843 
2024-05-13 17:29:01.454118: train_loss -0.8386 
2024-05-13 17:29:01.454340: val_loss -0.8349 
2024-05-13 17:29:01.454424: Pseudo dice [0.9166] 
2024-05-13 17:29:01.454485: Epoch time: 49.1 s 
2024-05-13 17:29:02.472587:  
2024-05-13 17:29:02.472946: Epoch 174 
2024-05-13 17:29:02.473043: Current learning rate: 0.00842 
2024-05-13 17:29:51.500329: train_loss -0.8313 
2024-05-13 17:29:51.500635: val_loss -0.833 
2024-05-13 17:29:51.500726: Pseudo dice [0.9112] 
2024-05-13 17:29:51.500788: Epoch time: 49.03 s 
2024-05-13 17:29:52.559919:  
2024-05-13 17:29:52.560036: Epoch 175 
2024-05-13 17:29:52.560120: Current learning rate: 0.00841 
2024-05-13 17:30:41.604231: train_loss -0.8333 
2024-05-13 17:30:41.604395: val_loss -0.826 
2024-05-13 17:30:41.604455: Pseudo dice [0.9092] 
2024-05-13 17:30:41.604512: Epoch time: 49.05 s 
2024-05-13 17:30:42.623021:  
2024-05-13 17:30:42.623216: Epoch 176 
2024-05-13 17:30:42.623303: Current learning rate: 0.0084 
2024-05-13 17:31:31.712883: train_loss -0.8379 
2024-05-13 17:31:31.713064: val_loss -0.841 
2024-05-13 17:31:31.713123: Pseudo dice [0.9142] 
2024-05-13 17:31:31.713186: Epoch time: 49.09 s 
2024-05-13 17:31:32.760931:  
2024-05-13 17:31:32.761035: Epoch 177 
2024-05-13 17:31:32.761130: Current learning rate: 0.00839 
2024-05-13 17:32:21.832247: train_loss -0.8246 
2024-05-13 17:32:21.832579: val_loss -0.8436 
2024-05-13 17:32:21.832709: Pseudo dice [0.9195] 
2024-05-13 17:32:21.832805: Epoch time: 49.07 s 
2024-05-13 17:32:21.832869: Yayy! New best EMA pseudo Dice: 0.9107 
2024-05-13 17:32:23.232641:  
2024-05-13 17:32:23.232750: Epoch 178 
2024-05-13 17:32:23.232835: Current learning rate: 0.00838 
2024-05-13 17:33:12.265109: train_loss -0.8277 
2024-05-13 17:33:12.265281: val_loss -0.84 
2024-05-13 17:33:12.265340: Pseudo dice [0.9174] 
2024-05-13 17:33:12.265395: Epoch time: 49.03 s 
2024-05-13 17:33:12.265443: Yayy! New best EMA pseudo Dice: 0.9114 
2024-05-13 17:33:13.615976:  
2024-05-13 17:33:13.616182: Epoch 179 
2024-05-13 17:33:13.616265: Current learning rate: 0.00837 
2024-05-13 17:34:02.649034: train_loss -0.8309 
2024-05-13 17:34:02.649199: val_loss -0.8324 
2024-05-13 17:34:02.649259: Pseudo dice [0.9108] 
2024-05-13 17:34:02.649315: Epoch time: 49.03 s 
2024-05-13 17:34:04.219154:  
2024-05-13 17:34:04.219387: Epoch 180 
2024-05-13 17:34:04.219598: Current learning rate: 0.00836 
2024-05-13 17:34:53.347914: train_loss -0.8293 
2024-05-13 17:34:53.348601: val_loss -0.8383 
2024-05-13 17:34:53.348666: Pseudo dice [0.9156] 
2024-05-13 17:34:53.348717: Epoch time: 49.13 s 
2024-05-13 17:34:53.348757: Yayy! New best EMA pseudo Dice: 0.9117 
2024-05-13 17:34:54.711138:  
2024-05-13 17:34:54.711284: Epoch 181 
2024-05-13 17:34:54.711368: Current learning rate: 0.00836 
2024-05-13 17:35:43.765460: train_loss -0.8268 
2024-05-13 17:35:43.765651: val_loss -0.8216 
2024-05-13 17:35:43.765714: Pseudo dice [0.9058] 
2024-05-13 17:35:43.765788: Epoch time: 49.06 s 
2024-05-13 17:35:44.778624:  
2024-05-13 17:35:44.778777: Epoch 182 
2024-05-13 17:35:44.778880: Current learning rate: 0.00835 
2024-05-13 17:36:33.875078: train_loss -0.8308 
2024-05-13 17:36:33.875244: val_loss -0.8376 
2024-05-13 17:36:33.875305: Pseudo dice [0.9165] 
2024-05-13 17:36:33.875362: Epoch time: 49.1 s 
2024-05-13 17:36:34.900633:  
2024-05-13 17:36:34.900837: Epoch 183 
2024-05-13 17:36:34.900923: Current learning rate: 0.00834 
2024-05-13 17:37:24.063907: train_loss -0.8343 
2024-05-13 17:37:24.064616: val_loss -0.8499 
2024-05-13 17:37:24.064697: Pseudo dice [0.9221] 
2024-05-13 17:37:24.064770: Epoch time: 49.16 s 
2024-05-13 17:37:24.064835: Yayy! New best EMA pseudo Dice: 0.9127 
2024-05-13 17:37:25.413341:  
2024-05-13 17:37:25.413461: Epoch 184 
2024-05-13 17:37:25.413587: Current learning rate: 0.00833 
2024-05-13 17:38:14.476295: train_loss -0.8375 
2024-05-13 17:38:14.476482: val_loss -0.8306 
2024-05-13 17:38:14.476548: Pseudo dice [0.9125] 
2024-05-13 17:38:14.476610: Epoch time: 49.06 s 
2024-05-13 17:38:15.533561:  
2024-05-13 17:38:15.533678: Epoch 185 
2024-05-13 17:38:15.533758: Current learning rate: 0.00832 
2024-05-13 17:39:04.601353: train_loss -0.837 
2024-05-13 17:39:04.601551: val_loss -0.8377 
2024-05-13 17:39:04.601619: Pseudo dice [0.9154] 
2024-05-13 17:39:04.601678: Epoch time: 49.07 s 
2024-05-13 17:39:04.601724: Yayy! New best EMA pseudo Dice: 0.913 
2024-05-13 17:39:05.979625:  
2024-05-13 17:39:05.979743: Epoch 186 
2024-05-13 17:39:05.979831: Current learning rate: 0.00831 
2024-05-13 17:39:55.061866: train_loss -0.8266 
2024-05-13 17:39:55.062156: val_loss -0.8281 
2024-05-13 17:39:55.062223: Pseudo dice [0.9076] 
2024-05-13 17:39:55.062281: Epoch time: 49.08 s 
2024-05-13 17:39:56.081885:  
2024-05-13 17:39:56.082226: Epoch 187 
2024-05-13 17:39:56.082321: Current learning rate: 0.0083 
2024-05-13 17:40:45.072139: train_loss -0.8258 
2024-05-13 17:40:45.072319: val_loss -0.8359 
2024-05-13 17:40:45.072395: Pseudo dice [0.9158] 
2024-05-13 17:40:45.072452: Epoch time: 48.99 s 
2024-05-13 17:40:46.109978:  
2024-05-13 17:40:46.110177: Epoch 188 
2024-05-13 17:40:46.110264: Current learning rate: 0.00829 
2024-05-13 17:41:35.167517: train_loss -0.8268 
2024-05-13 17:41:35.167702: val_loss -0.849 
2024-05-13 17:41:35.167802: Pseudo dice [0.9196] 
2024-05-13 17:41:35.167886: Epoch time: 49.06 s 
2024-05-13 17:41:35.167959: Yayy! New best EMA pseudo Dice: 0.9135 
2024-05-13 17:41:36.516845:  
2024-05-13 17:41:36.517033: Epoch 189 
2024-05-13 17:41:36.517208: Current learning rate: 0.00828 
2024-05-13 17:42:26.028681: train_loss -0.834 
2024-05-13 17:42:26.029372: val_loss -0.8331 
2024-05-13 17:42:26.029431: Pseudo dice [0.9146] 
2024-05-13 17:42:26.029480: Epoch time: 49.51 s 
2024-05-13 17:42:26.029518: Yayy! New best EMA pseudo Dice: 0.9136 
2024-05-13 17:42:27.376664:  
2024-05-13 17:42:27.376793: Epoch 190 
2024-05-13 17:42:27.376890: Current learning rate: 0.00827 
2024-05-13 17:43:16.370497: train_loss -0.8413 
2024-05-13 17:43:16.370690: val_loss -0.8231 
2024-05-13 17:43:16.370748: Pseudo dice [0.9074] 
2024-05-13 17:43:16.370805: Epoch time: 48.99 s 
2024-05-13 17:43:17.400401:  
2024-05-13 17:43:17.400653: Epoch 191 
2024-05-13 17:43:17.400743: Current learning rate: 0.00826 
2024-05-13 17:44:06.480256: train_loss -0.841 
2024-05-13 17:44:06.480438: val_loss -0.8433 
2024-05-13 17:44:06.480505: Pseudo dice [0.9187] 
2024-05-13 17:44:06.480570: Epoch time: 49.08 s 
2024-05-13 17:44:07.544644:  
2024-05-13 17:44:07.544769: Epoch 192 
2024-05-13 17:44:07.544852: Current learning rate: 0.00825 
2024-05-13 17:44:56.655703: train_loss -0.8345 
2024-05-13 17:44:56.655879: val_loss -0.8408 
2024-05-13 17:44:56.655938: Pseudo dice [0.9132] 
2024-05-13 17:44:56.656012: Epoch time: 49.11 s 
2024-05-13 17:44:57.693549:  
2024-05-13 17:44:57.693666: Epoch 193 
2024-05-13 17:44:57.693749: Current learning rate: 0.00824 
2024-05-13 17:45:46.767969: train_loss -0.8387 
2024-05-13 17:45:46.768671: val_loss -0.8412 
2024-05-13 17:45:46.768727: Pseudo dice [0.9166] 
2024-05-13 17:45:46.768782: Epoch time: 49.08 s 
2024-05-13 17:45:46.768821: Yayy! New best EMA pseudo Dice: 0.9138 
2024-05-13 17:45:48.121296:  
2024-05-13 17:45:48.121411: Epoch 194 
2024-05-13 17:45:48.121510: Current learning rate: 0.00824 
2024-05-13 17:46:37.152670: train_loss -0.8348 
2024-05-13 17:46:37.152843: val_loss -0.8263 
2024-05-13 17:46:37.152903: Pseudo dice [0.9091] 
2024-05-13 17:46:37.152960: Epoch time: 49.03 s 
2024-05-13 17:46:38.228084:  
2024-05-13 17:46:38.228428: Epoch 195 
2024-05-13 17:46:38.228516: Current learning rate: 0.00823 
2024-05-13 17:47:27.446491: train_loss -0.8237 
2024-05-13 17:47:27.446667: val_loss -0.8444 
2024-05-13 17:47:27.446727: Pseudo dice [0.9186] 
2024-05-13 17:47:27.446888: Epoch time: 49.22 s 
2024-05-13 17:47:27.446942: Yayy! New best EMA pseudo Dice: 0.9139 
2024-05-13 17:47:28.816528:  
2024-05-13 17:47:28.816696: Epoch 196 
2024-05-13 17:47:28.816787: Current learning rate: 0.00822 
2024-05-13 17:48:17.883896: train_loss -0.8306 
2024-05-13 17:48:17.884084: val_loss -0.8389 
2024-05-13 17:48:17.884143: Pseudo dice [0.9151] 
2024-05-13 17:48:17.884200: Epoch time: 49.07 s 
2024-05-13 17:48:17.884251: Yayy! New best EMA pseudo Dice: 0.914 
2024-05-13 17:48:19.275906:  
2024-05-13 17:48:19.276036: Epoch 197 
2024-05-13 17:48:19.276132: Current learning rate: 0.00821 
2024-05-13 17:49:08.344659: train_loss -0.8307 
2024-05-13 17:49:08.344846: val_loss -0.8169 
2024-05-13 17:49:08.345456: Pseudo dice [0.9105] 
2024-05-13 17:49:08.345519: Epoch time: 49.07 s 
2024-05-13 17:49:09.394238:  
2024-05-13 17:49:09.394603: Epoch 198 
2024-05-13 17:49:09.394851: Current learning rate: 0.0082 
2024-05-13 17:49:58.464590: train_loss -0.835 
2024-05-13 17:49:58.464889: val_loss -0.8333 
2024-05-13 17:49:58.464954: Pseudo dice [0.9131] 
2024-05-13 17:49:58.465008: Epoch time: 49.07 s 
2024-05-13 17:49:59.880490:  
2024-05-13 17:49:59.880795: Epoch 199 
2024-05-13 17:49:59.880925: Current learning rate: 0.00819 
2024-05-13 17:50:48.869784: train_loss -0.8269 
2024-05-13 17:50:48.869961: val_loss -0.8351 
2024-05-13 17:50:48.870019: Pseudo dice [0.9127] 
2024-05-13 17:50:48.870075: Epoch time: 48.99 s 
2024-05-13 17:50:50.230085:  
2024-05-13 17:50:50.230228: Epoch 200 
2024-05-13 17:50:50.230316: Current learning rate: 0.00818 
2024-05-13 17:51:39.234637: train_loss -0.8262 
2024-05-13 17:51:39.234805: val_loss -0.8251 
2024-05-13 17:51:39.234864: Pseudo dice [0.9077] 
2024-05-13 17:51:39.234928: Epoch time: 49.01 s 
2024-05-13 17:51:40.282749:  
2024-05-13 17:51:40.282999: Epoch 201 
2024-05-13 17:51:40.283087: Current learning rate: 0.00817 
2024-05-13 17:52:29.331418: train_loss -0.8239 
2024-05-13 17:52:29.331604: val_loss -0.8313 
2024-05-13 17:52:29.331665: Pseudo dice [0.9154] 
2024-05-13 17:52:29.331722: Epoch time: 49.05 s 
2024-05-13 17:52:30.442615:  
2024-05-13 17:52:30.442908: Epoch 202 
2024-05-13 17:52:30.443092: Current learning rate: 0.00816 
2024-05-13 17:53:19.443850: train_loss -0.8291 
2024-05-13 17:53:19.444041: val_loss -0.8228 
2024-05-13 17:53:19.444103: Pseudo dice [0.9136] 
2024-05-13 17:53:19.444160: Epoch time: 49.0 s 
2024-05-13 17:53:20.524973:  
2024-05-13 17:53:20.525362: Epoch 203 
2024-05-13 17:53:20.525451: Current learning rate: 0.00815 
2024-05-13 17:54:09.549678: train_loss -0.8236 
2024-05-13 17:54:09.549851: val_loss -0.8442 
2024-05-13 17:54:09.549917: Pseudo dice [0.9197] 
2024-05-13 17:54:09.549975: Epoch time: 49.03 s 
2024-05-13 17:54:10.584198:  
2024-05-13 17:54:10.584306: Epoch 204 
2024-05-13 17:54:10.584388: Current learning rate: 0.00814 
2024-05-13 17:54:59.614923: train_loss -0.8264 
2024-05-13 17:54:59.615225: val_loss -0.8274 
2024-05-13 17:54:59.615311: Pseudo dice [0.9116] 
2024-05-13 17:54:59.615382: Epoch time: 49.03 s 
2024-05-13 17:55:00.689052:  
2024-05-13 17:55:00.689225: Epoch 205 
2024-05-13 17:55:00.689317: Current learning rate: 0.00813 
2024-05-13 17:55:49.692360: train_loss -0.8297 
2024-05-13 17:55:49.692531: val_loss -0.838 
2024-05-13 17:55:49.692588: Pseudo dice [0.9122] 
2024-05-13 17:55:49.692641: Epoch time: 49.0 s 
2024-05-13 17:55:50.661442:  
2024-05-13 17:55:50.661638: Epoch 206 
2024-05-13 17:55:50.661730: Current learning rate: 0.00813 
2024-05-13 17:56:39.781664: train_loss -0.824 
2024-05-13 17:56:39.781858: val_loss -0.8411 
2024-05-13 17:56:39.781924: Pseudo dice [0.9172] 
2024-05-13 17:56:39.781982: Epoch time: 49.12 s 
2024-05-13 17:56:40.771907:  
2024-05-13 17:56:40.772216: Epoch 207 
2024-05-13 17:56:40.772302: Current learning rate: 0.00812 
2024-05-13 17:57:29.927567: train_loss -0.8229 
2024-05-13 17:57:29.927812: val_loss -0.8285 
2024-05-13 17:57:29.927883: Pseudo dice [0.9068] 
2024-05-13 17:57:29.927958: Epoch time: 49.16 s 
2024-05-13 17:57:30.889946:  
2024-05-13 17:57:30.890201: Epoch 208 
2024-05-13 17:57:30.890302: Current learning rate: 0.00811 
2024-05-13 17:58:20.003696: train_loss -0.8313 
2024-05-13 17:58:20.003977: val_loss -0.8416 
2024-05-13 17:58:20.004053: Pseudo dice [0.9128] 
2024-05-13 17:58:20.004111: Epoch time: 49.11 s 
2024-05-13 17:58:20.982595:  
2024-05-13 17:58:20.982703: Epoch 209 
2024-05-13 17:58:20.982793: Current learning rate: 0.0081 
2024-05-13 17:59:10.039582: train_loss -0.8358 
2024-05-13 17:59:10.039751: val_loss -0.8228 
2024-05-13 17:59:10.039811: Pseudo dice [0.9043] 
2024-05-13 17:59:10.039871: Epoch time: 49.06 s 
2024-05-13 17:59:11.532630:  
2024-05-13 17:59:11.533034: Epoch 210 
2024-05-13 17:59:11.533124: Current learning rate: 0.00809 
2024-05-13 18:00:00.557748: train_loss -0.8312 
2024-05-13 18:00:00.557954: val_loss -0.8446 
2024-05-13 18:00:00.558012: Pseudo dice [0.9197] 
2024-05-13 18:00:00.558070: Epoch time: 49.03 s 
2024-05-13 18:00:01.553977:  
2024-05-13 18:00:01.554229: Epoch 211 
2024-05-13 18:00:01.554340: Current learning rate: 0.00808 
2024-05-13 18:00:50.635369: train_loss -0.8337 
2024-05-13 18:00:50.636065: val_loss -0.8371 
2024-05-13 18:00:50.636145: Pseudo dice [0.917] 
2024-05-13 18:00:50.636199: Epoch time: 49.08 s 
2024-05-13 18:00:51.609640:  
2024-05-13 18:00:51.609763: Epoch 212 
2024-05-13 18:00:51.609864: Current learning rate: 0.00807 
2024-05-13 18:01:40.710154: train_loss -0.8327 
2024-05-13 18:01:40.710352: val_loss -0.8288 
2024-05-13 18:01:40.710418: Pseudo dice [0.9087] 
2024-05-13 18:01:40.710475: Epoch time: 49.1 s 
2024-05-13 18:01:41.683050:  
2024-05-13 18:01:41.683164: Epoch 213 
2024-05-13 18:01:41.683248: Current learning rate: 0.00806 
2024-05-13 18:02:30.712867: train_loss -0.8214 
2024-05-13 18:02:30.713046: val_loss -0.8204 
2024-05-13 18:02:30.713106: Pseudo dice [0.9064] 
2024-05-13 18:02:30.713164: Epoch time: 49.03 s 
2024-05-13 18:02:31.694977:  
2024-05-13 18:02:31.695094: Epoch 214 
2024-05-13 18:02:31.695178: Current learning rate: 0.00805 
2024-05-13 18:03:20.779483: train_loss -0.8331 
2024-05-13 18:03:20.779763: val_loss -0.8388 
2024-05-13 18:03:20.779834: Pseudo dice [0.9133] 
2024-05-13 18:03:20.779902: Epoch time: 49.09 s 
2024-05-13 18:03:21.811948:  
2024-05-13 18:03:21.812068: Epoch 215 
2024-05-13 18:03:21.812168: Current learning rate: 0.00804 
2024-05-13 18:04:10.895633: train_loss -0.8331 
2024-05-13 18:04:10.895799: val_loss -0.8421 
2024-05-13 18:04:10.895857: Pseudo dice [0.9222] 
2024-05-13 18:04:10.895912: Epoch time: 49.08 s 
2024-05-13 18:04:11.868484:  
2024-05-13 18:04:11.868609: Epoch 216 
2024-05-13 18:04:11.868705: Current learning rate: 0.00803 
2024-05-13 18:05:00.921583: train_loss -0.8328 
2024-05-13 18:05:00.921763: val_loss -0.8571 
2024-05-13 18:05:00.921821: Pseudo dice [0.9205] 
2024-05-13 18:05:00.921896: Epoch time: 49.05 s 
2024-05-13 18:05:00.921941: Yayy! New best EMA pseudo Dice: 0.9141 
2024-05-13 18:05:02.223521:  
2024-05-13 18:05:02.223641: Epoch 217 
2024-05-13 18:05:02.223735: Current learning rate: 0.00802 
2024-05-13 18:05:51.301978: train_loss -0.8391 
2024-05-13 18:05:51.302257: val_loss -0.8377 
2024-05-13 18:05:51.302334: Pseudo dice [0.9138] 
2024-05-13 18:05:51.302407: Epoch time: 49.08 s 
2024-05-13 18:05:52.267660:  
2024-05-13 18:05:52.268045: Epoch 218 
2024-05-13 18:05:52.268134: Current learning rate: 0.00801 
2024-05-13 18:06:41.303677: train_loss -0.8412 
2024-05-13 18:06:41.303843: val_loss -0.8355 
2024-05-13 18:06:41.303904: Pseudo dice [0.9147] 
2024-05-13 18:06:41.303968: Epoch time: 49.04 s 
2024-05-13 18:06:41.304016: Yayy! New best EMA pseudo Dice: 0.9141 
2024-05-13 18:06:42.600438:  
2024-05-13 18:06:42.600636: Epoch 219 
2024-05-13 18:06:42.600721: Current learning rate: 0.00801 
2024-05-13 18:07:31.765942: train_loss -0.8323 
2024-05-13 18:07:31.766117: val_loss -0.8278 
2024-05-13 18:07:31.766196: Pseudo dice [0.9112] 
2024-05-13 18:07:31.766253: Epoch time: 49.17 s 
2024-05-13 18:07:33.172495:  
2024-05-13 18:07:33.172651: Epoch 220 
2024-05-13 18:07:33.172773: Current learning rate: 0.008 
2024-05-13 18:08:22.174417: train_loss -0.8223 
2024-05-13 18:08:22.174956: val_loss -0.8161 
2024-05-13 18:08:22.175031: Pseudo dice [0.9028] 
2024-05-13 18:08:22.175082: Epoch time: 49.0 s 
2024-05-13 18:08:23.145899:  
2024-05-13 18:08:23.146009: Epoch 221 
2024-05-13 18:08:23.146112: Current learning rate: 0.00799 
2024-05-13 18:09:12.163276: train_loss -0.8239 
2024-05-13 18:09:12.163557: val_loss -0.8313 
2024-05-13 18:09:12.163621: Pseudo dice [0.9103] 
2024-05-13 18:09:12.163698: Epoch time: 49.02 s 
2024-05-13 18:09:13.174502:  
2024-05-13 18:09:13.174742: Epoch 222 
2024-05-13 18:09:13.174830: Current learning rate: 0.00798 
2024-05-13 18:10:02.160028: train_loss -0.8317 
2024-05-13 18:10:02.160192: val_loss -0.8419 
2024-05-13 18:10:02.160267: Pseudo dice [0.9196] 
2024-05-13 18:10:02.160333: Epoch time: 48.99 s 
2024-05-13 18:10:03.127869:  
2024-05-13 18:10:03.128263: Epoch 223 
2024-05-13 18:10:03.128350: Current learning rate: 0.00797 
2024-05-13 18:10:52.201051: train_loss -0.8408 
2024-05-13 18:10:52.201740: val_loss -0.8292 
2024-05-13 18:10:52.201800: Pseudo dice [0.9134] 
2024-05-13 18:10:52.201852: Epoch time: 49.07 s 
2024-05-13 18:10:53.174031:  
2024-05-13 18:10:53.174473: Epoch 224 
2024-05-13 18:10:53.174724: Current learning rate: 0.00796 
2024-05-13 18:11:42.204798: train_loss -0.8378 
2024-05-13 18:11:42.204973: val_loss -0.8493 
2024-05-13 18:11:42.205035: Pseudo dice [0.9201] 
2024-05-13 18:11:42.205098: Epoch time: 49.03 s 
2024-05-13 18:11:43.187568:  
2024-05-13 18:11:43.187909: Epoch 225 
2024-05-13 18:11:43.187997: Current learning rate: 0.00795 
2024-05-13 18:12:32.228972: train_loss -0.8381 
2024-05-13 18:12:32.229132: val_loss -0.8386 
2024-05-13 18:12:32.229189: Pseudo dice [0.9159] 
2024-05-13 18:12:32.229261: Epoch time: 49.04 s 
2024-05-13 18:12:33.185338:  
2024-05-13 18:12:33.185567: Epoch 226 
2024-05-13 18:12:33.185770: Current learning rate: 0.00794 
2024-05-13 18:13:22.207938: train_loss -0.8342 
2024-05-13 18:13:22.208233: val_loss -0.8175 
2024-05-13 18:13:22.208325: Pseudo dice [0.91] 
2024-05-13 18:13:22.208386: Epoch time: 49.02 s 
2024-05-13 18:13:23.198009:  
2024-05-13 18:13:23.198121: Epoch 227 
2024-05-13 18:13:23.198246: Current learning rate: 0.00793 
2024-05-13 18:14:12.225364: train_loss -0.8316 
2024-05-13 18:14:12.225554: val_loss -0.8156 
2024-05-13 18:14:12.225612: Pseudo dice [0.9074] 
2024-05-13 18:14:12.225668: Epoch time: 49.03 s 
2024-05-13 18:14:13.184476:  
2024-05-13 18:14:13.184598: Epoch 228 
2024-05-13 18:14:13.184680: Current learning rate: 0.00792 
2024-05-13 18:15:02.223110: train_loss -0.8294 
2024-05-13 18:15:02.223274: val_loss -0.8435 
2024-05-13 18:15:02.223334: Pseudo dice [0.9223] 
2024-05-13 18:15:02.223394: Epoch time: 49.04 s 
2024-05-13 18:15:03.196266:  
2024-05-13 18:15:03.196372: Epoch 229 
2024-05-13 18:15:03.196471: Current learning rate: 0.00791 
2024-05-13 18:15:52.300308: train_loss -0.8301 
2024-05-13 18:15:52.300586: val_loss -0.8301 
2024-05-13 18:15:52.300658: Pseudo dice [0.9119] 
2024-05-13 18:15:52.300717: Epoch time: 49.1 s 
2024-05-13 18:15:53.281713:  
2024-05-13 18:15:53.281905: Epoch 230 
2024-05-13 18:15:53.282007: Current learning rate: 0.0079 
2024-05-13 18:16:42.321355: train_loss -0.8369 
2024-05-13 18:16:42.321538: val_loss -0.8325 
2024-05-13 18:16:42.321600: Pseudo dice [0.912] 
2024-05-13 18:16:42.321656: Epoch time: 49.04 s 
2024-05-13 18:16:43.270217:  
2024-05-13 18:16:43.270440: Epoch 231 
2024-05-13 18:16:43.270530: Current learning rate: 0.00789 
2024-05-13 18:17:32.366408: train_loss -0.831 
2024-05-13 18:17:32.366581: val_loss -0.8291 
2024-05-13 18:17:32.366641: Pseudo dice [0.9133] 
2024-05-13 18:17:32.366698: Epoch time: 49.1 s 
2024-05-13 18:17:33.863360:  
2024-05-13 18:17:33.863513: Epoch 232 
2024-05-13 18:17:33.863622: Current learning rate: 0.00789 
2024-05-13 18:18:22.928128: train_loss -0.8369 
2024-05-13 18:18:22.928283: val_loss -0.842 
2024-05-13 18:18:22.928353: Pseudo dice [0.9179] 
2024-05-13 18:18:22.928415: Epoch time: 49.07 s 
2024-05-13 18:18:23.885212:  
2024-05-13 18:18:23.885584: Epoch 233 
2024-05-13 18:18:23.885796: Current learning rate: 0.00788 
2024-05-13 18:19:12.925248: train_loss -0.8322 
2024-05-13 18:19:12.925401: val_loss -0.8385 
2024-05-13 18:19:12.925459: Pseudo dice [0.9152] 
2024-05-13 18:19:12.925531: Epoch time: 49.04 s 
2024-05-13 18:19:12.925577: Yayy! New best EMA pseudo Dice: 0.9141 
2024-05-13 18:19:14.227176:  
2024-05-13 18:19:14.227315: Epoch 234 
2024-05-13 18:19:14.227397: Current learning rate: 0.00787 
2024-05-13 18:20:03.265503: train_loss -0.8304 
2024-05-13 18:20:03.265671: val_loss -0.8417 
2024-05-13 18:20:03.265746: Pseudo dice [0.9176] 
2024-05-13 18:20:03.265823: Epoch time: 49.04 s 
2024-05-13 18:20:03.265893: Yayy! New best EMA pseudo Dice: 0.9145 
2024-05-13 18:20:04.600218:  
2024-05-13 18:20:04.600389: Epoch 235 
2024-05-13 18:20:04.600482: Current learning rate: 0.00786 
2024-05-13 18:20:53.666118: train_loss -0.8242 
2024-05-13 18:20:53.666872: val_loss -0.835 
2024-05-13 18:20:53.667015: Pseudo dice [0.9143] 
2024-05-13 18:20:53.667114: Epoch time: 49.07 s 
2024-05-13 18:20:54.648272:  
2024-05-13 18:20:54.648476: Epoch 236 
2024-05-13 18:20:54.648561: Current learning rate: 0.00785 
2024-05-13 18:21:43.764707: train_loss -0.8186 
2024-05-13 18:21:43.764882: val_loss -0.8237 
2024-05-13 18:21:43.764956: Pseudo dice [0.9084] 
2024-05-13 18:21:43.765016: Epoch time: 49.12 s 
2024-05-13 18:21:44.721416:  
2024-05-13 18:21:44.721808: Epoch 237 
2024-05-13 18:21:44.721896: Current learning rate: 0.00784 
2024-05-13 18:22:33.699718: train_loss -0.8203 
2024-05-13 18:22:33.699901: val_loss -0.8173 
2024-05-13 18:22:33.699964: Pseudo dice [0.9092] 
2024-05-13 18:22:33.700024: Epoch time: 48.98 s 
2024-05-13 18:22:34.709586:  
2024-05-13 18:22:34.709839: Epoch 238 
2024-05-13 18:22:34.709922: Current learning rate: 0.00783 
2024-05-13 18:23:23.796741: train_loss -0.8225 
2024-05-13 18:23:23.797031: val_loss -0.8338 
2024-05-13 18:23:23.797115: Pseudo dice [0.9149] 
2024-05-13 18:23:23.797172: Epoch time: 49.09 s 
2024-05-13 18:23:24.780641:  
2024-05-13 18:23:24.780883: Epoch 239 
2024-05-13 18:23:24.780971: Current learning rate: 0.00782 
2024-05-13 18:24:13.855519: train_loss -0.831 
2024-05-13 18:24:13.855687: val_loss -0.8524 
2024-05-13 18:24:13.855750: Pseudo dice [0.9213] 
2024-05-13 18:24:13.855805: Epoch time: 49.08 s 
2024-05-13 18:24:14.875437:  
2024-05-13 18:24:14.875552: Epoch 240 
2024-05-13 18:24:14.875637: Current learning rate: 0.00781 
2024-05-13 18:25:03.952140: train_loss -0.828 
2024-05-13 18:25:03.952328: val_loss -0.8413 
2024-05-13 18:25:03.952390: Pseudo dice [0.9144] 
2024-05-13 18:25:03.952450: Epoch time: 49.08 s 
2024-05-13 18:25:04.951161:  
2024-05-13 18:25:04.951270: Epoch 241 
2024-05-13 18:25:04.951353: Current learning rate: 0.0078 
2024-05-13 18:25:53.977437: train_loss -0.8363 
2024-05-13 18:25:53.978131: val_loss -0.8416 
2024-05-13 18:25:53.978215: Pseudo dice [0.9153] 
2024-05-13 18:25:53.978269: Epoch time: 49.03 s 
2024-05-13 18:25:54.980766:  
2024-05-13 18:25:54.981077: Epoch 242 
2024-05-13 18:25:54.981164: Current learning rate: 0.00779 
2024-05-13 18:26:44.078760: train_loss -0.8397 
2024-05-13 18:26:44.078929: val_loss -0.8306 
2024-05-13 18:26:44.078988: Pseudo dice [0.9123] 
2024-05-13 18:26:44.079044: Epoch time: 49.1 s 
2024-05-13 18:26:45.538879:  
2024-05-13 18:26:45.539003: Epoch 243 
2024-05-13 18:26:45.539086: Current learning rate: 0.00778 
2024-05-13 18:27:34.574189: train_loss -0.8374 
2024-05-13 18:27:34.574393: val_loss -0.8612 
2024-05-13 18:27:34.574472: Pseudo dice [0.9258] 
2024-05-13 18:27:34.574530: Epoch time: 49.04 s 
2024-05-13 18:27:34.574581: Yayy! New best EMA pseudo Dice: 0.9154 
2024-05-13 18:27:35.884906:  
2024-05-13 18:27:35.885027: Epoch 244 
2024-05-13 18:27:35.885121: Current learning rate: 0.00777 
2024-05-13 18:28:24.908483: train_loss -0.8504 
2024-05-13 18:28:24.908662: val_loss -0.8535 
2024-05-13 18:28:24.908756: Pseudo dice [0.9219] 
2024-05-13 18:28:24.908816: Epoch time: 49.02 s 
2024-05-13 18:28:24.908863: Yayy! New best EMA pseudo Dice: 0.916 
2024-05-13 18:28:26.273771:  
2024-05-13 18:28:26.274158: Epoch 245 
2024-05-13 18:28:26.274249: Current learning rate: 0.00777 
2024-05-13 18:29:15.306457: train_loss -0.8414 
2024-05-13 18:29:15.306634: val_loss -0.842 
2024-05-13 18:29:15.306695: Pseudo dice [0.92] 
2024-05-13 18:29:15.306753: Epoch time: 49.03 s 
2024-05-13 18:29:15.306803: Yayy! New best EMA pseudo Dice: 0.9164 
2024-05-13 18:29:16.612151:  
2024-05-13 18:29:16.612356: Epoch 246 
2024-05-13 18:29:16.612446: Current learning rate: 0.00776 
2024-05-13 18:30:05.752988: train_loss -0.828 
2024-05-13 18:30:05.753149: val_loss -0.844 
2024-05-13 18:30:05.753208: Pseudo dice [0.9179] 
2024-05-13 18:30:05.753266: Epoch time: 49.14 s 
2024-05-13 18:30:05.753309: Yayy! New best EMA pseudo Dice: 0.9166 
2024-05-13 18:30:07.091751:  
2024-05-13 18:30:07.091882: Epoch 247 
2024-05-13 18:30:07.091969: Current learning rate: 0.00775 
2024-05-13 18:30:56.143388: train_loss -0.8304 
2024-05-13 18:30:56.143705: val_loss -0.8352 
2024-05-13 18:30:56.143770: Pseudo dice [0.9137] 
2024-05-13 18:30:56.143827: Epoch time: 49.05 s 
2024-05-13 18:30:57.117604:  
2024-05-13 18:30:57.117841: Epoch 248 
2024-05-13 18:30:57.117940: Current learning rate: 0.00774 
2024-05-13 18:31:46.142290: train_loss -0.8337 
2024-05-13 18:31:46.142489: val_loss -0.8489 
2024-05-13 18:31:46.142554: Pseudo dice [0.9188] 
2024-05-13 18:31:46.142612: Epoch time: 49.03 s 
2024-05-13 18:31:47.111112:  
2024-05-13 18:31:47.111229: Epoch 249 
2024-05-13 18:31:47.111310: Current learning rate: 0.00773 
2024-05-13 18:32:36.128366: train_loss -0.8488 
2024-05-13 18:32:36.128533: val_loss -0.8442 
2024-05-13 18:32:36.128590: Pseudo dice [0.9217] 
2024-05-13 18:32:36.128646: Epoch time: 49.02 s 
2024-05-13 18:32:36.462063: Yayy! New best EMA pseudo Dice: 0.917 
2024-05-13 18:32:37.742140:  
2024-05-13 18:32:37.742253: Epoch 250 
2024-05-13 18:32:37.742356: Current learning rate: 0.00772 
2024-05-13 18:33:26.771943: train_loss -0.8316 
2024-05-13 18:33:26.772105: val_loss -0.8339 
2024-05-13 18:33:26.772164: Pseudo dice [0.9153] 
2024-05-13 18:33:26.772221: Epoch time: 49.03 s 
2024-05-13 18:33:27.764835:  
2024-05-13 18:33:27.764941: Epoch 251 
2024-05-13 18:33:27.765035: Current learning rate: 0.00771 
2024-05-13 18:34:16.871464: train_loss -0.8277 
2024-05-13 18:34:16.872157: val_loss -0.8454 
2024-05-13 18:34:16.872222: Pseudo dice [0.9176] 
2024-05-13 18:34:16.872283: Epoch time: 49.11 s 
2024-05-13 18:34:17.842664:  
2024-05-13 18:34:17.842858: Epoch 252 
2024-05-13 18:34:17.842944: Current learning rate: 0.0077 
2024-05-13 18:35:06.941401: train_loss -0.8354 
2024-05-13 18:35:06.941570: val_loss -0.8472 
2024-05-13 18:35:06.941628: Pseudo dice [0.9187] 
2024-05-13 18:35:06.941689: Epoch time: 49.1 s 
2024-05-13 18:35:06.941734: Yayy! New best EMA pseudo Dice: 0.9171 
2024-05-13 18:35:08.277040:  
2024-05-13 18:35:08.277242: Epoch 253 
2024-05-13 18:35:08.277329: Current learning rate: 0.00769 
2024-05-13 18:35:57.345262: train_loss -0.8315 
2024-05-13 18:35:57.345430: val_loss -0.8344 
2024-05-13 18:35:57.345488: Pseudo dice [0.9148] 
2024-05-13 18:35:57.345544: Epoch time: 49.07 s 
2024-05-13 18:35:58.816518:  
2024-05-13 18:35:58.816650: Epoch 254 
2024-05-13 18:35:58.816734: Current learning rate: 0.00768 
2024-05-13 18:36:47.832392: train_loss -0.8341 
2024-05-13 18:36:47.832652: val_loss -0.8225 
2024-05-13 18:36:47.832730: Pseudo dice [0.9139] 
2024-05-13 18:36:47.832787: Epoch time: 49.02 s 
2024-05-13 18:36:48.803895:  
2024-05-13 18:36:48.804026: Epoch 255 
2024-05-13 18:36:48.804128: Current learning rate: 0.00767 
2024-05-13 18:37:37.938318: train_loss -0.8407 
2024-05-13 18:37:37.938505: val_loss -0.8239 
2024-05-13 18:37:37.938565: Pseudo dice [0.9109] 
2024-05-13 18:37:37.938621: Epoch time: 49.14 s 
2024-05-13 18:37:38.916690:  
2024-05-13 18:37:38.916924: Epoch 256 
2024-05-13 18:37:38.917010: Current learning rate: 0.00766 
2024-05-13 18:38:27.922980: train_loss -0.8437 
2024-05-13 18:38:27.923159: val_loss -0.8369 
2024-05-13 18:38:27.923220: Pseudo dice [0.9158] 
2024-05-13 18:38:27.923282: Epoch time: 49.01 s 
2024-05-13 18:38:28.905178:  
2024-05-13 18:38:28.905393: Epoch 257 
2024-05-13 18:38:28.905539: Current learning rate: 0.00765 
2024-05-13 18:39:17.991321: train_loss -0.8451 
2024-05-13 18:39:17.991483: val_loss -0.85 
2024-05-13 18:39:17.991543: Pseudo dice [0.9202] 
2024-05-13 18:39:17.991609: Epoch time: 49.09 s 
2024-05-13 18:39:18.964101:  
2024-05-13 18:39:18.964262: Epoch 258 
2024-05-13 18:39:18.964393: Current learning rate: 0.00764 
2024-05-13 18:40:08.033559: train_loss -0.8477 
2024-05-13 18:40:08.033744: val_loss -0.8458 
2024-05-13 18:40:08.033805: Pseudo dice [0.92] 
2024-05-13 18:40:08.033864: Epoch time: 49.07 s 
2024-05-13 18:40:09.008128:  
2024-05-13 18:40:09.008507: Epoch 259 
2024-05-13 18:40:09.008597: Current learning rate: 0.00764 
2024-05-13 18:40:58.039543: train_loss -0.8454 
2024-05-13 18:40:58.040274: val_loss -0.8489 
2024-05-13 18:40:58.040343: Pseudo dice [0.9204] 
2024-05-13 18:40:58.040400: Epoch time: 49.03 s 
2024-05-13 18:40:58.040450: Yayy! New best EMA pseudo Dice: 0.9171 
2024-05-13 18:40:59.320099:  
2024-05-13 18:40:59.320219: Epoch 260 
2024-05-13 18:40:59.320305: Current learning rate: 0.00763 
2024-05-13 18:41:48.405733: train_loss -0.8465 
2024-05-13 18:41:48.405929: val_loss -0.8334 
2024-05-13 18:41:48.406011: Pseudo dice [0.9152] 
2024-05-13 18:41:48.406069: Epoch time: 49.09 s 
2024-05-13 18:41:49.379352:  
2024-05-13 18:41:49.379570: Epoch 261 
2024-05-13 18:41:49.379673: Current learning rate: 0.00762 
2024-05-13 18:42:38.485939: train_loss -0.8372 
2024-05-13 18:42:38.486125: val_loss -0.8279 
2024-05-13 18:42:38.486206: Pseudo dice [0.9159] 
2024-05-13 18:42:38.486262: Epoch time: 49.11 s 
2024-05-13 18:42:39.512505:  
2024-05-13 18:42:39.512758: Epoch 262 
2024-05-13 18:42:39.512847: Current learning rate: 0.00761 
2024-05-13 18:43:28.658334: train_loss -0.8322 
2024-05-13 18:43:28.658530: val_loss -0.853 
2024-05-13 18:43:28.658590: Pseudo dice [0.9204] 
2024-05-13 18:43:28.658648: Epoch time: 49.15 s 
2024-05-13 18:43:28.658694: Yayy! New best EMA pseudo Dice: 0.9172 
2024-05-13 18:43:29.945527:  
2024-05-13 18:43:29.945638: Epoch 263 
2024-05-13 18:43:29.945740: Current learning rate: 0.0076 
2024-05-13 18:44:18.973616: train_loss -0.8282 
2024-05-13 18:44:18.973786: val_loss -0.8252 
2024-05-13 18:44:18.973859: Pseudo dice [0.9086] 
2024-05-13 18:44:18.973917: Epoch time: 49.03 s 
2024-05-13 18:44:19.946691:  
2024-05-13 18:44:19.946873: Epoch 264 
2024-05-13 18:44:19.946955: Current learning rate: 0.00759 
2024-05-13 18:45:08.990667: train_loss -0.8253 
2024-05-13 18:45:08.991364: val_loss -0.8343 
2024-05-13 18:45:08.991420: Pseudo dice [0.9126] 
2024-05-13 18:45:08.991470: Epoch time: 49.04 s 
2024-05-13 18:45:10.356531:  
2024-05-13 18:45:10.356784: Epoch 265 
2024-05-13 18:45:10.356874: Current learning rate: 0.00758 
2024-05-13 18:45:59.446379: train_loss -0.8295 
2024-05-13 18:45:59.446553: val_loss -0.8308 
2024-05-13 18:45:59.446617: Pseudo dice [0.9131] 
2024-05-13 18:45:59.446677: Epoch time: 49.09 s 
2024-05-13 18:46:00.454006:  
2024-05-13 18:46:00.454137: Epoch 266 
2024-05-13 18:46:00.454235: Current learning rate: 0.00757 
2024-05-13 18:46:49.456926: train_loss -0.8346 
2024-05-13 18:46:49.457219: val_loss -0.8307 
2024-05-13 18:46:49.457286: Pseudo dice [0.9143] 
2024-05-13 18:46:49.457343: Epoch time: 49.0 s 
2024-05-13 18:46:50.432518:  
2024-05-13 18:46:50.432642: Epoch 267 
2024-05-13 18:46:50.432723: Current learning rate: 0.00756 
2024-05-13 18:47:39.510409: train_loss -0.8407 
2024-05-13 18:47:39.510655: val_loss -0.8462 
2024-05-13 18:47:39.510734: Pseudo dice [0.921] 
2024-05-13 18:47:39.510794: Epoch time: 49.08 s 
2024-05-13 18:47:40.495447:  
2024-05-13 18:47:40.495575: Epoch 268 
2024-05-13 18:47:40.495653: Current learning rate: 0.00755 
2024-05-13 18:48:29.472660: train_loss -0.8333 
2024-05-13 18:48:29.472826: val_loss -0.8412 
2024-05-13 18:48:29.472881: Pseudo dice [0.9178] 
2024-05-13 18:48:29.472953: Epoch time: 48.98 s 
2024-05-13 18:48:30.460251:  
2024-05-13 18:48:30.460612: Epoch 269 
2024-05-13 18:48:30.460703: Current learning rate: 0.00754 
2024-05-13 18:49:19.438807: train_loss -0.8459 
2024-05-13 18:49:19.438982: val_loss -0.8585 
2024-05-13 18:49:19.439142: Pseudo dice [0.9284] 
2024-05-13 18:49:19.439332: Epoch time: 48.98 s 
2024-05-13 18:49:19.439410: Yayy! New best EMA pseudo Dice: 0.9175 
2024-05-13 18:49:20.752613:  
2024-05-13 18:49:20.752825: Epoch 270 
2024-05-13 18:49:20.752909: Current learning rate: 0.00753 
2024-05-13 18:50:09.777768: train_loss -0.8476 
2024-05-13 18:50:09.777945: val_loss -0.8188 
2024-05-13 18:50:09.778005: Pseudo dice [0.9046] 
2024-05-13 18:50:09.778063: Epoch time: 49.03 s 
2024-05-13 18:50:10.759533:  
2024-05-13 18:50:10.759832: Epoch 271 
2024-05-13 18:50:10.760023: Current learning rate: 0.00752 
2024-05-13 18:50:59.791364: train_loss -0.8415 
2024-05-13 18:50:59.792021: val_loss -0.8403 
2024-05-13 18:50:59.792077: Pseudo dice [0.9165] 
2024-05-13 18:50:59.792131: Epoch time: 49.03 s 
2024-05-13 18:51:00.823652:  
2024-05-13 18:51:00.823822: Epoch 272 
2024-05-13 18:51:00.823990: Current learning rate: 0.00751 
2024-05-13 18:51:49.844354: train_loss -0.8414 
2024-05-13 18:51:49.844534: val_loss -0.8483 
2024-05-13 18:51:49.844613: Pseudo dice [0.9217] 
2024-05-13 18:51:49.844676: Epoch time: 49.02 s 
2024-05-13 18:51:50.837309:  
2024-05-13 18:51:50.837433: Epoch 273 
2024-05-13 18:51:50.837520: Current learning rate: 0.00751 
2024-05-13 18:52:39.882253: train_loss -0.8384 
2024-05-13 18:52:39.882440: val_loss -0.8512 
2024-05-13 18:52:39.882503: Pseudo dice [0.9193] 
2024-05-13 18:52:39.882564: Epoch time: 49.05 s 
2024-05-13 18:52:40.874093:  
2024-05-13 18:52:40.874481: Epoch 274 
2024-05-13 18:52:40.874754: Current learning rate: 0.0075 
2024-05-13 18:53:29.936133: train_loss -0.8412 
2024-05-13 18:53:29.936480: val_loss -0.8386 
2024-05-13 18:53:29.936553: Pseudo dice [0.915] 
2024-05-13 18:53:29.936615: Epoch time: 49.06 s 
2024-05-13 18:53:31.387321:  
2024-05-13 18:53:31.387464: Epoch 275 
2024-05-13 18:53:31.387549: Current learning rate: 0.00749 
2024-05-13 18:54:20.476836: train_loss -0.849 
2024-05-13 18:54:20.477026: val_loss -0.845 
2024-05-13 18:54:20.477088: Pseudo dice [0.9192] 
2024-05-13 18:54:20.477150: Epoch time: 49.09 s 
2024-05-13 18:54:21.481556:  
2024-05-13 18:54:21.481677: Epoch 276 
2024-05-13 18:54:21.481760: Current learning rate: 0.00748 
2024-05-13 18:55:10.548800: train_loss -0.8367 
2024-05-13 18:55:10.548989: val_loss -0.8312 
2024-05-13 18:55:10.549049: Pseudo dice [0.9153] 
2024-05-13 18:55:10.549109: Epoch time: 49.07 s 
2024-05-13 18:55:11.529380:  
2024-05-13 18:55:11.529583: Epoch 277 
2024-05-13 18:55:11.529683: Current learning rate: 0.00747 
2024-05-13 18:56:00.558786: train_loss -0.8272 
2024-05-13 18:56:00.559052: val_loss -0.8257 
2024-05-13 18:56:00.559120: Pseudo dice [0.9122] 
2024-05-13 18:56:00.559178: Epoch time: 49.03 s 
2024-05-13 18:56:01.593589:  
2024-05-13 18:56:01.593813: Epoch 278 
2024-05-13 18:56:01.593903: Current learning rate: 0.00746 
2024-05-13 18:56:50.648597: train_loss -0.8413 
2024-05-13 18:56:50.648758: val_loss -0.8365 
2024-05-13 18:56:50.648815: Pseudo dice [0.9099] 
2024-05-13 18:56:50.648871: Epoch time: 49.06 s 
2024-05-13 18:56:51.663452:  
2024-05-13 18:56:51.663814: Epoch 279 
2024-05-13 18:56:51.663899: Current learning rate: 0.00745 
2024-05-13 18:57:40.737341: train_loss -0.8442 
2024-05-13 18:57:40.737514: val_loss -0.8482 
2024-05-13 18:57:40.737573: Pseudo dice [0.9148] 
2024-05-13 18:57:40.737628: Epoch time: 49.07 s 
2024-05-13 18:57:41.723496:  
2024-05-13 18:57:41.723617: Epoch 280 
2024-05-13 18:57:41.723711: Current learning rate: 0.00744 
2024-05-13 18:58:30.835650: train_loss -0.8451 
2024-05-13 18:58:30.836052: val_loss -0.8534 
2024-05-13 18:58:30.836217: Pseudo dice [0.9214] 
2024-05-13 18:58:30.836360: Epoch time: 49.11 s 
2024-05-13 18:58:31.838927:  
2024-05-13 18:58:31.839047: Epoch 281 
2024-05-13 18:58:31.839131: Current learning rate: 0.00743 
2024-05-13 18:59:20.918580: train_loss -0.8421 
2024-05-13 18:59:20.918762: val_loss -0.8542 
2024-05-13 18:59:20.918822: Pseudo dice [0.9205] 
2024-05-13 18:59:20.919402: Epoch time: 49.08 s 
2024-05-13 18:59:21.917845:  
2024-05-13 18:59:21.918131: Epoch 282 
2024-05-13 18:59:21.918315: Current learning rate: 0.00742 
2024-05-13 19:00:10.922269: train_loss -0.8441 
2024-05-13 19:00:10.922459: val_loss -0.85 
2024-05-13 19:00:10.922518: Pseudo dice [0.9225] 
2024-05-13 19:00:10.922577: Epoch time: 49.01 s 
2024-05-13 19:00:11.899887:  
2024-05-13 19:00:11.900001: Epoch 283 
2024-05-13 19:00:11.900085: Current learning rate: 0.00741 
2024-05-13 19:01:01.010410: train_loss -0.8515 
2024-05-13 19:01:01.010589: val_loss -0.8565 
2024-05-13 19:01:01.010650: Pseudo dice [0.9241] 
2024-05-13 19:01:01.010712: Epoch time: 49.11 s 
2024-05-13 19:01:01.010757: Yayy! New best EMA pseudo Dice: 0.9179 
2024-05-13 19:01:02.337265:  
2024-05-13 19:01:02.337391: Epoch 284 
2024-05-13 19:01:02.337494: Current learning rate: 0.0074 
2024-05-13 19:01:51.423428: train_loss -0.8536 
2024-05-13 19:01:51.424132: val_loss -0.8512 
2024-05-13 19:01:51.424190: Pseudo dice [0.9227] 
2024-05-13 19:01:51.424238: Epoch time: 49.09 s 
2024-05-13 19:01:51.424277: Yayy! New best EMA pseudo Dice: 0.9184 
2024-05-13 19:01:52.767682:  
2024-05-13 19:01:52.767937: Epoch 285 
2024-05-13 19:01:52.768041: Current learning rate: 0.00739 
2024-05-13 19:02:41.798861: train_loss -0.8431 
2024-05-13 19:02:41.799033: val_loss -0.8487 
2024-05-13 19:02:41.799093: Pseudo dice [0.9202] 
2024-05-13 19:02:41.799152: Epoch time: 49.03 s 
2024-05-13 19:02:41.799197: Yayy! New best EMA pseudo Dice: 0.9186 
2024-05-13 19:02:43.586915:  
2024-05-13 19:02:43.587085: Epoch 286 
2024-05-13 19:02:43.587179: Current learning rate: 0.00738 
2024-05-13 19:03:32.738177: train_loss -0.847 
2024-05-13 19:03:32.738351: val_loss -0.8417 
2024-05-13 19:03:32.738420: Pseudo dice [0.9152] 
2024-05-13 19:03:32.738479: Epoch time: 49.15 s 
2024-05-13 19:03:33.730765:  
2024-05-13 19:03:33.730956: Epoch 287 
2024-05-13 19:03:33.731041: Current learning rate: 0.00738 
2024-05-13 19:04:22.803584: train_loss -0.8389 
2024-05-13 19:04:22.804303: val_loss -0.8471 
2024-05-13 19:04:22.804363: Pseudo dice [0.9203] 
2024-05-13 19:04:22.804413: Epoch time: 49.07 s 
2024-05-13 19:04:23.815507:  
2024-05-13 19:04:23.815726: Epoch 288 
2024-05-13 19:04:23.815814: Current learning rate: 0.00737 
2024-05-13 19:05:12.916239: train_loss -0.846 
2024-05-13 19:05:12.916408: val_loss -0.849 
2024-05-13 19:05:12.916471: Pseudo dice [0.9262] 
2024-05-13 19:05:12.916534: Epoch time: 49.1 s 
2024-05-13 19:05:12.916583: Yayy! New best EMA pseudo Dice: 0.9192 
2024-05-13 19:05:14.228689:  
2024-05-13 19:05:14.228896: Epoch 289 
2024-05-13 19:05:14.228998: Current learning rate: 0.00736 
2024-05-13 19:06:03.284869: train_loss -0.8414 
2024-05-13 19:06:03.285040: val_loss -0.8421 
2024-05-13 19:06:03.285118: Pseudo dice [0.9154] 
2024-05-13 19:06:03.285185: Epoch time: 49.06 s 
2024-05-13 19:06:04.275409:  
2024-05-13 19:06:04.275527: Epoch 290 
2024-05-13 19:06:04.275627: Current learning rate: 0.00735 
2024-05-13 19:06:53.328686: train_loss -0.8437 
2024-05-13 19:06:53.328942: val_loss -0.8425 
2024-05-13 19:06:53.329011: Pseudo dice [0.9148] 
2024-05-13 19:06:53.329071: Epoch time: 49.05 s 
2024-05-13 19:06:54.327264:  
2024-05-13 19:06:54.327379: Epoch 291 
2024-05-13 19:06:54.327464: Current learning rate: 0.00734 
2024-05-13 19:07:43.367589: train_loss -0.8349 
2024-05-13 19:07:43.367757: val_loss -0.8562 
2024-05-13 19:07:43.367832: Pseudo dice [0.9241] 
2024-05-13 19:07:43.367891: Epoch time: 49.04 s 
2024-05-13 19:07:44.400179:  
2024-05-13 19:07:44.400291: Epoch 292 
2024-05-13 19:07:44.400398: Current learning rate: 0.00733 
2024-05-13 19:08:33.414272: train_loss -0.8424 
2024-05-13 19:08:33.414456: val_loss -0.8606 
2024-05-13 19:08:33.414532: Pseudo dice [0.9242] 
2024-05-13 19:08:33.414593: Epoch time: 49.01 s 
2024-05-13 19:08:33.414638: Yayy! New best EMA pseudo Dice: 0.9195 
2024-05-13 19:08:34.751728:  
2024-05-13 19:08:34.751853: Epoch 293 
2024-05-13 19:08:34.751947: Current learning rate: 0.00732 
2024-05-13 19:09:23.797147: train_loss -0.8495 
2024-05-13 19:09:23.797458: val_loss -0.8615 
2024-05-13 19:09:23.797537: Pseudo dice [0.9284] 
2024-05-13 19:09:23.797594: Epoch time: 49.05 s 
2024-05-13 19:09:23.797642: Yayy! New best EMA pseudo Dice: 0.9204 
2024-05-13 19:09:25.143871:  
2024-05-13 19:09:25.143975: Epoch 294 
2024-05-13 19:09:25.144068: Current learning rate: 0.00731 
2024-05-13 19:10:14.144056: train_loss -0.8468 
2024-05-13 19:10:14.144208: val_loss -0.851 
2024-05-13 19:10:14.144259: Pseudo dice [0.9206] 
2024-05-13 19:10:14.144307: Epoch time: 49.0 s 
2024-05-13 19:10:14.144346: Yayy! New best EMA pseudo Dice: 0.9204 
2024-05-13 19:10:15.520330:  
2024-05-13 19:10:15.520552: Epoch 295 
2024-05-13 19:10:15.520651: Current learning rate: 0.0073 
2024-05-13 19:11:04.515245: train_loss -0.8556 
2024-05-13 19:11:04.515432: val_loss -0.848 
2024-05-13 19:11:04.515514: Pseudo dice [0.9199] 
2024-05-13 19:11:04.515587: Epoch time: 49.0 s 
2024-05-13 19:11:05.507704:  
2024-05-13 19:11:05.508139: Epoch 296 
2024-05-13 19:11:05.508222: Current learning rate: 0.00729 
2024-05-13 19:11:54.518778: train_loss -0.835 
2024-05-13 19:11:54.519031: val_loss -0.8271 
2024-05-13 19:11:54.519095: Pseudo dice [0.9198] 
2024-05-13 19:11:54.519156: Epoch time: 49.01 s 
2024-05-13 19:11:56.048877:  
2024-05-13 19:11:56.049135: Epoch 297 
2024-05-13 19:11:56.049224: Current learning rate: 0.00728 
2024-05-13 19:12:45.137273: train_loss -0.8429 
2024-05-13 19:12:45.137470: val_loss -0.8494 
2024-05-13 19:12:45.137553: Pseudo dice [0.9191] 
2024-05-13 19:12:45.137626: Epoch time: 49.09 s 
2024-05-13 19:12:46.153644:  
2024-05-13 19:12:46.154034: Epoch 298 
2024-05-13 19:12:46.154120: Current learning rate: 0.00727 
2024-05-13 19:13:35.146940: train_loss -0.848 
2024-05-13 19:13:35.147122: val_loss -0.8349 
2024-05-13 19:13:35.147184: Pseudo dice [0.9128] 
2024-05-13 19:13:35.147244: Epoch time: 48.99 s 
2024-05-13 19:13:36.142649:  
2024-05-13 19:13:36.142990: Epoch 299 
2024-05-13 19:13:36.143079: Current learning rate: 0.00726 
2024-05-13 19:14:25.180326: train_loss -0.8416 
2024-05-13 19:14:25.180986: val_loss -0.8589 
2024-05-13 19:14:25.181047: Pseudo dice [0.9244] 
2024-05-13 19:14:25.181099: Epoch time: 49.04 s 
2024-05-13 19:14:26.500401:  
2024-05-13 19:14:26.500617: Epoch 300 
2024-05-13 19:14:26.500698: Current learning rate: 0.00725 
2024-05-13 19:15:15.573059: train_loss -0.8327 
2024-05-13 19:15:15.573270: val_loss -0.8389 
2024-05-13 19:15:15.573359: Pseudo dice [0.9184] 
2024-05-13 19:15:15.573433: Epoch time: 49.07 s 
2024-05-13 19:15:16.581262:  
2024-05-13 19:15:16.581392: Epoch 301 
2024-05-13 19:15:16.581513: Current learning rate: 0.00724 
2024-05-13 19:16:05.636444: train_loss -0.8217 
2024-05-13 19:16:05.636610: val_loss -0.8139 
2024-05-13 19:16:05.636668: Pseudo dice [0.9029] 
2024-05-13 19:16:05.636724: Epoch time: 49.06 s 
2024-05-13 19:16:06.649590:  
2024-05-13 19:16:06.649933: Epoch 302 
2024-05-13 19:16:06.650020: Current learning rate: 0.00724 
2024-05-13 19:16:55.701734: train_loss -0.8213 
2024-05-13 19:16:55.702413: val_loss -0.8416 
2024-05-13 19:16:55.702493: Pseudo dice [0.9162] 
2024-05-13 19:16:55.702547: Epoch time: 49.05 s 
2024-05-13 19:16:56.708349:  
2024-05-13 19:16:56.708463: Epoch 303 
2024-05-13 19:16:56.708545: Current learning rate: 0.00723 
2024-05-13 19:17:45.689335: train_loss -0.8372 
2024-05-13 19:17:45.689535: val_loss -0.8486 
2024-05-13 19:17:45.689635: Pseudo dice [0.9229] 
2024-05-13 19:17:45.689724: Epoch time: 48.98 s 
2024-05-13 19:17:46.701858:  
2024-05-13 19:17:46.701980: Epoch 304 
2024-05-13 19:17:46.702066: Current learning rate: 0.00722 
2024-05-13 19:18:35.747547: train_loss -0.8377 
2024-05-13 19:18:35.747709: val_loss -0.8297 
2024-05-13 19:18:35.747784: Pseudo dice [0.9086] 
2024-05-13 19:18:35.747866: Epoch time: 49.05 s 
2024-05-13 19:18:36.745818:  
2024-05-13 19:18:36.746133: Epoch 305 
2024-05-13 19:18:36.746260: Current learning rate: 0.00721 
2024-05-13 19:19:25.737407: train_loss -0.8389 
2024-05-13 19:19:25.737564: val_loss -0.8489 
2024-05-13 19:19:25.737620: Pseudo dice [0.9188] 
2024-05-13 19:19:25.738195: Epoch time: 48.99 s 
2024-05-13 19:19:26.733572:  
2024-05-13 19:19:26.733750: Epoch 306 
2024-05-13 19:19:26.733836: Current learning rate: 0.0072 
2024-05-13 19:20:15.759577: train_loss -0.8476 
2024-05-13 19:20:15.759765: val_loss -0.8484 
2024-05-13 19:20:15.759867: Pseudo dice [0.9186] 
2024-05-13 19:20:15.759949: Epoch time: 49.03 s 
2024-05-13 19:20:16.764154:  
2024-05-13 19:20:16.764256: Epoch 307 
2024-05-13 19:20:16.764352: Current learning rate: 0.00719 
2024-05-13 19:21:05.841395: train_loss -0.8354 
2024-05-13 19:21:05.841557: val_loss -0.8491 
2024-05-13 19:21:05.841640: Pseudo dice [0.9172] 
2024-05-13 19:21:05.841696: Epoch time: 49.08 s 
2024-05-13 19:21:07.354709:  
2024-05-13 19:21:07.354832: Epoch 308 
2024-05-13 19:21:07.354916: Current learning rate: 0.00718 
2024-05-13 19:21:56.389265: train_loss -0.8468 
2024-05-13 19:21:56.389507: val_loss -0.8484 
2024-05-13 19:21:56.389580: Pseudo dice [0.9227] 
2024-05-13 19:21:56.389642: Epoch time: 49.04 s 
2024-05-13 19:21:57.406987:  
2024-05-13 19:21:57.407112: Epoch 309 
2024-05-13 19:21:57.407194: Current learning rate: 0.00717 
2024-05-13 19:22:46.508166: train_loss -0.8459 
2024-05-13 19:22:46.508337: val_loss -0.83 
2024-05-13 19:22:46.508395: Pseudo dice [0.9094] 
2024-05-13 19:22:46.508449: Epoch time: 49.1 s 
2024-05-13 19:22:47.537132:  
2024-05-13 19:22:47.537257: Epoch 310 
2024-05-13 19:22:47.537355: Current learning rate: 0.00716 
2024-05-13 19:23:36.560262: train_loss -0.8321 
2024-05-13 19:23:36.560529: val_loss -0.835 
2024-05-13 19:23:36.560596: Pseudo dice [0.9117] 
2024-05-13 19:23:36.560652: Epoch time: 49.02 s 
2024-05-13 19:23:37.550451:  
2024-05-13 19:23:37.550568: Epoch 311 
2024-05-13 19:23:37.550649: Current learning rate: 0.00715 
2024-05-13 19:24:26.556030: train_loss -0.8481 
2024-05-13 19:24:26.556201: val_loss -0.8528 
2024-05-13 19:24:26.556276: Pseudo dice [0.9208] 
2024-05-13 19:24:26.556339: Epoch time: 49.01 s 
2024-05-13 19:24:27.550142:  
2024-05-13 19:24:27.550683: Epoch 312 
2024-05-13 19:24:27.550959: Current learning rate: 0.00714 
2024-05-13 19:25:16.562011: train_loss -0.848 
2024-05-13 19:25:16.562180: val_loss -0.8659 
2024-05-13 19:25:16.562239: Pseudo dice [0.9261] 
2024-05-13 19:25:16.562305: Epoch time: 49.01 s 
2024-05-13 19:25:17.557368:  
2024-05-13 19:25:17.557566: Epoch 313 
2024-05-13 19:25:17.557658: Current learning rate: 0.00713 
2024-05-13 19:26:06.531809: train_loss -0.8522 
2024-05-13 19:26:06.532522: val_loss -0.8655 
2024-05-13 19:26:06.532588: Pseudo dice [0.9309] 
2024-05-13 19:26:06.532639: Epoch time: 48.98 s 
2024-05-13 19:26:07.546944:  
2024-05-13 19:26:07.547152: Epoch 314 
2024-05-13 19:26:07.547238: Current learning rate: 0.00712 
2024-05-13 19:26:56.570802: train_loss -0.8484 
2024-05-13 19:26:56.570989: val_loss -0.8653 
2024-05-13 19:26:56.571050: Pseudo dice [0.928] 
2024-05-13 19:26:56.571108: Epoch time: 49.02 s 
2024-05-13 19:26:57.568636:  
2024-05-13 19:26:57.568926: Epoch 315 
2024-05-13 19:26:57.569101: Current learning rate: 0.00711 
2024-05-13 19:27:46.593186: train_loss -0.8472 
2024-05-13 19:27:46.593379: val_loss -0.8513 
2024-05-13 19:27:46.593441: Pseudo dice [0.9252] 
2024-05-13 19:27:46.593497: Epoch time: 49.03 s 
2024-05-13 19:27:46.593542: Yayy! New best EMA pseudo Dice: 0.9207 
2024-05-13 19:27:47.941618:  
2024-05-13 19:27:47.941752: Epoch 316 
2024-05-13 19:27:47.941844: Current learning rate: 0.0071 
2024-05-13 19:28:36.925122: train_loss -0.8418 
2024-05-13 19:28:36.925810: val_loss -0.8436 
2024-05-13 19:28:36.925867: Pseudo dice [0.9172] 
2024-05-13 19:28:36.925916: Epoch time: 48.98 s 
2024-05-13 19:28:37.919174:  
2024-05-13 19:28:37.919430: Epoch 317 
2024-05-13 19:28:37.919601: Current learning rate: 0.0071 
2024-05-13 19:29:26.937758: train_loss -0.8434 
2024-05-13 19:29:26.937967: val_loss -0.8405 
2024-05-13 19:29:26.938029: Pseudo dice [0.9134] 
2024-05-13 19:29:26.938088: Epoch time: 49.02 s 
2024-05-13 19:29:28.442306:  
2024-05-13 19:29:28.442557: Epoch 318 
2024-05-13 19:29:28.442646: Current learning rate: 0.00709 
2024-05-13 19:30:17.399998: train_loss -0.8444 
2024-05-13 19:30:17.400176: val_loss -0.8362 
2024-05-13 19:30:17.400239: Pseudo dice [0.9161] 
2024-05-13 19:30:17.400296: Epoch time: 48.96 s 
2024-05-13 19:30:18.397478:  
2024-05-13 19:30:18.397695: Epoch 319 
2024-05-13 19:30:18.397787: Current learning rate: 0.00708 
2024-05-13 19:31:07.451894: train_loss -0.8241 
2024-05-13 19:31:07.452060: val_loss -0.837 
2024-05-13 19:31:07.452121: Pseudo dice [0.9148] 
2024-05-13 19:31:07.452179: Epoch time: 49.06 s 
2024-05-13 19:31:08.443988:  
2024-05-13 19:31:08.444351: Epoch 320 
2024-05-13 19:31:08.444438: Current learning rate: 0.00707 
2024-05-13 19:31:57.509540: train_loss -0.8222 
2024-05-13 19:31:57.510192: val_loss -0.8302 
2024-05-13 19:31:57.510251: Pseudo dice [0.915] 
2024-05-13 19:31:57.510310: Epoch time: 49.07 s 
2024-05-13 19:31:58.522293:  
2024-05-13 19:31:58.522497: Epoch 321 
2024-05-13 19:31:58.522583: Current learning rate: 0.00706 
2024-05-13 19:32:47.538739: train_loss -0.83 
2024-05-13 19:32:47.538913: val_loss -0.8501 
2024-05-13 19:32:47.538993: Pseudo dice [0.9232] 
2024-05-13 19:32:47.539052: Epoch time: 49.02 s 
2024-05-13 19:32:48.547581:  
2024-05-13 19:32:48.547706: Epoch 322 
2024-05-13 19:32:48.547804: Current learning rate: 0.00705 
2024-05-13 19:33:37.570188: train_loss -0.8311 
2024-05-13 19:33:37.570393: val_loss -0.8443 
2024-05-13 19:33:37.570457: Pseudo dice [0.9151] 
2024-05-13 19:33:37.570515: Epoch time: 49.02 s 
2024-05-13 19:33:38.587009:  
2024-05-13 19:33:38.587433: Epoch 323 
2024-05-13 19:33:38.587523: Current learning rate: 0.00704 
2024-05-13 19:34:27.601678: train_loss -0.8257 
2024-05-13 19:34:27.602533: val_loss -0.8267 
2024-05-13 19:34:27.602744: Pseudo dice [0.912] 
2024-05-13 19:34:27.602908: Epoch time: 49.02 s 
2024-05-13 19:34:28.648028:  
2024-05-13 19:34:28.648263: Epoch 324 
2024-05-13 19:34:28.648346: Current learning rate: 0.00703 
2024-05-13 19:35:17.779807: train_loss -0.8312 
2024-05-13 19:35:17.779962: val_loss -0.8509 
2024-05-13 19:35:17.780021: Pseudo dice [0.9205] 
2024-05-13 19:35:17.780093: Epoch time: 49.13 s 
2024-05-13 19:35:18.859950:  
2024-05-13 19:35:18.860060: Epoch 325 
2024-05-13 19:35:18.860141: Current learning rate: 0.00702 
2024-05-13 19:36:07.818063: train_loss -0.8396 
2024-05-13 19:36:07.818241: val_loss -0.8485 
2024-05-13 19:36:07.818308: Pseudo dice [0.9244] 
2024-05-13 19:36:07.818368: Epoch time: 48.96 s 
2024-05-13 19:36:08.824436:  
2024-05-13 19:36:08.824549: Epoch 326 
2024-05-13 19:36:08.824632: Current learning rate: 0.00701 
2024-05-13 19:36:57.814867: train_loss -0.8211 
2024-05-13 19:36:57.815119: val_loss -0.8351 
2024-05-13 19:36:57.815189: Pseudo dice [0.9149] 
2024-05-13 19:36:57.815251: Epoch time: 48.99 s 
2024-05-13 19:36:58.845258:  
2024-05-13 19:36:58.845571: Epoch 327 
2024-05-13 19:36:58.845749: Current learning rate: 0.007 
2024-05-13 19:37:47.853164: train_loss -0.8157 
2024-05-13 19:37:47.853346: val_loss -0.8177 
2024-05-13 19:37:47.853413: Pseudo dice [0.9061] 
2024-05-13 19:37:47.853492: Epoch time: 49.01 s 
2024-05-13 19:37:48.867475:  
2024-05-13 19:37:48.867807: Epoch 328 
2024-05-13 19:37:48.867909: Current learning rate: 0.00699 
2024-05-13 19:38:37.899716: train_loss -0.8205 
2024-05-13 19:38:37.899928: val_loss -0.8248 
2024-05-13 19:38:37.900002: Pseudo dice [0.9113] 
2024-05-13 19:38:37.900082: Epoch time: 49.03 s 
2024-05-13 19:38:39.418594:  
2024-05-13 19:38:39.418728: Epoch 329 
2024-05-13 19:38:39.418826: Current learning rate: 0.00698 
2024-05-13 19:39:28.353004: train_loss -0.8177 
2024-05-13 19:39:28.353359: val_loss -0.8155 
2024-05-13 19:39:28.353425: Pseudo dice [0.8988] 
2024-05-13 19:39:28.353482: Epoch time: 48.94 s 
2024-05-13 19:39:29.371250:  
2024-05-13 19:39:29.371627: Epoch 330 
2024-05-13 19:39:29.371716: Current learning rate: 0.00697 
2024-05-13 19:40:18.393871: train_loss -0.8233 
2024-05-13 19:40:18.394040: val_loss -0.8331 
2024-05-13 19:40:18.394117: Pseudo dice [0.915] 
2024-05-13 19:40:18.394173: Epoch time: 49.02 s 
2024-05-13 19:40:19.411063:  
2024-05-13 19:40:19.411387: Epoch 331 
2024-05-13 19:40:19.411643: Current learning rate: 0.00696 
2024-05-13 19:41:08.461903: train_loss -0.8311 
2024-05-13 19:41:08.462076: val_loss -0.8403 
2024-05-13 19:41:08.462150: Pseudo dice [0.9173] 
2024-05-13 19:41:08.462212: Epoch time: 49.05 s 
2024-05-13 19:41:09.454262:  
2024-05-13 19:41:09.454633: Epoch 332 
2024-05-13 19:41:09.454723: Current learning rate: 0.00696 
2024-05-13 19:41:58.482433: train_loss -0.8421 
2024-05-13 19:41:58.482609: val_loss -0.8357 
2024-05-13 19:41:58.482669: Pseudo dice [0.9154] 
2024-05-13 19:41:58.482730: Epoch time: 49.03 s 
2024-05-13 19:41:59.512089:  
2024-05-13 19:41:59.512464: Epoch 333 
2024-05-13 19:41:59.512556: Current learning rate: 0.00695 
2024-05-13 19:42:48.540809: train_loss -0.8502 
2024-05-13 19:42:48.541537: val_loss -0.8626 
2024-05-13 19:42:48.541599: Pseudo dice [0.9273] 
2024-05-13 19:42:48.541649: Epoch time: 49.03 s 
2024-05-13 19:42:49.562899:  
2024-05-13 19:42:49.563015: Epoch 334 
2024-05-13 19:42:49.563099: Current learning rate: 0.00694 
2024-05-13 19:43:38.582423: train_loss -0.8452 
2024-05-13 19:43:38.582590: val_loss -0.8621 
2024-05-13 19:43:38.582649: Pseudo dice [0.9245] 
2024-05-13 19:43:38.582705: Epoch time: 49.02 s 
2024-05-13 19:43:39.620465:  
2024-05-13 19:43:39.620711: Epoch 335 
2024-05-13 19:43:39.620799: Current learning rate: 0.00693 
2024-05-13 19:44:28.673473: train_loss -0.8478 
2024-05-13 19:44:28.673657: val_loss -0.8395 
2024-05-13 19:44:28.673723: Pseudo dice [0.9138] 
2024-05-13 19:44:28.673784: Epoch time: 49.05 s 
2024-05-13 19:44:29.728999:  
2024-05-13 19:44:29.729113: Epoch 336 
2024-05-13 19:44:29.729196: Current learning rate: 0.00692 
2024-05-13 19:45:18.825472: train_loss -0.8504 
2024-05-13 19:45:18.825727: val_loss -0.8468 
2024-05-13 19:45:18.825794: Pseudo dice [0.9258] 
2024-05-13 19:45:18.825854: Epoch time: 49.1 s 
2024-05-13 19:45:19.836416:  
2024-05-13 19:45:19.836533: Epoch 337 
2024-05-13 19:45:19.836642: Current learning rate: 0.00691 
2024-05-13 19:46:08.877181: train_loss -0.8474 
2024-05-13 19:46:08.877339: val_loss -0.8517 
2024-05-13 19:46:08.877396: Pseudo dice [0.9241] 
2024-05-13 19:46:08.877450: Epoch time: 49.04 s 
2024-05-13 19:46:09.905231:  
2024-05-13 19:46:09.905352: Epoch 338 
2024-05-13 19:46:09.905440: Current learning rate: 0.0069 
2024-05-13 19:46:58.953134: train_loss -0.8418 
2024-05-13 19:46:58.953322: val_loss -0.8365 
2024-05-13 19:46:58.953382: Pseudo dice [0.9191] 
2024-05-13 19:46:58.953441: Epoch time: 49.05 s 
2024-05-13 19:47:00.322196:  
2024-05-13 19:47:00.322444: Epoch 339 
2024-05-13 19:47:00.322532: Current learning rate: 0.00689 
2024-05-13 19:47:49.340856: train_loss -0.8394 
2024-05-13 19:47:49.341044: val_loss -0.8385 
2024-05-13 19:47:49.341108: Pseudo dice [0.9215] 
2024-05-13 19:47:49.341167: Epoch time: 49.02 s 
2024-05-13 19:47:50.354288:  
2024-05-13 19:47:50.354539: Epoch 340 
2024-05-13 19:47:50.354622: Current learning rate: 0.00688 
2024-05-13 19:48:39.404929: train_loss -0.8484 
2024-05-13 19:48:39.405174: val_loss -0.8297 
2024-05-13 19:48:39.405240: Pseudo dice [0.9151] 
2024-05-13 19:48:39.405300: Epoch time: 49.05 s 
2024-05-13 19:48:40.415217:  
2024-05-13 19:48:40.415347: Epoch 341 
2024-05-13 19:48:40.415430: Current learning rate: 0.00687 
2024-05-13 19:49:29.406264: train_loss -0.8478 
2024-05-13 19:49:29.406468: val_loss -0.8602 
2024-05-13 19:49:29.406529: Pseudo dice [0.9277] 
2024-05-13 19:49:29.406587: Epoch time: 48.99 s 
2024-05-13 19:49:30.438371:  
2024-05-13 19:49:30.438603: Epoch 342 
2024-05-13 19:49:30.438690: Current learning rate: 0.00686 
2024-05-13 19:50:19.481159: train_loss -0.8551 
2024-05-13 19:50:19.481348: val_loss -0.8569 
2024-05-13 19:50:19.481421: Pseudo dice [0.9284] 
2024-05-13 19:50:19.481496: Epoch time: 49.04 s 
2024-05-13 19:50:20.548597:  
2024-05-13 19:50:20.548894: Epoch 343 
2024-05-13 19:50:20.549105: Current learning rate: 0.00685 
2024-05-13 19:51:09.526452: train_loss -0.8495 
2024-05-13 19:51:09.527115: val_loss -0.842 
2024-05-13 19:51:09.527179: Pseudo dice [0.919] 
2024-05-13 19:51:09.527314: Epoch time: 48.98 s 
2024-05-13 19:51:10.575451:  
2024-05-13 19:51:10.575651: Epoch 344 
2024-05-13 19:51:10.575737: Current learning rate: 0.00684 
2024-05-13 19:51:59.621596: train_loss -0.848 
2024-05-13 19:51:59.621769: val_loss -0.8539 
2024-05-13 19:51:59.621827: Pseudo dice [0.9228] 
2024-05-13 19:51:59.621888: Epoch time: 49.05 s 
2024-05-13 19:52:00.680282:  
2024-05-13 19:52:00.680533: Epoch 345 
2024-05-13 19:52:00.680616: Current learning rate: 0.00683 
2024-05-13 19:52:49.746536: train_loss -0.8472 
2024-05-13 19:52:49.746708: val_loss -0.8402 
2024-05-13 19:52:49.746769: Pseudo dice [0.9135] 
2024-05-13 19:52:49.746829: Epoch time: 49.07 s 
2024-05-13 19:52:50.782135:  
2024-05-13 19:52:50.782427: Epoch 346 
2024-05-13 19:52:50.782780: Current learning rate: 0.00682 
2024-05-13 19:53:39.801754: train_loss -0.8487 
2024-05-13 19:53:39.802065: val_loss -0.8524 
2024-05-13 19:53:39.802129: Pseudo dice [0.92] 
2024-05-13 19:53:39.802186: Epoch time: 49.02 s 
2024-05-13 19:53:40.831373:  
2024-05-13 19:53:40.831624: Epoch 347 
2024-05-13 19:53:40.831713: Current learning rate: 0.00681 
2024-05-13 19:54:29.857195: train_loss -0.8507 
2024-05-13 19:54:29.857364: val_loss -0.8615 
2024-05-13 19:54:29.857421: Pseudo dice [0.9275] 
2024-05-13 19:54:29.857477: Epoch time: 49.03 s 
2024-05-13 19:54:30.871500:  
2024-05-13 19:54:30.871608: Epoch 348 
2024-05-13 19:54:30.871695: Current learning rate: 0.0068 
2024-05-13 19:55:19.940840: train_loss -0.8569 
2024-05-13 19:55:19.941012: val_loss -0.8631 
2024-05-13 19:55:19.941071: Pseudo dice [0.9278] 
2024-05-13 19:55:19.941127: Epoch time: 49.07 s 
2024-05-13 19:55:19.941171: Yayy! New best EMA pseudo Dice: 0.9212 
2024-05-13 19:55:21.314000:  
2024-05-13 19:55:21.314234: Epoch 349 
2024-05-13 19:55:21.314357: Current learning rate: 0.0068 
2024-05-13 19:56:10.404713: train_loss -0.8305 
2024-05-13 19:56:10.405382: val_loss -0.8559 
2024-05-13 19:56:10.405445: Pseudo dice [0.9233] 
2024-05-13 19:56:10.405494: Epoch time: 49.09 s 
2024-05-13 19:56:11.151593: Yayy! New best EMA pseudo Dice: 0.9214 
2024-05-13 19:56:12.517337:  
2024-05-13 19:56:12.517626: Epoch 350 
2024-05-13 19:56:12.517716: Current learning rate: 0.00679 
2024-05-13 19:57:01.519538: train_loss -0.8461 
2024-05-13 19:57:01.519742: val_loss -0.8588 
2024-05-13 19:57:01.519802: Pseudo dice [0.9267] 
2024-05-13 19:57:01.519863: Epoch time: 49.0 s 
2024-05-13 19:57:01.519910: Yayy! New best EMA pseudo Dice: 0.9219 
2024-05-13 19:57:02.912820:  
2024-05-13 19:57:02.913056: Epoch 351 
2024-05-13 19:57:02.913148: Current learning rate: 0.00678 
2024-05-13 19:57:51.931554: train_loss -0.8479 
2024-05-13 19:57:51.931723: val_loss -0.8545 
2024-05-13 19:57:51.931781: Pseudo dice [0.9226] 
2024-05-13 19:57:51.931836: Epoch time: 49.02 s 
2024-05-13 19:57:51.931879: Yayy! New best EMA pseudo Dice: 0.922 
2024-05-13 19:57:53.320744:  
2024-05-13 19:57:53.320963: Epoch 352 
2024-05-13 19:57:53.321051: Current learning rate: 0.00677 
2024-05-13 19:58:42.335170: train_loss -0.8531 
2024-05-13 19:58:42.335455: val_loss -0.8414 
2024-05-13 19:58:42.335520: Pseudo dice [0.9238] 
2024-05-13 19:58:42.335578: Epoch time: 49.02 s 
2024-05-13 19:58:42.335625: Yayy! New best EMA pseudo Dice: 0.9222 
2024-05-13 19:58:43.762607:  
2024-05-13 19:58:43.762724: Epoch 353 
2024-05-13 19:58:43.762807: Current learning rate: 0.00676 
2024-05-13 19:59:32.827806: train_loss -0.8569 
2024-05-13 19:59:32.827991: val_loss -0.8675 
2024-05-13 19:59:32.828051: Pseudo dice [0.9302] 
2024-05-13 19:59:32.828112: Epoch time: 49.07 s 
2024-05-13 19:59:32.828157: Yayy! New best EMA pseudo Dice: 0.923 
2024-05-13 19:59:34.198364:  
2024-05-13 19:59:34.198480: Epoch 354 
2024-05-13 19:59:34.198563: Current learning rate: 0.00675 
2024-05-13 20:00:23.191544: train_loss -0.856 
2024-05-13 20:00:23.191705: val_loss -0.8544 
2024-05-13 20:00:23.191761: Pseudo dice [0.9207] 
2024-05-13 20:00:23.191833: Epoch time: 48.99 s 
2024-05-13 20:00:24.203484:  
2024-05-13 20:00:24.203749: Epoch 355 
2024-05-13 20:00:24.203840: Current learning rate: 0.00674 
2024-05-13 20:01:13.186581: train_loss -0.848 
2024-05-13 20:01:13.186759: val_loss -0.8565 
2024-05-13 20:01:13.186820: Pseudo dice [0.9229] 
2024-05-13 20:01:13.186878: Epoch time: 48.98 s 
2024-05-13 20:01:14.207358:  
2024-05-13 20:01:14.207471: Epoch 356 
2024-05-13 20:01:14.207554: Current learning rate: 0.00673 
2024-05-13 20:02:03.259356: train_loss -0.8405 
2024-05-13 20:02:03.259560: val_loss -0.8491 
2024-05-13 20:02:03.259619: Pseudo dice [0.9228] 
2024-05-13 20:02:03.259676: Epoch time: 49.05 s 
2024-05-13 20:02:04.290845:  
2024-05-13 20:02:04.291075: Epoch 357 
2024-05-13 20:02:04.291166: Current learning rate: 0.00672 
2024-05-13 20:02:53.318694: train_loss -0.8424 
2024-05-13 20:02:53.319370: val_loss -0.8449 
2024-05-13 20:02:53.319431: Pseudo dice [0.922] 
2024-05-13 20:02:53.319482: Epoch time: 49.03 s 
2024-05-13 20:02:54.369855:  
2024-05-13 20:02:54.370088: Epoch 358 
2024-05-13 20:02:54.370175: Current learning rate: 0.00671 
2024-05-13 20:03:43.330692: train_loss -0.8541 
2024-05-13 20:03:43.330865: val_loss -0.8553 
2024-05-13 20:03:43.330925: Pseudo dice [0.9177] 
2024-05-13 20:03:43.330983: Epoch time: 48.96 s 
2024-05-13 20:03:44.386892:  
2024-05-13 20:03:44.387005: Epoch 359 
2024-05-13 20:03:44.387093: Current learning rate: 0.0067 
2024-05-13 20:04:33.346038: train_loss -0.8538 
2024-05-13 20:04:33.346221: val_loss -0.8689 
2024-05-13 20:04:33.346304: Pseudo dice [0.9289] 
2024-05-13 20:04:33.346367: Epoch time: 48.96 s 
2024-05-13 20:04:34.757934:  
2024-05-13 20:04:34.758059: Epoch 360 
2024-05-13 20:04:34.758159: Current learning rate: 0.00669 
2024-05-13 20:05:23.783272: train_loss -0.857 
2024-05-13 20:05:23.783984: val_loss -0.8567 
2024-05-13 20:05:23.784044: Pseudo dice [0.9217] 
2024-05-13 20:05:23.784095: Epoch time: 49.03 s 
2024-05-13 20:05:24.803315:  
2024-05-13 20:05:24.803448: Epoch 361 
2024-05-13 20:05:24.803541: Current learning rate: 0.00668 
2024-05-13 20:06:13.849575: train_loss -0.8502 
2024-05-13 20:06:13.849761: val_loss -0.8553 
2024-05-13 20:06:13.849821: Pseudo dice [0.9258] 
2024-05-13 20:06:13.849878: Epoch time: 49.05 s 
2024-05-13 20:06:13.849922: Yayy! New best EMA pseudo Dice: 0.9231 
2024-05-13 20:06:15.194436:  
2024-05-13 20:06:15.194555: Epoch 362 
2024-05-13 20:06:15.194642: Current learning rate: 0.00667 
2024-05-13 20:07:04.242668: train_loss -0.8531 
2024-05-13 20:07:04.242842: val_loss -0.8673 
2024-05-13 20:07:04.242901: Pseudo dice [0.9225] 
2024-05-13 20:07:04.242959: Epoch time: 49.05 s 
2024-05-13 20:07:05.266870:  
2024-05-13 20:07:05.266987: Epoch 363 
2024-05-13 20:07:05.267070: Current learning rate: 0.00666 
2024-05-13 20:07:54.312075: train_loss -0.8502 
2024-05-13 20:07:54.312362: val_loss -0.8591 
2024-05-13 20:07:54.312432: Pseudo dice [0.9243] 
2024-05-13 20:07:54.312501: Epoch time: 49.05 s 
2024-05-13 20:07:54.312550: Yayy! New best EMA pseudo Dice: 0.9231 
2024-05-13 20:07:55.657528:  
2024-05-13 20:07:55.657638: Epoch 364 
2024-05-13 20:07:55.657734: Current learning rate: 0.00665 
2024-05-13 20:08:44.744004: train_loss -0.8521 
2024-05-13 20:08:44.744170: val_loss -0.8527 
2024-05-13 20:08:44.744228: Pseudo dice [0.9271] 
2024-05-13 20:08:44.744300: Epoch time: 49.09 s 
2024-05-13 20:08:44.744345: Yayy! New best EMA pseudo Dice: 0.9235 
2024-05-13 20:08:46.120148:  
2024-05-13 20:08:46.120273: Epoch 365 
2024-05-13 20:08:46.120355: Current learning rate: 0.00665 
2024-05-13 20:09:35.197754: train_loss -0.8587 
2024-05-13 20:09:35.197969: val_loss -0.8576 
2024-05-13 20:09:35.198029: Pseudo dice [0.9226] 
2024-05-13 20:09:35.198086: Epoch time: 49.08 s 
2024-05-13 20:09:36.242896:  
2024-05-13 20:09:36.243151: Epoch 366 
2024-05-13 20:09:36.243239: Current learning rate: 0.00664 
2024-05-13 20:10:25.279938: train_loss -0.8463 
2024-05-13 20:10:25.280282: val_loss -0.8612 
2024-05-13 20:10:25.280366: Pseudo dice [0.9252] 
2024-05-13 20:10:25.280424: Epoch time: 49.04 s 
2024-05-13 20:10:25.280470: Yayy! New best EMA pseudo Dice: 0.9236 
2024-05-13 20:10:26.660125:  
2024-05-13 20:10:26.660235: Epoch 367 
2024-05-13 20:10:26.660355: Current learning rate: 0.00663 
2024-05-13 20:11:15.699134: train_loss -0.848 
2024-05-13 20:11:15.699332: val_loss -0.8497 
2024-05-13 20:11:15.699400: Pseudo dice [0.9202] 
2024-05-13 20:11:15.699459: Epoch time: 49.04 s 
2024-05-13 20:11:16.737441:  
2024-05-13 20:11:16.737633: Epoch 368 
2024-05-13 20:11:16.737721: Current learning rate: 0.00662 
2024-05-13 20:12:05.688666: train_loss -0.8559 
2024-05-13 20:12:05.688857: val_loss -0.8553 
2024-05-13 20:12:05.688918: Pseudo dice [0.9281] 
2024-05-13 20:12:05.688976: Epoch time: 48.95 s 
2024-05-13 20:12:05.689021: Yayy! New best EMA pseudo Dice: 0.9238 
2024-05-13 20:12:07.494088:  
2024-05-13 20:12:07.494217: Epoch 369 
2024-05-13 20:12:07.494308: Current learning rate: 0.00661 
2024-05-13 20:12:56.526577: train_loss -0.8497 
2024-05-13 20:12:56.527266: val_loss -0.8706 
2024-05-13 20:12:56.527325: Pseudo dice [0.9305] 
2024-05-13 20:12:56.527376: Epoch time: 49.03 s 
2024-05-13 20:12:56.527415: Yayy! New best EMA pseudo Dice: 0.9244 
2024-05-13 20:12:57.901576:  
2024-05-13 20:12:57.901697: Epoch 370 
2024-05-13 20:12:57.901795: Current learning rate: 0.0066 
2024-05-13 20:13:46.925673: train_loss -0.8477 
2024-05-13 20:13:46.925850: val_loss -0.8549 
2024-05-13 20:13:46.925911: Pseudo dice [0.9272] 
2024-05-13 20:13:46.925969: Epoch time: 49.02 s 
2024-05-13 20:13:46.926018: Yayy! New best EMA pseudo Dice: 0.9247 
2024-05-13 20:13:48.294165:  
2024-05-13 20:13:48.294453: Epoch 371 
2024-05-13 20:13:48.294714: Current learning rate: 0.00659 
2024-05-13 20:14:37.363450: train_loss -0.8425 
2024-05-13 20:14:37.363637: val_loss -0.8293 
2024-05-13 20:14:37.363700: Pseudo dice [0.9183] 
2024-05-13 20:14:37.363762: Epoch time: 49.07 s 
2024-05-13 20:14:38.428211:  
2024-05-13 20:14:38.428331: Epoch 372 
2024-05-13 20:14:38.428416: Current learning rate: 0.00658 
2024-05-13 20:15:27.507246: train_loss -0.8528 
2024-05-13 20:15:27.507529: val_loss -0.8628 
2024-05-13 20:15:27.507596: Pseudo dice [0.9297] 
2024-05-13 20:15:27.507654: Epoch time: 49.08 s 
2024-05-13 20:15:28.616370:  
2024-05-13 20:15:28.616485: Epoch 373 
2024-05-13 20:15:28.616566: Current learning rate: 0.00657 
2024-05-13 20:16:17.668941: train_loss -0.8523 
2024-05-13 20:16:17.669109: val_loss -0.8583 
2024-05-13 20:16:17.669168: Pseudo dice [0.9262] 
2024-05-13 20:16:17.669224: Epoch time: 49.05 s 
2024-05-13 20:16:17.669273: Yayy! New best EMA pseudo Dice: 0.9248 
2024-05-13 20:16:19.057088:  
2024-05-13 20:16:19.057341: Epoch 374 
2024-05-13 20:16:19.057446: Current learning rate: 0.00656 
2024-05-13 20:17:08.089092: train_loss -0.8548 
2024-05-13 20:17:08.089270: val_loss -0.845 
2024-05-13 20:17:08.089389: Pseudo dice [0.9192] 
2024-05-13 20:17:08.089472: Epoch time: 49.03 s 
2024-05-13 20:17:09.139845:  
2024-05-13 20:17:09.140206: Epoch 375 
2024-05-13 20:17:09.140298: Current learning rate: 0.00655 
2024-05-13 20:17:58.189432: train_loss -0.8532 
2024-05-13 20:17:58.190088: val_loss -0.8616 
2024-05-13 20:17:58.190145: Pseudo dice [0.9272] 
2024-05-13 20:17:58.190193: Epoch time: 49.05 s 
2024-05-13 20:17:59.213234:  
2024-05-13 20:17:59.213443: Epoch 376 
2024-05-13 20:17:59.213544: Current learning rate: 0.00654 
2024-05-13 20:18:48.199919: train_loss -0.8484 
2024-05-13 20:18:48.200090: val_loss -0.8497 
2024-05-13 20:18:48.200150: Pseudo dice [0.9194] 
2024-05-13 20:18:48.200206: Epoch time: 48.99 s 
2024-05-13 20:18:49.220696:  
2024-05-13 20:18:49.220931: Epoch 377 
2024-05-13 20:18:49.221020: Current learning rate: 0.00653 
2024-05-13 20:19:38.211021: train_loss -0.8389 
2024-05-13 20:19:38.211303: val_loss -0.843 
2024-05-13 20:19:38.211364: Pseudo dice [0.9148] 
2024-05-13 20:19:38.211421: Epoch time: 48.99 s 
2024-05-13 20:19:39.245851:  
2024-05-13 20:19:39.246020: Epoch 378 
2024-05-13 20:19:39.246113: Current learning rate: 0.00652 
2024-05-13 20:20:28.147488: train_loss -0.8315 
2024-05-13 20:20:28.147802: val_loss -0.846 
2024-05-13 20:20:28.147886: Pseudo dice [0.9184] 
2024-05-13 20:20:28.147946: Epoch time: 48.9 s 
2024-05-13 20:20:29.169494:  
2024-05-13 20:20:29.169697: Epoch 379 
2024-05-13 20:20:29.169865: Current learning rate: 0.00651 
2024-05-13 20:21:18.137304: train_loss -0.8488 
2024-05-13 20:21:18.137472: val_loss -0.8447 
2024-05-13 20:21:18.137532: Pseudo dice [0.9219] 
2024-05-13 20:21:18.137588: Epoch time: 48.97 s 
2024-05-13 20:21:19.661941:  
2024-05-13 20:21:19.662143: Epoch 380 
2024-05-13 20:21:19.662248: Current learning rate: 0.0065 
2024-05-13 20:22:08.696174: train_loss -0.8524 
2024-05-13 20:22:08.696363: val_loss -0.8534 
2024-05-13 20:22:08.696442: Pseudo dice [0.9232] 
2024-05-13 20:22:08.696511: Epoch time: 49.04 s 
2024-05-13 20:22:09.718290:  
2024-05-13 20:22:09.718607: Epoch 381 
2024-05-13 20:22:09.718821: Current learning rate: 0.00649 
2024-05-13 20:22:58.663660: train_loss -0.8555 
2024-05-13 20:22:58.663918: val_loss -0.8588 
2024-05-13 20:22:58.663977: Pseudo dice [0.928] 
2024-05-13 20:22:58.664027: Epoch time: 48.95 s 
2024-05-13 20:22:59.705377:  
2024-05-13 20:22:59.705499: Epoch 382 
2024-05-13 20:22:59.705582: Current learning rate: 0.00648 
2024-05-13 20:23:48.725224: train_loss -0.8379 
2024-05-13 20:23:48.725413: val_loss -0.843 
2024-05-13 20:23:48.725474: Pseudo dice [0.9146] 
2024-05-13 20:23:48.725531: Epoch time: 49.02 s 
2024-05-13 20:23:49.767986:  
2024-05-13 20:23:49.768119: Epoch 383 
2024-05-13 20:23:49.768199: Current learning rate: 0.00648 
2024-05-13 20:24:38.778064: train_loss -0.8217 
2024-05-13 20:24:38.778243: val_loss -0.8555 
2024-05-13 20:24:38.778311: Pseudo dice [0.9212] 
2024-05-13 20:24:38.778386: Epoch time: 49.01 s 
2024-05-13 20:24:39.819989:  
2024-05-13 20:24:39.820113: Epoch 384 
2024-05-13 20:24:39.820198: Current learning rate: 0.00647 
2024-05-13 20:25:28.847171: train_loss -0.8321 
2024-05-13 20:25:28.847888: val_loss -0.8175 
2024-05-13 20:25:28.847948: Pseudo dice [0.9044] 
2024-05-13 20:25:28.848003: Epoch time: 49.03 s 
2024-05-13 20:25:29.928806:  
2024-05-13 20:25:29.929055: Epoch 385 
2024-05-13 20:25:29.929161: Current learning rate: 0.00646 
2024-05-13 20:26:18.922306: train_loss -0.8393 
2024-05-13 20:26:18.922656: val_loss -0.8439 
2024-05-13 20:26:18.922720: Pseudo dice [0.9196] 
2024-05-13 20:26:18.922778: Epoch time: 48.99 s 
2024-05-13 20:26:19.963299:  
2024-05-13 20:26:19.963462: Epoch 386 
2024-05-13 20:26:19.963600: Current learning rate: 0.00645 
2024-05-13 20:27:08.967220: train_loss -0.8421 
2024-05-13 20:27:08.967391: val_loss -0.858 
2024-05-13 20:27:08.967450: Pseudo dice [0.9285] 
2024-05-13 20:27:08.967509: Epoch time: 49.01 s 
2024-05-13 20:27:10.047695:  
2024-05-13 20:27:10.047801: Epoch 387 
2024-05-13 20:27:10.047897: Current learning rate: 0.00644 
2024-05-13 20:27:59.072412: train_loss -0.8559 
2024-05-13 20:27:59.073070: val_loss -0.854 
2024-05-13 20:27:59.073129: Pseudo dice [0.9254] 
2024-05-13 20:27:59.073179: Epoch time: 49.03 s 
2024-05-13 20:28:00.132365:  
2024-05-13 20:28:00.132482: Epoch 388 
2024-05-13 20:28:00.132565: Current learning rate: 0.00643 
2024-05-13 20:28:49.102572: train_loss -0.8575 
2024-05-13 20:28:49.102863: val_loss -0.8549 
2024-05-13 20:28:49.102927: Pseudo dice [0.9254] 
2024-05-13 20:28:49.102986: Epoch time: 48.97 s 
2024-05-13 20:28:50.132358:  
2024-05-13 20:28:50.132694: Epoch 389 
2024-05-13 20:28:50.132783: Current learning rate: 0.00642 
2024-05-13 20:29:39.136007: train_loss -0.8545 
2024-05-13 20:29:39.136182: val_loss -0.846 
2024-05-13 20:29:39.136261: Pseudo dice [0.9189] 
2024-05-13 20:29:39.136321: Epoch time: 49.0 s 
2024-05-13 20:29:40.700685:  
2024-05-13 20:29:40.700902: Epoch 390 
2024-05-13 20:29:40.700988: Current learning rate: 0.00641 
2024-05-13 20:30:29.921554: train_loss -0.8341 
2024-05-13 20:30:29.922230: val_loss -0.8355 
2024-05-13 20:30:29.922306: Pseudo dice [0.916] 
2024-05-13 20:30:29.922368: Epoch time: 49.22 s 
2024-05-13 20:30:30.983579:  
2024-05-13 20:30:30.983818: Epoch 391 
2024-05-13 20:30:30.983906: Current learning rate: 0.0064 
2024-05-13 20:31:20.020010: train_loss -0.8315 
2024-05-13 20:31:20.020178: val_loss -0.864 
2024-05-13 20:31:20.020238: Pseudo dice [0.9251] 
2024-05-13 20:31:20.020295: Epoch time: 49.04 s 
2024-05-13 20:31:21.071306:  
2024-05-13 20:31:21.071438: Epoch 392 
2024-05-13 20:31:21.071529: Current learning rate: 0.00639 
2024-05-13 20:32:10.157166: train_loss -0.8468 
2024-05-13 20:32:10.157387: val_loss -0.8356 
2024-05-13 20:32:10.157447: Pseudo dice [0.9154] 
2024-05-13 20:32:10.157522: Epoch time: 49.09 s 
2024-05-13 20:32:11.195559:  
2024-05-13 20:32:11.195687: Epoch 393 
2024-05-13 20:32:11.195789: Current learning rate: 0.00638 
2024-05-13 20:33:00.201705: train_loss -0.8391 
2024-05-13 20:33:00.201894: val_loss -0.8529 
2024-05-13 20:33:00.201970: Pseudo dice [0.9216] 
2024-05-13 20:33:00.202034: Epoch time: 49.01 s 
2024-05-13 20:33:01.243825:  
2024-05-13 20:33:01.243952: Epoch 394 
2024-05-13 20:33:01.244036: Current learning rate: 0.00637 
2024-05-13 20:33:50.262414: train_loss -0.844 
2024-05-13 20:33:50.262704: val_loss -0.8635 
2024-05-13 20:33:50.262774: Pseudo dice [0.9306] 
2024-05-13 20:33:50.262834: Epoch time: 49.02 s 
2024-05-13 20:33:51.314058:  
2024-05-13 20:33:51.314166: Epoch 395 
2024-05-13 20:33:51.314259: Current learning rate: 0.00636 
2024-05-13 20:34:40.298385: train_loss -0.8524 
2024-05-13 20:34:40.298558: val_loss -0.8559 
2024-05-13 20:34:40.298623: Pseudo dice [0.9291] 
2024-05-13 20:34:40.298679: Epoch time: 48.99 s 
2024-05-13 20:34:41.366732:  
2024-05-13 20:34:41.366848: Epoch 396 
2024-05-13 20:34:41.366933: Current learning rate: 0.00635 
2024-05-13 20:35:30.495050: train_loss -0.8359 
2024-05-13 20:35:30.495216: val_loss -0.8263 
2024-05-13 20:35:30.495275: Pseudo dice [0.9152] 
2024-05-13 20:35:30.495333: Epoch time: 49.13 s 
2024-05-13 20:35:31.538646:  
2024-05-13 20:35:31.538881: Epoch 397 
2024-05-13 20:35:31.538966: Current learning rate: 0.00634 
2024-05-13 20:36:20.626177: train_loss -0.8425 
2024-05-13 20:36:20.626854: val_loss -0.8505 
2024-05-13 20:36:20.626915: Pseudo dice [0.9182] 
2024-05-13 20:36:20.626970: Epoch time: 49.09 s 
2024-05-13 20:36:21.662711:  
2024-05-13 20:36:21.662888: Epoch 398 
2024-05-13 20:36:21.663054: Current learning rate: 0.00633 
2024-05-13 20:37:10.701730: train_loss -0.8521 
2024-05-13 20:37:10.701924: val_loss -0.86 
2024-05-13 20:37:10.701986: Pseudo dice [0.9285] 
2024-05-13 20:37:10.702060: Epoch time: 49.04 s 
2024-05-13 20:37:11.739259:  
2024-05-13 20:37:11.739567: Epoch 399 
2024-05-13 20:37:11.739660: Current learning rate: 0.00632 
2024-05-13 20:38:00.791143: train_loss -0.855 
2024-05-13 20:38:00.791337: val_loss -0.8694 
2024-05-13 20:38:00.791399: Pseudo dice [0.9306] 
2024-05-13 20:38:00.791458: Epoch time: 49.05 s 
2024-05-13 20:38:02.663360:  
2024-05-13 20:38:02.663501: Epoch 400 
2024-05-13 20:38:02.663595: Current learning rate: 0.00631 
2024-05-13 20:38:51.848232: train_loss -0.8444 
2024-05-13 20:38:51.848517: val_loss -0.8392 
2024-05-13 20:38:51.848589: Pseudo dice [0.9171] 
2024-05-13 20:38:51.848649: Epoch time: 49.19 s 
2024-05-13 20:38:52.937872:  
2024-05-13 20:38:52.938163: Epoch 401 
2024-05-13 20:38:52.938347: Current learning rate: 0.0063 
2024-05-13 20:39:42.063102: train_loss -0.8484 
2024-05-13 20:39:42.063273: val_loss -0.8521 
2024-05-13 20:39:42.063354: Pseudo dice [0.9249] 
2024-05-13 20:39:42.063411: Epoch time: 49.13 s 
2024-05-13 20:39:43.175731:  
2024-05-13 20:39:43.175978: Epoch 402 
2024-05-13 20:39:43.176105: Current learning rate: 0.0063 
2024-05-13 20:40:32.167902: train_loss -0.8519 
2024-05-13 20:40:32.168082: val_loss -0.8624 
2024-05-13 20:40:32.168146: Pseudo dice [0.9292] 
2024-05-13 20:40:32.168207: Epoch time: 48.99 s 
2024-05-13 20:40:33.204607:  
2024-05-13 20:40:33.204727: Epoch 403 
2024-05-13 20:40:33.204808: Current learning rate: 0.00629 
2024-05-13 20:41:22.280158: train_loss -0.8575 
2024-05-13 20:41:22.280428: val_loss -0.8713 
2024-05-13 20:41:22.280513: Pseudo dice [0.9323] 
2024-05-13 20:41:22.280574: Epoch time: 49.08 s 
2024-05-13 20:41:23.352282:  
2024-05-13 20:41:23.352564: Epoch 404 
2024-05-13 20:41:23.352748: Current learning rate: 0.00628 
2024-05-13 20:42:12.360393: train_loss -0.854 
2024-05-13 20:42:12.360572: val_loss -0.8633 
2024-05-13 20:42:12.360739: Pseudo dice [0.9308] 
2024-05-13 20:42:12.360804: Epoch time: 49.01 s 
2024-05-13 20:42:12.360850: Yayy! New best EMA pseudo Dice: 0.9249 
2024-05-13 20:42:13.727866:  
2024-05-13 20:42:13.727978: Epoch 405 
2024-05-13 20:42:13.728075: Current learning rate: 0.00627 
2024-05-13 20:43:02.830911: train_loss -0.8597 
2024-05-13 20:43:02.831079: val_loss -0.8497 
2024-05-13 20:43:02.831141: Pseudo dice [0.9212] 
2024-05-13 20:43:02.831198: Epoch time: 49.1 s 
2024-05-13 20:43:03.875227:  
2024-05-13 20:43:03.875432: Epoch 406 
2024-05-13 20:43:03.875520: Current learning rate: 0.00626 
2024-05-13 20:43:52.920279: train_loss -0.8587 
2024-05-13 20:43:52.920456: val_loss -0.8621 
2024-05-13 20:43:52.920515: Pseudo dice [0.9297] 
2024-05-13 20:43:52.920586: Epoch time: 49.05 s 
2024-05-13 20:43:52.920631: Yayy! New best EMA pseudo Dice: 0.9251 
2024-05-13 20:43:54.351495:  
2024-05-13 20:43:54.351615: Epoch 407 
2024-05-13 20:43:54.351712: Current learning rate: 0.00625 
2024-05-13 20:44:43.387878: train_loss -0.8559 
2024-05-13 20:44:43.388549: val_loss -0.8457 
2024-05-13 20:44:43.388609: Pseudo dice [0.9215] 
2024-05-13 20:44:43.388664: Epoch time: 49.04 s 
2024-05-13 20:44:44.455164:  
2024-05-13 20:44:44.455275: Epoch 408 
2024-05-13 20:44:44.455360: Current learning rate: 0.00624 
2024-05-13 20:45:33.513584: train_loss -0.8644 
2024-05-13 20:45:33.513772: val_loss -0.8724 
2024-05-13 20:45:33.513831: Pseudo dice [0.9326] 
2024-05-13 20:45:33.513889: Epoch time: 49.06 s 
2024-05-13 20:45:33.513933: Yayy! New best EMA pseudo Dice: 0.9255 
2024-05-13 20:45:35.362488:  
2024-05-13 20:45:35.362691: Epoch 409 
2024-05-13 20:45:35.362778: Current learning rate: 0.00623 
2024-05-13 20:46:24.370142: train_loss -0.8592 
2024-05-13 20:46:24.370333: val_loss -0.85 
2024-05-13 20:46:24.370416: Pseudo dice [0.9171] 
2024-05-13 20:46:24.370479: Epoch time: 49.01 s 
2024-05-13 20:46:25.410051:  
2024-05-13 20:46:25.410185: Epoch 410 
2024-05-13 20:46:25.410267: Current learning rate: 0.00622 
2024-05-13 20:47:14.497163: train_loss -0.8469 
2024-05-13 20:47:14.497997: val_loss -0.8434 
2024-05-13 20:47:14.498055: Pseudo dice [0.9219] 
2024-05-13 20:47:14.498108: Epoch time: 49.09 s 
2024-05-13 20:47:15.476599:  
2024-05-13 20:47:15.476736: Epoch 411 
2024-05-13 20:47:15.476817: Current learning rate: 0.00621 
2024-05-13 20:48:04.513587: train_loss -0.8581 
2024-05-13 20:48:04.513780: val_loss -0.8557 
2024-05-13 20:48:04.513858: Pseudo dice [0.9246] 
2024-05-13 20:48:04.513922: Epoch time: 49.04 s 
2024-05-13 20:48:05.487242:  
2024-05-13 20:48:05.487444: Epoch 412 
2024-05-13 20:48:05.487537: Current learning rate: 0.0062 
2024-05-13 20:48:54.533851: train_loss -0.8564 
2024-05-13 20:48:54.534038: val_loss -0.8581 
2024-05-13 20:48:54.534116: Pseudo dice [0.9244] 
2024-05-13 20:48:54.534174: Epoch time: 49.05 s 
2024-05-13 20:48:55.533136:  
2024-05-13 20:48:55.533451: Epoch 413 
2024-05-13 20:48:55.533597: Current learning rate: 0.00619 
2024-05-13 20:49:44.622117: train_loss -0.8533 
2024-05-13 20:49:44.622383: val_loss -0.8725 
2024-05-13 20:49:44.622448: Pseudo dice [0.9332] 
2024-05-13 20:49:44.622508: Epoch time: 49.09 s 
2024-05-13 20:49:45.602491:  
2024-05-13 20:49:45.602612: Epoch 414 
2024-05-13 20:49:45.602694: Current learning rate: 0.00618 
2024-05-13 20:50:34.599853: train_loss -0.8527 
2024-05-13 20:50:34.600007: val_loss -0.8445 
2024-05-13 20:50:34.600064: Pseudo dice [0.9187] 
2024-05-13 20:50:34.600117: Epoch time: 49.0 s 
2024-05-13 20:50:35.575983:  
2024-05-13 20:50:35.576096: Epoch 415 
2024-05-13 20:50:35.576183: Current learning rate: 0.00617 
2024-05-13 20:51:24.622370: train_loss -0.8508 
2024-05-13 20:51:24.622536: val_loss -0.8549 
2024-05-13 20:51:24.622599: Pseudo dice [0.9235] 
2024-05-13 20:51:24.622655: Epoch time: 49.05 s 
2024-05-13 20:51:25.625656:  
2024-05-13 20:51:25.625897: Epoch 416 
2024-05-13 20:51:25.625985: Current learning rate: 0.00616 
2024-05-13 20:52:14.633151: train_loss -0.8487 
2024-05-13 20:52:14.633812: val_loss -0.8676 
2024-05-13 20:52:14.633868: Pseudo dice [0.9284] 
2024-05-13 20:52:14.634002: Epoch time: 49.01 s 
2024-05-13 20:52:15.618482:  
2024-05-13 20:52:15.618845: Epoch 417 
2024-05-13 20:52:15.618936: Current learning rate: 0.00615 
2024-05-13 20:53:04.674551: train_loss -0.8479 
2024-05-13 20:53:04.674730: val_loss -0.8647 
2024-05-13 20:53:04.674794: Pseudo dice [0.9289] 
2024-05-13 20:53:04.674852: Epoch time: 49.06 s 
2024-05-13 20:53:05.651610:  
2024-05-13 20:53:05.651717: Epoch 418 
2024-05-13 20:53:05.651813: Current learning rate: 0.00614 
2024-05-13 20:53:54.748000: train_loss -0.8473 
2024-05-13 20:53:54.748207: val_loss -0.8415 
2024-05-13 20:53:54.748296: Pseudo dice [0.9152] 
2024-05-13 20:53:54.748366: Epoch time: 49.1 s 
2024-05-13 20:53:55.719230:  
2024-05-13 20:53:55.719337: Epoch 419 
2024-05-13 20:53:55.719427: Current learning rate: 0.00613 
2024-05-13 20:54:44.673617: train_loss -0.8464 
2024-05-13 20:54:44.673933: val_loss -0.8388 
2024-05-13 20:54:44.674041: Pseudo dice [0.9165] 
2024-05-13 20:54:44.674108: Epoch time: 48.96 s 
2024-05-13 20:54:46.149186:  
2024-05-13 20:54:46.149461: Epoch 420 
2024-05-13 20:54:46.149553: Current learning rate: 0.00612 
2024-05-13 20:55:35.220154: train_loss -0.8536 
2024-05-13 20:55:35.220334: val_loss -0.85 
2024-05-13 20:55:35.220396: Pseudo dice [0.9181] 
2024-05-13 20:55:35.220454: Epoch time: 49.07 s 
2024-05-13 20:55:36.198664:  
2024-05-13 20:55:36.198798: Epoch 421 
2024-05-13 20:55:36.198882: Current learning rate: 0.00612 
2024-05-13 20:56:25.214732: train_loss -0.8441 
2024-05-13 20:56:25.214901: val_loss -0.8615 
2024-05-13 20:56:25.214961: Pseudo dice [0.9266] 
2024-05-13 20:56:25.215023: Epoch time: 49.02 s 
2024-05-13 20:56:26.209249:  
2024-05-13 20:56:26.209376: Epoch 422 
2024-05-13 20:56:26.209475: Current learning rate: 0.00611 
2024-05-13 20:57:15.212135: train_loss -0.8484 
2024-05-13 20:57:15.212634: val_loss -0.8462 
2024-05-13 20:57:15.212706: Pseudo dice [0.9214] 
2024-05-13 20:57:15.212767: Epoch time: 49.0 s 
2024-05-13 20:57:16.196068:  
2024-05-13 20:57:16.196182: Epoch 423 
2024-05-13 20:57:16.196281: Current learning rate: 0.0061 
2024-05-13 20:58:05.210309: train_loss -0.8502 
2024-05-13 20:58:05.210508: val_loss -0.8547 
2024-05-13 20:58:05.210569: Pseudo dice [0.9248] 
2024-05-13 20:58:05.210627: Epoch time: 49.02 s 
2024-05-13 20:58:06.230168:  
2024-05-13 20:58:06.230394: Epoch 424 
2024-05-13 20:58:06.230481: Current learning rate: 0.00609 
2024-05-13 20:58:55.270151: train_loss -0.8579 
2024-05-13 20:58:55.270380: val_loss -0.8585 
2024-05-13 20:58:55.270466: Pseudo dice [0.928] 
2024-05-13 20:58:55.270527: Epoch time: 49.04 s 
2024-05-13 20:58:56.315614:  
2024-05-13 20:58:56.315727: Epoch 425 
2024-05-13 20:58:56.315808: Current learning rate: 0.00608 
2024-05-13 20:59:45.388287: train_loss -0.8541 
2024-05-13 20:59:45.389021: val_loss -0.8607 
2024-05-13 20:59:45.389086: Pseudo dice [0.9295] 
2024-05-13 20:59:45.389146: Epoch time: 49.07 s 
2024-05-13 20:59:46.446348:  
2024-05-13 20:59:46.446680: Epoch 426 
2024-05-13 20:59:46.446772: Current learning rate: 0.00607 
2024-05-13 21:00:35.411866: train_loss -0.8539 
2024-05-13 21:00:35.412026: val_loss -0.8475 
2024-05-13 21:00:35.412086: Pseudo dice [0.9217] 
2024-05-13 21:00:35.412141: Epoch time: 48.97 s 
2024-05-13 21:00:36.447133:  
2024-05-13 21:00:36.447245: Epoch 427 
2024-05-13 21:00:36.447329: Current learning rate: 0.00606 
2024-05-13 21:01:25.490724: train_loss -0.8559 
2024-05-13 21:01:25.490975: val_loss -0.8677 
2024-05-13 21:01:25.491041: Pseudo dice [0.9309] 
2024-05-13 21:01:25.491100: Epoch time: 49.04 s 
2024-05-13 21:01:26.465662:  
2024-05-13 21:01:26.465780: Epoch 428 
2024-05-13 21:01:26.465866: Current learning rate: 0.00605 
2024-05-13 21:02:15.540912: train_loss -0.8453 
2024-05-13 21:02:15.541643: val_loss -0.8642 
2024-05-13 21:02:15.541709: Pseudo dice [0.9272] 
2024-05-13 21:02:15.541763: Epoch time: 49.08 s 
2024-05-13 21:02:16.521979:  
2024-05-13 21:02:16.522092: Epoch 429 
2024-05-13 21:02:16.522177: Current learning rate: 0.00604 
2024-05-13 21:03:05.498230: train_loss -0.8566 
2024-05-13 21:03:05.498931: val_loss -0.8497 
2024-05-13 21:03:05.498992: Pseudo dice [0.9198] 
2024-05-13 21:03:05.499046: Epoch time: 48.98 s 
2024-05-13 21:03:06.486251:  
2024-05-13 21:03:06.486392: Epoch 430 
2024-05-13 21:03:06.486477: Current learning rate: 0.00603 
2024-05-13 21:03:55.485161: train_loss -0.8529 
2024-05-13 21:03:55.485456: val_loss -0.8643 
2024-05-13 21:03:55.485527: Pseudo dice [0.9254] 
2024-05-13 21:03:55.485585: Epoch time: 49.0 s 
2024-05-13 21:03:56.957263:  
2024-05-13 21:03:56.957502: Epoch 431 
2024-05-13 21:03:56.957778: Current learning rate: 0.00602 
2024-05-13 21:04:46.050895: train_loss -0.856 
2024-05-13 21:04:46.051073: val_loss -0.8678 
2024-05-13 21:04:46.051132: Pseudo dice [0.9299] 
2024-05-13 21:04:46.051191: Epoch time: 49.09 s 
2024-05-13 21:04:47.026862:  
2024-05-13 21:04:47.026985: Epoch 432 
2024-05-13 21:04:47.027069: Current learning rate: 0.00601 
2024-05-13 21:05:36.077637: train_loss -0.8574 
2024-05-13 21:05:36.077912: val_loss -0.8648 
2024-05-13 21:05:36.077979: Pseudo dice [0.929] 
2024-05-13 21:05:36.078053: Epoch time: 49.05 s 
2024-05-13 21:05:37.084113:  
2024-05-13 21:05:37.084236: Epoch 433 
2024-05-13 21:05:37.084320: Current learning rate: 0.006 
2024-05-13 21:06:26.106385: train_loss -0.8537 
2024-05-13 21:06:26.106702: val_loss -0.854 
2024-05-13 21:06:26.106766: Pseudo dice [0.925] 
2024-05-13 21:06:26.106826: Epoch time: 49.02 s 
2024-05-13 21:06:27.102431:  
2024-05-13 21:06:27.102641: Epoch 434 
2024-05-13 21:06:27.102729: Current learning rate: 0.00599 
2024-05-13 21:07:16.125285: train_loss -0.8594 
2024-05-13 21:07:16.125458: val_loss -0.8536 
2024-05-13 21:07:16.125519: Pseudo dice [0.9253] 
2024-05-13 21:07:16.125578: Epoch time: 49.02 s 
2024-05-13 21:07:17.109965:  
2024-05-13 21:07:17.110080: Epoch 435 
2024-05-13 21:07:17.110176: Current learning rate: 0.00598 
2024-05-13 21:08:06.158339: train_loss -0.8567 
2024-05-13 21:08:06.158612: val_loss -0.8551 
2024-05-13 21:08:06.158683: Pseudo dice [0.9214] 
2024-05-13 21:08:06.158744: Epoch time: 49.05 s 
2024-05-13 21:08:07.159009:  
2024-05-13 21:08:07.159124: Epoch 436 
2024-05-13 21:08:07.159209: Current learning rate: 0.00597 
2024-05-13 21:08:56.196145: train_loss -0.8618 
2024-05-13 21:08:56.196325: val_loss -0.8621 
2024-05-13 21:08:56.196400: Pseudo dice [0.9293] 
2024-05-13 21:08:56.196474: Epoch time: 49.04 s 
2024-05-13 21:08:57.175816:  
2024-05-13 21:08:57.176030: Epoch 437 
2024-05-13 21:08:57.176134: Current learning rate: 0.00596 
2024-05-13 21:09:46.223273: train_loss -0.8576 
2024-05-13 21:09:46.223452: val_loss -0.8688 
2024-05-13 21:09:46.223513: Pseudo dice [0.9317] 
2024-05-13 21:09:46.223580: Epoch time: 49.05 s 
2024-05-13 21:09:46.223624: Yayy! New best EMA pseudo Dice: 0.9261 
2024-05-13 21:09:47.618645:  
2024-05-13 21:09:47.618842: Epoch 438 
2024-05-13 21:09:47.618928: Current learning rate: 0.00595 
2024-05-13 21:10:36.697864: train_loss -0.8635 
2024-05-13 21:10:36.698038: val_loss -0.8462 
2024-05-13 21:10:36.698097: Pseudo dice [0.9283] 
2024-05-13 21:10:36.698158: Epoch time: 49.08 s 
2024-05-13 21:10:36.698203: Yayy! New best EMA pseudo Dice: 0.9263 
2024-05-13 21:10:38.026277:  
2024-05-13 21:10:38.026416: Epoch 439 
2024-05-13 21:10:38.026503: Current learning rate: 0.00594 
2024-05-13 21:11:27.092905: train_loss -0.8582 
2024-05-13 21:11:27.093185: val_loss -0.8588 
2024-05-13 21:11:27.093269: Pseudo dice [0.9266] 
2024-05-13 21:11:27.093328: Epoch time: 49.07 s 
2024-05-13 21:11:27.093374: Yayy! New best EMA pseudo Dice: 0.9263 
2024-05-13 21:11:28.462520:  
2024-05-13 21:11:28.462629: Epoch 440 
2024-05-13 21:11:28.462710: Current learning rate: 0.00593 
2024-05-13 21:12:17.513546: train_loss -0.8461 
2024-05-13 21:12:17.513726: val_loss -0.8499 
2024-05-13 21:12:17.513783: Pseudo dice [0.9227] 
2024-05-13 21:12:17.513840: Epoch time: 49.05 s 
2024-05-13 21:12:18.491035:  
2024-05-13 21:12:18.491147: Epoch 441 
2024-05-13 21:12:18.491232: Current learning rate: 0.00592 
2024-05-13 21:13:07.536496: train_loss -0.8545 
2024-05-13 21:13:07.536669: val_loss -0.8662 
2024-05-13 21:13:07.536902: Pseudo dice [0.9307] 
2024-05-13 21:13:07.536965: Epoch time: 49.05 s 
2024-05-13 21:13:07.537011: Yayy! New best EMA pseudo Dice: 0.9264 
2024-05-13 21:13:09.225572:  
2024-05-13 21:13:09.225717: Epoch 442 
2024-05-13 21:13:09.225815: Current learning rate: 0.00592 
2024-05-13 21:13:58.276396: train_loss -0.8503 
2024-05-13 21:13:58.276590: val_loss -0.8539 
2024-05-13 21:13:58.276676: Pseudo dice [0.9274] 
2024-05-13 21:13:58.276734: Epoch time: 49.05 s 
2024-05-13 21:13:58.276781: Yayy! New best EMA pseudo Dice: 0.9265 
2024-05-13 21:13:59.632184:  
2024-05-13 21:13:59.632434: Epoch 443 
2024-05-13 21:13:59.632523: Current learning rate: 0.00591 
2024-05-13 21:14:48.659778: train_loss -0.8567 
2024-05-13 21:14:48.659956: val_loss -0.8641 
2024-05-13 21:14:48.660014: Pseudo dice [0.9271] 
2024-05-13 21:14:48.660085: Epoch time: 49.03 s 
2024-05-13 21:14:48.660131: Yayy! New best EMA pseudo Dice: 0.9266 
2024-05-13 21:14:49.986843:  
2024-05-13 21:14:49.987102: Epoch 444 
2024-05-13 21:14:49.987189: Current learning rate: 0.0059 
2024-05-13 21:15:39.009790: train_loss -0.8554 
2024-05-13 21:15:39.010615: val_loss -0.8668 
2024-05-13 21:15:39.010895: Pseudo dice [0.9292] 
2024-05-13 21:15:39.011132: Epoch time: 49.02 s 
2024-05-13 21:15:39.011333: Yayy! New best EMA pseudo Dice: 0.9268 
2024-05-13 21:15:40.354358:  
2024-05-13 21:15:40.354481: Epoch 445 
2024-05-13 21:15:40.354564: Current learning rate: 0.00589 
2024-05-13 21:16:29.395377: train_loss -0.8544 
2024-05-13 21:16:29.395546: val_loss -0.8627 
2024-05-13 21:16:29.395602: Pseudo dice [0.9292] 
2024-05-13 21:16:29.395663: Epoch time: 49.04 s 
2024-05-13 21:16:29.395708: Yayy! New best EMA pseudo Dice: 0.9271 
2024-05-13 21:16:30.772787:  
2024-05-13 21:16:30.772912: Epoch 446 
2024-05-13 21:16:30.773009: Current learning rate: 0.00588 
2024-05-13 21:17:19.746149: train_loss -0.8474 
2024-05-13 21:17:19.746333: val_loss -0.8514 
2024-05-13 21:17:19.746396: Pseudo dice [0.9205] 
2024-05-13 21:17:19.746454: Epoch time: 48.97 s 
2024-05-13 21:17:20.713074:  
2024-05-13 21:17:20.713206: Epoch 447 
2024-05-13 21:17:20.713305: Current learning rate: 0.00587 
2024-05-13 21:18:09.716143: train_loss -0.8542 
2024-05-13 21:18:09.716870: val_loss -0.8428 
2024-05-13 21:18:09.716933: Pseudo dice [0.919] 
2024-05-13 21:18:09.716984: Epoch time: 49.0 s 
2024-05-13 21:18:10.696121:  
2024-05-13 21:18:10.696405: Epoch 448 
2024-05-13 21:18:10.696577: Current learning rate: 0.00586 
2024-05-13 21:18:59.694166: train_loss -0.845 
2024-05-13 21:18:59.694341: val_loss -0.8458 
2024-05-13 21:18:59.694403: Pseudo dice [0.9253] 
2024-05-13 21:18:59.694457: Epoch time: 49.0 s 
2024-05-13 21:19:00.670465:  
2024-05-13 21:19:00.670575: Epoch 449 
2024-05-13 21:19:00.670659: Current learning rate: 0.00585 
2024-05-13 21:19:49.646874: train_loss -0.8572 
2024-05-13 21:19:49.647053: val_loss -0.8543 
2024-05-13 21:19:49.647116: Pseudo dice [0.9274] 
2024-05-13 21:19:49.647178: Epoch time: 48.98 s 
2024-05-13 21:19:50.919811:  
2024-05-13 21:19:50.920135: Epoch 450 
2024-05-13 21:19:50.920220: Current learning rate: 0.00584 
2024-05-13 21:20:39.935918: train_loss -0.85 
2024-05-13 21:20:39.936628: val_loss -0.864 
2024-05-13 21:20:39.936685: Pseudo dice [0.9275] 
2024-05-13 21:20:39.936734: Epoch time: 49.02 s 
2024-05-13 21:20:40.909795:  
2024-05-13 21:20:40.909927: Epoch 451 
2024-05-13 21:20:40.910028: Current learning rate: 0.00583 
2024-05-13 21:21:30.010550: train_loss -0.8557 
2024-05-13 21:21:30.010749: val_loss -0.8598 
2024-05-13 21:21:30.010815: Pseudo dice [0.9278] 
2024-05-13 21:21:30.010873: Epoch time: 49.1 s 
2024-05-13 21:21:31.035341:  
2024-05-13 21:21:31.035449: Epoch 452 
2024-05-13 21:21:31.035533: Current learning rate: 0.00582 
2024-05-13 21:22:20.064473: train_loss -0.8581 
2024-05-13 21:22:20.064646: val_loss -0.8516 
2024-05-13 21:22:20.064705: Pseudo dice [0.9232] 
2024-05-13 21:22:20.064789: Epoch time: 49.03 s 
2024-05-13 21:22:21.529456:  
2024-05-13 21:22:21.529581: Epoch 453 
2024-05-13 21:22:21.529663: Current learning rate: 0.00581 
2024-05-13 21:23:10.862827: train_loss -0.8568 
2024-05-13 21:23:10.863029: val_loss -0.8687 
2024-05-13 21:23:10.863098: Pseudo dice [0.9317] 
2024-05-13 21:23:10.863161: Epoch time: 49.33 s 
2024-05-13 21:23:11.878597:  
2024-05-13 21:23:11.878724: Epoch 454 
2024-05-13 21:23:11.878815: Current learning rate: 0.0058 
2024-05-13 21:24:00.907008: train_loss -0.858 
2024-05-13 21:24:00.907203: val_loss -0.8641 
2024-05-13 21:24:00.907322: Pseudo dice [0.931] 
2024-05-13 21:24:00.907399: Epoch time: 49.03 s 
2024-05-13 21:24:01.877885:  
2024-05-13 21:24:01.878018: Epoch 455 
2024-05-13 21:24:01.878102: Current learning rate: 0.00579 
2024-05-13 21:24:50.884147: train_loss -0.846 
2024-05-13 21:24:50.884376: val_loss -0.8575 
2024-05-13 21:24:50.884453: Pseudo dice [0.928] 
2024-05-13 21:24:50.884512: Epoch time: 49.01 s 
2024-05-13 21:24:51.860551:  
2024-05-13 21:24:51.860676: Epoch 456 
2024-05-13 21:24:51.860776: Current learning rate: 0.00578 
2024-05-13 21:25:40.902627: train_loss -0.8555 
2024-05-13 21:25:40.902779: val_loss -0.8619 
2024-05-13 21:25:40.902837: Pseudo dice [0.9242] 
2024-05-13 21:25:40.902900: Epoch time: 49.04 s 
2024-05-13 21:25:41.875589:  
2024-05-13 21:25:41.875721: Epoch 457 
2024-05-13 21:25:41.875823: Current learning rate: 0.00577 
2024-05-13 21:26:30.956153: train_loss -0.8621 
2024-05-13 21:26:30.956347: val_loss -0.8586 
2024-05-13 21:26:30.956408: Pseudo dice [0.9314] 
2024-05-13 21:26:30.956467: Epoch time: 49.08 s 
2024-05-13 21:26:30.956516: Yayy! New best EMA pseudo Dice: 0.9272 
2024-05-13 21:26:32.261970:  
2024-05-13 21:26:32.262101: Epoch 458 
2024-05-13 21:26:32.262184: Current learning rate: 0.00576 
2024-05-13 21:27:21.265135: train_loss -0.8564 
2024-05-13 21:27:21.265858: val_loss -0.868 
2024-05-13 21:27:21.265923: Pseudo dice [0.9283] 
2024-05-13 21:27:21.265974: Epoch time: 49.0 s 
2024-05-13 21:27:21.266014: Yayy! New best EMA pseudo Dice: 0.9273 
2024-05-13 21:27:22.610569:  
2024-05-13 21:27:22.610687: Epoch 459 
2024-05-13 21:27:22.610771: Current learning rate: 0.00575 
2024-05-13 21:28:11.694892: train_loss -0.8562 
2024-05-13 21:28:11.695058: val_loss -0.8521 
2024-05-13 21:28:11.695122: Pseudo dice [0.9192] 
2024-05-13 21:28:11.695180: Epoch time: 49.09 s 
2024-05-13 21:28:12.677488:  
2024-05-13 21:28:12.677614: Epoch 460 
2024-05-13 21:28:12.677712: Current learning rate: 0.00574 
2024-05-13 21:29:01.730051: train_loss -0.8542 
2024-05-13 21:29:01.730232: val_loss -0.8536 
2024-05-13 21:29:01.730290: Pseudo dice [0.9254] 
2024-05-13 21:29:01.730372: Epoch time: 49.05 s 
2024-05-13 21:29:02.713079:  
2024-05-13 21:29:02.713289: Epoch 461 
2024-05-13 21:29:02.713375: Current learning rate: 0.00573 
2024-05-13 21:29:51.700437: train_loss -0.8497 
2024-05-13 21:29:51.700868: val_loss -0.8418 
2024-05-13 21:29:51.701033: Pseudo dice [0.9189] 
2024-05-13 21:29:51.701176: Epoch time: 48.99 s 
2024-05-13 21:29:52.736761:  
2024-05-13 21:29:52.736868: Epoch 462 
2024-05-13 21:29:52.736951: Current learning rate: 0.00572 
2024-05-13 21:30:41.806525: train_loss -0.8511 
2024-05-13 21:30:41.806688: val_loss -0.8518 
2024-05-13 21:30:41.806746: Pseudo dice [0.9262] 
2024-05-13 21:30:41.806803: Epoch time: 49.07 s 
2024-05-13 21:30:42.783502:  
2024-05-13 21:30:42.783606: Epoch 463 
2024-05-13 21:30:42.783687: Current learning rate: 0.00571 
2024-05-13 21:31:32.379744: train_loss -0.8552 
2024-05-13 21:31:32.379943: val_loss -0.8462 
2024-05-13 21:31:32.380013: Pseudo dice [0.9176] 
2024-05-13 21:31:32.380079: Epoch time: 49.6 s 
2024-05-13 21:31:33.364667:  
2024-05-13 21:31:33.364794: Epoch 464 
2024-05-13 21:31:33.364876: Current learning rate: 0.0057 
2024-05-13 21:32:22.321357: train_loss -0.8599 
2024-05-13 21:32:22.322023: val_loss -0.8657 
2024-05-13 21:32:22.322102: Pseudo dice [0.9315] 
2024-05-13 21:32:22.322175: Epoch time: 48.96 s 
2024-05-13 21:32:23.304379:  
2024-05-13 21:32:23.304533: Epoch 465 
2024-05-13 21:32:23.304617: Current learning rate: 0.0057 
2024-05-13 21:33:12.333721: train_loss -0.8519 
2024-05-13 21:33:12.333895: val_loss -0.8592 
2024-05-13 21:33:12.334085: Pseudo dice [0.927] 
2024-05-13 21:33:12.334149: Epoch time: 49.03 s 
2024-05-13 21:33:13.316389:  
2024-05-13 21:33:13.316586: Epoch 466 
2024-05-13 21:33:13.316668: Current learning rate: 0.00569 
2024-05-13 21:34:02.371301: train_loss -0.8525 
2024-05-13 21:34:02.371560: val_loss -0.8588 
2024-05-13 21:34:02.371634: Pseudo dice [0.9254] 
2024-05-13 21:34:02.371716: Epoch time: 49.06 s 
2024-05-13 21:34:03.340652:  
2024-05-13 21:34:03.340837: Epoch 467 
2024-05-13 21:34:03.340936: Current learning rate: 0.00568 
2024-05-13 21:34:52.413865: train_loss -0.8568 
2024-05-13 21:34:52.414049: val_loss -0.8437 
2024-05-13 21:34:52.414108: Pseudo dice [0.918] 
2024-05-13 21:34:52.414165: Epoch time: 49.07 s 
2024-05-13 21:34:53.401389:  
2024-05-13 21:34:53.401529: Epoch 468 
2024-05-13 21:34:53.401628: Current learning rate: 0.00567 
2024-05-13 21:35:42.476289: train_loss -0.8617 
2024-05-13 21:35:42.476962: val_loss -0.865 
2024-05-13 21:35:42.477021: Pseudo dice [0.934] 
2024-05-13 21:35:42.477074: Epoch time: 49.08 s 
2024-05-13 21:35:43.445016:  
2024-05-13 21:35:43.445156: Epoch 469 
2024-05-13 21:35:43.445237: Current learning rate: 0.00566 
2024-05-13 21:36:32.501999: train_loss -0.8562 
2024-05-13 21:36:32.502190: val_loss -0.8629 
2024-05-13 21:36:32.502259: Pseudo dice [0.9288] 
2024-05-13 21:36:32.502345: Epoch time: 49.06 s 
2024-05-13 21:36:33.487083:  
2024-05-13 21:36:33.487287: Epoch 470 
2024-05-13 21:36:33.487375: Current learning rate: 0.00565 
2024-05-13 21:37:22.661778: train_loss -0.8566 
2024-05-13 21:37:22.661945: val_loss -0.8553 
2024-05-13 21:37:22.662002: Pseudo dice [0.9315] 
2024-05-13 21:37:22.662057: Epoch time: 49.18 s 
2024-05-13 21:37:23.672346:  
2024-05-13 21:37:23.672551: Epoch 471 
2024-05-13 21:37:23.672639: Current learning rate: 0.00564 
2024-05-13 21:38:12.729286: train_loss -0.8674 
2024-05-13 21:38:12.729723: val_loss -0.8547 
2024-05-13 21:38:12.729793: Pseudo dice [0.9238] 
2024-05-13 21:38:12.729850: Epoch time: 49.06 s 
2024-05-13 21:38:13.714917:  
2024-05-13 21:38:13.715024: Epoch 472 
2024-05-13 21:38:13.715106: Current learning rate: 0.00563 
2024-05-13 21:39:02.777806: train_loss -0.8491 
2024-05-13 21:39:02.777982: val_loss -0.8661 
2024-05-13 21:39:02.778040: Pseudo dice [0.9292] 
2024-05-13 21:39:02.778097: Epoch time: 49.06 s 
2024-05-13 21:39:03.744266:  
2024-05-13 21:39:03.744376: Epoch 473 
2024-05-13 21:39:03.744460: Current learning rate: 0.00562 
2024-05-13 21:39:52.807806: train_loss -0.8543 
2024-05-13 21:39:52.807981: val_loss -0.8543 
2024-05-13 21:39:52.808038: Pseudo dice [0.9284] 
2024-05-13 21:39:52.808109: Epoch time: 49.06 s 
2024-05-13 21:39:54.267773:  
2024-05-13 21:39:54.268006: Epoch 474 
2024-05-13 21:39:54.268101: Current learning rate: 0.00561 
2024-05-13 21:40:43.348010: train_loss -0.8577 
2024-05-13 21:40:43.348191: val_loss -0.8578 
2024-05-13 21:40:43.348251: Pseudo dice [0.9263] 
2024-05-13 21:40:43.348323: Epoch time: 49.08 s 
2024-05-13 21:40:44.315871:  
2024-05-13 21:40:44.316002: Epoch 475 
2024-05-13 21:40:44.316084: Current learning rate: 0.0056 
2024-05-13 21:41:33.346066: train_loss -0.8614 
2024-05-13 21:41:33.346233: val_loss -0.8633 
2024-05-13 21:41:33.346293: Pseudo dice [0.9288] 
2024-05-13 21:41:33.346362: Epoch time: 49.03 s 
2024-05-13 21:41:34.313349:  
2024-05-13 21:41:34.313481: Epoch 476 
2024-05-13 21:41:34.313581: Current learning rate: 0.00559 
2024-05-13 21:42:23.410654: train_loss -0.8554 
2024-05-13 21:42:23.410934: val_loss -0.8689 
2024-05-13 21:42:23.411003: Pseudo dice [0.93] 
2024-05-13 21:42:23.411064: Epoch time: 49.1 s 
2024-05-13 21:42:24.376895:  
2024-05-13 21:42:24.377025: Epoch 477 
2024-05-13 21:42:24.377124: Current learning rate: 0.00558 
2024-05-13 21:43:13.377281: train_loss -0.8598 
2024-05-13 21:43:13.377448: val_loss -0.8607 
2024-05-13 21:43:13.377524: Pseudo dice [0.9245] 
2024-05-13 21:43:13.377580: Epoch time: 49.0 s 
2024-05-13 21:43:14.359300:  
2024-05-13 21:43:14.359645: Epoch 478 
2024-05-13 21:43:14.359731: Current learning rate: 0.00557 
2024-05-13 21:44:03.431750: train_loss -0.8624 
2024-05-13 21:44:03.431916: val_loss -0.8575 
2024-05-13 21:44:03.431975: Pseudo dice [0.9328] 
2024-05-13 21:44:03.432031: Epoch time: 49.07 s 
2024-05-13 21:44:03.432076: Yayy! New best EMA pseudo Dice: 0.9276 
2024-05-13 21:44:04.757343:  
2024-05-13 21:44:04.757489: Epoch 479 
2024-05-13 21:44:04.757589: Current learning rate: 0.00556 
2024-05-13 21:44:53.778210: train_loss -0.8626 
2024-05-13 21:44:53.778405: val_loss -0.8564 
2024-05-13 21:44:53.778465: Pseudo dice [0.9317] 
2024-05-13 21:44:53.778521: Epoch time: 49.02 s 
2024-05-13 21:44:53.778567: Yayy! New best EMA pseudo Dice: 0.928 
2024-05-13 21:44:55.137279:  
2024-05-13 21:44:55.137523: Epoch 480 
2024-05-13 21:44:55.137650: Current learning rate: 0.00555 
2024-05-13 21:45:44.121957: train_loss -0.8628 
2024-05-13 21:45:44.122269: val_loss -0.8493 
2024-05-13 21:45:44.122352: Pseudo dice [0.9239] 
2024-05-13 21:45:44.122412: Epoch time: 48.99 s 
2024-05-13 21:45:45.108145:  
2024-05-13 21:45:45.108333: Epoch 481 
2024-05-13 21:45:45.108420: Current learning rate: 0.00554 
2024-05-13 21:46:34.177194: train_loss -0.8596 
2024-05-13 21:46:34.177359: val_loss -0.8583 
2024-05-13 21:46:34.177421: Pseudo dice [0.9276] 
2024-05-13 21:46:34.177483: Epoch time: 49.07 s 
2024-05-13 21:46:35.192118:  
2024-05-13 21:46:35.192311: Epoch 482 
2024-05-13 21:46:35.192406: Current learning rate: 0.00553 
2024-05-13 21:47:24.250255: train_loss -0.8608 
2024-05-13 21:47:24.250465: val_loss -0.8608 
2024-05-13 21:47:24.250530: Pseudo dice [0.9253] 
2024-05-13 21:47:24.250596: Epoch time: 49.06 s 
2024-05-13 21:47:25.229458:  
2024-05-13 21:47:25.229664: Epoch 483 
2024-05-13 21:47:25.229748: Current learning rate: 0.00552 
2024-05-13 21:48:14.304922: train_loss -0.8646 
2024-05-13 21:48:14.305631: val_loss -0.8675 
2024-05-13 21:48:14.305715: Pseudo dice [0.9257] 
2024-05-13 21:48:14.305803: Epoch time: 49.08 s 
2024-05-13 21:48:15.311617:  
2024-05-13 21:48:15.311721: Epoch 484 
2024-05-13 21:48:15.311804: Current learning rate: 0.00551 
2024-05-13 21:49:04.364581: train_loss -0.859 
2024-05-13 21:49:04.364759: val_loss -0.8653 
2024-05-13 21:49:04.364822: Pseudo dice [0.9286] 
2024-05-13 21:49:04.364882: Epoch time: 49.05 s 
2024-05-13 21:49:05.864609:  
2024-05-13 21:49:05.864773: Epoch 485 
2024-05-13 21:49:05.864872: Current learning rate: 0.0055 
2024-05-13 21:49:54.916821: train_loss -0.8496 
2024-05-13 21:49:54.917035: val_loss -0.848 
2024-05-13 21:49:54.917177: Pseudo dice [0.9218] 
2024-05-13 21:49:54.917320: Epoch time: 49.05 s 
2024-05-13 21:49:55.941034:  
2024-05-13 21:49:55.941429: Epoch 486 
2024-05-13 21:49:55.941519: Current learning rate: 0.00549 
2024-05-13 21:50:44.972870: train_loss -0.8514 
2024-05-13 21:50:44.973590: val_loss -0.8458 
2024-05-13 21:50:44.973656: Pseudo dice [0.9197] 
2024-05-13 21:50:44.973709: Epoch time: 49.03 s 
2024-05-13 21:50:46.001517:  
2024-05-13 21:50:46.001648: Epoch 487 
2024-05-13 21:50:46.001747: Current learning rate: 0.00548 
2024-05-13 21:51:34.930763: train_loss -0.8507 
2024-05-13 21:51:34.930975: val_loss -0.8638 
2024-05-13 21:51:34.931066: Pseudo dice [0.9324] 
2024-05-13 21:51:34.931149: Epoch time: 48.93 s 
2024-05-13 21:51:35.930833:  
2024-05-13 21:51:35.931073: Epoch 488 
2024-05-13 21:51:35.931164: Current learning rate: 0.00547 
2024-05-13 21:52:24.994488: train_loss -0.8634 
2024-05-13 21:52:24.994668: val_loss -0.8615 
2024-05-13 21:52:24.994737: Pseudo dice [0.9292] 
2024-05-13 21:52:24.994799: Epoch time: 49.06 s 
2024-05-13 21:52:25.976756:  
2024-05-13 21:52:25.976877: Epoch 489 
2024-05-13 21:52:25.976965: Current learning rate: 0.00546 
2024-05-13 21:53:14.968774: train_loss -0.8656 
2024-05-13 21:53:14.969520: val_loss -0.8511 
2024-05-13 21:53:14.969585: Pseudo dice [0.9243] 
2024-05-13 21:53:14.969637: Epoch time: 48.99 s 
2024-05-13 21:53:15.950725:  
2024-05-13 21:53:15.950839: Epoch 490 
2024-05-13 21:53:15.950924: Current learning rate: 0.00546 
2024-05-13 21:54:04.963019: train_loss -0.8628 
2024-05-13 21:54:04.963199: val_loss -0.8722 
2024-05-13 21:54:04.963774: Pseudo dice [0.93] 
2024-05-13 21:54:04.963831: Epoch time: 49.01 s 
2024-05-13 21:54:05.979184:  
2024-05-13 21:54:05.979431: Epoch 491 
2024-05-13 21:54:05.979599: Current learning rate: 0.00545 
2024-05-13 21:54:54.952149: train_loss -0.8629 
2024-05-13 21:54:54.952331: val_loss -0.8538 
2024-05-13 21:54:54.952390: Pseudo dice [0.9259] 
2024-05-13 21:54:54.952445: Epoch time: 48.97 s 
2024-05-13 21:54:55.939540:  
2024-05-13 21:54:55.939654: Epoch 492 
2024-05-13 21:54:55.939760: Current learning rate: 0.00544 
2024-05-13 21:55:44.959158: train_loss -0.861 
2024-05-13 21:55:44.959364: val_loss -0.8722 
2024-05-13 21:55:44.959427: Pseudo dice [0.9313] 
2024-05-13 21:55:44.959489: Epoch time: 49.02 s 
2024-05-13 21:55:45.956401:  
2024-05-13 21:55:45.956510: Epoch 493 
2024-05-13 21:55:45.956610: Current learning rate: 0.00543 
2024-05-13 21:56:35.010035: train_loss -0.8443 
2024-05-13 21:56:35.010363: val_loss -0.8325 
2024-05-13 21:56:35.010456: Pseudo dice [0.9084] 
2024-05-13 21:56:35.010517: Epoch time: 49.05 s 
2024-05-13 21:56:36.004129:  
2024-05-13 21:56:36.004236: Epoch 494 
2024-05-13 21:56:36.004335: Current learning rate: 0.00542 
2024-05-13 21:57:25.043383: train_loss -0.7881 
2024-05-13 21:57:25.043571: val_loss -0.808 
2024-05-13 21:57:25.043633: Pseudo dice [0.8969] 
2024-05-13 21:57:25.043689: Epoch time: 49.04 s 
2024-05-13 21:57:26.025066:  
2024-05-13 21:57:26.025180: Epoch 495 
2024-05-13 21:57:26.025283: Current learning rate: 0.00541 
2024-05-13 21:58:15.074111: train_loss -0.7931 
2024-05-13 21:58:15.074291: val_loss -0.8149 
2024-05-13 21:58:15.074365: Pseudo dice [0.9035] 
2024-05-13 21:58:15.074423: Epoch time: 49.05 s 
2024-05-13 21:58:16.548554:  
2024-05-13 21:58:16.548680: Epoch 496 
2024-05-13 21:58:16.548781: Current learning rate: 0.0054 
2024-05-13 21:59:05.524808: train_loss -0.8152 
2024-05-13 21:59:05.525655: val_loss -0.8283 
2024-05-13 21:59:05.525759: Pseudo dice [0.9098] 
2024-05-13 21:59:05.525840: Epoch time: 48.98 s 
2024-05-13 21:59:06.522178:  
2024-05-13 21:59:06.522330: Epoch 497 
2024-05-13 21:59:06.522427: Current learning rate: 0.00539 
2024-05-13 21:59:55.548269: train_loss -0.8103 
2024-05-13 21:59:55.548447: val_loss -0.8464 
2024-05-13 21:59:55.548507: Pseudo dice [0.9152] 
2024-05-13 21:59:55.548565: Epoch time: 49.03 s 
2024-05-13 21:59:56.551097:  
2024-05-13 21:59:56.551236: Epoch 498 
2024-05-13 21:59:56.551327: Current learning rate: 0.00538 
2024-05-13 22:00:45.537647: train_loss -0.8302 
2024-05-13 22:00:45.537822: val_loss -0.858 
2024-05-13 22:00:45.537899: Pseudo dice [0.9258] 
2024-05-13 22:00:45.537958: Epoch time: 48.99 s 
2024-05-13 22:00:46.551643:  
2024-05-13 22:00:46.551895: Epoch 499 
2024-05-13 22:00:46.551984: Current learning rate: 0.00537 
2024-05-13 22:01:35.568151: train_loss -0.8344 
2024-05-13 22:01:35.568831: val_loss -0.8462 
2024-05-13 22:01:35.568891: Pseudo dice [0.9227] 
2024-05-13 22:01:35.568941: Epoch time: 49.02 s 
2024-05-13 22:01:36.921377:  
2024-05-13 22:01:36.921730: Epoch 500 
2024-05-13 22:01:36.921820: Current learning rate: 0.00536 
2024-05-13 22:02:25.989067: train_loss -0.8441 
2024-05-13 22:02:25.989232: val_loss -0.8329 
2024-05-13 22:02:25.989311: Pseudo dice [0.9146] 
2024-05-13 22:02:25.989369: Epoch time: 49.07 s 
2024-05-13 22:02:27.024236:  
2024-05-13 22:02:27.024355: Epoch 501 
2024-05-13 22:02:27.024438: Current learning rate: 0.00535 
2024-05-13 22:03:16.402078: train_loss -0.8489 
2024-05-13 22:03:16.402256: val_loss -0.8565 
2024-05-13 22:03:16.402346: Pseudo dice [0.922] 
2024-05-13 22:03:16.402405: Epoch time: 49.38 s 
2024-05-13 22:03:17.516838:  
2024-05-13 22:03:17.516953: Epoch 502 
2024-05-13 22:03:17.517036: Current learning rate: 0.00534 
2024-05-13 22:04:07.126010: train_loss -0.8486 
2024-05-13 22:04:07.126191: val_loss -0.8532 
2024-05-13 22:04:07.126261: Pseudo dice [0.9255] 
2024-05-13 22:04:07.126338: Epoch time: 49.61 s 
2024-05-13 22:04:08.325604:  
2024-05-13 22:04:08.325957: Epoch 503 
2024-05-13 22:04:08.326053: Current learning rate: 0.00533 
2024-05-13 22:04:58.018270: train_loss -0.8599 
2024-05-13 22:04:58.018464: val_loss -0.8621 
2024-05-13 22:04:58.018524: Pseudo dice [0.9287] 
2024-05-13 22:04:58.018581: Epoch time: 49.69 s 
2024-05-13 22:04:59.008993:  
2024-05-13 22:04:59.009105: Epoch 504 
2024-05-13 22:04:59.009188: Current learning rate: 0.00532 
2024-05-13 22:05:48.399900: train_loss -0.8566 
2024-05-13 22:05:48.400070: val_loss -0.862 
2024-05-13 22:05:48.400143: Pseudo dice [0.9302] 
2024-05-13 22:05:48.400200: Epoch time: 49.39 s 
2024-05-13 22:05:49.393119:  
2024-05-13 22:05:49.393337: Epoch 505 
2024-05-13 22:05:49.393425: Current learning rate: 0.00531 
2024-05-13 22:06:39.045789: train_loss -0.8601 
2024-05-13 22:06:39.046536: val_loss -0.8489 
2024-05-13 22:06:39.046639: Pseudo dice [0.9249] 
2024-05-13 22:06:39.046695: Epoch time: 49.65 s 
2024-05-13 22:06:40.064613:  
2024-05-13 22:06:40.064732: Epoch 506 
2024-05-13 22:06:40.064815: Current learning rate: 0.0053 
2024-05-13 22:07:29.179585: train_loss -0.861 
2024-05-13 22:07:29.179750: val_loss -0.8644 
2024-05-13 22:07:29.179824: Pseudo dice [0.9283] 
2024-05-13 22:07:29.179907: Epoch time: 49.12 s 
2024-05-13 22:07:30.166141:  
2024-05-13 22:07:30.166244: Epoch 507 
2024-05-13 22:07:30.166340: Current learning rate: 0.00529 
2024-05-13 22:08:19.178006: train_loss -0.862 
2024-05-13 22:08:19.178174: val_loss -0.867 
2024-05-13 22:08:19.178233: Pseudo dice [0.9271] 
2024-05-13 22:08:19.178288: Epoch time: 49.01 s 
2024-05-13 22:08:20.732549:  
2024-05-13 22:08:20.732696: Epoch 508 
2024-05-13 22:08:20.732798: Current learning rate: 0.00528 
2024-05-13 22:09:09.908824: train_loss -0.8521 
2024-05-13 22:09:09.908998: val_loss -0.8677 
2024-05-13 22:09:09.909056: Pseudo dice [0.9304] 
2024-05-13 22:09:09.909112: Epoch time: 49.18 s 
2024-05-13 22:09:10.913511:  
2024-05-13 22:09:10.913658: Epoch 509 
2024-05-13 22:09:10.913767: Current learning rate: 0.00527 
2024-05-13 22:10:00.004771: train_loss -0.8612 
2024-05-13 22:10:00.005089: val_loss -0.8547 
2024-05-13 22:10:00.005163: Pseudo dice [0.9285] 
2024-05-13 22:10:00.005224: Epoch time: 49.09 s 
2024-05-13 22:10:01.033020:  
2024-05-13 22:10:01.033157: Epoch 510 
2024-05-13 22:10:01.033250: Current learning rate: 0.00526 
2024-05-13 22:10:50.169668: train_loss -0.8629 
2024-05-13 22:10:50.169837: val_loss -0.8691 
2024-05-13 22:10:50.169920: Pseudo dice [0.9315] 
2024-05-13 22:10:50.169979: Epoch time: 49.14 s 
2024-05-13 22:10:51.162030:  
2024-05-13 22:10:51.162156: Epoch 511 
2024-05-13 22:10:51.162255: Current learning rate: 0.00525 
2024-05-13 22:11:40.227304: train_loss -0.8657 
2024-05-13 22:11:40.227484: val_loss -0.8618 
2024-05-13 22:11:40.227546: Pseudo dice [0.9337] 
2024-05-13 22:11:40.227604: Epoch time: 49.07 s 
2024-05-13 22:11:41.228856:  
2024-05-13 22:11:41.229055: Epoch 512 
2024-05-13 22:11:41.229144: Current learning rate: 0.00524 
2024-05-13 22:12:30.380820: train_loss -0.861 
2024-05-13 22:12:30.381516: val_loss -0.8682 
2024-05-13 22:12:30.381586: Pseudo dice [0.9309] 
2024-05-13 22:12:30.381637: Epoch time: 49.15 s 
2024-05-13 22:12:31.380879:  
2024-05-13 22:12:31.380998: Epoch 513 
2024-05-13 22:12:31.381079: Current learning rate: 0.00523 
2024-05-13 22:13:20.428401: train_loss -0.8526 
2024-05-13 22:13:20.428599: val_loss -0.8521 
2024-05-13 22:13:20.428659: Pseudo dice [0.9201] 
2024-05-13 22:13:20.428719: Epoch time: 49.05 s 
2024-05-13 22:13:21.415544:  
2024-05-13 22:13:21.415655: Epoch 514 
2024-05-13 22:13:21.415751: Current learning rate: 0.00522 
2024-05-13 22:14:10.507220: train_loss -0.8591 
2024-05-13 22:14:10.507506: val_loss -0.8736 
2024-05-13 22:14:10.507571: Pseudo dice [0.9333] 
2024-05-13 22:14:10.507644: Epoch time: 49.09 s 
2024-05-13 22:14:11.489804:  
2024-05-13 22:14:11.489926: Epoch 515 
2024-05-13 22:14:11.490014: Current learning rate: 0.00521 
2024-05-13 22:15:00.513384: train_loss -0.845 
2024-05-13 22:15:00.513677: val_loss -0.8486 
2024-05-13 22:15:00.513748: Pseudo dice [0.924] 
2024-05-13 22:15:00.513810: Epoch time: 49.02 s 
2024-05-13 22:15:01.504573:  
2024-05-13 22:15:01.504799: Epoch 516 
2024-05-13 22:15:01.504970: Current learning rate: 0.0052 
2024-05-13 22:15:50.533262: train_loss -0.862 
2024-05-13 22:15:50.533459: val_loss -0.8736 
2024-05-13 22:15:50.533519: Pseudo dice [0.9341] 
2024-05-13 22:15:50.533584: Epoch time: 49.03 s 
2024-05-13 22:15:51.575367:  
2024-05-13 22:15:51.575475: Epoch 517 
2024-05-13 22:15:51.575559: Current learning rate: 0.00519 
2024-05-13 22:16:40.647404: train_loss -0.8618 
2024-05-13 22:16:40.647614: val_loss -0.8621 
2024-05-13 22:16:40.647675: Pseudo dice [0.9289] 
2024-05-13 22:16:40.647734: Epoch time: 49.07 s 
2024-05-13 22:16:41.638412:  
2024-05-13 22:16:41.638525: Epoch 518 
2024-05-13 22:16:41.638612: Current learning rate: 0.00518 
2024-05-13 22:17:30.617544: train_loss -0.8603 
2024-05-13 22:17:30.617840: val_loss -0.8724 
2024-05-13 22:17:30.617912: Pseudo dice [0.9349] 
2024-05-13 22:17:30.617972: Epoch time: 48.98 s 
2024-05-13 22:17:30.618019: Yayy! New best EMA pseudo Dice: 0.9281 
2024-05-13 22:17:32.407812:  
2024-05-13 22:17:32.407936: Epoch 519 
2024-05-13 22:17:32.408031: Current learning rate: 0.00518 
2024-05-13 22:18:21.481284: train_loss -0.8524 
2024-05-13 22:18:21.481473: val_loss -0.8627 
2024-05-13 22:18:21.481536: Pseudo dice [0.9312] 
2024-05-13 22:18:21.481603: Epoch time: 49.07 s 
2024-05-13 22:18:21.481763: Yayy! New best EMA pseudo Dice: 0.9284 
2024-05-13 22:18:22.841042:  
2024-05-13 22:18:22.841170: Epoch 520 
2024-05-13 22:18:22.841270: Current learning rate: 0.00517 
2024-05-13 22:19:11.880220: train_loss -0.863 
2024-05-13 22:19:11.880411: val_loss -0.8707 
2024-05-13 22:19:11.880486: Pseudo dice [0.9314] 
2024-05-13 22:19:11.880547: Epoch time: 49.04 s 
2024-05-13 22:19:11.880594: Yayy! New best EMA pseudo Dice: 0.9287 
2024-05-13 22:19:13.274843:  
2024-05-13 22:19:13.275056: Epoch 521 
2024-05-13 22:19:13.275143: Current learning rate: 0.00516 
2024-05-13 22:20:02.290162: train_loss -0.8616 
2024-05-13 22:20:02.290862: val_loss -0.86 
2024-05-13 22:20:02.290931: Pseudo dice [0.9286] 
2024-05-13 22:20:02.290987: Epoch time: 49.02 s 
2024-05-13 22:20:03.287045:  
2024-05-13 22:20:03.287169: Epoch 522 
2024-05-13 22:20:03.287252: Current learning rate: 0.00515 
2024-05-13 22:20:52.335368: train_loss -0.8606 
2024-05-13 22:20:52.335545: val_loss -0.8706 
2024-05-13 22:20:52.335603: Pseudo dice [0.9321] 
2024-05-13 22:20:52.335662: Epoch time: 49.05 s 
2024-05-13 22:20:52.335708: Yayy! New best EMA pseudo Dice: 0.929 
2024-05-13 22:20:53.667857:  
2024-05-13 22:20:53.667994: Epoch 523 
2024-05-13 22:20:53.668077: Current learning rate: 0.00514 
2024-05-13 22:21:42.644355: train_loss -0.8599 
2024-05-13 22:21:42.644527: val_loss -0.8566 
2024-05-13 22:21:42.644592: Pseudo dice [0.928] 
2024-05-13 22:21:42.644668: Epoch time: 48.98 s 
2024-05-13 22:21:43.653029:  
2024-05-13 22:21:43.653146: Epoch 524 
2024-05-13 22:21:43.653247: Current learning rate: 0.00513 
2024-05-13 22:22:32.705709: train_loss -0.8654 
2024-05-13 22:22:32.706456: val_loss -0.8614 
2024-05-13 22:22:32.706575: Pseudo dice [0.9281] 
2024-05-13 22:22:32.706770: Epoch time: 49.05 s 
2024-05-13 22:22:33.709243:  
2024-05-13 22:22:33.709449: Epoch 525 
2024-05-13 22:22:33.709535: Current learning rate: 0.00512 
2024-05-13 22:23:22.765861: train_loss -0.8689 
2024-05-13 22:23:22.766149: val_loss -0.8593 
2024-05-13 22:23:22.766216: Pseudo dice [0.9211] 
2024-05-13 22:23:22.766276: Epoch time: 49.06 s 
2024-05-13 22:23:23.747696:  
2024-05-13 22:23:23.747801: Epoch 526 
2024-05-13 22:23:23.747897: Current learning rate: 0.00511 
2024-05-13 22:24:12.828576: train_loss -0.8617 
2024-05-13 22:24:12.828748: val_loss -0.8559 
2024-05-13 22:24:12.828810: Pseudo dice [0.9248] 
2024-05-13 22:24:12.828867: Epoch time: 49.08 s 
2024-05-13 22:24:13.816582:  
2024-05-13 22:24:13.816701: Epoch 527 
2024-05-13 22:24:13.816782: Current learning rate: 0.0051 
2024-05-13 22:25:02.935281: train_loss -0.8593 
2024-05-13 22:25:02.935742: val_loss -0.855 
2024-05-13 22:25:02.935815: Pseudo dice [0.9265] 
2024-05-13 22:25:02.935911: Epoch time: 49.12 s 
2024-05-13 22:25:03.945190:  
2024-05-13 22:25:03.945410: Epoch 528 
2024-05-13 22:25:03.945500: Current learning rate: 0.00509 
2024-05-13 22:25:52.957181: train_loss -0.8652 
2024-05-13 22:25:52.957366: val_loss -0.8651 
2024-05-13 22:25:52.957430: Pseudo dice [0.9257] 
2024-05-13 22:25:52.957510: Epoch time: 49.01 s 
2024-05-13 22:25:54.385956:  
2024-05-13 22:25:54.386231: Epoch 529 
2024-05-13 22:25:54.386324: Current learning rate: 0.00508 
2024-05-13 22:26:43.451580: train_loss -0.8653 
2024-05-13 22:26:43.451769: val_loss -0.8786 
2024-05-13 22:26:43.451849: Pseudo dice [0.9372] 
2024-05-13 22:26:43.451908: Epoch time: 49.07 s 
2024-05-13 22:26:44.436612:  
2024-05-13 22:26:44.436743: Epoch 530 
2024-05-13 22:26:44.436854: Current learning rate: 0.00507 
2024-05-13 22:27:33.479829: train_loss -0.8717 
2024-05-13 22:27:33.480208: val_loss -0.8709 
2024-05-13 22:27:33.480277: Pseudo dice [0.9322] 
2024-05-13 22:27:33.480337: Epoch time: 49.04 s 
2024-05-13 22:27:34.487638:  
2024-05-13 22:27:34.487808: Epoch 531 
2024-05-13 22:27:34.487899: Current learning rate: 0.00506 
2024-05-13 22:28:23.623246: train_loss -0.8563 
2024-05-13 22:28:23.623433: val_loss -0.8696 
2024-05-13 22:28:23.623511: Pseudo dice [0.9351] 
2024-05-13 22:28:23.623576: Epoch time: 49.14 s 
2024-05-13 22:28:23.623634: Yayy! New best EMA pseudo Dice: 0.9294 
2024-05-13 22:28:24.973710:  
2024-05-13 22:28:24.973876: Epoch 532 
2024-05-13 22:28:24.973964: Current learning rate: 0.00505 
2024-05-13 22:29:14.045278: train_loss -0.8597 
2024-05-13 22:29:14.045470: val_loss -0.8482 
2024-05-13 22:29:14.045530: Pseudo dice [0.9185] 
2024-05-13 22:29:14.045589: Epoch time: 49.07 s 
2024-05-13 22:29:15.035175:  
2024-05-13 22:29:15.035289: Epoch 533 
2024-05-13 22:29:15.035378: Current learning rate: 0.00504 
2024-05-13 22:30:04.154391: train_loss -0.8522 
2024-05-13 22:30:04.154705: val_loss -0.8684 
2024-05-13 22:30:04.154774: Pseudo dice [0.9341] 
2024-05-13 22:30:04.154839: Epoch time: 49.12 s 
2024-05-13 22:30:05.171462:  
2024-05-13 22:30:05.171582: Epoch 534 
2024-05-13 22:30:05.171665: Current learning rate: 0.00503 
2024-05-13 22:30:54.194165: train_loss -0.8609 
2024-05-13 22:30:54.194339: val_loss -0.8489 
2024-05-13 22:30:54.194417: Pseudo dice [0.9193] 
2024-05-13 22:30:54.194476: Epoch time: 49.02 s 
2024-05-13 22:30:55.224036:  
2024-05-13 22:30:55.224152: Epoch 535 
2024-05-13 22:30:55.224236: Current learning rate: 0.00502 
2024-05-13 22:31:44.267945: train_loss -0.8643 
2024-05-13 22:31:44.268113: val_loss -0.8551 
2024-05-13 22:31:44.268191: Pseudo dice [0.9288] 
2024-05-13 22:31:44.268248: Epoch time: 49.04 s 
2024-05-13 22:31:45.254925:  
2024-05-13 22:31:45.255175: Epoch 536 
2024-05-13 22:31:45.255266: Current learning rate: 0.00501 
2024-05-13 22:32:34.326992: train_loss -0.8601 
2024-05-13 22:32:34.327819: val_loss -0.8687 
2024-05-13 22:32:34.327904: Pseudo dice [0.9322] 
2024-05-13 22:32:34.327964: Epoch time: 49.07 s 
2024-05-13 22:32:35.346695:  
2024-05-13 22:32:35.346806: Epoch 537 
2024-05-13 22:32:35.346891: Current learning rate: 0.005 
2024-05-13 22:33:24.378431: train_loss -0.8607 
2024-05-13 22:33:24.378607: val_loss -0.8594 
2024-05-13 22:33:24.378666: Pseudo dice [0.9243] 
2024-05-13 22:33:24.378734: Epoch time: 49.03 s 
2024-05-13 22:33:25.366444:  
2024-05-13 22:33:25.366547: Epoch 538 
2024-05-13 22:33:25.366628: Current learning rate: 0.00499 
2024-05-13 22:34:14.548983: train_loss -0.862 
2024-05-13 22:34:14.549167: val_loss -0.8601 
2024-05-13 22:34:14.549231: Pseudo dice [0.9294] 
2024-05-13 22:34:14.549296: Epoch time: 49.18 s 
2024-05-13 22:34:15.557787:  
2024-05-13 22:34:15.557899: Epoch 539 
2024-05-13 22:34:15.557983: Current learning rate: 0.00498 
2024-05-13 22:35:05.227341: train_loss -0.865 
2024-05-13 22:35:05.227621: val_loss -0.8699 
2024-05-13 22:35:05.227690: Pseudo dice [0.9292] 
2024-05-13 22:35:05.227747: Epoch time: 49.67 s 
2024-05-13 22:35:06.231484:  
2024-05-13 22:35:06.231658: Epoch 540 
2024-05-13 22:35:06.231758: Current learning rate: 0.00497 
2024-05-13 22:35:55.256028: train_loss -0.8575 
2024-05-13 22:35:55.256354: val_loss -0.866 
2024-05-13 22:35:55.256425: Pseudo dice [0.9298] 
2024-05-13 22:35:55.256483: Epoch time: 49.03 s 
2024-05-13 22:35:56.313361:  
2024-05-13 22:35:56.313606: Epoch 541 
2024-05-13 22:35:56.313697: Current learning rate: 0.00496 
2024-05-13 22:36:45.424502: train_loss -0.8605 
2024-05-13 22:36:45.424677: val_loss -0.8689 
2024-05-13 22:36:45.424765: Pseudo dice [0.929] 
2024-05-13 22:36:45.424849: Epoch time: 49.11 s 
2024-05-13 22:36:46.414925:  
2024-05-13 22:36:46.415051: Epoch 542 
2024-05-13 22:36:46.415156: Current learning rate: 0.00495 
2024-05-13 22:37:35.400470: train_loss -0.8608 
2024-05-13 22:37:35.400648: val_loss -0.8655 
2024-05-13 22:37:35.400709: Pseudo dice [0.926] 
2024-05-13 22:37:35.400783: Epoch time: 48.99 s 
2024-05-13 22:37:36.410701:  
2024-05-13 22:37:36.410819: Epoch 543 
2024-05-13 22:37:36.410910: Current learning rate: 0.00494 
2024-05-13 22:38:25.443380: train_loss -0.8678 
2024-05-13 22:38:25.444058: val_loss -0.8619 
2024-05-13 22:38:25.444131: Pseudo dice [0.9262] 
2024-05-13 22:38:25.444195: Epoch time: 49.03 s 
2024-05-13 22:38:26.445839:  
2024-05-13 22:38:26.445959: Epoch 544 
2024-05-13 22:38:26.446046: Current learning rate: 0.00493 
2024-05-13 22:39:15.516147: train_loss -0.8646 
2024-05-13 22:39:15.516342: val_loss -0.8664 
2024-05-13 22:39:15.516401: Pseudo dice [0.9283] 
2024-05-13 22:39:15.516460: Epoch time: 49.07 s 
2024-05-13 22:39:16.556726:  
2024-05-13 22:39:16.556851: Epoch 545 
2024-05-13 22:39:16.556951: Current learning rate: 0.00492 
2024-05-13 22:40:05.591618: train_loss -0.8615 
2024-05-13 22:40:05.591805: val_loss -0.8508 
2024-05-13 22:40:05.591866: Pseudo dice [0.9255] 
2024-05-13 22:40:05.591925: Epoch time: 49.04 s 
2024-05-13 22:40:06.584860:  
2024-05-13 22:40:06.584981: Epoch 546 
2024-05-13 22:40:06.585071: Current learning rate: 0.00491 
2024-05-13 22:40:55.617264: train_loss -0.8573 
2024-05-13 22:40:55.617427: val_loss -0.861 
2024-05-13 22:40:55.617479: Pseudo dice [0.9263] 
2024-05-13 22:40:55.617528: Epoch time: 49.03 s 
2024-05-13 22:40:56.642817:  
2024-05-13 22:40:56.643049: Epoch 547 
2024-05-13 22:40:56.643136: Current learning rate: 0.0049 
2024-05-13 22:41:45.628273: train_loss -0.8541 
2024-05-13 22:41:45.628999: val_loss -0.8828 
2024-05-13 22:41:45.629080: Pseudo dice [0.9383] 
2024-05-13 22:41:45.629150: Epoch time: 48.99 s 
2024-05-13 22:41:46.617091:  
2024-05-13 22:41:46.617198: Epoch 548 
2024-05-13 22:41:46.617283: Current learning rate: 0.00489 
2024-05-13 22:42:35.641924: train_loss -0.845 
2024-05-13 22:42:35.642085: val_loss -0.8605 
2024-05-13 22:42:35.642142: Pseudo dice [0.9264] 
2024-05-13 22:42:35.642218: Epoch time: 49.03 s 
2024-05-13 22:42:36.642103:  
2024-05-13 22:42:36.642204: Epoch 549 
2024-05-13 22:42:36.642320: Current learning rate: 0.00488 
2024-05-13 22:43:25.636427: train_loss -0.8578 
2024-05-13 22:43:25.636599: val_loss -0.8486 
2024-05-13 22:43:25.636658: Pseudo dice [0.9239] 
2024-05-13 22:43:25.636730: Epoch time: 49.0 s 
2024-05-13 22:43:27.456609:  
2024-05-13 22:43:27.456947: Epoch 550 
2024-05-13 22:43:27.457113: Current learning rate: 0.00487 
2024-05-13 22:44:16.472633: train_loss -0.8565 
2024-05-13 22:44:16.472982: val_loss -0.8604 
2024-05-13 22:44:16.473055: Pseudo dice [0.9291] 
2024-05-13 22:44:16.473119: Epoch time: 49.02 s 
2024-05-13 22:44:17.503583:  
2024-05-13 22:44:17.503758: Epoch 551 
2024-05-13 22:44:17.503868: Current learning rate: 0.00486 
2024-05-13 22:45:06.478239: train_loss -0.858 
2024-05-13 22:45:06.478441: val_loss -0.8701 
2024-05-13 22:45:06.478500: Pseudo dice [0.9291] 
2024-05-13 22:45:06.478562: Epoch time: 48.98 s 
2024-05-13 22:45:07.519746:  
2024-05-13 22:45:07.519878: Epoch 552 
2024-05-13 22:45:07.519960: Current learning rate: 0.00485 
2024-05-13 22:45:56.564719: train_loss -0.8511 
2024-05-13 22:45:56.564995: val_loss -0.8709 
2024-05-13 22:45:56.565060: Pseudo dice [0.9329] 
2024-05-13 22:45:56.565117: Epoch time: 49.05 s 
2024-05-13 22:45:57.555557:  
2024-05-13 22:45:57.555786: Epoch 553 
2024-05-13 22:45:57.555889: Current learning rate: 0.00484 
2024-05-13 22:46:46.564469: train_loss -0.8593 
2024-05-13 22:46:46.564671: val_loss -0.868 
2024-05-13 22:46:46.564753: Pseudo dice [0.9314] 
2024-05-13 22:46:46.564835: Epoch time: 49.01 s 
2024-05-13 22:46:47.575543:  
2024-05-13 22:46:47.575682: Epoch 554 
2024-05-13 22:46:47.575767: Current learning rate: 0.00484 
2024-05-13 22:47:36.636007: train_loss -0.857 
2024-05-13 22:47:36.636194: val_loss -0.8397 
2024-05-13 22:47:36.636261: Pseudo dice [0.9184] 
2024-05-13 22:47:36.636324: Epoch time: 49.06 s 
2024-05-13 22:47:37.669108:  
2024-05-13 22:47:37.669372: Epoch 555 
2024-05-13 22:47:37.669562: Current learning rate: 0.00483 
2024-05-13 22:48:26.735884: train_loss -0.855 
2024-05-13 22:48:26.736185: val_loss -0.8557 
2024-05-13 22:48:26.736250: Pseudo dice [0.9239] 
2024-05-13 22:48:26.736308: Epoch time: 49.07 s 
2024-05-13 22:48:27.787072:  
2024-05-13 22:48:27.787189: Epoch 556 
2024-05-13 22:48:27.787271: Current learning rate: 0.00482 
2024-05-13 22:49:16.818292: train_loss -0.8599 
2024-05-13 22:49:16.818473: val_loss -0.856 
2024-05-13 22:49:16.818535: Pseudo dice [0.924] 
2024-05-13 22:49:16.818594: Epoch time: 49.03 s 
2024-05-13 22:49:17.825307:  
2024-05-13 22:49:17.825457: Epoch 557 
2024-05-13 22:49:17.825545: Current learning rate: 0.00481 
2024-05-13 22:50:06.901192: train_loss -0.8568 
2024-05-13 22:50:06.901366: val_loss -0.8587 
2024-05-13 22:50:06.901440: Pseudo dice [0.929] 
2024-05-13 22:50:06.901497: Epoch time: 49.08 s 
2024-05-13 22:50:07.899779:  
2024-05-13 22:50:07.899894: Epoch 558 
2024-05-13 22:50:07.899979: Current learning rate: 0.0048 
2024-05-13 22:50:56.951839: train_loss -0.8645 
2024-05-13 22:50:56.952555: val_loss -0.8725 
2024-05-13 22:50:56.952614: Pseudo dice [0.9343] 
2024-05-13 22:50:56.952670: Epoch time: 49.05 s 
2024-05-13 22:50:57.969656:  
2024-05-13 22:50:57.969779: Epoch 559 
2024-05-13 22:50:57.969864: Current learning rate: 0.00479 
2024-05-13 22:51:47.102199: train_loss -0.8622 
2024-05-13 22:51:47.102392: val_loss -0.8542 
2024-05-13 22:51:47.102457: Pseudo dice [0.9303] 
2024-05-13 22:51:47.102515: Epoch time: 49.13 s 
2024-05-13 22:51:48.097669:  
2024-05-13 22:51:48.097774: Epoch 560 
2024-05-13 22:51:48.097855: Current learning rate: 0.00478 
2024-05-13 22:52:37.158607: train_loss -0.8613 
2024-05-13 22:52:37.158781: val_loss -0.8576 
2024-05-13 22:52:37.158842: Pseudo dice [0.9262] 
2024-05-13 22:52:37.158898: Epoch time: 49.06 s 
2024-05-13 22:52:38.687179:  
2024-05-13 22:52:38.687448: Epoch 561 
2024-05-13 22:52:38.687537: Current learning rate: 0.00477 
2024-05-13 22:53:28.007681: train_loss -0.8641 
2024-05-13 22:53:28.008487: val_loss -0.8681 
2024-05-13 22:53:28.008556: Pseudo dice [0.9325] 
2024-05-13 22:53:28.008610: Epoch time: 49.32 s 
2024-05-13 22:53:28.996289:  
2024-05-13 22:53:28.996418: Epoch 562 
2024-05-13 22:53:28.996520: Current learning rate: 0.00476 
2024-05-13 22:54:18.032154: train_loss -0.8631 
2024-05-13 22:54:18.032314: val_loss -0.8683 
2024-05-13 22:54:18.032366: Pseudo dice [0.9353] 
2024-05-13 22:54:18.032415: Epoch time: 49.04 s 
2024-05-13 22:54:19.020464:  
2024-05-13 22:54:19.020598: Epoch 563 
2024-05-13 22:54:19.020711: Current learning rate: 0.00475 
2024-05-13 22:55:08.041375: train_loss -0.864 
2024-05-13 22:55:08.041556: val_loss -0.8632 
2024-05-13 22:55:08.041616: Pseudo dice [0.9309] 
2024-05-13 22:55:08.041671: Epoch time: 49.02 s 
2024-05-13 22:55:09.077908:  
2024-05-13 22:55:09.078102: Epoch 564 
2024-05-13 22:55:09.078192: Current learning rate: 0.00474 
2024-05-13 22:55:58.103951: train_loss -0.8632 
2024-05-13 22:55:58.104688: val_loss -0.8516 
2024-05-13 22:55:58.104751: Pseudo dice [0.9233] 
2024-05-13 22:55:58.104804: Epoch time: 49.03 s 
2024-05-13 22:55:59.102063:  
2024-05-13 22:55:59.102275: Epoch 565 
2024-05-13 22:55:59.102371: Current learning rate: 0.00473 
2024-05-13 22:56:48.179521: train_loss -0.857 
2024-05-13 22:56:48.179700: val_loss -0.8182 
2024-05-13 22:56:48.180300: Pseudo dice [0.9125] 
2024-05-13 22:56:48.180357: Epoch time: 49.08 s 
2024-05-13 22:56:49.171716:  
2024-05-13 22:56:49.171932: Epoch 566 
2024-05-13 22:56:49.172026: Current learning rate: 0.00472 
2024-05-13 22:57:38.200496: train_loss -0.8456 
2024-05-13 22:57:38.200673: val_loss -0.839 
2024-05-13 22:57:38.200730: Pseudo dice [0.921] 
2024-05-13 22:57:38.200786: Epoch time: 49.03 s 
2024-05-13 22:57:39.194550:  
2024-05-13 22:57:39.194662: Epoch 567 
2024-05-13 22:57:39.194763: Current learning rate: 0.00471 
2024-05-13 22:58:28.320861: train_loss -0.8506 
2024-05-13 22:58:28.321031: val_loss -0.8542 
2024-05-13 22:58:28.321091: Pseudo dice [0.9236] 
2024-05-13 22:58:28.321149: Epoch time: 49.13 s 
2024-05-13 22:58:29.312257:  
2024-05-13 22:58:29.312364: Epoch 568 
2024-05-13 22:58:29.312474: Current learning rate: 0.0047 
2024-05-13 22:59:18.393481: train_loss -0.8593 
2024-05-13 22:59:18.393783: val_loss -0.8502 
2024-05-13 22:59:18.393864: Pseudo dice [0.9265] 
2024-05-13 22:59:18.393921: Epoch time: 49.08 s 
2024-05-13 22:59:19.442003:  
2024-05-13 22:59:19.442125: Epoch 569 
2024-05-13 22:59:19.442211: Current learning rate: 0.00469 
2024-05-13 23:00:08.473246: train_loss -0.8554 
2024-05-13 23:00:08.473411: val_loss -0.8604 
2024-05-13 23:00:08.473470: Pseudo dice [0.9239] 
2024-05-13 23:00:08.473542: Epoch time: 49.03 s 
2024-05-13 23:00:09.489784:  
2024-05-13 23:00:09.489897: Epoch 570 
2024-05-13 23:00:09.489981: Current learning rate: 0.00468 
2024-05-13 23:00:58.540873: train_loss -0.8624 
2024-05-13 23:00:58.541054: val_loss -0.8634 
2024-05-13 23:00:58.541113: Pseudo dice [0.9319] 
2024-05-13 23:00:58.541171: Epoch time: 49.05 s 
2024-05-13 23:00:59.522353:  
2024-05-13 23:00:59.522704: Epoch 571 
2024-05-13 23:00:59.522818: Current learning rate: 0.00467 
2024-05-13 23:01:48.609231: train_loss -0.8586 
2024-05-13 23:01:48.609904: val_loss -0.8508 
2024-05-13 23:01:48.609965: Pseudo dice [0.9265] 
2024-05-13 23:01:48.610014: Epoch time: 49.09 s 
2024-05-13 23:01:50.157024:  
2024-05-13 23:01:50.157176: Epoch 572 
2024-05-13 23:01:50.157279: Current learning rate: 0.00466 
2024-05-13 23:02:39.200038: train_loss -0.8551 
2024-05-13 23:02:39.200459: val_loss -0.8538 
2024-05-13 23:02:39.200732: Pseudo dice [0.9231] 
2024-05-13 23:02:39.200850: Epoch time: 49.04 s 
2024-05-13 23:02:40.215474:  
2024-05-13 23:02:40.215597: Epoch 573 
2024-05-13 23:02:40.215679: Current learning rate: 0.00465 
2024-05-13 23:03:29.262629: train_loss -0.8495 
2024-05-13 23:03:29.262794: val_loss -0.8337 
2024-05-13 23:03:29.262851: Pseudo dice [0.9217] 
2024-05-13 23:03:29.262920: Epoch time: 49.05 s 
2024-05-13 23:03:30.272033:  
2024-05-13 23:03:30.272167: Epoch 574 
2024-05-13 23:03:30.272254: Current learning rate: 0.00464 
2024-05-13 23:04:19.299508: train_loss -0.8424 
2024-05-13 23:04:19.299773: val_loss -0.8493 
2024-05-13 23:04:19.299841: Pseudo dice [0.9194] 
2024-05-13 23:04:19.299901: Epoch time: 49.03 s 
2024-05-13 23:04:20.304206:  
2024-05-13 23:04:20.304324: Epoch 575 
2024-05-13 23:04:20.304408: Current learning rate: 0.00463 
2024-05-13 23:05:09.403875: train_loss -0.853 
2024-05-13 23:05:09.404050: val_loss -0.8641 
2024-05-13 23:05:09.404109: Pseudo dice [0.9286] 
2024-05-13 23:05:09.404167: Epoch time: 49.1 s 
2024-05-13 23:05:10.410040:  
2024-05-13 23:05:10.410160: Epoch 576 
2024-05-13 23:05:10.410241: Current learning rate: 0.00462 
2024-05-13 23:05:59.550045: train_loss -0.858 
2024-05-13 23:05:59.550214: val_loss -0.8571 
2024-05-13 23:05:59.550278: Pseudo dice [0.9276] 
2024-05-13 23:05:59.550365: Epoch time: 49.14 s 
2024-05-13 23:06:00.637773:  
2024-05-13 23:06:00.637920: Epoch 577 
2024-05-13 23:06:00.638008: Current learning rate: 0.00461 
2024-05-13 23:06:49.660376: train_loss -0.8519 
2024-05-13 23:06:49.661120: val_loss -0.8644 
2024-05-13 23:06:49.661183: Pseudo dice [0.9333] 
2024-05-13 23:06:49.661236: Epoch time: 49.02 s 
2024-05-13 23:06:50.692798:  
2024-05-13 23:06:50.692913: Epoch 578 
2024-05-13 23:06:50.692997: Current learning rate: 0.0046 
2024-05-13 23:07:39.778826: train_loss -0.8639 
2024-05-13 23:07:39.779163: val_loss -0.854 
2024-05-13 23:07:39.779225: Pseudo dice [0.9233] 
2024-05-13 23:07:39.779809: Epoch time: 49.09 s 
2024-05-13 23:07:40.802445:  
2024-05-13 23:07:40.802557: Epoch 579 
2024-05-13 23:07:40.802638: Current learning rate: 0.00459 
2024-05-13 23:08:29.789168: train_loss -0.8634 
2024-05-13 23:08:29.789345: val_loss -0.8641 
2024-05-13 23:08:29.789403: Pseudo dice [0.9264] 
2024-05-13 23:08:29.789477: Epoch time: 48.99 s 
2024-05-13 23:08:30.792293:  
2024-05-13 23:08:30.792401: Epoch 580 
2024-05-13 23:08:30.792506: Current learning rate: 0.00458 
2024-05-13 23:09:19.755997: train_loss -0.8544 
2024-05-13 23:09:19.756191: val_loss -0.8581 
2024-05-13 23:09:19.756250: Pseudo dice [0.9237] 
2024-05-13 23:09:19.756306: Epoch time: 48.96 s 
2024-05-13 23:09:20.789934:  
2024-05-13 23:09:20.790040: Epoch 581 
2024-05-13 23:09:20.790142: Current learning rate: 0.00457 
2024-05-13 23:10:09.773651: train_loss -0.864 
2024-05-13 23:10:09.774322: val_loss -0.8547 
2024-05-13 23:10:09.774389: Pseudo dice [0.9224] 
2024-05-13 23:10:09.774441: Epoch time: 48.98 s 
2024-05-13 23:10:10.809371:  
2024-05-13 23:10:10.809476: Epoch 582 
2024-05-13 23:10:10.809562: Current learning rate: 0.00456 
2024-05-13 23:10:59.875124: train_loss -0.8617 
2024-05-13 23:10:59.875326: val_loss -0.8739 
2024-05-13 23:10:59.875385: Pseudo dice [0.9342] 
2024-05-13 23:10:59.875445: Epoch time: 49.07 s 
2024-05-13 23:11:01.277830:  
2024-05-13 23:11:01.277950: Epoch 583 
2024-05-13 23:11:01.278059: Current learning rate: 0.00455 
2024-05-13 23:11:50.304940: train_loss -0.8539 
2024-05-13 23:11:50.305138: val_loss -0.8531 
2024-05-13 23:11:50.305197: Pseudo dice [0.9283] 
2024-05-13 23:11:50.305253: Epoch time: 49.03 s 
2024-05-13 23:11:51.316831:  
2024-05-13 23:11:51.316958: Epoch 584 
2024-05-13 23:11:51.317041: Current learning rate: 0.00454 
2024-05-13 23:12:40.374174: train_loss -0.8648 
2024-05-13 23:12:40.374870: val_loss -0.8666 
2024-05-13 23:12:40.374937: Pseudo dice [0.9317] 
2024-05-13 23:12:40.374989: Epoch time: 49.06 s 
2024-05-13 23:12:41.375277:  
2024-05-13 23:12:41.375530: Epoch 585 
2024-05-13 23:12:41.375618: Current learning rate: 0.00453 
2024-05-13 23:13:30.419832: train_loss -0.8616 
2024-05-13 23:13:30.420075: val_loss -0.8873 
2024-05-13 23:13:30.420177: Pseudo dice [0.9358] 
2024-05-13 23:13:30.420288: Epoch time: 49.05 s 
2024-05-13 23:13:31.442021:  
2024-05-13 23:13:31.442147: Epoch 586 
2024-05-13 23:13:31.442232: Current learning rate: 0.00452 
2024-05-13 23:14:20.484933: train_loss -0.8587 
2024-05-13 23:14:20.485112: val_loss -0.8701 
2024-05-13 23:14:20.485170: Pseudo dice [0.9293] 
2024-05-13 23:14:20.485225: Epoch time: 49.04 s 
2024-05-13 23:14:21.520309:  
2024-05-13 23:14:21.520426: Epoch 587 
2024-05-13 23:14:21.520511: Current learning rate: 0.00451 
2024-05-13 23:15:10.572612: train_loss -0.8638 
2024-05-13 23:15:10.572911: val_loss -0.8459 
2024-05-13 23:15:10.572992: Pseudo dice [0.9191] 
2024-05-13 23:15:10.573052: Epoch time: 49.05 s 
2024-05-13 23:15:11.578143:  
2024-05-13 23:15:11.578272: Epoch 588 
2024-05-13 23:15:11.578374: Current learning rate: 0.0045 
2024-05-13 23:16:00.604194: train_loss -0.8606 
2024-05-13 23:16:00.604424: val_loss -0.8791 
2024-05-13 23:16:00.604493: Pseudo dice [0.9323] 
2024-05-13 23:16:00.604558: Epoch time: 49.03 s 
2024-05-13 23:16:01.623376:  
2024-05-13 23:16:01.623491: Epoch 589 
2024-05-13 23:16:01.623577: Current learning rate: 0.00449 
2024-05-13 23:16:50.702441: train_loss -0.8619 
2024-05-13 23:16:50.702615: val_loss -0.8678 
2024-05-13 23:16:50.702677: Pseudo dice [0.9315] 
2024-05-13 23:16:50.702736: Epoch time: 49.08 s 
2024-05-13 23:16:51.717103:  
2024-05-13 23:16:51.717218: Epoch 590 
2024-05-13 23:16:51.717342: Current learning rate: 0.00448 
2024-05-13 23:17:40.765351: train_loss -0.8586 
2024-05-13 23:17:40.765518: val_loss -0.862 
2024-05-13 23:17:40.765580: Pseudo dice [0.9254] 
2024-05-13 23:17:40.765637: Epoch time: 49.05 s 
2024-05-13 23:17:41.770545:  
2024-05-13 23:17:41.770655: Epoch 591 
2024-05-13 23:17:41.770741: Current learning rate: 0.00447 
2024-05-13 23:18:30.851725: train_loss -0.8496 
2024-05-13 23:18:30.852478: val_loss -0.865 
2024-05-13 23:18:30.852542: Pseudo dice [0.9331] 
2024-05-13 23:18:30.852594: Epoch time: 49.08 s 
2024-05-13 23:18:31.872035:  
2024-05-13 23:18:31.872420: Epoch 592 
2024-05-13 23:18:31.872534: Current learning rate: 0.00446 
2024-05-13 23:19:20.954735: train_loss -0.8511 
2024-05-13 23:19:20.954904: val_loss -0.8495 
2024-05-13 23:19:20.954962: Pseudo dice [0.9254] 
2024-05-13 23:19:20.955035: Epoch time: 49.08 s 
2024-05-13 23:19:22.449288:  
2024-05-13 23:19:22.449586: Epoch 593 
2024-05-13 23:19:22.449696: Current learning rate: 0.00445 
2024-05-13 23:20:11.537216: train_loss -0.8639 
2024-05-13 23:20:11.537388: val_loss -0.8745 
2024-05-13 23:20:11.537466: Pseudo dice [0.9366] 
2024-05-13 23:20:11.537524: Epoch time: 49.09 s 
2024-05-13 23:20:12.546064:  
2024-05-13 23:20:12.546210: Epoch 594 
2024-05-13 23:20:12.546301: Current learning rate: 0.00444 
2024-05-13 23:21:01.584119: train_loss -0.8598 
2024-05-13 23:21:01.584395: val_loss -0.8671 
2024-05-13 23:21:01.584466: Pseudo dice [0.9323] 
2024-05-13 23:21:01.584526: Epoch time: 49.04 s 
2024-05-13 23:21:02.587718:  
2024-05-13 23:21:02.587860: Epoch 595 
2024-05-13 23:21:02.587963: Current learning rate: 0.00443 
2024-05-13 23:21:51.752605: train_loss -0.859 
2024-05-13 23:21:51.752808: val_loss -0.8628 
2024-05-13 23:21:51.752870: Pseudo dice [0.929] 
2024-05-13 23:21:51.752927: Epoch time: 49.17 s 
2024-05-13 23:21:52.764478:  
2024-05-13 23:21:52.764604: Epoch 596 
2024-05-13 23:21:52.764692: Current learning rate: 0.00442 
2024-05-13 23:22:41.816643: train_loss -0.8617 
2024-05-13 23:22:41.816841: val_loss -0.8565 
2024-05-13 23:22:41.816904: Pseudo dice [0.9284] 
2024-05-13 23:22:41.816965: Epoch time: 49.05 s 
2024-05-13 23:22:42.834594:  
2024-05-13 23:22:42.834716: Epoch 597 
2024-05-13 23:22:42.834801: Current learning rate: 0.00441 
2024-05-13 23:23:31.907137: train_loss -0.8562 
2024-05-13 23:23:31.907415: val_loss -0.8637 
2024-05-13 23:23:31.907485: Pseudo dice [0.9294] 
2024-05-13 23:23:31.907544: Epoch time: 49.07 s 
2024-05-13 23:23:32.930594:  
2024-05-13 23:23:32.930853: Epoch 598 
2024-05-13 23:23:32.930944: Current learning rate: 0.0044 
2024-05-13 23:24:22.020517: train_loss -0.8597 
2024-05-13 23:24:22.020703: val_loss -0.8574 
2024-05-13 23:24:22.020762: Pseudo dice [0.9283] 
2024-05-13 23:24:22.020821: Epoch time: 49.09 s 
2024-05-13 23:24:23.041667:  
2024-05-13 23:24:23.041789: Epoch 599 
2024-05-13 23:24:23.041877: Current learning rate: 0.00439 
2024-05-13 23:25:12.077033: train_loss -0.8611 
2024-05-13 23:25:12.077192: val_loss -0.8647 
2024-05-13 23:25:12.077266: Pseudo dice [0.9305] 
2024-05-13 23:25:12.077323: Epoch time: 49.04 s 
2024-05-13 23:25:13.423691:  
2024-05-13 23:25:13.423800: Epoch 600 
2024-05-13 23:25:13.423912: Current learning rate: 0.00438 
2024-05-13 23:26:02.434134: train_loss -0.8639 
2024-05-13 23:26:02.434852: val_loss -0.8632 
2024-05-13 23:26:02.434942: Pseudo dice [0.9245] 
2024-05-13 23:26:02.434996: Epoch time: 49.01 s 
2024-05-13 23:26:03.444335:  
2024-05-13 23:26:03.444528: Epoch 601 
2024-05-13 23:26:03.444612: Current learning rate: 0.00437 
2024-05-13 23:26:52.496414: train_loss -0.8675 
2024-05-13 23:26:52.496593: val_loss -0.872 
2024-05-13 23:26:52.496667: Pseudo dice [0.9347] 
2024-05-13 23:26:52.496724: Epoch time: 49.05 s 
2024-05-13 23:26:53.503886:  
2024-05-13 23:26:53.503999: Epoch 602 
2024-05-13 23:26:53.504089: Current learning rate: 0.00436 
2024-05-13 23:27:42.531950: train_loss -0.8633 
2024-05-13 23:27:42.532151: val_loss -0.8701 
2024-05-13 23:27:42.532220: Pseudo dice [0.9284] 
2024-05-13 23:27:42.532295: Epoch time: 49.03 s 
2024-05-13 23:27:43.542178:  
2024-05-13 23:27:43.542453: Epoch 603 
2024-05-13 23:27:43.542545: Current learning rate: 0.00435 
2024-05-13 23:28:32.612968: train_loss -0.8671 
2024-05-13 23:28:32.613645: val_loss -0.8753 
2024-05-13 23:28:32.613710: Pseudo dice [0.9346] 
2024-05-13 23:28:32.613764: Epoch time: 49.07 s 
2024-05-13 23:28:32.613806: Yayy! New best EMA pseudo Dice: 0.9298 
2024-05-13 23:28:34.399401:  
2024-05-13 23:28:34.399643: Epoch 604 
2024-05-13 23:28:34.399736: Current learning rate: 0.00434 
2024-05-13 23:29:23.482771: train_loss -0.8697 
2024-05-13 23:29:23.482950: val_loss -0.8671 
2024-05-13 23:29:23.483015: Pseudo dice [0.9314] 
2024-05-13 23:29:23.483074: Epoch time: 49.08 s 
2024-05-13 23:29:23.483120: Yayy! New best EMA pseudo Dice: 0.93 
2024-05-13 23:29:24.849324:  
2024-05-13 23:29:24.849618: Epoch 605 
2024-05-13 23:29:24.849879: Current learning rate: 0.00433 
2024-05-13 23:30:13.869073: train_loss -0.8652 
2024-05-13 23:30:13.869276: val_loss -0.8679 
2024-05-13 23:30:13.869344: Pseudo dice [0.9304] 
2024-05-13 23:30:13.869423: Epoch time: 49.02 s 
2024-05-13 23:30:13.869472: Yayy! New best EMA pseudo Dice: 0.93 
2024-05-13 23:30:15.217268:  
2024-05-13 23:30:15.217520: Epoch 606 
2024-05-13 23:30:15.217608: Current learning rate: 0.00432 
2024-05-13 23:31:04.315872: train_loss -0.8672 
2024-05-13 23:31:04.316156: val_loss -0.8626 
2024-05-13 23:31:04.316222: Pseudo dice [0.9289] 
2024-05-13 23:31:04.316287: Epoch time: 49.1 s 
2024-05-13 23:31:05.323292:  
2024-05-13 23:31:05.323417: Epoch 607 
2024-05-13 23:31:05.323500: Current learning rate: 0.00431 
2024-05-13 23:31:54.426039: train_loss -0.8572 
2024-05-13 23:31:54.426244: val_loss -0.861 
2024-05-13 23:31:54.426362: Pseudo dice [0.9296] 
2024-05-13 23:31:54.426425: Epoch time: 49.1 s 
2024-05-13 23:31:55.434077:  
2024-05-13 23:31:55.434199: Epoch 608 
2024-05-13 23:31:55.434282: Current learning rate: 0.0043 
2024-05-13 23:32:44.582605: train_loss -0.8667 
2024-05-13 23:32:44.582794: val_loss -0.8687 
2024-05-13 23:32:44.583020: Pseudo dice [0.9328] 
2024-05-13 23:32:44.583108: Epoch time: 49.15 s 
2024-05-13 23:32:44.583182: Yayy! New best EMA pseudo Dice: 0.9302 
2024-05-13 23:32:45.954475:  
2024-05-13 23:32:45.954700: Epoch 609 
2024-05-13 23:32:45.954787: Current learning rate: 0.00429 
2024-05-13 23:33:35.050619: train_loss -0.8608 
2024-05-13 23:33:35.051097: val_loss -0.8446 
2024-05-13 23:33:35.051165: Pseudo dice [0.9208] 
2024-05-13 23:33:35.051228: Epoch time: 49.1 s 
2024-05-13 23:33:36.074532:  
2024-05-13 23:33:36.074651: Epoch 610 
2024-05-13 23:33:36.074736: Current learning rate: 0.00429 
2024-05-13 23:34:25.259629: train_loss -0.8617 
2024-05-13 23:34:25.259800: val_loss -0.8517 
2024-05-13 23:34:25.259860: Pseudo dice [0.9273] 
2024-05-13 23:34:25.259917: Epoch time: 49.19 s 
2024-05-13 23:34:26.278700:  
2024-05-13 23:34:26.278810: Epoch 611 
2024-05-13 23:34:26.278895: Current learning rate: 0.00428 
2024-05-13 23:35:15.372207: train_loss -0.8552 
2024-05-13 23:35:15.372385: val_loss -0.8727 
2024-05-13 23:35:15.372452: Pseudo dice [0.9331] 
2024-05-13 23:35:15.372514: Epoch time: 49.09 s 
2024-05-13 23:35:16.383098:  
2024-05-13 23:35:16.383312: Epoch 612 
2024-05-13 23:35:16.383397: Current learning rate: 0.00427 
2024-05-13 23:36:05.402462: train_loss -0.8651 
2024-05-13 23:36:05.402727: val_loss -0.8683 
2024-05-13 23:36:05.402796: Pseudo dice [0.9315] 
2024-05-13 23:36:05.402853: Epoch time: 49.02 s 
2024-05-13 23:36:06.427857:  
2024-05-13 23:36:06.427978: Epoch 613 
2024-05-13 23:36:06.428063: Current learning rate: 0.00426 
2024-05-13 23:36:55.505049: train_loss -0.8674 
2024-05-13 23:36:55.505219: val_loss -0.8742 
2024-05-13 23:36:55.505300: Pseudo dice [0.9325] 
2024-05-13 23:36:55.505375: Epoch time: 49.08 s 
2024-05-13 23:36:57.003724:  
2024-05-13 23:36:57.003844: Epoch 614 
2024-05-13 23:36:57.003954: Current learning rate: 0.00425 
2024-05-13 23:37:46.087226: train_loss -0.8673 
2024-05-13 23:37:46.087406: val_loss -0.8766 
2024-05-13 23:37:46.087471: Pseudo dice [0.9335] 
2024-05-13 23:37:46.087550: Epoch time: 49.08 s 
2024-05-13 23:37:46.087620: Yayy! New best EMA pseudo Dice: 0.9303 
2024-05-13 23:37:47.429431:  
2024-05-13 23:37:47.429544: Epoch 615 
2024-05-13 23:37:47.429641: Current learning rate: 0.00424 
2024-05-13 23:38:36.451404: train_loss -0.8647 
2024-05-13 23:38:36.452067: val_loss -0.8683 
2024-05-13 23:38:36.452125: Pseudo dice [0.9321] 
2024-05-13 23:38:36.452175: Epoch time: 49.02 s 
2024-05-13 23:38:36.452302: Yayy! New best EMA pseudo Dice: 0.9305 
2024-05-13 23:38:37.812909:  
2024-05-13 23:38:37.813024: Epoch 616 
2024-05-13 23:38:37.813124: Current learning rate: 0.00423 
2024-05-13 23:39:26.927497: train_loss -0.8653 
2024-05-13 23:39:26.927681: val_loss -0.8696 
2024-05-13 23:39:26.927743: Pseudo dice [0.9315] 
2024-05-13 23:39:26.927806: Epoch time: 49.12 s 
2024-05-13 23:39:26.927869: Yayy! New best EMA pseudo Dice: 0.9306 
2024-05-13 23:39:28.290795:  
2024-05-13 23:39:28.290914: Epoch 617 
2024-05-13 23:39:28.290997: Current learning rate: 0.00422 
2024-05-13 23:40:17.376836: train_loss -0.8615 
2024-05-13 23:40:17.377023: val_loss -0.8733 
2024-05-13 23:40:17.377106: Pseudo dice [0.9344] 
2024-05-13 23:40:17.377185: Epoch time: 49.09 s 
2024-05-13 23:40:17.377251: Yayy! New best EMA pseudo Dice: 0.931 
2024-05-13 23:40:18.742553:  
2024-05-13 23:40:18.742675: Epoch 618 
2024-05-13 23:40:18.742758: Current learning rate: 0.00421 
2024-05-13 23:41:07.799881: train_loss -0.8699 
2024-05-13 23:41:07.800561: val_loss -0.8735 
2024-05-13 23:41:07.800630: Pseudo dice [0.9323] 
2024-05-13 23:41:07.800683: Epoch time: 49.06 s 
2024-05-13 23:41:07.800723: Yayy! New best EMA pseudo Dice: 0.9311 
2024-05-13 23:41:09.152181:  
2024-05-13 23:41:09.152381: Epoch 619 
2024-05-13 23:41:09.152486: Current learning rate: 0.0042 
2024-05-13 23:41:58.200301: train_loss -0.8727 
2024-05-13 23:41:58.200466: val_loss -0.8725 
2024-05-13 23:41:58.200542: Pseudo dice [0.9327] 
2024-05-13 23:41:58.200599: Epoch time: 49.05 s 
2024-05-13 23:41:58.200644: Yayy! New best EMA pseudo Dice: 0.9312 
2024-05-13 23:41:59.569401:  
2024-05-13 23:41:59.569659: Epoch 620 
2024-05-13 23:41:59.569764: Current learning rate: 0.00419 
2024-05-13 23:42:48.647062: train_loss -0.87 
2024-05-13 23:42:48.647349: val_loss -0.8666 
2024-05-13 23:42:48.647440: Pseudo dice [0.9305] 
2024-05-13 23:42:48.647523: Epoch time: 49.08 s 
2024-05-13 23:42:49.680645:  
2024-05-13 23:42:49.680753: Epoch 621 
2024-05-13 23:42:49.680835: Current learning rate: 0.00418 
2024-05-13 23:43:38.759709: train_loss -0.8673 
2024-05-13 23:43:38.759997: val_loss -0.8615 
2024-05-13 23:43:38.760063: Pseudo dice [0.9288] 
2024-05-13 23:43:38.760120: Epoch time: 49.08 s 
2024-05-13 23:43:39.768148:  
2024-05-13 23:43:39.768376: Epoch 622 
2024-05-13 23:43:39.768497: Current learning rate: 0.00417 
2024-05-13 23:44:28.810944: train_loss -0.8689 
2024-05-13 23:44:28.811125: val_loss -0.8756 
2024-05-13 23:44:28.811183: Pseudo dice [0.9336] 
2024-05-13 23:44:28.811246: Epoch time: 49.04 s 
2024-05-13 23:44:30.331942:  
2024-05-13 23:44:30.332098: Epoch 623 
2024-05-13 23:44:30.332198: Current learning rate: 0.00416 
2024-05-13 23:45:19.550322: train_loss -0.8642 
2024-05-13 23:45:19.550515: val_loss -0.871 
2024-05-13 23:45:19.550581: Pseudo dice [0.9313] 
2024-05-13 23:45:19.550641: Epoch time: 49.22 s 
2024-05-13 23:45:20.571386:  
2024-05-13 23:45:20.571518: Epoch 624 
2024-05-13 23:45:20.571604: Current learning rate: 0.00415 
2024-05-13 23:46:09.624744: train_loss -0.8612 
2024-05-13 23:46:09.625055: val_loss -0.876 
2024-05-13 23:46:09.625138: Pseudo dice [0.9357] 
2024-05-13 23:46:09.625202: Epoch time: 49.05 s 
2024-05-13 23:46:09.625251: Yayy! New best EMA pseudo Dice: 0.9317 
2024-05-13 23:46:10.955141:  
2024-05-13 23:46:10.955403: Epoch 625 
2024-05-13 23:46:10.955494: Current learning rate: 0.00414 
2024-05-13 23:46:59.979359: train_loss -0.8674 
2024-05-13 23:46:59.979676: val_loss -0.87 
2024-05-13 23:46:59.979756: Pseudo dice [0.9278] 
2024-05-13 23:46:59.979815: Epoch time: 49.03 s 
2024-05-13 23:47:00.989163:  
2024-05-13 23:47:00.989285: Epoch 626 
2024-05-13 23:47:00.989366: Current learning rate: 0.00413 
2024-05-13 23:47:50.039584: train_loss -0.8532 
2024-05-13 23:47:50.039758: val_loss -0.8526 
2024-05-13 23:47:50.039820: Pseudo dice [0.9218] 
2024-05-13 23:47:50.039879: Epoch time: 49.05 s 
2024-05-13 23:47:51.070738:  
2024-05-13 23:47:51.070866: Epoch 627 
2024-05-13 23:47:51.070953: Current learning rate: 0.00412 
2024-05-13 23:48:40.166023: train_loss -0.8424 
2024-05-13 23:48:40.166979: val_loss -0.8576 
2024-05-13 23:48:40.167105: Pseudo dice [0.928] 
2024-05-13 23:48:40.167195: Epoch time: 49.1 s 
2024-05-13 23:48:41.221869:  
2024-05-13 23:48:41.222003: Epoch 628 
2024-05-13 23:48:41.222092: Current learning rate: 0.00411 
2024-05-13 23:49:30.263031: train_loss -0.8575 
2024-05-13 23:49:30.263225: val_loss -0.8777 
2024-05-13 23:49:30.263316: Pseudo dice [0.933] 
2024-05-13 23:49:30.263399: Epoch time: 49.04 s 
2024-05-13 23:49:31.298714:  
2024-05-13 23:49:31.298830: Epoch 629 
2024-05-13 23:49:31.298916: Current learning rate: 0.0041 
2024-05-13 23:50:20.352817: train_loss -0.8653 
2024-05-13 23:50:20.353010: val_loss -0.8689 
2024-05-13 23:50:20.353085: Pseudo dice [0.9327] 
2024-05-13 23:50:20.353142: Epoch time: 49.05 s 
2024-05-13 23:50:21.364098:  
2024-05-13 23:50:21.364211: Epoch 630 
2024-05-13 23:50:21.364295: Current learning rate: 0.00409 
2024-05-13 23:51:10.430902: train_loss -0.859 
2024-05-13 23:51:10.431655: val_loss -0.8631 
2024-05-13 23:51:10.431738: Pseudo dice [0.9258] 
2024-05-13 23:51:10.431793: Epoch time: 49.07 s 
2024-05-13 23:51:11.488986:  
2024-05-13 23:51:11.489202: Epoch 631 
2024-05-13 23:51:11.489291: Current learning rate: 0.00408 
2024-05-13 23:52:00.573559: train_loss -0.8544 
2024-05-13 23:52:00.573720: val_loss -0.8569 
2024-05-13 23:52:00.573794: Pseudo dice [0.9256] 
2024-05-13 23:52:00.573855: Epoch time: 49.09 s 
2024-05-13 23:52:01.597799:  
2024-05-13 23:52:01.597920: Epoch 632 
2024-05-13 23:52:01.598016: Current learning rate: 0.00407 
2024-05-13 23:52:50.644951: train_loss -0.8583 
2024-05-13 23:52:50.645118: val_loss -0.8803 
2024-05-13 23:52:50.645194: Pseudo dice [0.9345] 
2024-05-13 23:52:50.645253: Epoch time: 49.05 s 
2024-05-13 23:52:51.711769:  
2024-05-13 23:52:51.711874: Epoch 633 
2024-05-13 23:52:51.711959: Current learning rate: 0.00406 
2024-05-13 23:53:40.779991: train_loss -0.8654 
2024-05-13 23:53:40.780707: val_loss -0.862 
2024-05-13 23:53:40.780771: Pseudo dice [0.9289] 
2024-05-13 23:53:40.780838: Epoch time: 49.07 s 
2024-05-13 23:53:42.183531:  
2024-05-13 23:53:42.183753: Epoch 634 
2024-05-13 23:53:42.183871: Current learning rate: 0.00405 
2024-05-13 23:54:31.294807: train_loss -0.8692 
2024-05-13 23:54:31.295001: val_loss -0.8709 
2024-05-13 23:54:31.295062: Pseudo dice [0.9346] 
2024-05-13 23:54:31.295121: Epoch time: 49.11 s 
2024-05-13 23:54:32.301984:  
2024-05-13 23:54:32.302104: Epoch 635 
2024-05-13 23:54:32.302188: Current learning rate: 0.00404 
2024-05-13 23:55:21.390551: train_loss -0.8641 
2024-05-13 23:55:21.390752: val_loss -0.8646 
2024-05-13 23:55:21.390833: Pseudo dice [0.9291] 
2024-05-13 23:55:21.390894: Epoch time: 49.09 s 
2024-05-13 23:55:22.399373:  
2024-05-13 23:55:22.399497: Epoch 636 
2024-05-13 23:55:22.399580: Current learning rate: 0.00403 
2024-05-13 23:56:11.456087: train_loss -0.8556 
2024-05-13 23:56:11.456748: val_loss -0.8797 
2024-05-13 23:56:11.456811: Pseudo dice [0.9362] 
2024-05-13 23:56:11.456863: Epoch time: 49.06 s 
2024-05-13 23:56:12.504918:  
2024-05-13 23:56:12.505043: Epoch 637 
2024-05-13 23:56:12.505133: Current learning rate: 0.00402 
2024-05-13 23:57:01.619467: train_loss -0.8607 
2024-05-13 23:57:01.619634: val_loss -0.8721 
2024-05-13 23:57:01.619692: Pseudo dice [0.9293] 
2024-05-13 23:57:01.619746: Epoch time: 49.12 s 
2024-05-13 23:57:02.640909:  
2024-05-13 23:57:02.641023: Epoch 638 
2024-05-13 23:57:02.641106: Current learning rate: 0.00401 
2024-05-13 23:57:51.707283: train_loss -0.8634 
2024-05-13 23:57:51.707462: val_loss -0.875 
2024-05-13 23:57:51.707520: Pseudo dice [0.9319] 
2024-05-13 23:57:51.707586: Epoch time: 49.07 s 
2024-05-13 23:57:52.774898:  
2024-05-13 23:57:52.775016: Epoch 639 
2024-05-13 23:57:52.775107: Current learning rate: 0.004 
2024-05-13 23:58:41.768787: train_loss -0.8612 
2024-05-13 23:58:41.769031: val_loss -0.8741 
2024-05-13 23:58:41.769099: Pseudo dice [0.9337] 
2024-05-13 23:58:41.769156: Epoch time: 48.99 s 
2024-05-13 23:58:42.829838:  
2024-05-13 23:58:42.829964: Epoch 640 
2024-05-13 23:58:42.830153: Current learning rate: 0.00399 
2024-05-13 23:59:31.897242: train_loss -0.8592 
2024-05-13 23:59:31.897585: val_loss -0.8524 
2024-05-13 23:59:31.897652: Pseudo dice [0.9313] 
2024-05-13 23:59:31.897715: Epoch time: 49.07 s 
2024-05-13 23:59:32.916810:  
2024-05-13 23:59:32.916924: Epoch 641 
2024-05-13 23:59:32.917005: Current learning rate: 0.00398 
2024-05-14 00:00:21.934294: train_loss -0.8649 
2024-05-14 00:00:21.934495: val_loss -0.877 
2024-05-14 00:00:21.934556: Pseudo dice [0.934] 
2024-05-14 00:00:21.934617: Epoch time: 49.02 s 
2024-05-14 00:00:22.958212:  
2024-05-14 00:00:22.958343: Epoch 642 
2024-05-14 00:00:22.958432: Current learning rate: 0.00397 
2024-05-14 00:01:11.999655: train_loss -0.8647 
2024-05-14 00:01:12.000369: val_loss -0.8833 
2024-05-14 00:01:12.000428: Pseudo dice [0.9375] 
2024-05-14 00:01:12.000520: Epoch time: 49.04 s 
2024-05-14 00:01:12.000620: Yayy! New best EMA pseudo Dice: 0.9321 
2024-05-14 00:01:13.374633:  
2024-05-14 00:01:13.375006: Epoch 643 
2024-05-14 00:01:13.375097: Current learning rate: 0.00396 
2024-05-14 00:02:02.413738: train_loss -0.8643 
2024-05-14 00:02:02.413910: val_loss -0.8635 
2024-05-14 00:02:02.413985: Pseudo dice [0.9268] 
2024-05-14 00:02:02.414050: Epoch time: 49.04 s 
2024-05-14 00:02:03.924249:  
2024-05-14 00:02:03.924387: Epoch 644 
2024-05-14 00:02:03.924468: Current learning rate: 0.00395 
2024-05-14 00:02:53.068505: train_loss -0.8692 
2024-05-14 00:02:53.068694: val_loss -0.8799 
2024-05-14 00:02:53.068770: Pseudo dice [0.9378] 
2024-05-14 00:02:53.068827: Epoch time: 49.15 s 
2024-05-14 00:02:53.068880: Yayy! New best EMA pseudo Dice: 0.9322 
2024-05-14 00:02:54.491351:  
2024-05-14 00:02:54.491483: Epoch 645 
2024-05-14 00:02:54.491568: Current learning rate: 0.00394 
2024-05-14 00:03:43.550874: train_loss -0.8652 
2024-05-14 00:03:43.551581: val_loss -0.8752 
2024-05-14 00:03:43.551643: Pseudo dice [0.9363] 
2024-05-14 00:03:43.551692: Epoch time: 49.06 s 
2024-05-14 00:03:43.551730: Yayy! New best EMA pseudo Dice: 0.9326 
2024-05-14 00:03:44.928137:  
2024-05-14 00:03:44.928263: Epoch 646 
2024-05-14 00:03:44.928346: Current learning rate: 0.00393 
2024-05-14 00:04:34.013646: train_loss -0.8681 
2024-05-14 00:04:34.013837: val_loss -0.8667 
2024-05-14 00:04:34.013901: Pseudo dice [0.9274] 
2024-05-14 00:04:34.013961: Epoch time: 49.09 s 
2024-05-14 00:04:35.032707:  
2024-05-14 00:04:35.032840: Epoch 647 
2024-05-14 00:04:35.032939: Current learning rate: 0.00392 
2024-05-14 00:05:24.112207: train_loss -0.8657 
2024-05-14 00:05:24.112387: val_loss -0.8582 
2024-05-14 00:05:24.112454: Pseudo dice [0.9268] 
2024-05-14 00:05:24.112520: Epoch time: 49.08 s 
2024-05-14 00:05:25.123339:  
2024-05-14 00:05:25.123456: Epoch 648 
2024-05-14 00:05:25.123542: Current learning rate: 0.00391 
2024-05-14 00:06:14.201740: train_loss -0.8636 
2024-05-14 00:06:14.201965: val_loss -0.8679 
2024-05-14 00:06:14.202060: Pseudo dice [0.9321] 
2024-05-14 00:06:14.202152: Epoch time: 49.08 s 
2024-05-14 00:06:15.214554:  
2024-05-14 00:06:15.214668: Epoch 649 
2024-05-14 00:06:15.214752: Current learning rate: 0.0039 
2024-05-14 00:07:04.325217: train_loss -0.8657 
2024-05-14 00:07:04.325400: val_loss -0.8632 
2024-05-14 00:07:04.325495: Pseudo dice [0.9258] 
2024-05-14 00:07:04.325572: Epoch time: 49.11 s 
2024-05-14 00:07:05.647279:  
2024-05-14 00:07:05.647509: Epoch 650 
2024-05-14 00:07:05.647593: Current learning rate: 0.00389 
2024-05-14 00:07:54.733664: train_loss -0.8657 
2024-05-14 00:07:54.733859: val_loss -0.8653 
2024-05-14 00:07:54.733921: Pseudo dice [0.9297] 
2024-05-14 00:07:54.733982: Epoch time: 49.09 s 
2024-05-14 00:07:55.750977:  
2024-05-14 00:07:55.751205: Epoch 651 
2024-05-14 00:07:55.751290: Current learning rate: 0.00388 
2024-05-14 00:08:44.800293: train_loss -0.8649 
2024-05-14 00:08:44.800958: val_loss -0.8688 
2024-05-14 00:08:44.801019: Pseudo dice [0.9314] 
2024-05-14 00:08:44.801070: Epoch time: 49.05 s 
2024-05-14 00:08:45.816990:  
2024-05-14 00:08:45.817227: Epoch 652 
2024-05-14 00:08:45.817315: Current learning rate: 0.00387 
2024-05-14 00:09:34.905485: train_loss -0.8631 
2024-05-14 00:09:34.905643: val_loss -0.8823 
2024-05-14 00:09:34.905718: Pseudo dice [0.9356] 
2024-05-14 00:09:34.905775: Epoch time: 49.09 s 
2024-05-14 00:09:35.918810:  
2024-05-14 00:09:35.918918: Epoch 653 
2024-05-14 00:09:35.919006: Current learning rate: 0.00386 
2024-05-14 00:10:24.985161: train_loss -0.8696 
2024-05-14 00:10:24.985349: val_loss -0.8571 
2024-05-14 00:10:24.985410: Pseudo dice [0.9256] 
2024-05-14 00:10:24.985470: Epoch time: 49.07 s 
2024-05-14 00:10:26.470267:  
2024-05-14 00:10:26.470394: Epoch 654 
2024-05-14 00:10:26.470479: Current learning rate: 0.00385 
2024-05-14 00:11:15.514619: train_loss -0.861 
2024-05-14 00:11:15.515298: val_loss -0.8698 
2024-05-14 00:11:15.515359: Pseudo dice [0.9314] 
2024-05-14 00:11:15.515414: Epoch time: 49.05 s 
2024-05-14 00:11:16.523422:  
2024-05-14 00:11:16.523552: Epoch 655 
2024-05-14 00:11:16.523635: Current learning rate: 0.00384 
2024-05-14 00:12:05.576441: train_loss -0.865 
2024-05-14 00:12:05.576617: val_loss -0.8591 
2024-05-14 00:12:05.576677: Pseudo dice [0.9315] 
2024-05-14 00:12:05.576735: Epoch time: 49.05 s 
2024-05-14 00:12:06.585933:  
2024-05-14 00:12:06.586183: Epoch 656 
2024-05-14 00:12:06.586275: Current learning rate: 0.00383 
2024-05-14 00:12:55.651217: train_loss -0.8663 
2024-05-14 00:12:55.651388: val_loss -0.8787 
2024-05-14 00:12:55.651449: Pseudo dice [0.9366] 
2024-05-14 00:12:55.651510: Epoch time: 49.07 s 
2024-05-14 00:12:56.690210:  
2024-05-14 00:12:56.690421: Epoch 657 
2024-05-14 00:12:56.690511: Current learning rate: 0.00382 
2024-05-14 00:13:45.723713: train_loss -0.865 
2024-05-14 00:13:45.724012: val_loss -0.882 
2024-05-14 00:13:45.724091: Pseudo dice [0.9397] 
2024-05-14 00:13:45.724149: Epoch time: 49.03 s 
2024-05-14 00:13:46.733681:  
2024-05-14 00:13:46.733796: Epoch 658 
2024-05-14 00:13:46.733875: Current learning rate: 0.00381 
2024-05-14 00:14:35.858948: train_loss -0.8712 
2024-05-14 00:14:35.859115: val_loss -0.8759 
2024-05-14 00:14:35.859175: Pseudo dice [0.9347] 
2024-05-14 00:14:35.859232: Epoch time: 49.13 s 
2024-05-14 00:14:36.866577:  
2024-05-14 00:14:36.866694: Epoch 659 
2024-05-14 00:14:36.866779: Current learning rate: 0.0038 
2024-05-14 00:15:25.919863: train_loss -0.8732 
2024-05-14 00:15:25.920052: val_loss -0.8696 
2024-05-14 00:15:25.920113: Pseudo dice [0.9303] 
2024-05-14 00:15:25.920178: Epoch time: 49.05 s 
2024-05-14 00:15:26.940658:  
2024-05-14 00:15:26.940769: Epoch 660 
2024-05-14 00:15:26.940853: Current learning rate: 0.00379 
2024-05-14 00:16:16.102722: train_loss -0.8664 
2024-05-14 00:16:16.102979: val_loss -0.8584 
2024-05-14 00:16:16.103045: Pseudo dice [0.9305] 
2024-05-14 00:16:16.103105: Epoch time: 49.16 s 
2024-05-14 00:16:17.117332:  
2024-05-14 00:16:17.117442: Epoch 661 
2024-05-14 00:16:17.117522: Current learning rate: 0.00378 
2024-05-14 00:17:06.178289: train_loss -0.8619 
2024-05-14 00:17:06.178468: val_loss -0.8789 
2024-05-14 00:17:06.178545: Pseudo dice [0.9395] 
2024-05-14 00:17:06.178760: Epoch time: 49.06 s 
2024-05-14 00:17:06.178812: Yayy! New best EMA pseudo Dice: 0.9329 
2024-05-14 00:17:07.514466:  
2024-05-14 00:17:07.514664: Epoch 662 
2024-05-14 00:17:07.514751: Current learning rate: 0.00377 
2024-05-14 00:17:56.607645: train_loss -0.871 
2024-05-14 00:17:56.607808: val_loss -0.8728 
2024-05-14 00:17:56.607891: Pseudo dice [0.9338] 
2024-05-14 00:17:56.607970: Epoch time: 49.09 s 
2024-05-14 00:17:56.608041: Yayy! New best EMA pseudo Dice: 0.933 
2024-05-14 00:17:57.983425:  
2024-05-14 00:17:57.983531: Epoch 663 
2024-05-14 00:17:57.983614: Current learning rate: 0.00376 
2024-05-14 00:18:47.054751: train_loss -0.8727 
2024-05-14 00:18:47.055035: val_loss -0.8637 
2024-05-14 00:18:47.055106: Pseudo dice [0.9315] 
2024-05-14 00:18:47.055165: Epoch time: 49.07 s 
2024-05-14 00:18:48.589516:  
2024-05-14 00:18:48.589748: Epoch 664 
2024-05-14 00:18:48.589837: Current learning rate: 0.00375 
2024-05-14 00:19:37.638173: train_loss -0.8733 
2024-05-14 00:19:37.638378: val_loss -0.8762 
2024-05-14 00:19:37.639153: Pseudo dice [0.9317] 
2024-05-14 00:19:37.639383: Epoch time: 49.05 s 
2024-05-14 00:19:38.683200:  
2024-05-14 00:19:38.683334: Epoch 665 
2024-05-14 00:19:38.683418: Current learning rate: 0.00374 
2024-05-14 00:20:27.803145: train_loss -0.8702 
2024-05-14 00:20:27.803332: val_loss -0.8688 
2024-05-14 00:20:27.803394: Pseudo dice [0.9305] 
2024-05-14 00:20:27.803452: Epoch time: 49.12 s 
2024-05-14 00:20:28.813030:  
2024-05-14 00:20:28.813349: Epoch 666 
2024-05-14 00:20:28.813443: Current learning rate: 0.00373 
2024-05-14 00:21:17.887074: train_loss -0.8771 
2024-05-14 00:21:17.887256: val_loss -0.8699 
2024-05-14 00:21:17.887316: Pseudo dice [0.9338] 
2024-05-14 00:21:17.887373: Epoch time: 49.07 s 
2024-05-14 00:21:18.903556:  
2024-05-14 00:21:18.903849: Epoch 667 
2024-05-14 00:21:18.904043: Current learning rate: 0.00372 
2024-05-14 00:22:07.951556: train_loss -0.8729 
2024-05-14 00:22:07.951910: val_loss -0.879 
2024-05-14 00:22:07.951982: Pseudo dice [0.9352] 
2024-05-14 00:22:07.952043: Epoch time: 49.05 s 
2024-05-14 00:22:08.990132:  
2024-05-14 00:22:08.990249: Epoch 668 
2024-05-14 00:22:08.990339: Current learning rate: 0.00371 
2024-05-14 00:22:57.996945: train_loss -0.8702 
2024-05-14 00:22:57.997113: val_loss -0.8726 
2024-05-14 00:22:57.997194: Pseudo dice [0.933] 
2024-05-14 00:22:57.997275: Epoch time: 49.01 s 
2024-05-14 00:22:59.036689:  
2024-05-14 00:22:59.036805: Epoch 669 
2024-05-14 00:22:59.036892: Current learning rate: 0.0037 
2024-05-14 00:23:48.070490: train_loss -0.866 
2024-05-14 00:23:48.070674: val_loss -0.8615 
2024-05-14 00:23:48.070735: Pseudo dice [0.9299] 
2024-05-14 00:23:48.070797: Epoch time: 49.03 s 
2024-05-14 00:23:49.110601:  
2024-05-14 00:23:49.110714: Epoch 670 
2024-05-14 00:23:49.110800: Current learning rate: 0.00369 
2024-05-14 00:24:38.207757: train_loss -0.8714 
2024-05-14 00:24:38.208493: val_loss -0.8616 
2024-05-14 00:24:38.208558: Pseudo dice [0.9269] 
2024-05-14 00:24:38.208617: Epoch time: 49.1 s 
2024-05-14 00:24:39.262584:  
2024-05-14 00:24:39.262743: Epoch 671 
2024-05-14 00:24:39.262933: Current learning rate: 0.00368 
2024-05-14 00:25:28.321441: train_loss -0.8726 
2024-05-14 00:25:28.321619: val_loss -0.8645 
2024-05-14 00:25:28.321686: Pseudo dice [0.9281] 
2024-05-14 00:25:28.321751: Epoch time: 49.06 s 
2024-05-14 00:25:29.381799:  
2024-05-14 00:25:29.382028: Epoch 672 
2024-05-14 00:25:29.382116: Current learning rate: 0.00367 
2024-05-14 00:26:18.452005: train_loss -0.8724 
2024-05-14 00:26:18.452178: val_loss -0.8653 
2024-05-14 00:26:18.452237: Pseudo dice [0.9291] 
2024-05-14 00:26:18.452300: Epoch time: 49.07 s 
2024-05-14 00:26:19.476848:  
2024-05-14 00:26:19.476959: Epoch 673 
2024-05-14 00:26:19.477050: Current learning rate: 0.00366 
2024-05-14 00:27:08.597067: train_loss -0.8712 
2024-05-14 00:27:08.597240: val_loss -0.8778 
2024-05-14 00:27:08.597317: Pseudo dice [0.9373] 
2024-05-14 00:27:08.597374: Epoch time: 49.12 s 
2024-05-14 00:27:09.645671:  
2024-05-14 00:27:09.645921: Epoch 674 
2024-05-14 00:27:09.646015: Current learning rate: 0.00365 
2024-05-14 00:27:58.717329: train_loss -0.8738 
2024-05-14 00:27:58.717629: val_loss -0.8725 
2024-05-14 00:27:58.717701: Pseudo dice [0.9334] 
2024-05-14 00:27:58.717759: Epoch time: 49.07 s 
2024-05-14 00:28:00.335788:  
2024-05-14 00:28:00.335928: Epoch 675 
2024-05-14 00:28:00.336012: Current learning rate: 0.00364 
2024-05-14 00:28:49.502017: train_loss -0.8714 
2024-05-14 00:28:49.502187: val_loss -0.881 
2024-05-14 00:28:49.502245: Pseudo dice [0.9401] 
2024-05-14 00:28:49.502325: Epoch time: 49.17 s 
2024-05-14 00:28:50.520546:  
2024-05-14 00:28:50.520682: Epoch 676 
2024-05-14 00:28:50.520768: Current learning rate: 0.00363 
2024-05-14 00:29:39.615326: train_loss -0.8721 
2024-05-14 00:29:39.615491: val_loss -0.8622 
2024-05-14 00:29:39.615552: Pseudo dice [0.9298] 
2024-05-14 00:29:39.615610: Epoch time: 49.1 s 
2024-05-14 00:29:40.639882:  
2024-05-14 00:29:40.640002: Epoch 677 
2024-05-14 00:29:40.640085: Current learning rate: 0.00362 
2024-05-14 00:30:29.654464: train_loss -0.8739 
2024-05-14 00:30:29.654638: val_loss -0.8813 
2024-05-14 00:30:29.654697: Pseudo dice [0.9356] 
2024-05-14 00:30:29.654756: Epoch time: 49.02 s 
2024-05-14 00:30:30.674828:  
2024-05-14 00:30:30.675157: Epoch 678 
2024-05-14 00:30:30.675244: Current learning rate: 0.00361 
2024-05-14 00:31:19.777602: train_loss -0.8724 
2024-05-14 00:31:19.777788: val_loss -0.8774 
2024-05-14 00:31:19.777869: Pseudo dice [0.9367] 
2024-05-14 00:31:19.777955: Epoch time: 49.1 s 
2024-05-14 00:31:19.778033: Yayy! New best EMA pseudo Dice: 0.9333 
2024-05-14 00:31:21.212963:  
2024-05-14 00:31:21.213170: Epoch 679 
2024-05-14 00:31:21.213273: Current learning rate: 0.0036 
2024-05-14 00:32:10.315182: train_loss -0.8734 
2024-05-14 00:32:10.315902: val_loss -0.8814 
2024-05-14 00:32:10.315967: Pseudo dice [0.936] 
2024-05-14 00:32:10.316017: Epoch time: 49.1 s 
2024-05-14 00:32:10.316057: Yayy! New best EMA pseudo Dice: 0.9336 
2024-05-14 00:32:11.695245:  
2024-05-14 00:32:11.695411: Epoch 680 
2024-05-14 00:32:11.695592: Current learning rate: 0.00359 
2024-05-14 00:33:00.713124: train_loss -0.8689 
2024-05-14 00:33:00.713336: val_loss -0.8573 
2024-05-14 00:33:00.713397: Pseudo dice [0.9321] 
2024-05-14 00:33:00.713456: Epoch time: 49.02 s 
2024-05-14 00:33:01.758017:  
2024-05-14 00:33:01.758408: Epoch 681 
2024-05-14 00:33:01.758504: Current learning rate: 0.00358 
2024-05-14 00:33:50.805404: train_loss -0.8661 
2024-05-14 00:33:50.805576: val_loss -0.8711 
2024-05-14 00:33:50.805640: Pseudo dice [0.9357] 
2024-05-14 00:33:50.805713: Epoch time: 49.05 s 
2024-05-14 00:33:50.805758: Yayy! New best EMA pseudo Dice: 0.9336 
2024-05-14 00:33:52.170155:  
2024-05-14 00:33:52.170479: Epoch 682 
2024-05-14 00:33:52.170705: Current learning rate: 0.00357 
2024-05-14 00:34:41.242434: train_loss -0.8667 
2024-05-14 00:34:41.243091: val_loss -0.858 
2024-05-14 00:34:41.243153: Pseudo dice [0.9273] 
2024-05-14 00:34:41.243219: Epoch time: 49.07 s 
2024-05-14 00:34:42.273407:  
2024-05-14 00:34:42.273528: Epoch 683 
2024-05-14 00:34:42.273615: Current learning rate: 0.00356 
2024-05-14 00:35:31.351713: train_loss -0.8681 
2024-05-14 00:35:31.351900: val_loss -0.8748 
2024-05-14 00:35:31.351964: Pseudo dice [0.9321] 
2024-05-14 00:35:31.352022: Epoch time: 49.08 s 
2024-05-14 00:35:32.385035:  
2024-05-14 00:35:32.385275: Epoch 684 
2024-05-14 00:35:32.385363: Current learning rate: 0.00355 
2024-05-14 00:36:21.472088: train_loss -0.8671 
2024-05-14 00:36:21.472260: val_loss -0.8718 
2024-05-14 00:36:21.472787: Pseudo dice [0.9312] 
2024-05-14 00:36:21.472862: Epoch time: 49.09 s 
2024-05-14 00:36:23.076749:  
2024-05-14 00:36:23.076894: Epoch 685 
2024-05-14 00:36:23.076993: Current learning rate: 0.00354 
2024-05-14 00:37:12.164640: train_loss -0.8691 
2024-05-14 00:37:12.165338: val_loss -0.885 
2024-05-14 00:37:12.165402: Pseudo dice [0.939] 
2024-05-14 00:37:12.165458: Epoch time: 49.09 s 
2024-05-14 00:37:13.204637:  
2024-05-14 00:37:13.204891: Epoch 686 
2024-05-14 00:37:13.204980: Current learning rate: 0.00353 
2024-05-14 00:38:02.281318: train_loss -0.8692 
2024-05-14 00:38:02.281524: val_loss -0.885 
2024-05-14 00:38:02.281583: Pseudo dice [0.9371] 
2024-05-14 00:38:02.281639: Epoch time: 49.08 s 
2024-05-14 00:38:02.281684: Yayy! New best EMA pseudo Dice: 0.9337 
2024-05-14 00:38:03.672832:  
2024-05-14 00:38:03.673066: Epoch 687 
2024-05-14 00:38:03.673167: Current learning rate: 0.00352 
2024-05-14 00:38:52.774790: train_loss -0.8711 
2024-05-14 00:38:52.774950: val_loss -0.8694 
2024-05-14 00:38:52.775008: Pseudo dice [0.9327] 
2024-05-14 00:38:52.775071: Epoch time: 49.1 s 
2024-05-14 00:38:53.823046:  
2024-05-14 00:38:53.823168: Epoch 688 
2024-05-14 00:38:53.823253: Current learning rate: 0.00351 
2024-05-14 00:39:42.872891: train_loss -0.8723 
2024-05-14 00:39:42.873632: val_loss -0.8751 
2024-05-14 00:39:42.873706: Pseudo dice [0.934] 
2024-05-14 00:39:42.873768: Epoch time: 49.05 s 
2024-05-14 00:39:43.913689:  
2024-05-14 00:39:43.913811: Epoch 689 
2024-05-14 00:39:43.913896: Current learning rate: 0.0035 
2024-05-14 00:40:32.981370: train_loss -0.8695 
2024-05-14 00:40:32.981540: val_loss -0.8569 
2024-05-14 00:40:32.981613: Pseudo dice [0.9292] 
2024-05-14 00:40:32.981670: Epoch time: 49.07 s 
2024-05-14 00:40:34.047050:  
2024-05-14 00:40:34.047166: Epoch 690 
2024-05-14 00:40:34.047263: Current learning rate: 0.00349 
2024-05-14 00:41:23.159855: train_loss -0.8637 
2024-05-14 00:41:23.160026: val_loss -0.8816 
2024-05-14 00:41:23.160088: Pseudo dice [0.9382] 
2024-05-14 00:41:23.160146: Epoch time: 49.11 s 
2024-05-14 00:41:24.221000:  
2024-05-14 00:41:24.221198: Epoch 691 
2024-05-14 00:41:24.221354: Current learning rate: 0.00348 
2024-05-14 00:42:13.331672: train_loss -0.8716 
2024-05-14 00:42:13.332355: val_loss -0.8716 
2024-05-14 00:42:13.332424: Pseudo dice [0.9298] 
2024-05-14 00:42:13.332478: Epoch time: 49.11 s 
2024-05-14 00:42:14.372275:  
2024-05-14 00:42:14.372382: Epoch 692 
2024-05-14 00:42:14.372465: Current learning rate: 0.00346 
2024-05-14 00:43:03.469900: train_loss -0.8645 
2024-05-14 00:43:03.470111: val_loss -0.8868 
2024-05-14 00:43:03.470191: Pseudo dice [0.9412] 
2024-05-14 00:43:03.470250: Epoch time: 49.1 s 
2024-05-14 00:43:03.470303: Yayy! New best EMA pseudo Dice: 0.9341 
2024-05-14 00:43:04.831025:  
2024-05-14 00:43:04.831203: Epoch 693 
2024-05-14 00:43:04.831293: Current learning rate: 0.00345 
2024-05-14 00:43:53.827705: train_loss -0.8677 
2024-05-14 00:43:53.827872: val_loss -0.8722 
2024-05-14 00:43:53.827931: Pseudo dice [0.9317] 
2024-05-14 00:43:53.827992: Epoch time: 49.0 s 
2024-05-14 00:43:54.869482:  
2024-05-14 00:43:54.869599: Epoch 694 
2024-05-14 00:43:54.869682: Current learning rate: 0.00344 
2024-05-14 00:44:44.027720: train_loss -0.8725 
2024-05-14 00:44:44.028412: val_loss -0.8721 
2024-05-14 00:44:44.028467: Pseudo dice [0.9324] 
2024-05-14 00:44:44.028516: Epoch time: 49.16 s 
2024-05-14 00:44:45.609139:  
2024-05-14 00:44:45.609292: Epoch 695 
2024-05-14 00:44:45.609373: Current learning rate: 0.00343 
2024-05-14 00:45:34.652645: train_loss -0.8559 
2024-05-14 00:45:34.652832: val_loss -0.854 
2024-05-14 00:45:34.652911: Pseudo dice [0.9213] 
2024-05-14 00:45:34.652985: Epoch time: 49.04 s 
2024-05-14 00:45:35.709394:  
2024-05-14 00:45:35.709524: Epoch 696 
2024-05-14 00:45:35.709623: Current learning rate: 0.00342 
2024-05-14 00:46:24.723682: train_loss -0.8418 
2024-05-14 00:46:24.723843: val_loss -0.8267 
2024-05-14 00:46:24.723902: Pseudo dice [0.9078] 
2024-05-14 00:46:24.723958: Epoch time: 49.02 s 
2024-05-14 00:46:25.764134:  
2024-05-14 00:46:25.764257: Epoch 697 
2024-05-14 00:46:25.764357: Current learning rate: 0.00341 
2024-05-14 00:47:14.808679: train_loss -0.8191 
2024-05-14 00:47:14.808980: val_loss -0.8264 
2024-05-14 00:47:14.809066: Pseudo dice [0.9089] 
2024-05-14 00:47:14.809125: Epoch time: 49.05 s 
2024-05-14 00:47:15.878551:  
2024-05-14 00:47:15.878677: Epoch 698 
2024-05-14 00:47:15.878763: Current learning rate: 0.0034 
2024-05-14 00:48:04.881999: train_loss -0.8412 
2024-05-14 00:48:04.882168: val_loss -0.8682 
2024-05-14 00:48:04.882227: Pseudo dice [0.9304] 
2024-05-14 00:48:04.882285: Epoch time: 49.0 s 
2024-05-14 00:48:05.924017:  
2024-05-14 00:48:05.924139: Epoch 699 
2024-05-14 00:48:05.924226: Current learning rate: 0.00339 
2024-05-14 00:48:54.987158: train_loss -0.8444 
2024-05-14 00:48:54.987322: val_loss -0.8573 
2024-05-14 00:48:54.987380: Pseudo dice [0.9278] 
2024-05-14 00:48:54.987437: Epoch time: 49.06 s 
2024-05-14 00:48:56.348729:  
2024-05-14 00:48:56.349130: Epoch 700 
2024-05-14 00:48:56.349227: Current learning rate: 0.00338 
2024-05-14 00:49:45.387813: train_loss -0.8563 
2024-05-14 00:49:45.388125: val_loss -0.864 
2024-05-14 00:49:45.388210: Pseudo dice [0.9294] 
2024-05-14 00:49:45.388285: Epoch time: 49.04 s 
2024-05-14 00:49:46.419934:  
2024-05-14 00:49:46.420074: Epoch 701 
2024-05-14 00:49:46.420164: Current learning rate: 0.00337 
2024-05-14 00:50:35.411096: train_loss -0.8654 
2024-05-14 00:50:35.411283: val_loss -0.8542 
2024-05-14 00:50:35.411344: Pseudo dice [0.9244] 
2024-05-14 00:50:35.411562: Epoch time: 48.99 s 
2024-05-14 00:50:36.450567:  
2024-05-14 00:50:36.450761: Epoch 702 
2024-05-14 00:50:36.450843: Current learning rate: 0.00336 
2024-05-14 00:51:25.476802: train_loss -0.8554 
2024-05-14 00:51:25.476977: val_loss -0.8649 
2024-05-14 00:51:25.477038: Pseudo dice [0.9321] 
2024-05-14 00:51:25.477094: Epoch time: 49.03 s 
2024-05-14 00:51:26.501334:  
2024-05-14 00:51:26.501447: Epoch 703 
2024-05-14 00:51:26.501532: Current learning rate: 0.00335 
2024-05-14 00:52:15.483495: train_loss -0.8639 
2024-05-14 00:52:15.483672: val_loss -0.872 
2024-05-14 00:52:15.483729: Pseudo dice [0.9285] 
2024-05-14 00:52:15.483791: Epoch time: 48.98 s 
2024-05-14 00:52:16.525121:  
2024-05-14 00:52:16.525222: Epoch 704 
2024-05-14 00:52:16.525320: Current learning rate: 0.00334 
2024-05-14 00:53:05.963784: train_loss -0.8633 
2024-05-14 00:53:05.963980: val_loss -0.8701 
2024-05-14 00:53:05.964043: Pseudo dice [0.9294] 
2024-05-14 00:53:05.964103: Epoch time: 49.44 s 
2024-05-14 00:53:06.992359:  
2024-05-14 00:53:06.992488: Epoch 705 
2024-05-14 00:53:06.992572: Current learning rate: 0.00333 
2024-05-14 00:53:56.047196: train_loss -0.8634 
2024-05-14 00:53:56.047471: val_loss -0.8625 
2024-05-14 00:53:56.047569: Pseudo dice [0.9264] 
2024-05-14 00:53:56.047658: Epoch time: 49.06 s 
2024-05-14 00:53:57.088524:  
2024-05-14 00:53:57.088761: Epoch 706 
2024-05-14 00:53:57.088851: Current learning rate: 0.00332 
2024-05-14 00:54:46.058385: train_loss -0.8697 
2024-05-14 00:54:46.058575: val_loss -0.8661 
2024-05-14 00:54:46.058635: Pseudo dice [0.9305] 
2024-05-14 00:54:46.058693: Epoch time: 48.97 s 
2024-05-14 00:54:47.094680:  
2024-05-14 00:54:47.094798: Epoch 707 
2024-05-14 00:54:47.094881: Current learning rate: 0.00331 
2024-05-14 00:55:36.135821: train_loss -0.8702 
2024-05-14 00:55:36.135994: val_loss -0.8635 
2024-05-14 00:55:36.136054: Pseudo dice [0.9292] 
2024-05-14 00:55:36.136111: Epoch time: 49.04 s 
2024-05-14 00:55:37.176552:  
2024-05-14 00:55:37.176671: Epoch 708 
2024-05-14 00:55:37.176757: Current learning rate: 0.0033 
2024-05-14 00:56:26.248857: train_loss -0.857 
2024-05-14 00:56:26.249532: val_loss -0.8617 
2024-05-14 00:56:26.249590: Pseudo dice [0.9266] 
2024-05-14 00:56:26.249641: Epoch time: 49.07 s 
2024-05-14 00:56:27.304787:  
2024-05-14 00:56:27.304906: Epoch 709 
2024-05-14 00:56:27.304991: Current learning rate: 0.00329 
2024-05-14 00:57:16.343251: train_loss -0.8635 
2024-05-14 00:57:16.343440: val_loss -0.8482 
2024-05-14 00:57:16.343504: Pseudo dice [0.9264] 
2024-05-14 00:57:16.343565: Epoch time: 49.04 s 
2024-05-14 00:57:17.392391:  
2024-05-14 00:57:17.392508: Epoch 710 
2024-05-14 00:57:17.392594: Current learning rate: 0.00328 
2024-05-14 00:58:06.448537: train_loss -0.8681 
2024-05-14 00:58:06.448715: val_loss -0.8552 
2024-05-14 00:58:06.448774: Pseudo dice [0.9333] 
2024-05-14 00:58:06.448830: Epoch time: 49.06 s 
2024-05-14 00:58:07.479417:  
2024-05-14 00:58:07.479630: Epoch 711 
2024-05-14 00:58:07.479721: Current learning rate: 0.00327 
2024-05-14 00:58:56.448065: train_loss -0.8731 
2024-05-14 00:58:56.448738: val_loss -0.8806 
2024-05-14 00:58:56.448800: Pseudo dice [0.9375] 
2024-05-14 00:58:56.448855: Epoch time: 48.97 s 
2024-05-14 00:58:57.518833:  
2024-05-14 00:58:57.518936: Epoch 712 
2024-05-14 00:58:57.519019: Current learning rate: 0.00326 
2024-05-14 00:59:46.590354: train_loss -0.8688 
2024-05-14 00:59:46.590546: val_loss -0.8762 
2024-05-14 00:59:46.590628: Pseudo dice [0.9341] 
2024-05-14 00:59:46.590710: Epoch time: 49.07 s 
2024-05-14 00:59:47.622550:  
2024-05-14 00:59:47.622653: Epoch 713 
2024-05-14 00:59:47.622735: Current learning rate: 0.00325 
2024-05-14 01:00:36.668378: train_loss -0.8749 
2024-05-14 01:00:36.668559: val_loss -0.8641 
2024-05-14 01:00:36.668622: Pseudo dice [0.9334] 
2024-05-14 01:00:36.668682: Epoch time: 49.05 s 
2024-05-14 01:00:37.713306:  
2024-05-14 01:00:37.713511: Epoch 714 
2024-05-14 01:00:37.713599: Current learning rate: 0.00324 
2024-05-14 01:01:26.819391: train_loss -0.8676 
2024-05-14 01:01:26.820180: val_loss -0.8746 
2024-05-14 01:01:26.820266: Pseudo dice [0.9372] 
2024-05-14 01:01:26.820338: Epoch time: 49.11 s 
2024-05-14 01:01:28.438822:  
2024-05-14 01:01:28.439077: Epoch 715 
2024-05-14 01:01:28.439163: Current learning rate: 0.00323 
2024-05-14 01:02:17.483834: train_loss -0.8609 
2024-05-14 01:02:17.484018: val_loss -0.862 
2024-05-14 01:02:17.484083: Pseudo dice [0.9332] 
2024-05-14 01:02:17.484142: Epoch time: 49.05 s 
2024-05-14 01:02:18.521600:  
2024-05-14 01:02:18.521757: Epoch 716 
2024-05-14 01:02:18.521841: Current learning rate: 0.00322 
2024-05-14 01:03:07.543239: train_loss -0.8649 
2024-05-14 01:03:07.543412: val_loss -0.8636 
2024-05-14 01:03:07.543503: Pseudo dice [0.9313] 
2024-05-14 01:03:07.543582: Epoch time: 49.02 s 
2024-05-14 01:03:08.618332:  
2024-05-14 01:03:08.618471: Epoch 717 
2024-05-14 01:03:08.618552: Current learning rate: 0.00321 
2024-05-14 01:03:57.596184: train_loss -0.8734 
2024-05-14 01:03:57.596442: val_loss -0.8562 
2024-05-14 01:03:57.596509: Pseudo dice [0.9267] 
2024-05-14 01:03:57.596570: Epoch time: 48.98 s 
2024-05-14 01:03:58.655980:  
2024-05-14 01:03:58.656104: Epoch 718 
2024-05-14 01:03:58.656187: Current learning rate: 0.0032 
2024-05-14 01:04:47.721477: train_loss -0.8755 
2024-05-14 01:04:47.721661: val_loss -0.8697 
2024-05-14 01:04:47.721725: Pseudo dice [0.9339] 
2024-05-14 01:04:47.721785: Epoch time: 49.07 s 
2024-05-14 01:04:48.783916:  
2024-05-14 01:04:48.784048: Epoch 719 
2024-05-14 01:04:48.784151: Current learning rate: 0.00319 
2024-05-14 01:05:37.881376: train_loss -0.8704 
2024-05-14 01:05:37.881538: val_loss -0.8612 
2024-05-14 01:05:37.881598: Pseudo dice [0.9318] 
2024-05-14 01:05:37.881673: Epoch time: 49.1 s 
2024-05-14 01:05:38.930134:  
2024-05-14 01:05:38.930247: Epoch 720 
2024-05-14 01:05:38.930352: Current learning rate: 0.00318 
2024-05-14 01:06:27.964254: train_loss -0.864 
2024-05-14 01:06:27.964992: val_loss -0.8648 
2024-05-14 01:06:27.965057: Pseudo dice [0.9287] 
2024-05-14 01:06:27.965110: Epoch time: 49.03 s 
2024-05-14 01:06:29.028857:  
2024-05-14 01:06:29.029120: Epoch 721 
2024-05-14 01:06:29.029213: Current learning rate: 0.00317 
2024-05-14 01:07:18.099312: train_loss -0.8653 
2024-05-14 01:07:18.099478: val_loss -0.8743 
2024-05-14 01:07:18.099529: Pseudo dice [0.932] 
2024-05-14 01:07:18.099578: Epoch time: 49.07 s 
2024-05-14 01:07:19.163168:  
2024-05-14 01:07:19.163530: Epoch 722 
2024-05-14 01:07:19.163624: Current learning rate: 0.00316 
2024-05-14 01:08:08.301824: train_loss -0.862 
2024-05-14 01:08:08.302012: val_loss -0.8638 
2024-05-14 01:08:08.302078: Pseudo dice [0.9299] 
2024-05-14 01:08:08.302138: Epoch time: 49.14 s 
2024-05-14 01:08:09.355136:  
2024-05-14 01:08:09.355238: Epoch 723 
2024-05-14 01:08:09.355321: Current learning rate: 0.00315 
2024-05-14 01:08:58.406426: train_loss -0.8676 
2024-05-14 01:08:58.407103: val_loss -0.8806 
2024-05-14 01:08:58.407168: Pseudo dice [0.9368] 
2024-05-14 01:08:58.407223: Epoch time: 49.05 s 
2024-05-14 01:08:59.461026:  
2024-05-14 01:08:59.461139: Epoch 724 
2024-05-14 01:08:59.461236: Current learning rate: 0.00314 
2024-05-14 01:09:48.535151: train_loss -0.8676 
2024-05-14 01:09:48.535334: val_loss -0.8656 
2024-05-14 01:09:48.535398: Pseudo dice [0.9342] 
2024-05-14 01:09:48.535457: Epoch time: 49.07 s 
2024-05-14 01:09:50.118040:  
2024-05-14 01:09:50.118181: Epoch 725 
2024-05-14 01:09:50.118265: Current learning rate: 0.00313 
2024-05-14 01:10:39.182101: train_loss -0.8679 
2024-05-14 01:10:39.182309: val_loss -0.8703 
2024-05-14 01:10:39.182375: Pseudo dice [0.935] 
2024-05-14 01:10:39.182434: Epoch time: 49.06 s 
2024-05-14 01:10:40.218773:  
2024-05-14 01:10:40.218907: Epoch 726 
2024-05-14 01:10:40.218990: Current learning rate: 0.00312 
2024-05-14 01:11:29.330541: train_loss -0.8634 
2024-05-14 01:11:29.330907: val_loss -0.8763 
2024-05-14 01:11:29.330978: Pseudo dice [0.9361] 
2024-05-14 01:11:29.331041: Epoch time: 49.11 s 
2024-05-14 01:11:30.386633:  
2024-05-14 01:11:30.386769: Epoch 727 
2024-05-14 01:11:30.386857: Current learning rate: 0.00311 
2024-05-14 01:12:19.508796: train_loss -0.8664 
2024-05-14 01:12:19.508992: val_loss -0.8834 
2024-05-14 01:12:19.509053: Pseudo dice [0.9379] 
2024-05-14 01:12:19.509116: Epoch time: 49.12 s 
2024-05-14 01:12:20.546767:  
2024-05-14 01:12:20.546890: Epoch 728 
2024-05-14 01:12:20.546977: Current learning rate: 0.0031 
2024-05-14 01:13:09.615805: train_loss -0.8697 
2024-05-14 01:13:09.615986: val_loss -0.8804 
2024-05-14 01:13:09.616046: Pseudo dice [0.9367] 
2024-05-14 01:13:09.616105: Epoch time: 49.07 s 
2024-05-14 01:13:10.661183:  
2024-05-14 01:13:10.661391: Epoch 729 
2024-05-14 01:13:10.661484: Current learning rate: 0.00309 
2024-05-14 01:13:59.668050: train_loss -0.8763 
2024-05-14 01:13:59.668339: val_loss -0.8728 
2024-05-14 01:13:59.668402: Pseudo dice [0.9345] 
2024-05-14 01:13:59.668465: Epoch time: 49.01 s 
2024-05-14 01:14:00.755724:  
2024-05-14 01:14:00.755852: Epoch 730 
2024-05-14 01:14:00.755948: Current learning rate: 0.00308 
2024-05-14 01:14:49.787195: train_loss -0.8693 
2024-05-14 01:14:49.787362: val_loss -0.8666 
2024-05-14 01:14:49.787419: Pseudo dice [0.9314] 
2024-05-14 01:14:49.787475: Epoch time: 49.03 s 
2024-05-14 01:14:50.825914:  
2024-05-14 01:14:50.826027: Epoch 731 
2024-05-14 01:14:50.826110: Current learning rate: 0.00307 
2024-05-14 01:15:39.899462: train_loss -0.8698 
2024-05-14 01:15:39.899663: val_loss -0.8642 
2024-05-14 01:15:39.899722: Pseudo dice [0.9281] 
2024-05-14 01:15:39.899780: Epoch time: 49.07 s 
2024-05-14 01:15:40.938487:  
2024-05-14 01:15:40.938599: Epoch 732 
2024-05-14 01:15:40.938686: Current learning rate: 0.00306 
2024-05-14 01:16:29.939886: train_loss -0.8757 
2024-05-14 01:16:29.940167: val_loss -0.8775 
2024-05-14 01:16:29.940246: Pseudo dice [0.9348] 
2024-05-14 01:16:29.940336: Epoch time: 49.0 s 
2024-05-14 01:16:30.991636:  
2024-05-14 01:16:30.991749: Epoch 733 
2024-05-14 01:16:30.991834: Current learning rate: 0.00305 
2024-05-14 01:17:20.000243: train_loss -0.8731 
2024-05-14 01:17:20.000539: val_loss -0.8825 
2024-05-14 01:17:20.000609: Pseudo dice [0.938] 
2024-05-14 01:17:20.000670: Epoch time: 49.01 s 
2024-05-14 01:17:21.038214:  
2024-05-14 01:17:21.038329: Epoch 734 
2024-05-14 01:17:21.038420: Current learning rate: 0.00304 
2024-05-14 01:18:10.082011: train_loss -0.8706 
2024-05-14 01:18:10.082171: val_loss -0.8539 
2024-05-14 01:18:10.082229: Pseudo dice [0.927] 
2024-05-14 01:18:10.082286: Epoch time: 49.04 s 
2024-05-14 01:18:11.578312:  
2024-05-14 01:18:11.578471: Epoch 735 
2024-05-14 01:18:11.578555: Current learning rate: 0.00303 
2024-05-14 01:19:00.673769: train_loss -0.8681 
2024-05-14 01:19:00.674611: val_loss -0.8673 
2024-05-14 01:19:00.674844: Pseudo dice [0.9324] 
2024-05-14 01:19:00.675008: Epoch time: 49.1 s 
2024-05-14 01:19:01.774208:  
2024-05-14 01:19:01.774374: Epoch 736 
2024-05-14 01:19:01.774463: Current learning rate: 0.00302 
2024-05-14 01:19:50.779482: train_loss -0.8667 
2024-05-14 01:19:50.779674: val_loss -0.8843 
2024-05-14 01:19:50.779745: Pseudo dice [0.9411] 
2024-05-14 01:19:50.779825: Epoch time: 49.01 s 
2024-05-14 01:19:51.830706:  
2024-05-14 01:19:51.830844: Epoch 737 
2024-05-14 01:19:51.830934: Current learning rate: 0.00301 
2024-05-14 01:20:40.951345: train_loss -0.8727 
2024-05-14 01:20:40.951521: val_loss -0.8753 
2024-05-14 01:20:40.951601: Pseudo dice [0.9417] 
2024-05-14 01:20:40.951699: Epoch time: 49.12 s 
2024-05-14 01:20:40.951776: Yayy! New best EMA pseudo Dice: 0.9344 
2024-05-14 01:20:42.316732:  
2024-05-14 01:20:42.316941: Epoch 738 
2024-05-14 01:20:42.317030: Current learning rate: 0.003 
2024-05-14 01:21:31.329257: train_loss -0.8708 
2024-05-14 01:21:31.329585: val_loss -0.8836 
2024-05-14 01:21:31.329684: Pseudo dice [0.9385] 
2024-05-14 01:21:31.329767: Epoch time: 49.01 s 
2024-05-14 01:21:31.329844: Yayy! New best EMA pseudo Dice: 0.9348 
2024-05-14 01:21:32.712450:  
2024-05-14 01:21:32.712822: Epoch 739 
2024-05-14 01:21:32.712935: Current learning rate: 0.00299 
2024-05-14 01:22:21.749988: train_loss -0.8723 
2024-05-14 01:22:21.750264: val_loss -0.8567 
2024-05-14 01:22:21.750536: Pseudo dice [0.9241] 
2024-05-14 01:22:21.750678: Epoch time: 49.04 s 
2024-05-14 01:22:22.801800:  
2024-05-14 01:22:22.801918: Epoch 740 
2024-05-14 01:22:22.801999: Current learning rate: 0.00297 
2024-05-14 01:23:11.880145: train_loss -0.8709 
2024-05-14 01:23:11.880332: val_loss -0.8801 
2024-05-14 01:23:11.880392: Pseudo dice [0.9361] 
2024-05-14 01:23:11.880451: Epoch time: 49.08 s 
2024-05-14 01:23:12.919513:  
2024-05-14 01:23:12.919637: Epoch 741 
2024-05-14 01:23:12.919737: Current learning rate: 0.00296 
2024-05-14 01:24:01.991834: train_loss -0.8735 
2024-05-14 01:24:01.992002: val_loss -0.8689 
2024-05-14 01:24:01.992077: Pseudo dice [0.9309] 
2024-05-14 01:24:01.992157: Epoch time: 49.07 s 
2024-05-14 01:24:03.049080:  
2024-05-14 01:24:03.049200: Epoch 742 
2024-05-14 01:24:03.049285: Current learning rate: 0.00295 
2024-05-14 01:24:52.096224: train_loss -0.8742 
2024-05-14 01:24:52.096488: val_loss -0.8763 
2024-05-14 01:24:52.096558: Pseudo dice [0.9344] 
2024-05-14 01:24:52.096617: Epoch time: 49.05 s 
2024-05-14 01:24:53.202617:  
2024-05-14 01:24:53.202804: Epoch 743 
2024-05-14 01:24:53.202887: Current learning rate: 0.00294 
2024-05-14 01:25:42.210774: train_loss -0.8626 
2024-05-14 01:25:42.210939: val_loss -0.8683 
2024-05-14 01:25:42.210998: Pseudo dice [0.9302] 
2024-05-14 01:25:42.211054: Epoch time: 49.01 s 
2024-05-14 01:25:43.242407:  
2024-05-14 01:25:43.242513: Epoch 744 
2024-05-14 01:25:43.242598: Current learning rate: 0.00293 
2024-05-14 01:26:32.297558: train_loss -0.8653 
2024-05-14 01:26:32.297723: val_loss -0.8743 
2024-05-14 01:26:32.297800: Pseudo dice [0.9346] 
2024-05-14 01:26:32.297857: Epoch time: 49.06 s 
2024-05-14 01:26:33.848800:  
2024-05-14 01:26:33.849185: Epoch 745 
2024-05-14 01:26:33.849271: Current learning rate: 0.00292 
2024-05-14 01:27:22.934947: train_loss -0.8699 
2024-05-14 01:27:22.935299: val_loss -0.8694 
2024-05-14 01:27:22.935375: Pseudo dice [0.9363] 
2024-05-14 01:27:22.935443: Epoch time: 49.09 s 
2024-05-14 01:27:24.007756:  
2024-05-14 01:27:24.008007: Epoch 746 
2024-05-14 01:27:24.008098: Current learning rate: 0.00291 
2024-05-14 01:28:13.045773: train_loss -0.879 
2024-05-14 01:28:13.045948: val_loss -0.8784 
2024-05-14 01:28:13.046010: Pseudo dice [0.9371] 
2024-05-14 01:28:13.046085: Epoch time: 49.04 s 
2024-05-14 01:28:14.111089:  
2024-05-14 01:28:14.111221: Epoch 747 
2024-05-14 01:28:14.111308: Current learning rate: 0.0029 
2024-05-14 01:29:03.137621: train_loss -0.8718 
2024-05-14 01:29:03.137869: val_loss -0.8786 
2024-05-14 01:29:03.137943: Pseudo dice [0.9372] 
2024-05-14 01:29:03.138005: Epoch time: 49.03 s 
2024-05-14 01:29:04.179635:  
2024-05-14 01:29:04.179935: Epoch 748 
2024-05-14 01:29:04.180025: Current learning rate: 0.00289 
2024-05-14 01:29:53.259772: train_loss -0.8684 
2024-05-14 01:29:53.260008: val_loss -0.8784 
2024-05-14 01:29:53.260074: Pseudo dice [0.9375] 
2024-05-14 01:29:53.260139: Epoch time: 49.08 s 
2024-05-14 01:29:54.300698:  
2024-05-14 01:29:54.300816: Epoch 749 
2024-05-14 01:29:54.300898: Current learning rate: 0.00288 
2024-05-14 01:30:43.352152: train_loss -0.8632 
2024-05-14 01:30:43.352318: val_loss -0.8829 
2024-05-14 01:30:43.352374: Pseudo dice [0.9359] 
2024-05-14 01:30:43.352428: Epoch time: 49.05 s 
2024-05-14 01:30:43.691565: Yayy! New best EMA pseudo Dice: 0.9349 
2024-05-14 01:30:45.052473:  
2024-05-14 01:30:45.052620: Epoch 750 
2024-05-14 01:30:45.052711: Current learning rate: 0.00287 
2024-05-14 01:31:34.047901: train_loss -0.8692 
2024-05-14 01:31:34.048567: val_loss -0.8714 
2024-05-14 01:31:34.048624: Pseudo dice [0.9309] 
2024-05-14 01:31:34.048673: Epoch time: 49.0 s 
2024-05-14 01:31:35.113236:  
2024-05-14 01:31:35.113361: Epoch 751 
2024-05-14 01:31:35.113447: Current learning rate: 0.00286 
2024-05-14 01:32:24.181318: train_loss -0.8736 
2024-05-14 01:32:24.181512: val_loss -0.8737 
2024-05-14 01:32:24.181573: Pseudo dice [0.9393] 
2024-05-14 01:32:24.181643: Epoch time: 49.07 s 
2024-05-14 01:32:24.181708: Yayy! New best EMA pseudo Dice: 0.9349 
2024-05-14 01:32:25.661986:  
2024-05-14 01:32:25.662099: Epoch 752 
2024-05-14 01:32:25.662182: Current learning rate: 0.00285 
2024-05-14 01:33:14.698934: train_loss -0.8796 
2024-05-14 01:33:14.699111: val_loss -0.8825 
2024-05-14 01:33:14.699172: Pseudo dice [0.9384] 
2024-05-14 01:33:14.699234: Epoch time: 49.04 s 
2024-05-14 01:33:14.699281: Yayy! New best EMA pseudo Dice: 0.9353 
2024-05-14 01:33:16.120519:  
2024-05-14 01:33:16.120628: Epoch 753 
2024-05-14 01:33:16.120712: Current learning rate: 0.00284 
2024-05-14 01:34:05.169878: train_loss -0.8695 
2024-05-14 01:34:05.170098: val_loss -0.8746 
2024-05-14 01:34:05.170159: Pseudo dice [0.9316] 
2024-05-14 01:34:05.170216: Epoch time: 49.05 s 
2024-05-14 01:34:06.232719:  
2024-05-14 01:34:06.232821: Epoch 754 
2024-05-14 01:34:06.232906: Current learning rate: 0.00283 
2024-05-14 01:34:55.345475: train_loss -0.8712 
2024-05-14 01:34:55.345805: val_loss -0.8757 
2024-05-14 01:34:55.345871: Pseudo dice [0.9371] 
2024-05-14 01:34:55.345934: Epoch time: 49.11 s 
2024-05-14 01:34:56.917180:  
2024-05-14 01:34:56.917311: Epoch 755 
2024-05-14 01:34:56.917392: Current learning rate: 0.00282 
2024-05-14 01:35:45.970339: train_loss -0.8739 
2024-05-14 01:35:45.970550: val_loss -0.8709 
2024-05-14 01:35:45.970614: Pseudo dice [0.9317] 
2024-05-14 01:35:45.970674: Epoch time: 49.05 s 
2024-05-14 01:35:47.067912:  
2024-05-14 01:35:47.068045: Epoch 756 
2024-05-14 01:35:47.068130: Current learning rate: 0.00281 
2024-05-14 01:36:36.136357: train_loss -0.8743 
2024-05-14 01:36:36.136560: val_loss -0.887 
2024-05-14 01:36:36.136622: Pseudo dice [0.9413] 
2024-05-14 01:36:36.136687: Epoch time: 49.07 s 
2024-05-14 01:36:36.136732: Yayy! New best EMA pseudo Dice: 0.9355 
2024-05-14 01:36:37.486891:  
2024-05-14 01:36:37.487052: Epoch 757 
2024-05-14 01:36:37.487160: Current learning rate: 0.0028 
2024-05-14 01:37:26.573122: train_loss -0.8739 
2024-05-14 01:37:26.573447: val_loss -0.8678 
2024-05-14 01:37:26.573532: Pseudo dice [0.9352] 
2024-05-14 01:37:26.573592: Epoch time: 49.09 s 
2024-05-14 01:37:27.635881:  
2024-05-14 01:37:27.636007: Epoch 758 
2024-05-14 01:37:27.636091: Current learning rate: 0.00279 
2024-05-14 01:38:16.752551: train_loss -0.8733 
2024-05-14 01:38:16.752731: val_loss -0.8921 
2024-05-14 01:38:16.752791: Pseudo dice [0.9432] 
2024-05-14 01:38:16.752852: Epoch time: 49.12 s 
2024-05-14 01:38:16.752897: Yayy! New best EMA pseudo Dice: 0.9362 
2024-05-14 01:38:18.161650:  
2024-05-14 01:38:18.161768: Epoch 759 
2024-05-14 01:38:18.161870: Current learning rate: 0.00278 
2024-05-14 01:39:07.180307: train_loss -0.8751 
2024-05-14 01:39:07.180491: val_loss -0.8655 
2024-05-14 01:39:07.181115: Pseudo dice [0.927] 
2024-05-14 01:39:07.181206: Epoch time: 49.02 s 
2024-05-14 01:39:08.233999:  
2024-05-14 01:39:08.234108: Epoch 760 
2024-05-14 01:39:08.234221: Current learning rate: 0.00277 
2024-05-14 01:39:57.434388: train_loss -0.8737 
2024-05-14 01:39:57.434547: val_loss -0.8732 
2024-05-14 01:39:57.434607: Pseudo dice [0.9372] 
2024-05-14 01:39:57.434666: Epoch time: 49.2 s 
2024-05-14 01:39:58.467780:  
2024-05-14 01:39:58.467903: Epoch 761 
2024-05-14 01:39:58.467989: Current learning rate: 0.00276 
2024-05-14 01:40:47.543868: train_loss -0.8686 
2024-05-14 01:40:47.544030: val_loss -0.8695 
2024-05-14 01:40:47.544106: Pseudo dice [0.9378] 
2024-05-14 01:40:47.544308: Epoch time: 49.08 s 
2024-05-14 01:40:48.594615:  
2024-05-14 01:40:48.594722: Epoch 762 
2024-05-14 01:40:48.594805: Current learning rate: 0.00275 
2024-05-14 01:41:37.684618: train_loss -0.8621 
2024-05-14 01:41:37.685358: val_loss -0.8653 
2024-05-14 01:41:37.685426: Pseudo dice [0.9308] 
2024-05-14 01:41:37.685481: Epoch time: 49.09 s 
2024-05-14 01:41:38.746850:  
2024-05-14 01:41:38.746957: Epoch 763 
2024-05-14 01:41:38.747043: Current learning rate: 0.00274 
2024-05-14 01:42:27.894988: train_loss -0.8676 
2024-05-14 01:42:27.895147: val_loss -0.8614 
2024-05-14 01:42:27.895195: Pseudo dice [0.9322] 
2024-05-14 01:42:27.895245: Epoch time: 49.15 s 
2024-05-14 01:42:28.941808:  
2024-05-14 01:42:28.941930: Epoch 764 
2024-05-14 01:42:28.942015: Current learning rate: 0.00273 
2024-05-14 01:43:18.002364: train_loss -0.8649 
2024-05-14 01:43:18.002545: val_loss -0.8799 
2024-05-14 01:43:18.002606: Pseudo dice [0.9353] 
2024-05-14 01:43:18.002665: Epoch time: 49.06 s 
2024-05-14 01:43:19.557367:  
2024-05-14 01:43:19.557618: Epoch 765 
2024-05-14 01:43:19.557703: Current learning rate: 0.00272 
2024-05-14 01:44:08.626156: train_loss -0.8716 
2024-05-14 01:44:08.626379: val_loss -0.8622 
2024-05-14 01:44:08.626461: Pseudo dice [0.9297] 
2024-05-14 01:44:08.626519: Epoch time: 49.07 s 
2024-05-14 01:44:09.707211:  
2024-05-14 01:44:09.707345: Epoch 766 
2024-05-14 01:44:09.707450: Current learning rate: 0.00271 
2024-05-14 01:44:58.712862: train_loss -0.8795 
2024-05-14 01:44:58.713548: val_loss -0.8809 
2024-05-14 01:44:58.713616: Pseudo dice [0.9366] 
2024-05-14 01:44:58.713688: Epoch time: 49.01 s 
2024-05-14 01:44:59.781346:  
2024-05-14 01:44:59.781478: Epoch 767 
2024-05-14 01:44:59.781590: Current learning rate: 0.0027 
2024-05-14 01:45:48.866180: train_loss -0.8682 
2024-05-14 01:45:48.866421: val_loss -0.8791 
2024-05-14 01:45:48.866488: Pseudo dice [0.9359] 
2024-05-14 01:45:48.866549: Epoch time: 49.09 s 
2024-05-14 01:45:49.936444:  
2024-05-14 01:45:49.936576: Epoch 768 
2024-05-14 01:45:49.936659: Current learning rate: 0.00268 
2024-05-14 01:46:38.952483: train_loss -0.8744 
2024-05-14 01:46:38.952678: val_loss -0.8747 
2024-05-14 01:46:38.952756: Pseudo dice [0.9346] 
2024-05-14 01:46:38.952814: Epoch time: 49.02 s 
2024-05-14 01:46:40.023031:  
2024-05-14 01:46:40.023361: Epoch 769 
2024-05-14 01:46:40.023511: Current learning rate: 0.00267 
2024-05-14 01:47:29.145766: train_loss -0.872 
2024-05-14 01:47:29.146044: val_loss -0.8732 
2024-05-14 01:47:29.146116: Pseudo dice [0.9327] 
2024-05-14 01:47:29.146183: Epoch time: 49.12 s 
2024-05-14 01:47:30.192877:  
2024-05-14 01:47:30.193002: Epoch 770 
2024-05-14 01:47:30.193085: Current learning rate: 0.00266 
2024-05-14 01:48:19.234438: train_loss -0.8738 
2024-05-14 01:48:19.234605: val_loss -0.8866 
2024-05-14 01:48:19.234664: Pseudo dice [0.937] 
2024-05-14 01:48:19.234720: Epoch time: 49.04 s 
2024-05-14 01:48:20.292158:  
2024-05-14 01:48:20.292271: Epoch 771 
2024-05-14 01:48:20.292370: Current learning rate: 0.00265 
2024-05-14 01:49:09.381862: train_loss -0.8732 
2024-05-14 01:49:09.382027: val_loss -0.8763 
2024-05-14 01:49:09.382085: Pseudo dice [0.9355] 
2024-05-14 01:49:09.382150: Epoch time: 49.09 s 
2024-05-14 01:49:10.451856:  
2024-05-14 01:49:10.451978: Epoch 772 
2024-05-14 01:49:10.452058: Current learning rate: 0.00264 
2024-05-14 01:49:59.523698: train_loss -0.8756 
2024-05-14 01:49:59.524416: val_loss -0.8826 
2024-05-14 01:49:59.524488: Pseudo dice [0.9388] 
2024-05-14 01:49:59.524539: Epoch time: 49.07 s 
2024-05-14 01:50:00.610737:  
2024-05-14 01:50:00.610844: Epoch 773 
2024-05-14 01:50:00.610926: Current learning rate: 0.00263 
2024-05-14 01:50:49.695550: train_loss -0.8743 
2024-05-14 01:50:49.695733: val_loss -0.8619 
2024-05-14 01:50:49.695820: Pseudo dice [0.9283] 
2024-05-14 01:50:49.695901: Epoch time: 49.09 s 
2024-05-14 01:50:50.744738:  
2024-05-14 01:50:50.744842: Epoch 774 
2024-05-14 01:50:50.744941: Current learning rate: 0.00262 
2024-05-14 01:51:39.833462: train_loss -0.8752 
2024-05-14 01:51:39.833648: val_loss -0.8834 
2024-05-14 01:51:39.833712: Pseudo dice [0.9348] 
2024-05-14 01:51:39.833771: Epoch time: 49.09 s 
2024-05-14 01:51:41.376416:  
2024-05-14 01:51:41.376539: Epoch 775 
2024-05-14 01:51:41.376634: Current learning rate: 0.00261 
2024-05-14 01:52:30.404604: train_loss -0.8687 
2024-05-14 01:52:30.405334: val_loss -0.8759 
2024-05-14 01:52:30.405396: Pseudo dice [0.9384] 
2024-05-14 01:52:30.405447: Epoch time: 49.03 s 
2024-05-14 01:52:31.471168:  
2024-05-14 01:52:31.471301: Epoch 776 
2024-05-14 01:52:31.471384: Current learning rate: 0.0026 
2024-05-14 01:53:20.569263: train_loss -0.8744 
2024-05-14 01:53:20.569452: val_loss -0.8677 
2024-05-14 01:53:20.569514: Pseudo dice [0.9338] 
2024-05-14 01:53:20.569686: Epoch time: 49.1 s 
2024-05-14 01:53:21.635018:  
2024-05-14 01:53:21.635142: Epoch 777 
2024-05-14 01:53:21.635231: Current learning rate: 0.00259 
2024-05-14 01:54:10.748293: train_loss -0.8701 
2024-05-14 01:54:10.748474: val_loss -0.881 
2024-05-14 01:54:10.748559: Pseudo dice [0.9374] 
2024-05-14 01:54:10.748637: Epoch time: 49.11 s 
2024-05-14 01:54:11.818873:  
2024-05-14 01:54:11.819085: Epoch 778 
2024-05-14 01:54:11.819170: Current learning rate: 0.00258 
2024-05-14 01:55:00.874598: train_loss -0.8755 
2024-05-14 01:55:00.874773: val_loss -0.86 
2024-05-14 01:55:00.874835: Pseudo dice [0.9312] 
2024-05-14 01:55:00.874895: Epoch time: 49.06 s 
2024-05-14 01:55:01.931899:  
2024-05-14 01:55:01.932030: Epoch 779 
2024-05-14 01:55:01.932121: Current learning rate: 0.00257 
2024-05-14 01:55:50.976920: train_loss -0.8733 
2024-05-14 01:55:50.977165: val_loss -0.8691 
2024-05-14 01:55:50.977232: Pseudo dice [0.9351] 
2024-05-14 01:55:50.977309: Epoch time: 49.05 s 
2024-05-14 01:55:52.070285:  
2024-05-14 01:55:52.070663: Epoch 780 
2024-05-14 01:55:52.070753: Current learning rate: 0.00256 
2024-05-14 01:56:41.152634: train_loss -0.8729 
2024-05-14 01:56:41.152802: val_loss -0.8788 
2024-05-14 01:56:41.152878: Pseudo dice [0.9334] 
2024-05-14 01:56:41.152934: Epoch time: 49.08 s 
2024-05-14 01:56:42.211748:  
2024-05-14 01:56:42.211877: Epoch 781 
2024-05-14 01:56:42.211965: Current learning rate: 0.00255 
2024-05-14 01:57:31.251601: train_loss -0.8803 
2024-05-14 01:57:31.251793: val_loss -0.8759 
2024-05-14 01:57:31.251859: Pseudo dice [0.9371] 
2024-05-14 01:57:31.251919: Epoch time: 49.04 s 
2024-05-14 01:57:32.308334:  
2024-05-14 01:57:32.308563: Epoch 782 
2024-05-14 01:57:32.308647: Current learning rate: 0.00254 
2024-05-14 01:58:21.353046: train_loss -0.8765 
2024-05-14 01:58:21.353729: val_loss -0.8643 
2024-05-14 01:58:21.353811: Pseudo dice [0.9332] 
2024-05-14 01:58:21.353881: Epoch time: 49.05 s 
2024-05-14 01:58:22.402425:  
2024-05-14 01:58:22.402527: Epoch 783 
2024-05-14 01:58:22.402610: Current learning rate: 0.00253 
2024-05-14 01:59:11.454644: train_loss -0.8753 
2024-05-14 01:59:11.454828: val_loss -0.8714 
2024-05-14 01:59:11.454891: Pseudo dice [0.9266] 
2024-05-14 01:59:11.454958: Epoch time: 49.05 s 
2024-05-14 01:59:12.513182:  
2024-05-14 01:59:12.513283: Epoch 784 
2024-05-14 01:59:12.513365: Current learning rate: 0.00252 
2024-05-14 02:00:01.512222: train_loss -0.87 
2024-05-14 02:00:01.512392: val_loss -0.8747 
2024-05-14 02:00:01.512466: Pseudo dice [0.9344] 
2024-05-14 02:00:01.512523: Epoch time: 49.0 s 
2024-05-14 02:00:02.998306:  
2024-05-14 02:00:02.998442: Epoch 785 
2024-05-14 02:00:02.998524: Current learning rate: 0.00251 
2024-05-14 02:00:52.017888: train_loss -0.8749 
2024-05-14 02:00:52.018179: val_loss -0.8571 
2024-05-14 02:00:52.018268: Pseudo dice [0.9289] 
2024-05-14 02:00:52.018340: Epoch time: 49.02 s 
2024-05-14 02:00:53.071487:  
2024-05-14 02:00:53.071614: Epoch 786 
2024-05-14 02:00:53.071704: Current learning rate: 0.0025 
2024-05-14 02:01:42.161421: train_loss -0.8716 
2024-05-14 02:01:42.161593: val_loss -0.8765 
2024-05-14 02:01:42.161644: Pseudo dice [0.9346] 
2024-05-14 02:01:42.161712: Epoch time: 49.09 s 
2024-05-14 02:01:43.228067:  
2024-05-14 02:01:43.228190: Epoch 787 
2024-05-14 02:01:43.228274: Current learning rate: 0.00249 
2024-05-14 02:02:32.327495: train_loss -0.872 
2024-05-14 02:02:32.327680: val_loss -0.8792 
2024-05-14 02:02:32.327741: Pseudo dice [0.9387] 
2024-05-14 02:02:32.327800: Epoch time: 49.1 s 
2024-05-14 02:02:33.389689:  
2024-05-14 02:02:33.389826: Epoch 788 
2024-05-14 02:02:33.389926: Current learning rate: 0.00248 
2024-05-14 02:03:22.436642: train_loss -0.8735 
2024-05-14 02:03:22.436904: val_loss -0.8767 
2024-05-14 02:03:22.436971: Pseudo dice [0.9371] 
2024-05-14 02:03:22.437028: Epoch time: 49.05 s 
2024-05-14 02:03:23.505382:  
2024-05-14 02:03:23.505626: Epoch 789 
2024-05-14 02:03:23.505728: Current learning rate: 0.00247 
2024-05-14 02:04:12.506836: train_loss -0.878 
2024-05-14 02:04:12.507143: val_loss -0.8838 
2024-05-14 02:04:12.507218: Pseudo dice [0.9393] 
2024-05-14 02:04:12.507276: Epoch time: 49.0 s 
2024-05-14 02:04:13.555176:  
2024-05-14 02:04:13.555340: Epoch 790 
2024-05-14 02:04:13.555435: Current learning rate: 0.00245 
2024-05-14 02:05:02.607043: train_loss -0.8734 
2024-05-14 02:05:02.607199: val_loss -0.8791 
2024-05-14 02:05:02.607259: Pseudo dice [0.9357] 
2024-05-14 02:05:02.607321: Epoch time: 49.05 s 
2024-05-14 02:05:03.653758:  
2024-05-14 02:05:03.653953: Epoch 791 
2024-05-14 02:05:03.654048: Current learning rate: 0.00244 
2024-05-14 02:05:52.680955: train_loss -0.8728 
2024-05-14 02:05:52.681127: val_loss -0.8734 
2024-05-14 02:05:52.681210: Pseudo dice [0.9345] 
2024-05-14 02:05:52.681279: Epoch time: 49.03 s 
2024-05-14 02:05:53.770798:  
2024-05-14 02:05:53.770991: Epoch 792 
2024-05-14 02:05:53.771077: Current learning rate: 0.00243 
2024-05-14 02:06:42.775907: train_loss -0.8741 
2024-05-14 02:06:42.776608: val_loss -0.8788 
2024-05-14 02:06:42.776666: Pseudo dice [0.932] 
2024-05-14 02:06:42.776717: Epoch time: 49.01 s 
2024-05-14 02:06:43.820381:  
2024-05-14 02:06:43.820490: Epoch 793 
2024-05-14 02:06:43.820576: Current learning rate: 0.00242 
2024-05-14 02:07:32.860277: train_loss -0.8662 
2024-05-14 02:07:32.860493: val_loss -0.8783 
2024-05-14 02:07:32.860553: Pseudo dice [0.9386] 
2024-05-14 02:07:32.860612: Epoch time: 49.04 s 
2024-05-14 02:07:33.909333:  
2024-05-14 02:07:33.909451: Epoch 794 
2024-05-14 02:07:33.909532: Current learning rate: 0.00241 
2024-05-14 02:08:22.945571: train_loss -0.8711 
2024-05-14 02:08:22.945735: val_loss -0.8874 
2024-05-14 02:08:22.945808: Pseudo dice [0.9382] 
2024-05-14 02:08:22.945868: Epoch time: 49.04 s 
2024-05-14 02:08:24.483311:  
2024-05-14 02:08:24.483448: Epoch 795 
2024-05-14 02:08:24.483533: Current learning rate: 0.0024 
2024-05-14 02:09:13.561208: train_loss -0.8785 
2024-05-14 02:09:13.561542: val_loss -0.8814 
2024-05-14 02:09:13.561631: Pseudo dice [0.9353] 
2024-05-14 02:09:13.561692: Epoch time: 49.08 s 
2024-05-14 02:09:14.615563:  
2024-05-14 02:09:14.615694: Epoch 796 
2024-05-14 02:09:14.615777: Current learning rate: 0.00239 
2024-05-14 02:10:03.674911: train_loss -0.8709 
2024-05-14 02:10:03.675082: val_loss -0.8647 
2024-05-14 02:10:03.675157: Pseudo dice [0.9329] 
2024-05-14 02:10:03.675214: Epoch time: 49.06 s 
2024-05-14 02:10:04.729666:  
2024-05-14 02:10:04.729878: Epoch 797 
2024-05-14 02:10:04.729970: Current learning rate: 0.00238 
2024-05-14 02:10:53.825953: train_loss -0.8719 
2024-05-14 02:10:53.826136: val_loss -0.8705 
2024-05-14 02:10:53.826196: Pseudo dice [0.9337] 
2024-05-14 02:10:53.826255: Epoch time: 49.1 s 
2024-05-14 02:10:54.895162:  
2024-05-14 02:10:54.895278: Epoch 798 
2024-05-14 02:10:54.895358: Current learning rate: 0.00237 
2024-05-14 02:11:44.053468: train_loss -0.8819 
2024-05-14 02:11:44.054180: val_loss -0.8728 
2024-05-14 02:11:44.054236: Pseudo dice [0.9327] 
2024-05-14 02:11:44.054290: Epoch time: 49.16 s 
2024-05-14 02:11:45.143120:  
2024-05-14 02:11:45.143234: Epoch 799 
2024-05-14 02:11:45.143319: Current learning rate: 0.00236 
2024-05-14 02:12:34.234266: train_loss -0.8804 
2024-05-14 02:12:34.234458: val_loss -0.8726 
2024-05-14 02:12:34.234524: Pseudo dice [0.9342] 
2024-05-14 02:12:34.234584: Epoch time: 49.09 s 
2024-05-14 02:12:35.632834:  
2024-05-14 02:12:35.632979: Epoch 800 
2024-05-14 02:12:35.633070: Current learning rate: 0.00235 
2024-05-14 02:13:24.722414: train_loss -0.8761 
2024-05-14 02:13:24.722585: val_loss -0.8743 
2024-05-14 02:13:24.722643: Pseudo dice [0.9364] 
2024-05-14 02:13:24.722707: Epoch time: 49.09 s 
2024-05-14 02:13:25.797468:  
2024-05-14 02:13:25.797577: Epoch 801 
2024-05-14 02:13:25.797676: Current learning rate: 0.00234 
2024-05-14 02:14:14.851999: train_loss -0.8752 
2024-05-14 02:14:14.852723: val_loss -0.8727 
2024-05-14 02:14:14.852784: Pseudo dice [0.9378] 
2024-05-14 02:14:14.852836: Epoch time: 49.06 s 
2024-05-14 02:14:15.971114:  
2024-05-14 02:14:15.971251: Epoch 802 
2024-05-14 02:14:15.971430: Current learning rate: 0.00233 
2024-05-14 02:15:05.047513: train_loss -0.8764 
2024-05-14 02:15:05.047697: val_loss -0.8717 
2024-05-14 02:15:05.047757: Pseudo dice [0.9318] 
2024-05-14 02:15:05.047816: Epoch time: 49.08 s 
2024-05-14 02:15:06.126392:  
2024-05-14 02:15:06.126732: Epoch 803 
2024-05-14 02:15:06.126824: Current learning rate: 0.00232 
2024-05-14 02:15:55.224401: train_loss -0.8724 
2024-05-14 02:15:55.224581: val_loss -0.8536 
2024-05-14 02:15:55.224645: Pseudo dice [0.9328] 
2024-05-14 02:15:55.224714: Epoch time: 49.1 s 
2024-05-14 02:15:56.277702:  
2024-05-14 02:15:56.277808: Epoch 804 
2024-05-14 02:15:56.277907: Current learning rate: 0.00231 
2024-05-14 02:16:45.283112: train_loss -0.8775 
2024-05-14 02:16:45.283376: val_loss -0.8801 
2024-05-14 02:16:45.283441: Pseudo dice [0.9346] 
2024-05-14 02:16:45.283504: Epoch time: 49.01 s 
2024-05-14 02:16:46.836471:  
2024-05-14 02:16:46.836762: Epoch 805 
2024-05-14 02:16:46.836853: Current learning rate: 0.0023 
2024-05-14 02:17:35.942583: train_loss -0.8762 
2024-05-14 02:17:35.942775: val_loss -0.8702 
2024-05-14 02:17:35.942833: Pseudo dice [0.938] 
2024-05-14 02:17:35.942894: Epoch time: 49.11 s 
2024-05-14 02:17:37.039147:  
2024-05-14 02:17:37.039274: Epoch 806 
2024-05-14 02:17:37.039358: Current learning rate: 0.00229 
2024-05-14 02:18:26.104524: train_loss -0.8788 
2024-05-14 02:18:26.104691: val_loss -0.873 
2024-05-14 02:18:26.104766: Pseudo dice [0.9364] 
2024-05-14 02:18:26.104827: Epoch time: 49.07 s 
2024-05-14 02:18:27.161561:  
2024-05-14 02:18:27.161703: Epoch 807 
2024-05-14 02:18:27.161787: Current learning rate: 0.00228 
2024-05-14 02:19:16.296401: train_loss -0.8688 
2024-05-14 02:19:16.297125: val_loss -0.8802 
2024-05-14 02:19:16.297187: Pseudo dice [0.9386] 
2024-05-14 02:19:16.297243: Epoch time: 49.14 s 
2024-05-14 02:19:17.362890:  
2024-05-14 02:19:17.363006: Epoch 808 
2024-05-14 02:19:17.363090: Current learning rate: 0.00226 
2024-05-14 02:20:06.506108: train_loss -0.8768 
2024-05-14 02:20:06.506279: val_loss -0.8858 
2024-05-14 02:20:06.506366: Pseudo dice [0.9417] 
2024-05-14 02:20:06.506424: Epoch time: 49.14 s 
2024-05-14 02:20:07.573361:  
2024-05-14 02:20:07.573468: Epoch 809 
2024-05-14 02:20:07.573579: Current learning rate: 0.00225 
2024-05-14 02:20:56.659862: train_loss -0.8741 
2024-05-14 02:20:56.660035: val_loss -0.8824 
2024-05-14 02:20:56.660093: Pseudo dice [0.9393] 
2024-05-14 02:20:56.660149: Epoch time: 49.09 s 
2024-05-14 02:20:56.660199: Yayy! New best EMA pseudo Dice: 0.9364 
2024-05-14 02:20:58.042673:  
2024-05-14 02:20:58.042868: Epoch 810 
2024-05-14 02:20:58.042953: Current learning rate: 0.00224 
2024-05-14 02:21:47.233165: train_loss -0.8738 
2024-05-14 02:21:47.233419: val_loss -0.8784 
2024-05-14 02:21:47.233486: Pseudo dice [0.9362] 
2024-05-14 02:21:47.233560: Epoch time: 49.19 s 
2024-05-14 02:21:48.295070:  
2024-05-14 02:21:48.295184: Epoch 811 
2024-05-14 02:21:48.295270: Current learning rate: 0.00223 
2024-05-14 02:22:37.343865: train_loss -0.8775 
2024-05-14 02:22:37.344174: val_loss -0.8864 
2024-05-14 02:22:37.344373: Pseudo dice [0.9404] 
2024-05-14 02:22:37.344685: Epoch time: 49.05 s 
2024-05-14 02:22:37.344863: Yayy! New best EMA pseudo Dice: 0.9368 
2024-05-14 02:22:38.749574:  
2024-05-14 02:22:38.749680: Epoch 812 
2024-05-14 02:22:38.749778: Current learning rate: 0.00222 
2024-05-14 02:23:27.780561: train_loss -0.8788 
2024-05-14 02:23:27.780753: val_loss -0.8849 
2024-05-14 02:23:27.781294: Pseudo dice [0.9376] 
2024-05-14 02:23:27.781345: Epoch time: 49.03 s 
2024-05-14 02:23:27.781385: Yayy! New best EMA pseudo Dice: 0.9369 
2024-05-14 02:23:29.233814:  
2024-05-14 02:23:29.233919: Epoch 813 
2024-05-14 02:23:29.234002: Current learning rate: 0.00221 
2024-05-14 02:24:18.314021: train_loss -0.8788 
2024-05-14 02:24:18.314733: val_loss -0.8796 
2024-05-14 02:24:18.314827: Pseudo dice [0.9333] 
2024-05-14 02:24:18.314884: Epoch time: 49.08 s 
2024-05-14 02:24:19.829458:  
2024-05-14 02:24:19.829608: Epoch 814 
2024-05-14 02:24:19.829694: Current learning rate: 0.0022 
2024-05-14 02:25:08.839130: train_loss -0.8747 
2024-05-14 02:25:08.839327: val_loss -0.8814 
2024-05-14 02:25:08.839413: Pseudo dice [0.9353] 
2024-05-14 02:25:08.839499: Epoch time: 49.01 s 
2024-05-14 02:25:09.907915:  
2024-05-14 02:25:09.908145: Epoch 815 
2024-05-14 02:25:09.908230: Current learning rate: 0.00219 
2024-05-14 02:25:58.929565: train_loss -0.8739 
2024-05-14 02:25:58.929763: val_loss -0.8696 
2024-05-14 02:25:58.929825: Pseudo dice [0.938] 
2024-05-14 02:25:58.929883: Epoch time: 49.02 s 
2024-05-14 02:25:59.991188:  
2024-05-14 02:25:59.991303: Epoch 816 
2024-05-14 02:25:59.991384: Current learning rate: 0.00218 
2024-05-14 02:26:49.062441: train_loss -0.8719 
2024-05-14 02:26:49.063121: val_loss -0.8708 
2024-05-14 02:26:49.063183: Pseudo dice [0.9329] 
2024-05-14 02:26:49.063235: Epoch time: 49.07 s 
2024-05-14 02:26:50.118145:  
2024-05-14 02:26:50.118259: Epoch 817 
2024-05-14 02:26:50.118347: Current learning rate: 0.00217 
2024-05-14 02:27:39.232104: train_loss -0.8741 
2024-05-14 02:27:39.232296: val_loss -0.883 
2024-05-14 02:27:39.232369: Pseudo dice [0.9407] 
2024-05-14 02:27:39.232436: Epoch time: 49.11 s 
2024-05-14 02:27:40.315804:  
2024-05-14 02:27:40.315921: Epoch 818 
2024-05-14 02:27:40.316004: Current learning rate: 0.00216 
2024-05-14 02:28:29.418826: train_loss -0.879 
2024-05-14 02:28:29.418979: val_loss -0.8851 
2024-05-14 02:28:29.419040: Pseudo dice [0.9407] 
2024-05-14 02:28:29.419099: Epoch time: 49.1 s 
2024-05-14 02:28:29.419146: Yayy! New best EMA pseudo Dice: 0.937 
2024-05-14 02:28:30.822926:  
2024-05-14 02:28:30.823168: Epoch 819 
2024-05-14 02:28:30.823256: Current learning rate: 0.00215 
2024-05-14 02:29:19.893833: train_loss -0.8751 
2024-05-14 02:29:19.894707: val_loss -0.8833 
2024-05-14 02:29:19.894975: Pseudo dice [0.9365] 
2024-05-14 02:29:19.895179: Epoch time: 49.07 s 
2024-05-14 02:29:20.929038:  
2024-05-14 02:29:20.929147: Epoch 820 
2024-05-14 02:29:20.929227: Current learning rate: 0.00214 
2024-05-14 02:30:10.056491: train_loss -0.8756 
2024-05-14 02:30:10.056705: val_loss -0.8805 
2024-05-14 02:30:10.056782: Pseudo dice [0.9354] 
2024-05-14 02:30:10.056848: Epoch time: 49.13 s 
2024-05-14 02:30:11.061136:  
2024-05-14 02:30:11.061249: Epoch 821 
2024-05-14 02:30:11.061338: Current learning rate: 0.00213 
2024-05-14 02:31:00.188561: train_loss -0.8745 
2024-05-14 02:31:00.188759: val_loss -0.8701 
2024-05-14 02:31:00.189264: Pseudo dice [0.933] 
2024-05-14 02:31:00.189318: Epoch time: 49.13 s 
2024-05-14 02:31:01.178623:  
2024-05-14 02:31:01.178730: Epoch 822 
2024-05-14 02:31:01.178811: Current learning rate: 0.00212 
2024-05-14 02:31:50.297329: train_loss -0.8792 
2024-05-14 02:31:50.297658: val_loss -0.8753 
2024-05-14 02:31:50.297728: Pseudo dice [0.9368] 
2024-05-14 02:31:50.297791: Epoch time: 49.12 s 
2024-05-14 02:31:51.280731:  
2024-05-14 02:31:51.280838: Epoch 823 
2024-05-14 02:31:51.280921: Current learning rate: 0.0021 
2024-05-14 02:32:40.327436: train_loss -0.8748 
2024-05-14 02:32:40.327618: val_loss -0.8881 
2024-05-14 02:32:40.327696: Pseudo dice [0.9423] 
2024-05-14 02:32:40.327761: Epoch time: 49.05 s 
2024-05-14 02:32:40.327807: Yayy! New best EMA pseudo Dice: 0.9371 
2024-05-14 02:32:42.054430:  
2024-05-14 02:32:42.054734: Epoch 824 
2024-05-14 02:32:42.054927: Current learning rate: 0.00209 
2024-05-14 02:33:31.095169: train_loss -0.8735 
2024-05-14 02:33:31.095344: val_loss -0.887 
2024-05-14 02:33:31.095427: Pseudo dice [0.9393] 
2024-05-14 02:33:31.095511: Epoch time: 49.04 s 
2024-05-14 02:33:31.095575: Yayy! New best EMA pseudo Dice: 0.9373 
2024-05-14 02:33:32.450399:  
2024-05-14 02:33:32.450604: Epoch 825 
2024-05-14 02:33:32.450696: Current learning rate: 0.00208 
2024-05-14 02:34:21.571110: train_loss -0.8727 
2024-05-14 02:34:21.571380: val_loss -0.8858 
2024-05-14 02:34:21.571448: Pseudo dice [0.9384] 
2024-05-14 02:34:21.571504: Epoch time: 49.12 s 
2024-05-14 02:34:21.571550: Yayy! New best EMA pseudo Dice: 0.9374 
2024-05-14 02:34:22.933424:  
2024-05-14 02:34:22.933564: Epoch 826 
2024-05-14 02:34:22.933762: Current learning rate: 0.00207 
2024-05-14 02:35:12.021703: train_loss -0.8768 
2024-05-14 02:35:12.021879: val_loss -0.8807 
2024-05-14 02:35:12.021939: Pseudo dice [0.9377] 
2024-05-14 02:35:12.022006: Epoch time: 49.09 s 
2024-05-14 02:35:12.022051: Yayy! New best EMA pseudo Dice: 0.9374 
2024-05-14 02:35:13.385563:  
2024-05-14 02:35:13.385781: Epoch 827 
2024-05-14 02:35:13.385871: Current learning rate: 0.00206 
2024-05-14 02:36:02.456207: train_loss -0.8795 
2024-05-14 02:36:02.456401: val_loss -0.8707 
2024-05-14 02:36:02.456483: Pseudo dice [0.9326] 
2024-05-14 02:36:02.456559: Epoch time: 49.07 s 
2024-05-14 02:36:03.477840:  
2024-05-14 02:36:03.478096: Epoch 828 
2024-05-14 02:36:03.478192: Current learning rate: 0.00205 
2024-05-14 02:36:52.549143: train_loss -0.8767 
2024-05-14 02:36:52.549851: val_loss -0.8786 
2024-05-14 02:36:52.549915: Pseudo dice [0.9369] 
2024-05-14 02:36:52.549968: Epoch time: 49.07 s 
2024-05-14 02:36:53.533575:  
2024-05-14 02:36:53.533698: Epoch 829 
2024-05-14 02:36:53.533795: Current learning rate: 0.00204 
2024-05-14 02:37:42.543998: train_loss -0.8733 
2024-05-14 02:37:42.544184: val_loss -0.8816 
2024-05-14 02:37:42.544244: Pseudo dice [0.9385] 
2024-05-14 02:37:42.544303: Epoch time: 49.01 s 
2024-05-14 02:37:43.566725:  
2024-05-14 02:37:43.566838: Epoch 830 
2024-05-14 02:37:43.566925: Current learning rate: 0.00203 
2024-05-14 02:38:32.664487: train_loss -0.8757 
2024-05-14 02:38:32.664657: val_loss -0.8695 
2024-05-14 02:38:32.664731: Pseudo dice [0.9304] 
2024-05-14 02:38:32.664791: Epoch time: 49.1 s 
2024-05-14 02:38:33.703617:  
2024-05-14 02:38:33.703723: Epoch 831 
2024-05-14 02:38:33.703806: Current learning rate: 0.00202 
2024-05-14 02:39:22.729963: train_loss -0.8739 
2024-05-14 02:39:22.730222: val_loss -0.8837 
2024-05-14 02:39:22.730329: Pseudo dice [0.9384] 
2024-05-14 02:39:22.730408: Epoch time: 49.03 s 
2024-05-14 02:39:23.721759:  
2024-05-14 02:39:23.721882: Epoch 832 
2024-05-14 02:39:23.721971: Current learning rate: 0.00201 
2024-05-14 02:40:12.754472: train_loss -0.8779 
2024-05-14 02:40:12.754821: val_loss -0.8757 
2024-05-14 02:40:12.754914: Pseudo dice [0.9348] 
2024-05-14 02:40:12.755001: Epoch time: 49.03 s 
2024-05-14 02:40:13.759388:  
2024-05-14 02:40:13.759607: Epoch 833 
2024-05-14 02:40:13.759695: Current learning rate: 0.002 
2024-05-14 02:41:02.853018: train_loss -0.8809 
2024-05-14 02:41:02.853188: val_loss -0.8864 
2024-05-14 02:41:02.853268: Pseudo dice [0.9379] 
2024-05-14 02:41:02.853325: Epoch time: 49.09 s 
2024-05-14 02:41:03.866887:  
2024-05-14 02:41:03.866995: Epoch 834 
2024-05-14 02:41:03.867087: Current learning rate: 0.00199 
2024-05-14 02:41:52.865761: train_loss -0.8778 
2024-05-14 02:41:52.865925: val_loss -0.8731 
2024-05-14 02:41:52.865983: Pseudo dice [0.9389] 
2024-05-14 02:41:52.866039: Epoch time: 49.0 s 
2024-05-14 02:41:54.232571:  
2024-05-14 02:41:54.232691: Epoch 835 
2024-05-14 02:41:54.232786: Current learning rate: 0.00198 
2024-05-14 02:42:43.274307: train_loss -0.8817 
2024-05-14 02:42:43.274501: val_loss -0.8878 
2024-05-14 02:42:43.274561: Pseudo dice [0.9384] 
2024-05-14 02:42:43.274618: Epoch time: 49.04 s 
2024-05-14 02:42:44.308942:  
2024-05-14 02:42:44.309147: Epoch 836 
2024-05-14 02:42:44.309234: Current learning rate: 0.00196 
2024-05-14 02:43:33.424932: train_loss -0.8772 
2024-05-14 02:43:33.425223: val_loss -0.8747 
2024-05-14 02:43:33.425287: Pseudo dice [0.9347] 
2024-05-14 02:43:33.425346: Epoch time: 49.12 s 
2024-05-14 02:43:34.424915:  
2024-05-14 02:43:34.425161: Epoch 837 
2024-05-14 02:43:34.425251: Current learning rate: 0.00195 
2024-05-14 02:44:23.440076: train_loss -0.88 
2024-05-14 02:44:23.440360: val_loss -0.886 
2024-05-14 02:44:23.440428: Pseudo dice [0.9403] 
2024-05-14 02:44:23.440489: Epoch time: 49.02 s 
2024-05-14 02:44:24.453899:  
2024-05-14 02:44:24.454142: Epoch 838 
2024-05-14 02:44:24.454234: Current learning rate: 0.00194 
2024-05-14 02:45:13.540714: train_loss -0.8743 
2024-05-14 02:45:13.540877: val_loss -0.875 
2024-05-14 02:45:13.540935: Pseudo dice [0.9341] 
2024-05-14 02:45:13.541593: Epoch time: 49.09 s 
2024-05-14 02:45:14.575934:  
2024-05-14 02:45:14.576051: Epoch 839 
2024-05-14 02:45:14.576180: Current learning rate: 0.00193 
2024-05-14 02:46:03.614611: train_loss -0.8818 
2024-05-14 02:46:03.614805: val_loss -0.8803 
2024-05-14 02:46:03.614881: Pseudo dice [0.9376] 
2024-05-14 02:46:03.614960: Epoch time: 49.04 s 
2024-05-14 02:46:04.608019:  
2024-05-14 02:46:04.608131: Epoch 840 
2024-05-14 02:46:04.608232: Current learning rate: 0.00192 
2024-05-14 02:46:53.855934: train_loss -0.8754 
2024-05-14 02:46:53.856127: val_loss -0.8759 
2024-05-14 02:46:53.856211: Pseudo dice [0.934] 
2024-05-14 02:46:53.856290: Epoch time: 49.25 s 
2024-05-14 02:46:54.839036:  
2024-05-14 02:46:54.839147: Epoch 841 
2024-05-14 02:46:54.839237: Current learning rate: 0.00191 
2024-05-14 02:47:43.886602: train_loss -0.8727 
2024-05-14 02:47:43.886860: val_loss -0.8744 
2024-05-14 02:47:43.886954: Pseudo dice [0.9375] 
2024-05-14 02:47:43.887037: Epoch time: 49.05 s 
2024-05-14 02:47:44.886773:  
2024-05-14 02:47:44.886883: Epoch 842 
2024-05-14 02:47:44.886966: Current learning rate: 0.0019 
2024-05-14 02:48:33.951083: train_loss -0.877 
2024-05-14 02:48:33.951267: val_loss -0.8718 
2024-05-14 02:48:33.951329: Pseudo dice [0.9365] 
2024-05-14 02:48:33.951388: Epoch time: 49.07 s 
2024-05-14 02:48:34.946926:  
2024-05-14 02:48:34.947037: Epoch 843 
2024-05-14 02:48:34.947124: Current learning rate: 0.00189 
2024-05-14 02:49:24.036119: train_loss -0.881 
2024-05-14 02:49:24.036289: val_loss -0.8833 
2024-05-14 02:49:24.036364: Pseudo dice [0.9419] 
2024-05-14 02:49:24.036427: Epoch time: 49.09 s 
2024-05-14 02:49:25.038679:  
2024-05-14 02:49:25.038785: Epoch 844 
2024-05-14 02:49:25.038868: Current learning rate: 0.00188 
2024-05-14 02:50:14.146689: train_loss -0.8764 
2024-05-14 02:50:14.147409: val_loss -0.8778 
2024-05-14 02:50:14.147471: Pseudo dice [0.9377] 
2024-05-14 02:50:14.147524: Epoch time: 49.11 s 
2024-05-14 02:50:15.137928:  
2024-05-14 02:50:15.138216: Epoch 845 
2024-05-14 02:50:15.138371: Current learning rate: 0.00187 
2024-05-14 02:51:04.172890: train_loss -0.8729 
2024-05-14 02:51:04.173090: val_loss -0.8761 
2024-05-14 02:51:04.173178: Pseudo dice [0.9367] 
2024-05-14 02:51:04.173263: Epoch time: 49.04 s 
2024-05-14 02:51:05.685416:  
2024-05-14 02:51:05.685562: Epoch 846 
2024-05-14 02:51:05.685647: Current learning rate: 0.00186 
2024-05-14 02:51:54.671713: train_loss -0.872 
2024-05-14 02:51:54.671972: val_loss -0.8669 
2024-05-14 02:51:54.672037: Pseudo dice [0.9316] 
2024-05-14 02:51:54.672100: Epoch time: 48.99 s 
2024-05-14 02:51:55.667865:  
2024-05-14 02:51:55.667991: Epoch 847 
2024-05-14 02:51:55.668078: Current learning rate: 0.00185 
2024-05-14 02:52:44.712933: train_loss -0.8745 
2024-05-14 02:52:44.713605: val_loss -0.8871 
2024-05-14 02:52:44.713666: Pseudo dice [0.9399] 
2024-05-14 02:52:44.713718: Epoch time: 49.05 s 
2024-05-14 02:52:45.716228:  
2024-05-14 02:52:45.716351: Epoch 848 
2024-05-14 02:52:45.716437: Current learning rate: 0.00184 
2024-05-14 02:53:34.727804: train_loss -0.8782 
2024-05-14 02:53:34.727969: val_loss -0.8775 
2024-05-14 02:53:34.728042: Pseudo dice [0.9354] 
2024-05-14 02:53:34.728099: Epoch time: 49.01 s 
2024-05-14 02:53:35.712801:  
2024-05-14 02:53:35.712933: Epoch 849 
2024-05-14 02:53:35.713020: Current learning rate: 0.00182 
2024-05-14 02:54:24.767452: train_loss -0.8752 
2024-05-14 02:54:24.767640: val_loss -0.8804 
2024-05-14 02:54:24.767700: Pseudo dice [0.9381] 
2024-05-14 02:54:24.767757: Epoch time: 49.06 s 
2024-05-14 02:54:26.121794:  
2024-05-14 02:54:26.121919: Epoch 850 
2024-05-14 02:54:26.122002: Current learning rate: 0.00181 
2024-05-14 02:55:15.134440: train_loss -0.8694 
2024-05-14 02:55:15.135126: val_loss -0.8718 
2024-05-14 02:55:15.135183: Pseudo dice [0.9363] 
2024-05-14 02:55:15.135233: Epoch time: 49.01 s 
2024-05-14 02:55:16.146020:  
2024-05-14 02:55:16.146144: Epoch 851 
2024-05-14 02:55:16.146224: Current learning rate: 0.0018 
2024-05-14 02:56:05.237772: train_loss -0.8714 
2024-05-14 02:56:05.237950: val_loss -0.8756 
2024-05-14 02:56:05.238026: Pseudo dice [0.9322] 
2024-05-14 02:56:05.238085: Epoch time: 49.09 s 
2024-05-14 02:56:06.221487:  
2024-05-14 02:56:06.221607: Epoch 852 
2024-05-14 02:56:06.221705: Current learning rate: 0.00179 
2024-05-14 02:56:55.311147: train_loss -0.8572 
2024-05-14 02:56:55.311355: val_loss -0.8629 
2024-05-14 02:56:55.311418: Pseudo dice [0.9295] 
2024-05-14 02:56:55.311483: Epoch time: 49.09 s 
2024-05-14 02:56:56.305214:  
2024-05-14 02:56:56.305350: Epoch 853 
2024-05-14 02:56:56.305432: Current learning rate: 0.00178 
2024-05-14 02:57:45.345424: train_loss -0.8557 
2024-05-14 02:57:45.345587: val_loss -0.8541 
2024-05-14 02:57:45.345650: Pseudo dice [0.9233] 
2024-05-14 02:57:45.345709: Epoch time: 49.04 s 
2024-05-14 02:57:46.309435:  
2024-05-14 02:57:46.309542: Epoch 854 
2024-05-14 02:57:46.309640: Current learning rate: 0.00177 
2024-05-14 02:58:35.323427: train_loss -0.8664 
2024-05-14 02:58:35.324345: val_loss -0.8756 
2024-05-14 02:58:35.324526: Pseudo dice [0.9354] 
2024-05-14 02:58:35.324685: Epoch time: 49.01 s 
2024-05-14 02:58:36.340016:  
2024-05-14 02:58:36.340131: Epoch 855 
2024-05-14 02:58:36.340232: Current learning rate: 0.00176 
2024-05-14 02:59:25.363161: train_loss -0.8692 
2024-05-14 02:59:25.363339: val_loss -0.8708 
2024-05-14 02:59:25.363412: Pseudo dice [0.9353] 
2024-05-14 02:59:25.363497: Epoch time: 49.02 s 
2024-05-14 02:59:26.707898:  
2024-05-14 02:59:26.708186: Epoch 856 
2024-05-14 02:59:26.708381: Current learning rate: 0.00175 
2024-05-14 03:00:15.710861: train_loss -0.8743 
2024-05-14 03:00:15.711059: val_loss -0.8746 
2024-05-14 03:00:15.711149: Pseudo dice [0.9362] 
2024-05-14 03:00:15.711227: Epoch time: 49.0 s 
2024-05-14 03:00:16.701084:  
2024-05-14 03:00:16.701234: Epoch 857 
2024-05-14 03:00:16.701344: Current learning rate: 0.00174 
2024-05-14 03:01:05.748537: train_loss -0.8778 
2024-05-14 03:01:05.748862: val_loss -0.8813 
2024-05-14 03:01:05.748933: Pseudo dice [0.9393] 
2024-05-14 03:01:05.748992: Epoch time: 49.05 s 
2024-05-14 03:01:06.716448:  
2024-05-14 03:01:06.716594: Epoch 858 
2024-05-14 03:01:06.716676: Current learning rate: 0.00173 
2024-05-14 03:01:55.757970: train_loss -0.8732 
2024-05-14 03:01:55.758141: val_loss -0.8746 
2024-05-14 03:01:55.758200: Pseudo dice [0.9365] 
2024-05-14 03:01:55.758257: Epoch time: 49.04 s 
2024-05-14 03:01:56.759577:  
2024-05-14 03:01:56.759695: Epoch 859 
2024-05-14 03:01:56.759781: Current learning rate: 0.00172 
2024-05-14 03:02:45.833103: train_loss -0.871 
2024-05-14 03:02:45.833311: val_loss -0.8769 
2024-05-14 03:02:45.833400: Pseudo dice [0.9338] 
2024-05-14 03:02:45.833467: Epoch time: 49.07 s 
2024-05-14 03:02:46.823043:  
2024-05-14 03:02:46.823156: Epoch 860 
2024-05-14 03:02:46.823241: Current learning rate: 0.0017 
2024-05-14 03:03:35.902771: train_loss -0.8726 
2024-05-14 03:03:35.903448: val_loss -0.8625 
2024-05-14 03:03:35.903507: Pseudo dice [0.9308] 
2024-05-14 03:03:35.903559: Epoch time: 49.08 s 
2024-05-14 03:03:36.876031:  
2024-05-14 03:03:36.876166: Epoch 861 
2024-05-14 03:03:36.876271: Current learning rate: 0.00169 
2024-05-14 03:04:25.919856: train_loss -0.8675 
2024-05-14 03:04:25.920042: val_loss -0.8888 
2024-05-14 03:04:25.920100: Pseudo dice [0.9405] 
2024-05-14 03:04:25.920157: Epoch time: 49.04 s 
2024-05-14 03:04:26.896640:  
2024-05-14 03:04:26.896748: Epoch 862 
2024-05-14 03:04:26.896842: Current learning rate: 0.00168 
2024-05-14 03:05:15.962211: train_loss -0.8723 
2024-05-14 03:05:15.962409: val_loss -0.8721 
2024-05-14 03:05:15.962471: Pseudo dice [0.9339] 
2024-05-14 03:05:15.962529: Epoch time: 49.07 s 
2024-05-14 03:05:16.983301:  
2024-05-14 03:05:16.983420: Epoch 863 
2024-05-14 03:05:16.983507: Current learning rate: 0.00167 
2024-05-14 03:06:05.978951: train_loss -0.8774 
2024-05-14 03:06:05.979782: val_loss -0.8854 
2024-05-14 03:06:05.979859: Pseudo dice [0.9372] 
2024-05-14 03:06:05.979926: Epoch time: 49.0 s 
2024-05-14 03:06:06.952462:  
2024-05-14 03:06:06.952567: Epoch 864 
2024-05-14 03:06:06.952796: Current learning rate: 0.00166 
2024-05-14 03:06:55.928348: train_loss -0.8735 
2024-05-14 03:06:55.928517: val_loss -0.88 
2024-05-14 03:06:55.928578: Pseudo dice [0.9378] 
2024-05-14 03:06:55.928635: Epoch time: 48.98 s 
2024-05-14 03:06:56.890736:  
2024-05-14 03:06:56.890857: Epoch 865 
2024-05-14 03:06:56.890939: Current learning rate: 0.00165 
2024-05-14 03:07:45.901353: train_loss -0.8734 
2024-05-14 03:07:45.901547: val_loss -0.8712 
2024-05-14 03:07:45.901611: Pseudo dice [0.9317] 
2024-05-14 03:07:45.901668: Epoch time: 49.01 s 
2024-05-14 03:07:46.866613:  
2024-05-14 03:07:46.866715: Epoch 866 
2024-05-14 03:07:46.866799: Current learning rate: 0.00164 
2024-05-14 03:08:35.888483: train_loss -0.8686 
2024-05-14 03:08:35.888768: val_loss -0.8842 
2024-05-14 03:08:35.888837: Pseudo dice [0.938] 
2024-05-14 03:08:35.888896: Epoch time: 49.02 s 
2024-05-14 03:08:36.855195:  
2024-05-14 03:08:36.855302: Epoch 867 
2024-05-14 03:08:36.855386: Current learning rate: 0.00163 
2024-05-14 03:09:25.870196: train_loss -0.8755 
2024-05-14 03:09:25.870401: val_loss -0.885 
2024-05-14 03:09:25.870466: Pseudo dice [0.9394] 
2024-05-14 03:09:25.870525: Epoch time: 49.02 s 
2024-05-14 03:09:27.360012:  
2024-05-14 03:09:27.360142: Epoch 868 
2024-05-14 03:09:27.360252: Current learning rate: 0.00162 
2024-05-14 03:10:16.397426: train_loss -0.8798 
2024-05-14 03:10:16.397614: val_loss -0.8687 
2024-05-14 03:10:16.397679: Pseudo dice [0.9342] 
2024-05-14 03:10:16.397739: Epoch time: 49.04 s 
2024-05-14 03:10:17.367837:  
2024-05-14 03:10:17.367959: Epoch 869 
2024-05-14 03:10:17.368046: Current learning rate: 0.00161 
2024-05-14 03:11:06.345299: train_loss -0.8775 
2024-05-14 03:11:06.345976: val_loss -0.886 
2024-05-14 03:11:06.346044: Pseudo dice [0.9357] 
2024-05-14 03:11:06.346104: Epoch time: 48.98 s 
2024-05-14 03:11:07.363166:  
2024-05-14 03:11:07.363287: Epoch 870 
2024-05-14 03:11:07.363372: Current learning rate: 0.00159 
2024-05-14 03:11:56.343894: train_loss -0.8742 
2024-05-14 03:11:56.344068: val_loss -0.878 
2024-05-14 03:11:56.344128: Pseudo dice [0.9367] 
2024-05-14 03:11:56.344203: Epoch time: 48.98 s 
2024-05-14 03:11:57.320208:  
2024-05-14 03:11:57.320499: Epoch 871 
2024-05-14 03:11:57.320588: Current learning rate: 0.00158 
2024-05-14 03:12:46.337937: train_loss -0.8793 
2024-05-14 03:12:46.338125: val_loss -0.8858 
2024-05-14 03:12:46.338184: Pseudo dice [0.9396] 
2024-05-14 03:12:46.338241: Epoch time: 49.02 s 
2024-05-14 03:12:47.332493:  
2024-05-14 03:12:47.332611: Epoch 872 
2024-05-14 03:12:47.332717: Current learning rate: 0.00157 
2024-05-14 03:13:36.329148: train_loss -0.8871 
2024-05-14 03:13:36.329416: val_loss -0.8905 
2024-05-14 03:13:36.329479: Pseudo dice [0.9407] 
2024-05-14 03:13:36.329529: Epoch time: 49.0 s 
2024-05-14 03:13:37.327126:  
2024-05-14 03:13:37.327377: Epoch 873 
2024-05-14 03:13:37.327464: Current learning rate: 0.00156 
2024-05-14 03:14:26.429148: train_loss -0.8795 
2024-05-14 03:14:26.429335: val_loss -0.8828 
2024-05-14 03:14:26.429410: Pseudo dice [0.9393] 
2024-05-14 03:14:26.429468: Epoch time: 49.1 s 
2024-05-14 03:14:27.408039:  
2024-05-14 03:14:27.408152: Epoch 874 
2024-05-14 03:14:27.408233: Current learning rate: 0.00155 
2024-05-14 03:15:16.409249: train_loss -0.8777 
2024-05-14 03:15:16.409426: val_loss -0.8752 
2024-05-14 03:15:16.409486: Pseudo dice [0.9369] 
2024-05-14 03:15:16.409544: Epoch time: 49.0 s 
2024-05-14 03:15:17.376363:  
2024-05-14 03:15:17.376491: Epoch 875 
2024-05-14 03:15:17.376591: Current learning rate: 0.00154 
2024-05-14 03:16:06.383569: train_loss -0.8799 
2024-05-14 03:16:06.384267: val_loss -0.887 
2024-05-14 03:16:06.384324: Pseudo dice [0.938] 
2024-05-14 03:16:06.384377: Epoch time: 49.01 s 
2024-05-14 03:16:07.354386:  
2024-05-14 03:16:07.354496: Epoch 876 
2024-05-14 03:16:07.354582: Current learning rate: 0.00153 
2024-05-14 03:16:56.377876: train_loss -0.8767 
2024-05-14 03:16:56.378045: val_loss -0.885 
2024-05-14 03:16:56.378102: Pseudo dice [0.941] 
2024-05-14 03:16:56.378164: Epoch time: 49.02 s 
2024-05-14 03:16:56.378838: Yayy! New best EMA pseudo Dice: 0.9374 
2024-05-14 03:16:57.730642:  
2024-05-14 03:16:57.730745: Epoch 877 
2024-05-14 03:16:57.730827: Current learning rate: 0.00152 
2024-05-14 03:17:46.735892: train_loss -0.8807 
2024-05-14 03:17:46.736056: val_loss -0.8768 
2024-05-14 03:17:46.736116: Pseudo dice [0.9358] 
2024-05-14 03:17:46.736174: Epoch time: 49.01 s 
2024-05-14 03:17:47.708467:  
2024-05-14 03:17:47.708572: Epoch 878 
2024-05-14 03:17:47.708656: Current learning rate: 0.00151 
2024-05-14 03:18:36.789044: train_loss -0.8844 
2024-05-14 03:18:36.789212: val_loss -0.878 
2024-05-14 03:18:36.789273: Pseudo dice [0.9441] 
2024-05-14 03:18:36.789330: Epoch time: 49.08 s 
2024-05-14 03:18:36.789376: Yayy! New best EMA pseudo Dice: 0.9379 
2024-05-14 03:18:38.577221:  
2024-05-14 03:18:38.577458: Epoch 879 
2024-05-14 03:18:38.577544: Current learning rate: 0.00149 
2024-05-14 03:19:27.610884: train_loss -0.8854 
2024-05-14 03:19:27.611650: val_loss -0.8782 
2024-05-14 03:19:27.611719: Pseudo dice [0.9363] 
2024-05-14 03:19:27.611777: Epoch time: 49.03 s 
2024-05-14 03:19:28.587779:  
2024-05-14 03:19:28.587911: Epoch 880 
2024-05-14 03:19:28.587994: Current learning rate: 0.00148 
2024-05-14 03:20:17.732395: train_loss -0.8814 
2024-05-14 03:20:17.732569: val_loss -0.869 
2024-05-14 03:20:17.732627: Pseudo dice [0.9392] 
2024-05-14 03:20:17.732701: Epoch time: 49.15 s 
2024-05-14 03:20:18.722495:  
2024-05-14 03:20:18.722613: Epoch 881 
2024-05-14 03:20:18.722697: Current learning rate: 0.00147 
2024-05-14 03:21:07.828160: train_loss -0.8852 
2024-05-14 03:21:07.828343: val_loss -0.8816 
2024-05-14 03:21:07.828418: Pseudo dice [0.9395] 
2024-05-14 03:21:07.828477: Epoch time: 49.11 s 
2024-05-14 03:21:07.828522: Yayy! New best EMA pseudo Dice: 0.9381 
2024-05-14 03:21:09.165776:  
2024-05-14 03:21:09.165900: Epoch 882 
2024-05-14 03:21:09.166000: Current learning rate: 0.00146 
2024-05-14 03:21:58.157677: train_loss -0.8819 
2024-05-14 03:21:58.157933: val_loss -0.8856 
2024-05-14 03:21:58.158016: Pseudo dice [0.9383] 
2024-05-14 03:21:58.158080: Epoch time: 48.99 s 
2024-05-14 03:21:58.158129: Yayy! New best EMA pseudo Dice: 0.9381 
2024-05-14 03:21:59.477682:  
2024-05-14 03:21:59.477875: Epoch 883 
2024-05-14 03:21:59.477965: Current learning rate: 0.00145 
2024-05-14 03:22:48.499540: train_loss -0.8786 
2024-05-14 03:22:48.499756: val_loss -0.8845 
2024-05-14 03:22:48.499822: Pseudo dice [0.94] 
2024-05-14 03:22:48.499881: Epoch time: 49.02 s 
2024-05-14 03:22:48.499927: Yayy! New best EMA pseudo Dice: 0.9383 
2024-05-14 03:22:49.824056:  
2024-05-14 03:22:49.824166: Epoch 884 
2024-05-14 03:22:49.824250: Current learning rate: 0.00144 
2024-05-14 03:23:38.852783: train_loss -0.88 
2024-05-14 03:23:38.852970: val_loss -0.8703 
2024-05-14 03:23:38.853040: Pseudo dice [0.9321] 
2024-05-14 03:23:38.853121: Epoch time: 49.03 s 
2024-05-14 03:23:39.853942:  
2024-05-14 03:23:39.854062: Epoch 885 
2024-05-14 03:23:39.854154: Current learning rate: 0.00143 
2024-05-14 03:24:28.881255: train_loss -0.8813 
2024-05-14 03:24:28.881511: val_loss -0.8696 
2024-05-14 03:24:28.881582: Pseudo dice [0.9331] 
2024-05-14 03:24:28.881642: Epoch time: 49.03 s 
2024-05-14 03:24:29.923664:  
2024-05-14 03:24:29.923776: Epoch 886 
2024-05-14 03:24:29.923875: Current learning rate: 0.00142 
2024-05-14 03:25:19.001945: train_loss -0.8773 
2024-05-14 03:25:19.002116: val_loss -0.8775 
2024-05-14 03:25:19.002172: Pseudo dice [0.9362] 
2024-05-14 03:25:19.002245: Epoch time: 49.08 s 
2024-05-14 03:25:19.973992:  
2024-05-14 03:25:19.974096: Epoch 887 
2024-05-14 03:25:19.974193: Current learning rate: 0.00141 
2024-05-14 03:26:09.004238: train_loss -0.8797 
2024-05-14 03:26:09.004440: val_loss -0.8759 
2024-05-14 03:26:09.004527: Pseudo dice [0.9362] 
2024-05-14 03:26:09.004608: Epoch time: 49.03 s 
2024-05-14 03:26:10.008919:  
2024-05-14 03:26:10.009149: Epoch 888 
2024-05-14 03:26:10.009233: Current learning rate: 0.00139 
2024-05-14 03:26:59.121452: train_loss -0.88 
2024-05-14 03:26:59.121720: val_loss -0.8814 
2024-05-14 03:26:59.121894: Pseudo dice [0.9375] 
2024-05-14 03:26:59.121969: Epoch time: 49.11 s 
2024-05-14 03:27:00.600794:  
2024-05-14 03:27:00.600923: Epoch 889 
2024-05-14 03:27:00.601036: Current learning rate: 0.00138 
2024-05-14 03:27:49.670141: train_loss -0.8803 
2024-05-14 03:27:49.670364: val_loss -0.8937 
2024-05-14 03:27:49.670439: Pseudo dice [0.9459] 
2024-05-14 03:27:49.670506: Epoch time: 49.07 s 
2024-05-14 03:27:50.647156:  
2024-05-14 03:27:50.647285: Epoch 890 
2024-05-14 03:27:50.647373: Current learning rate: 0.00137 
2024-05-14 03:28:39.753709: train_loss -0.8748 
2024-05-14 03:28:39.753891: val_loss -0.8891 
2024-05-14 03:28:39.753965: Pseudo dice [0.9426] 
2024-05-14 03:28:39.754038: Epoch time: 49.11 s 
2024-05-14 03:28:39.754097: Yayy! New best EMA pseudo Dice: 0.9384 
2024-05-14 03:28:41.073965:  
2024-05-14 03:28:41.074085: Epoch 891 
2024-05-14 03:28:41.074198: Current learning rate: 0.00136 
2024-05-14 03:29:30.118163: train_loss -0.8784 
2024-05-14 03:29:30.118935: val_loss -0.8845 
2024-05-14 03:29:30.119034: Pseudo dice [0.9394] 
2024-05-14 03:29:30.119112: Epoch time: 49.04 s 
2024-05-14 03:29:30.119184: Yayy! New best EMA pseudo Dice: 0.9385 
2024-05-14 03:29:31.442255:  
2024-05-14 03:29:31.442390: Epoch 892 
2024-05-14 03:29:31.442475: Current learning rate: 0.00135 
2024-05-14 03:30:20.433876: train_loss -0.8843 
2024-05-14 03:30:20.434041: val_loss -0.8844 
2024-05-14 03:30:20.434099: Pseudo dice [0.9403] 
2024-05-14 03:30:20.434157: Epoch time: 48.99 s 
2024-05-14 03:30:20.434200: Yayy! New best EMA pseudo Dice: 0.9387 
2024-05-14 03:30:21.766788:  
2024-05-14 03:30:21.766919: Epoch 893 
2024-05-14 03:30:21.767003: Current learning rate: 0.00134 
2024-05-14 03:31:10.757066: train_loss -0.8833 
2024-05-14 03:31:10.757286: val_loss -0.8853 
2024-05-14 03:31:10.757380: Pseudo dice [0.9426] 
2024-05-14 03:31:10.757474: Epoch time: 48.99 s 
2024-05-14 03:31:10.757551: Yayy! New best EMA pseudo Dice: 0.9391 
2024-05-14 03:31:12.112545:  
2024-05-14 03:31:12.112774: Epoch 894 
2024-05-14 03:31:12.112864: Current learning rate: 0.00133 
2024-05-14 03:32:01.159196: train_loss -0.8784 
2024-05-14 03:32:01.159489: val_loss -0.875 
2024-05-14 03:32:01.159549: Pseudo dice [0.9359] 
2024-05-14 03:32:01.159600: Epoch time: 49.05 s 
2024-05-14 03:32:02.133434:  
2024-05-14 03:32:02.133561: Epoch 895 
2024-05-14 03:32:02.133663: Current learning rate: 0.00132 
2024-05-14 03:32:51.177489: train_loss -0.8798 
2024-05-14 03:32:51.177700: val_loss -0.8679 
2024-05-14 03:32:51.177793: Pseudo dice [0.9319] 
2024-05-14 03:32:51.177872: Epoch time: 49.04 s 
2024-05-14 03:32:52.159690:  
2024-05-14 03:32:52.159800: Epoch 896 
2024-05-14 03:32:52.159912: Current learning rate: 0.0013 
2024-05-14 03:33:41.241491: train_loss -0.8795 
2024-05-14 03:33:41.241668: val_loss -0.88 
2024-05-14 03:33:41.241727: Pseudo dice [0.9359] 
2024-05-14 03:33:41.241784: Epoch time: 49.08 s 
2024-05-14 03:33:42.234263:  
2024-05-14 03:33:42.234392: Epoch 897 
2024-05-14 03:33:42.234483: Current learning rate: 0.00129 
2024-05-14 03:34:31.332962: train_loss -0.8771 
2024-05-14 03:34:31.333268: val_loss -0.8813 
2024-05-14 03:34:31.333342: Pseudo dice [0.9382] 
2024-05-14 03:34:31.333410: Epoch time: 49.1 s 
2024-05-14 03:34:32.312861:  
2024-05-14 03:34:32.312979: Epoch 898 
2024-05-14 03:34:32.313062: Current learning rate: 0.00128 
2024-05-14 03:35:21.351847: train_loss -0.8764 
2024-05-14 03:35:21.352090: val_loss -0.8922 
2024-05-14 03:35:21.352156: Pseudo dice [0.943] 
2024-05-14 03:35:21.352218: Epoch time: 49.04 s 
2024-05-14 03:35:22.326986:  
2024-05-14 03:35:22.327094: Epoch 899 
2024-05-14 03:35:22.327179: Current learning rate: 0.00127 
2024-05-14 03:36:11.367216: train_loss -0.882 
2024-05-14 03:36:11.367387: val_loss -0.8816 
2024-05-14 03:36:11.367458: Pseudo dice [0.9371] 
2024-05-14 03:36:11.367543: Epoch time: 49.04 s 
2024-05-14 03:36:13.072107:  
2024-05-14 03:36:13.072234: Epoch 900 
2024-05-14 03:36:13.072344: Current learning rate: 0.00126 
2024-05-14 03:37:02.202449: train_loss -0.8777 
2024-05-14 03:37:02.203206: val_loss -0.8773 
2024-05-14 03:37:02.203270: Pseudo dice [0.9392] 
2024-05-14 03:37:02.203320: Epoch time: 49.13 s 
2024-05-14 03:37:03.226402:  
2024-05-14 03:37:03.226533: Epoch 901 
2024-05-14 03:37:03.226644: Current learning rate: 0.00125 
2024-05-14 03:37:52.257370: train_loss -0.8812 
2024-05-14 03:37:52.257538: val_loss -0.8882 
2024-05-14 03:37:52.257599: Pseudo dice [0.9435] 
2024-05-14 03:37:52.257656: Epoch time: 49.03 s 
2024-05-14 03:37:53.229970:  
2024-05-14 03:37:53.230097: Epoch 902 
2024-05-14 03:37:53.230197: Current learning rate: 0.00124 
2024-05-14 03:38:42.330625: train_loss -0.8835 
2024-05-14 03:38:42.330803: val_loss -0.8843 
2024-05-14 03:38:42.330863: Pseudo dice [0.938] 
2024-05-14 03:38:42.330923: Epoch time: 49.1 s 
2024-05-14 03:38:43.351585:  
2024-05-14 03:38:43.351716: Epoch 903 
2024-05-14 03:38:43.351799: Current learning rate: 0.00122 
2024-05-14 03:39:32.372995: train_loss -0.8798 
2024-05-14 03:39:32.373713: val_loss -0.8643 
2024-05-14 03:39:32.373785: Pseudo dice [0.9374] 
2024-05-14 03:39:32.373836: Epoch time: 49.02 s 
2024-05-14 03:39:33.379275:  
2024-05-14 03:39:33.379394: Epoch 904 
2024-05-14 03:39:33.379501: Current learning rate: 0.00121 
2024-05-14 03:40:22.426450: train_loss -0.8776 
2024-05-14 03:40:22.426623: val_loss -0.8872 
2024-05-14 03:40:22.426686: Pseudo dice [0.9434] 
2024-05-14 03:40:22.426746: Epoch time: 49.05 s 
2024-05-14 03:40:22.426793: Yayy! New best EMA pseudo Dice: 0.9391 
2024-05-14 03:40:23.748081:  
2024-05-14 03:40:23.748312: Epoch 905 
2024-05-14 03:40:23.748401: Current learning rate: 0.0012 
2024-05-14 03:41:12.740719: train_loss -0.8837 
2024-05-14 03:41:12.740911: val_loss -0.8913 
2024-05-14 03:41:12.741002: Pseudo dice [0.9405] 
2024-05-14 03:41:12.741099: Epoch time: 48.99 s 
2024-05-14 03:41:12.741173: Yayy! New best EMA pseudo Dice: 0.9393 
2024-05-14 03:41:14.093846:  
2024-05-14 03:41:14.093959: Epoch 906 
2024-05-14 03:41:14.094039: Current learning rate: 0.00119 
2024-05-14 03:42:03.116817: train_loss -0.8778 
2024-05-14 03:42:03.117537: val_loss -0.8859 
2024-05-14 03:42:03.117606: Pseudo dice [0.9379] 
2024-05-14 03:42:03.117665: Epoch time: 49.02 s 
2024-05-14 03:42:04.129490:  
2024-05-14 03:42:04.129605: Epoch 907 
2024-05-14 03:42:04.129689: Current learning rate: 0.00118 
2024-05-14 03:42:53.130164: train_loss -0.8828 
2024-05-14 03:42:53.130353: val_loss -0.8847 
2024-05-14 03:42:53.130416: Pseudo dice [0.9382] 
2024-05-14 03:42:53.130474: Epoch time: 49.0 s 
2024-05-14 03:42:54.132234:  
2024-05-14 03:42:54.132353: Epoch 908 
2024-05-14 03:42:54.132443: Current learning rate: 0.00117 
2024-05-14 03:43:43.145023: train_loss -0.8807 
2024-05-14 03:43:43.145209: val_loss -0.8777 
2024-05-14 03:43:43.145290: Pseudo dice [0.9395] 
2024-05-14 03:43:43.145366: Epoch time: 49.01 s 
2024-05-14 03:43:44.119141:  
2024-05-14 03:43:44.119249: Epoch 909 
2024-05-14 03:43:44.119331: Current learning rate: 0.00116 
2024-05-14 03:44:33.168179: train_loss -0.8793 
2024-05-14 03:44:33.168455: val_loss -0.89 
2024-05-14 03:44:33.168531: Pseudo dice [0.9384] 
2024-05-14 03:44:33.168593: Epoch time: 49.05 s 
2024-05-14 03:44:34.611863:  
2024-05-14 03:44:34.612011: Epoch 910 
2024-05-14 03:44:34.612093: Current learning rate: 0.00115 
2024-05-14 03:45:23.755140: train_loss -0.8818 
2024-05-14 03:45:23.755313: val_loss -0.8823 
2024-05-14 03:45:23.755373: Pseudo dice [0.9387] 
2024-05-14 03:45:23.755431: Epoch time: 49.14 s 
2024-05-14 03:45:24.761734:  
2024-05-14 03:45:24.761875: Epoch 911 
2024-05-14 03:45:24.761987: Current learning rate: 0.00113 
2024-05-14 03:46:13.774427: train_loss -0.88 
2024-05-14 03:46:13.774597: val_loss -0.8806 
2024-05-14 03:46:13.774659: Pseudo dice [0.9375] 
2024-05-14 03:46:13.774718: Epoch time: 49.01 s 
2024-05-14 03:46:14.751976:  
2024-05-14 03:46:14.752112: Epoch 912 
2024-05-14 03:46:14.752213: Current learning rate: 0.00112 
2024-05-14 03:47:03.824644: train_loss -0.8825 
2024-05-14 03:47:03.825375: val_loss -0.8858 
2024-05-14 03:47:03.825483: Pseudo dice [0.9429] 
2024-05-14 03:47:03.825581: Epoch time: 49.07 s 
2024-05-14 03:47:04.817760:  
2024-05-14 03:47:04.817875: Epoch 913 
2024-05-14 03:47:04.817961: Current learning rate: 0.00111 
2024-05-14 03:47:53.854469: train_loss -0.8843 
2024-05-14 03:47:53.854644: val_loss -0.8722 
2024-05-14 03:47:53.854732: Pseudo dice [0.9389] 
2024-05-14 03:47:53.854814: Epoch time: 49.04 s 
2024-05-14 03:47:54.890774:  
2024-05-14 03:47:54.890888: Epoch 914 
2024-05-14 03:47:54.890972: Current learning rate: 0.0011 
2024-05-14 03:48:43.934793: train_loss -0.8834 
2024-05-14 03:48:43.934977: val_loss -0.8894 
2024-05-14 03:48:43.935039: Pseudo dice [0.9427] 
2024-05-14 03:48:43.935096: Epoch time: 49.04 s 
2024-05-14 03:48:43.935142: Yayy! New best EMA pseudo Dice: 0.9396 
2024-05-14 03:48:45.279209:  
2024-05-14 03:48:45.279319: Epoch 915 
2024-05-14 03:48:45.279402: Current learning rate: 0.00109 
2024-05-14 03:49:34.353595: train_loss -0.8814 
2024-05-14 03:49:34.353769: val_loss -0.8745 
2024-05-14 03:49:34.353845: Pseudo dice [0.9403] 
2024-05-14 03:49:34.353903: Epoch time: 49.08 s 
2024-05-14 03:49:34.353948: Yayy! New best EMA pseudo Dice: 0.9396 
2024-05-14 03:49:35.702190:  
2024-05-14 03:49:35.702440: Epoch 916 
2024-05-14 03:49:35.702525: Current learning rate: 0.00108 
2024-05-14 03:50:24.811264: train_loss -0.8851 
2024-05-14 03:50:24.811445: val_loss -0.8781 
2024-05-14 03:50:24.811505: Pseudo dice [0.9369] 
2024-05-14 03:50:24.811574: Epoch time: 49.11 s 
2024-05-14 03:50:25.781304:  
2024-05-14 03:50:25.781415: Epoch 917 
2024-05-14 03:50:25.781495: Current learning rate: 0.00106 
2024-05-14 03:51:14.826257: train_loss -0.8849 
2024-05-14 03:51:14.827012: val_loss -0.8877 
2024-05-14 03:51:14.827078: Pseudo dice [0.9441] 
2024-05-14 03:51:14.827137: Epoch time: 49.05 s 
2024-05-14 03:51:14.827181: Yayy! New best EMA pseudo Dice: 0.9398 
2024-05-14 03:51:16.151427:  
2024-05-14 03:51:16.151534: Epoch 918 
2024-05-14 03:51:16.151616: Current learning rate: 0.00105 
2024-05-14 03:52:05.214823: train_loss -0.8859 
2024-05-14 03:52:05.215003: val_loss -0.8822 
2024-05-14 03:52:05.215062: Pseudo dice [0.9388] 
2024-05-14 03:52:05.215120: Epoch time: 49.06 s 
2024-05-14 03:52:06.211761:  
2024-05-14 03:52:06.211879: Epoch 919 
2024-05-14 03:52:06.211992: Current learning rate: 0.00104 
2024-05-14 03:52:55.274615: train_loss -0.881 
2024-05-14 03:52:55.274796: val_loss -0.8766 
2024-05-14 03:52:55.274856: Pseudo dice [0.9391] 
2024-05-14 03:52:55.274913: Epoch time: 49.06 s 
2024-05-14 03:52:56.333448:  
2024-05-14 03:52:56.333584: Epoch 920 
2024-05-14 03:52:56.333668: Current learning rate: 0.00103 
2024-05-14 03:53:45.412960: train_loss -0.8813 
2024-05-14 03:53:45.413290: val_loss -0.8765 
2024-05-14 03:53:45.413381: Pseudo dice [0.9365] 
2024-05-14 03:53:45.413456: Epoch time: 49.08 s 
2024-05-14 03:53:46.782770:  
2024-05-14 03:53:46.782906: Epoch 921 
2024-05-14 03:53:46.782989: Current learning rate: 0.00102 
2024-05-14 03:54:35.819932: train_loss -0.8788 
2024-05-14 03:54:35.820139: val_loss -0.8874 
2024-05-14 03:54:35.820237: Pseudo dice [0.9401] 
2024-05-14 03:54:35.820318: Epoch time: 49.04 s 
2024-05-14 03:54:36.796464:  
2024-05-14 03:54:36.796581: Epoch 922 
2024-05-14 03:54:36.796679: Current learning rate: 0.00101 
2024-05-14 03:55:25.802412: train_loss -0.884 
2024-05-14 03:55:25.802597: val_loss -0.8765 
2024-05-14 03:55:25.802657: Pseudo dice [0.9358] 
2024-05-14 03:55:25.802721: Epoch time: 49.01 s 
2024-05-14 03:55:26.795066:  
2024-05-14 03:55:26.795190: Epoch 923 
2024-05-14 03:55:26.795275: Current learning rate: 0.001 
2024-05-14 03:56:15.852557: train_loss -0.8808 
2024-05-14 03:56:15.852862: val_loss -0.8827 
2024-05-14 03:56:15.852943: Pseudo dice [0.9407] 
2024-05-14 03:56:15.853005: Epoch time: 49.06 s 
2024-05-14 03:56:16.824525:  
2024-05-14 03:56:16.824652: Epoch 924 
2024-05-14 03:56:16.824734: Current learning rate: 0.00098 
2024-05-14 03:57:05.906431: train_loss -0.8847 
2024-05-14 03:57:05.906601: val_loss -0.8739 
2024-05-14 03:57:05.906664: Pseudo dice [0.9359] 
2024-05-14 03:57:05.906723: Epoch time: 49.08 s 
2024-05-14 03:57:06.880192:  
2024-05-14 03:57:06.880320: Epoch 925 
2024-05-14 03:57:06.880420: Current learning rate: 0.00097 
2024-05-14 03:57:55.949926: train_loss -0.8828 
2024-05-14 03:57:55.950112: val_loss -0.8814 
2024-05-14 03:57:55.950188: Pseudo dice [0.9393] 
2024-05-14 03:57:55.950249: Epoch time: 49.07 s 
2024-05-14 03:57:56.932641:  
2024-05-14 03:57:56.932765: Epoch 926 
2024-05-14 03:57:56.932864: Current learning rate: 0.00096 
2024-05-14 03:58:45.945646: train_loss -0.8868 
2024-05-14 03:58:45.945823: val_loss -0.8819 
2024-05-14 03:58:45.945881: Pseudo dice [0.9389] 
2024-05-14 03:58:45.945937: Epoch time: 49.01 s 
2024-05-14 03:58:46.983857:  
2024-05-14 03:58:46.983973: Epoch 927 
2024-05-14 03:58:46.984061: Current learning rate: 0.00095 
2024-05-14 03:59:36.063441: train_loss -0.8829 
2024-05-14 03:59:36.064172: val_loss -0.8799 
2024-05-14 03:59:36.064237: Pseudo dice [0.934] 
2024-05-14 03:59:36.064290: Epoch time: 49.08 s 
2024-05-14 03:59:37.078011:  
2024-05-14 03:59:37.078122: Epoch 928 
2024-05-14 03:59:37.078220: Current learning rate: 0.00094 
2024-05-14 04:00:26.142612: train_loss -0.8803 
2024-05-14 04:00:26.142774: val_loss -0.8732 
2024-05-14 04:00:26.142836: Pseudo dice [0.9326] 
2024-05-14 04:00:26.142894: Epoch time: 49.07 s 
2024-05-14 04:00:27.107212:  
2024-05-14 04:00:27.107321: Epoch 929 
2024-05-14 04:00:27.107405: Current learning rate: 0.00092 
2024-05-14 04:01:16.247450: train_loss -0.8879 
2024-05-14 04:01:16.247625: val_loss -0.9012 
2024-05-14 04:01:16.247684: Pseudo dice [0.9477] 
2024-05-14 04:01:16.247739: Epoch time: 49.14 s 
2024-05-14 04:01:17.214987:  
2024-05-14 04:01:17.215209: Epoch 930 
2024-05-14 04:01:17.215296: Current learning rate: 0.00091 
2024-05-14 04:02:06.276272: train_loss -0.8868 
2024-05-14 04:02:06.276977: val_loss -0.8824 
2024-05-14 04:02:06.277190: Pseudo dice [0.9394] 
2024-05-14 04:02:06.277281: Epoch time: 49.06 s 
2024-05-14 04:02:07.268050:  
2024-05-14 04:02:07.268179: Epoch 931 
2024-05-14 04:02:07.268260: Current learning rate: 0.0009 
2024-05-14 04:02:56.277604: train_loss -0.8819 
2024-05-14 04:02:56.277763: val_loss -0.8854 
2024-05-14 04:02:56.277998: Pseudo dice [0.9391] 
2024-05-14 04:02:56.278088: Epoch time: 49.01 s 
2024-05-14 04:02:57.744361:  
2024-05-14 04:02:57.744509: Epoch 932 
2024-05-14 04:02:57.744607: Current learning rate: 0.00089 
2024-05-14 04:03:46.822936: train_loss -0.8831 
2024-05-14 04:03:46.823124: val_loss -0.8787 
2024-05-14 04:03:46.823185: Pseudo dice [0.9387] 
2024-05-14 04:03:46.823245: Epoch time: 49.08 s 
2024-05-14 04:03:47.796199:  
2024-05-14 04:03:47.796325: Epoch 933 
2024-05-14 04:03:47.796437: Current learning rate: 0.00088 
2024-05-14 04:04:36.909594: train_loss -0.8876 
2024-05-14 04:04:36.910269: val_loss -0.8733 
2024-05-14 04:04:36.910342: Pseudo dice [0.9347] 
2024-05-14 04:04:36.910398: Epoch time: 49.11 s 
2024-05-14 04:04:37.887031:  
2024-05-14 04:04:37.887159: Epoch 934 
2024-05-14 04:04:37.887247: Current learning rate: 0.00087 
2024-05-14 04:05:26.922426: train_loss -0.8816 
2024-05-14 04:05:26.922637: val_loss -0.8877 
2024-05-14 04:05:26.922735: Pseudo dice [0.9428] 
2024-05-14 04:05:26.922826: Epoch time: 49.04 s 
2024-05-14 04:05:27.934287:  
2024-05-14 04:05:27.934428: Epoch 935 
2024-05-14 04:05:27.934513: Current learning rate: 0.00085 
2024-05-14 04:06:17.027986: train_loss -0.8812 
2024-05-14 04:06:17.028157: val_loss -0.882 
2024-05-14 04:06:17.028214: Pseudo dice [0.9421] 
2024-05-14 04:06:17.028271: Epoch time: 49.09 s 
2024-05-14 04:06:18.044474:  
2024-05-14 04:06:18.044592: Epoch 936 
2024-05-14 04:06:18.044679: Current learning rate: 0.00084 
2024-05-14 04:07:07.099107: train_loss -0.8822 
2024-05-14 04:07:07.099408: val_loss -0.8896 
2024-05-14 04:07:07.099474: Pseudo dice [0.9406] 
2024-05-14 04:07:07.099530: Epoch time: 49.06 s 
2024-05-14 04:07:08.103747:  
2024-05-14 04:07:08.103866: Epoch 937 
2024-05-14 04:07:08.103953: Current learning rate: 0.00083 
2024-05-14 04:07:57.172470: train_loss -0.8821 
2024-05-14 04:07:57.172662: val_loss -0.8851 
2024-05-14 04:07:57.172728: Pseudo dice [0.9394] 
2024-05-14 04:07:57.172948: Epoch time: 49.07 s 
2024-05-14 04:07:58.143428:  
2024-05-14 04:07:58.143543: Epoch 938 
2024-05-14 04:07:58.143629: Current learning rate: 0.00082 
2024-05-14 04:08:47.175628: train_loss -0.8821 
2024-05-14 04:08:47.175811: val_loss -0.8847 
2024-05-14 04:08:47.175878: Pseudo dice [0.9403] 
2024-05-14 04:08:47.175941: Epoch time: 49.03 s 
2024-05-14 04:08:48.154880:  
2024-05-14 04:08:48.154995: Epoch 939 
2024-05-14 04:08:48.155093: Current learning rate: 0.00081 
2024-05-14 04:09:37.177388: train_loss -0.8884 
2024-05-14 04:09:37.177589: val_loss -0.8885 
2024-05-14 04:09:37.177655: Pseudo dice [0.9417] 
2024-05-14 04:09:37.177720: Epoch time: 49.02 s 
2024-05-14 04:09:38.190451:  
2024-05-14 04:09:38.190570: Epoch 940 
2024-05-14 04:09:38.190679: Current learning rate: 0.00079 
2024-05-14 04:10:27.252290: train_loss -0.8843 
2024-05-14 04:10:27.252963: val_loss -0.892 
2024-05-14 04:10:27.253023: Pseudo dice [0.9408] 
2024-05-14 04:10:27.253073: Epoch time: 49.06 s 
2024-05-14 04:10:28.236261:  
2024-05-14 04:10:28.236475: Epoch 941 
2024-05-14 04:10:28.236564: Current learning rate: 0.00078 
2024-05-14 04:11:17.287631: train_loss -0.8845 
2024-05-14 04:11:17.287816: val_loss -0.8924 
2024-05-14 04:11:17.287936: Pseudo dice [0.9414] 
2024-05-14 04:11:17.288009: Epoch time: 49.05 s 
2024-05-14 04:11:17.288060: Yayy! New best EMA pseudo Dice: 0.94 
2024-05-14 04:11:18.645233:  
2024-05-14 04:11:18.645358: Epoch 942 
2024-05-14 04:11:18.645457: Current learning rate: 0.00077 
2024-05-14 04:12:07.700874: train_loss -0.8863 
2024-05-14 04:12:07.701043: val_loss -0.8909 
2024-05-14 04:12:07.701113: Pseudo dice [0.9402] 
2024-05-14 04:12:07.701200: Epoch time: 49.06 s 
2024-05-14 04:12:07.701267: Yayy! New best EMA pseudo Dice: 0.94 
2024-05-14 04:12:09.421473:  
2024-05-14 04:12:09.421613: Epoch 943 
2024-05-14 04:12:09.421717: Current learning rate: 0.00076 
2024-05-14 04:12:58.474806: train_loss -0.8878 
2024-05-14 04:12:58.475489: val_loss -0.8787 
2024-05-14 04:12:58.475563: Pseudo dice [0.9403] 
2024-05-14 04:12:58.475630: Epoch time: 49.05 s 
2024-05-14 04:12:58.475692: Yayy! New best EMA pseudo Dice: 0.94 
2024-05-14 04:12:59.819961:  
2024-05-14 04:12:59.820109: Epoch 944 
2024-05-14 04:12:59.820191: Current learning rate: 0.00075 
2024-05-14 04:13:48.820138: train_loss -0.8869 
2024-05-14 04:13:48.820304: val_loss -0.8852 
2024-05-14 04:13:48.820366: Pseudo dice [0.9421] 
2024-05-14 04:13:48.820425: Epoch time: 49.0 s 
2024-05-14 04:13:48.820471: Yayy! New best EMA pseudo Dice: 0.9402 
2024-05-14 04:13:50.166827:  
2024-05-14 04:13:50.167092: Epoch 945 
2024-05-14 04:13:50.167178: Current learning rate: 0.00074 
2024-05-14 04:14:39.301606: train_loss -0.8828 
2024-05-14 04:14:39.301794: val_loss -0.8788 
2024-05-14 04:14:39.301853: Pseudo dice [0.937] 
2024-05-14 04:14:39.301913: Epoch time: 49.14 s 
2024-05-14 04:14:40.273930:  
2024-05-14 04:14:40.274096: Epoch 946 
2024-05-14 04:14:40.274195: Current learning rate: 0.00072 
2024-05-14 04:15:29.272869: train_loss -0.8851 
2024-05-14 04:15:29.273129: val_loss -0.8944 
2024-05-14 04:15:29.273196: Pseudo dice [0.9465] 
2024-05-14 04:15:29.273254: Epoch time: 49.0 s 
2024-05-14 04:15:29.273306: Yayy! New best EMA pseudo Dice: 0.9406 
2024-05-14 04:15:30.590803:  
2024-05-14 04:15:30.591130: Epoch 947 
2024-05-14 04:15:30.591299: Current learning rate: 0.00071 
2024-05-14 04:16:19.701059: train_loss -0.8805 
2024-05-14 04:16:19.701239: val_loss -0.8852 
2024-05-14 04:16:19.701303: Pseudo dice [0.9405] 
2024-05-14 04:16:19.701359: Epoch time: 49.11 s 
2024-05-14 04:16:20.671016:  
2024-05-14 04:16:20.671128: Epoch 948 
2024-05-14 04:16:20.671213: Current learning rate: 0.0007 
2024-05-14 04:17:09.742781: train_loss -0.8856 
2024-05-14 04:17:09.742947: val_loss -0.8734 
2024-05-14 04:17:09.743008: Pseudo dice [0.9392] 
2024-05-14 04:17:09.743065: Epoch time: 49.07 s 
2024-05-14 04:17:10.714586:  
2024-05-14 04:17:10.714700: Epoch 949 
2024-05-14 04:17:10.714781: Current learning rate: 0.00069 
2024-05-14 04:17:59.909075: train_loss -0.8846 
2024-05-14 04:17:59.909258: val_loss -0.8876 
2024-05-14 04:17:59.909316: Pseudo dice [0.9403] 
2024-05-14 04:17:59.909374: Epoch time: 49.2 s 
2024-05-14 04:18:01.269872:  
2024-05-14 04:18:01.270128: Epoch 950 
2024-05-14 04:18:01.270217: Current learning rate: 0.00067 
2024-05-14 04:18:50.373065: train_loss -0.8855 
2024-05-14 04:18:50.373239: val_loss -0.8809 
2024-05-14 04:18:50.373298: Pseudo dice [0.9412] 
2024-05-14 04:18:50.373358: Epoch time: 49.1 s 
2024-05-14 04:18:51.389322:  
2024-05-14 04:18:51.389513: Epoch 951 
2024-05-14 04:18:51.389601: Current learning rate: 0.00066 
2024-05-14 04:19:40.496017: train_loss -0.8857 
2024-05-14 04:19:40.496721: val_loss -0.8848 
2024-05-14 04:19:40.496901: Pseudo dice [0.9407] 
2024-05-14 04:19:40.496959: Epoch time: 49.11 s 
2024-05-14 04:19:41.466394:  
2024-05-14 04:19:41.466502: Epoch 952 
2024-05-14 04:19:41.466582: Current learning rate: 0.00065 
2024-05-14 04:20:30.656581: train_loss -0.8844 
2024-05-14 04:20:30.656750: val_loss -0.8833 
2024-05-14 04:20:30.656808: Pseudo dice [0.9413] 
2024-05-14 04:20:30.656866: Epoch time: 49.19 s 
2024-05-14 04:20:30.656914: Yayy! New best EMA pseudo Dice: 0.9406 
2024-05-14 04:20:32.413161:  
2024-05-14 04:20:32.413299: Epoch 953 
2024-05-14 04:20:32.413422: Current learning rate: 0.00064 
2024-05-14 04:21:21.460488: train_loss -0.8869 
2024-05-14 04:21:21.460681: val_loss -0.8847 
2024-05-14 04:21:21.460742: Pseudo dice [0.939] 
2024-05-14 04:21:21.460799: Epoch time: 49.05 s 
2024-05-14 04:21:22.450414:  
2024-05-14 04:21:22.450541: Epoch 954 
2024-05-14 04:21:22.450625: Current learning rate: 0.00063 
2024-05-14 04:22:11.463707: train_loss -0.8817 
2024-05-14 04:22:11.463968: val_loss -0.8857 
2024-05-14 04:22:11.464034: Pseudo dice [0.9409] 
2024-05-14 04:22:11.464093: Epoch time: 49.01 s 
2024-05-14 04:22:12.497160:  
2024-05-14 04:22:12.497275: Epoch 955 
2024-05-14 04:22:12.497359: Current learning rate: 0.00061 
2024-05-14 04:23:01.573772: train_loss -0.8848 
2024-05-14 04:23:01.574007: val_loss -0.8849 
2024-05-14 04:23:01.574071: Pseudo dice [0.9423] 
2024-05-14 04:23:01.574131: Epoch time: 49.08 s 
2024-05-14 04:23:01.574176: Yayy! New best EMA pseudo Dice: 0.9407 
2024-05-14 04:23:02.887034:  
2024-05-14 04:23:02.887156: Epoch 956 
2024-05-14 04:23:02.887243: Current learning rate: 0.0006 
2024-05-14 04:23:52.074259: train_loss -0.8893 
2024-05-14 04:23:52.074455: val_loss -0.8965 
2024-05-14 04:23:52.074517: Pseudo dice [0.9445] 
2024-05-14 04:23:52.074574: Epoch time: 49.19 s 
2024-05-14 04:23:52.074621: Yayy! New best EMA pseudo Dice: 0.941 
2024-05-14 04:23:53.421225:  
2024-05-14 04:23:53.421483: Epoch 957 
2024-05-14 04:23:53.421657: Current learning rate: 0.00059 
2024-05-14 04:24:42.502958: train_loss -0.8861 
2024-05-14 04:24:42.503632: val_loss -0.8836 
2024-05-14 04:24:42.503694: Pseudo dice [0.9427] 
2024-05-14 04:24:42.503746: Epoch time: 49.08 s 
2024-05-14 04:24:42.503784: Yayy! New best EMA pseudo Dice: 0.9412 
2024-05-14 04:24:43.847880:  
2024-05-14 04:24:43.847992: Epoch 958 
2024-05-14 04:24:43.848091: Current learning rate: 0.00058 
2024-05-14 04:25:32.873980: train_loss -0.8868 
2024-05-14 04:25:32.874168: val_loss -0.8853 
2024-05-14 04:25:32.874230: Pseudo dice [0.9423] 
2024-05-14 04:25:32.874289: Epoch time: 49.03 s 
2024-05-14 04:25:32.874343: Yayy! New best EMA pseudo Dice: 0.9413 
2024-05-14 04:25:34.236641:  
2024-05-14 04:25:34.236877: Epoch 959 
2024-05-14 04:25:34.237029: Current learning rate: 0.00056 
2024-05-14 04:26:23.267330: train_loss -0.886 
2024-05-14 04:26:23.267503: val_loss -0.8804 
2024-05-14 04:26:23.267567: Pseudo dice [0.9362] 
2024-05-14 04:26:23.267626: Epoch time: 49.03 s 
2024-05-14 04:26:24.279821:  
2024-05-14 04:26:24.279943: Epoch 960 
2024-05-14 04:26:24.280023: Current learning rate: 0.00055 
2024-05-14 04:27:13.295954: train_loss -0.8871 
2024-05-14 04:27:13.296426: val_loss -0.8963 
2024-05-14 04:27:13.296521: Pseudo dice [0.944] 
2024-05-14 04:27:13.296597: Epoch time: 49.02 s 
2024-05-14 04:27:14.319357:  
2024-05-14 04:27:14.319562: Epoch 961 
2024-05-14 04:27:14.319651: Current learning rate: 0.00054 
2024-05-14 04:28:03.391377: train_loss -0.8848 
2024-05-14 04:28:03.391570: val_loss -0.8917 
2024-05-14 04:28:03.391661: Pseudo dice [0.9423] 
2024-05-14 04:28:03.391746: Epoch time: 49.07 s 
2024-05-14 04:28:04.384578:  
2024-05-14 04:28:04.384772: Epoch 962 
2024-05-14 04:28:04.384859: Current learning rate: 0.00053 
2024-05-14 04:28:53.404459: train_loss -0.8908 
2024-05-14 04:28:53.404642: val_loss -0.883 
2024-05-14 04:28:53.404703: Pseudo dice [0.941] 
2024-05-14 04:28:53.404764: Epoch time: 49.02 s 
2024-05-14 04:28:54.870489:  
2024-05-14 04:28:54.870614: Epoch 963 
2024-05-14 04:28:54.870695: Current learning rate: 0.00051 
2024-05-14 04:29:44.186535: train_loss -0.8853 
2024-05-14 04:29:44.186802: val_loss -0.8855 
2024-05-14 04:29:44.186872: Pseudo dice [0.939] 
2024-05-14 04:29:44.186930: Epoch time: 49.32 s 
2024-05-14 04:29:45.192408:  
2024-05-14 04:29:45.192534: Epoch 964 
2024-05-14 04:29:45.192632: Current learning rate: 0.0005 
2024-05-14 04:30:34.246157: train_loss -0.8825 
2024-05-14 04:30:34.246382: val_loss -0.8971 
2024-05-14 04:30:34.246453: Pseudo dice [0.9455] 
2024-05-14 04:30:34.246516: Epoch time: 49.05 s 
2024-05-14 04:30:34.246565: Yayy! New best EMA pseudo Dice: 0.9414 
2024-05-14 04:30:35.548787:  
2024-05-14 04:30:35.548915: Epoch 965 
2024-05-14 04:30:35.549001: Current learning rate: 0.00049 
2024-05-14 04:31:24.641154: train_loss -0.8847 
2024-05-14 04:31:24.641342: val_loss -0.8942 
2024-05-14 04:31:24.641403: Pseudo dice [0.9442] 
2024-05-14 04:31:24.641463: Epoch time: 49.09 s 
2024-05-14 04:31:24.641508: Yayy! New best EMA pseudo Dice: 0.9417 
2024-05-14 04:31:26.034175:  
2024-05-14 04:31:26.034302: Epoch 966 
2024-05-14 04:31:26.034404: Current learning rate: 0.00048 
2024-05-14 04:32:15.113392: train_loss -0.8845 
2024-05-14 04:32:15.113708: val_loss -0.8804 
2024-05-14 04:32:15.113770: Pseudo dice [0.9382] 
2024-05-14 04:32:15.113845: Epoch time: 49.08 s 
2024-05-14 04:32:16.106739:  
2024-05-14 04:32:16.106848: Epoch 967 
2024-05-14 04:32:16.106933: Current learning rate: 0.00046 
2024-05-14 04:33:05.166512: train_loss -0.8826 
2024-05-14 04:33:05.166691: val_loss -0.8884 
2024-05-14 04:33:05.166751: Pseudo dice [0.9444] 
2024-05-14 04:33:05.166809: Epoch time: 49.06 s 
2024-05-14 04:33:06.178200:  
2024-05-14 04:33:06.178315: Epoch 968 
2024-05-14 04:33:06.178415: Current learning rate: 0.00045 
2024-05-14 04:33:55.178112: train_loss -0.8823 
2024-05-14 04:33:55.178301: val_loss -0.8906 
2024-05-14 04:33:55.178380: Pseudo dice [0.9412] 
2024-05-14 04:33:55.178439: Epoch time: 49.0 s 
2024-05-14 04:33:56.195242:  
2024-05-14 04:33:56.195355: Epoch 969 
2024-05-14 04:33:56.195442: Current learning rate: 0.00044 
2024-05-14 04:34:45.229207: train_loss -0.8866 
2024-05-14 04:34:45.229934: val_loss -0.8752 
2024-05-14 04:34:45.229999: Pseudo dice [0.9354] 
2024-05-14 04:34:45.230066: Epoch time: 49.03 s 
2024-05-14 04:34:46.227732:  
2024-05-14 04:34:46.227854: Epoch 970 
2024-05-14 04:34:46.227953: Current learning rate: 0.00043 
2024-05-14 04:35:35.338862: train_loss -0.8854 
2024-05-14 04:35:35.339082: val_loss -0.8914 
2024-05-14 04:35:35.340401: Pseudo dice [0.9464] 
2024-05-14 04:35:35.340612: Epoch time: 49.11 s 
2024-05-14 04:35:36.383283:  
2024-05-14 04:35:36.383395: Epoch 971 
2024-05-14 04:35:36.383484: Current learning rate: 0.00041 
2024-05-14 04:36:25.478862: train_loss -0.8882 
2024-05-14 04:36:25.479168: val_loss -0.8768 
2024-05-14 04:36:25.479260: Pseudo dice [0.9368] 
2024-05-14 04:36:25.479338: Epoch time: 49.1 s 
2024-05-14 04:36:26.471609:  
2024-05-14 04:36:26.471720: Epoch 972 
2024-05-14 04:36:26.471806: Current learning rate: 0.0004 
2024-05-14 04:37:15.555695: train_loss -0.885 
2024-05-14 04:37:15.556385: val_loss -0.8893 
2024-05-14 04:37:15.556446: Pseudo dice [0.9423] 
2024-05-14 04:37:15.556500: Epoch time: 49.08 s 
2024-05-14 04:37:16.971943:  
2024-05-14 04:37:16.972073: Epoch 973 
2024-05-14 04:37:16.972157: Current learning rate: 0.00039 
2024-05-14 04:38:06.064066: train_loss -0.889 
2024-05-14 04:38:06.064797: val_loss -0.8906 
2024-05-14 04:38:06.064885: Pseudo dice [0.9424] 
2024-05-14 04:38:06.064961: Epoch time: 49.09 s 
2024-05-14 04:38:07.131357:  
2024-05-14 04:38:07.131488: Epoch 974 
2024-05-14 04:38:07.131576: Current learning rate: 0.00037 
2024-05-14 04:38:56.222682: train_loss -0.8884 
2024-05-14 04:38:56.222864: val_loss -0.8883 
2024-05-14 04:38:56.222935: Pseudo dice [0.9407] 
2024-05-14 04:38:56.222998: Epoch time: 49.09 s 
2024-05-14 04:38:57.218026:  
2024-05-14 04:38:57.218178: Epoch 975 
2024-05-14 04:38:57.218271: Current learning rate: 0.00036 
2024-05-14 04:39:46.390479: train_loss -0.8889 
2024-05-14 04:39:46.390647: val_loss -0.8921 
2024-05-14 04:39:46.390706: Pseudo dice [0.9435] 
2024-05-14 04:39:46.390763: Epoch time: 49.17 s 
2024-05-14 04:39:47.385700:  
2024-05-14 04:39:47.385821: Epoch 976 
2024-05-14 04:39:47.385907: Current learning rate: 0.00035 
2024-05-14 04:40:36.387715: train_loss -0.8878 
2024-05-14 04:40:36.388443: val_loss -0.8856 
2024-05-14 04:40:36.388503: Pseudo dice [0.9407] 
2024-05-14 04:40:36.388553: Epoch time: 49.0 s 
2024-05-14 04:40:37.413976:  
2024-05-14 04:40:37.414135: Epoch 977 
2024-05-14 04:40:37.414223: Current learning rate: 0.00034 
2024-05-14 04:41:26.560594: train_loss -0.8873 
2024-05-14 04:41:26.560770: val_loss -0.8895 
2024-05-14 04:41:26.560852: Pseudo dice [0.9426] 
2024-05-14 04:41:26.560925: Epoch time: 49.15 s 
2024-05-14 04:41:27.568480:  
2024-05-14 04:41:27.568682: Epoch 978 
2024-05-14 04:41:27.568768: Current learning rate: 0.00032 
2024-05-14 04:42:16.661617: train_loss -0.8826 
2024-05-14 04:42:16.661810: val_loss -0.8861 
2024-05-14 04:42:16.661871: Pseudo dice [0.9384] 
2024-05-14 04:42:16.661929: Epoch time: 49.09 s 
2024-05-14 04:42:17.674450:  
2024-05-14 04:42:17.674565: Epoch 979 
2024-05-14 04:42:17.674652: Current learning rate: 0.00031 
2024-05-14 04:43:06.727585: train_loss -0.8909 
2024-05-14 04:43:06.727841: val_loss -0.8921 
2024-05-14 04:43:06.727910: Pseudo dice [0.9461] 
2024-05-14 04:43:06.727975: Epoch time: 49.05 s 
2024-05-14 04:43:07.817241:  
2024-05-14 04:43:07.817466: Epoch 980 
2024-05-14 04:43:07.817553: Current learning rate: 0.0003 
2024-05-14 04:43:56.896135: train_loss -0.8869 
2024-05-14 04:43:56.896321: val_loss -0.8828 
2024-05-14 04:43:56.896382: Pseudo dice [0.9428] 
2024-05-14 04:43:56.896438: Epoch time: 49.08 s 
2024-05-14 04:43:56.896489: Yayy! New best EMA pseudo Dice: 0.9418 
2024-05-14 04:43:58.232998:  
2024-05-14 04:43:58.233232: Epoch 981 
2024-05-14 04:43:58.233321: Current learning rate: 0.00028 
2024-05-14 04:44:47.306685: train_loss -0.8837 
2024-05-14 04:44:47.306874: val_loss -0.8785 
2024-05-14 04:44:47.306935: Pseudo dice [0.9407] 
2024-05-14 04:44:47.306993: Epoch time: 49.07 s 
2024-05-14 04:44:48.301861:  
2024-05-14 04:44:48.301984: Epoch 982 
2024-05-14 04:44:48.302067: Current learning rate: 0.00027 
2024-05-14 04:45:37.388673: train_loss -0.8907 
2024-05-14 04:45:37.389384: val_loss -0.8956 
2024-05-14 04:45:37.389444: Pseudo dice [0.9462] 
2024-05-14 04:45:37.389496: Epoch time: 49.09 s 
2024-05-14 04:45:37.389535: Yayy! New best EMA pseudo Dice: 0.9422 
2024-05-14 04:45:39.201371:  
2024-05-14 04:45:39.201608: Epoch 983 
2024-05-14 04:45:39.201696: Current learning rate: 0.00026 
2024-05-14 04:46:28.254060: train_loss -0.8885 
2024-05-14 04:46:28.254278: val_loss -0.8906 
2024-05-14 04:46:28.254354: Pseudo dice [0.9413] 
2024-05-14 04:46:28.254413: Epoch time: 49.05 s 
2024-05-14 04:46:29.246258:  
2024-05-14 04:46:29.246401: Epoch 984 
2024-05-14 04:46:29.246484: Current learning rate: 0.00024 
2024-05-14 04:47:18.333433: train_loss -0.8898 
2024-05-14 04:47:18.333613: val_loss -0.865 
2024-05-14 04:47:18.333704: Pseudo dice [0.9315] 
2024-05-14 04:47:18.333789: Epoch time: 49.09 s 
2024-05-14 04:47:19.355681:  
2024-05-14 04:47:19.355820: Epoch 985 
2024-05-14 04:47:19.355904: Current learning rate: 0.00023 
2024-05-14 04:48:08.496141: train_loss -0.8912 
2024-05-14 04:48:08.496932: val_loss -0.8954 
2024-05-14 04:48:08.497000: Pseudo dice [0.9421] 
2024-05-14 04:48:08.497153: Epoch time: 49.14 s 
2024-05-14 04:48:09.489564:  
2024-05-14 04:48:09.489678: Epoch 986 
2024-05-14 04:48:09.489775: Current learning rate: 0.00021 
2024-05-14 04:48:58.643502: train_loss -0.8833 
2024-05-14 04:48:58.643699: val_loss -0.8899 
2024-05-14 04:48:58.643760: Pseudo dice [0.9427] 
2024-05-14 04:48:58.643819: Epoch time: 49.15 s 
2024-05-14 04:48:59.648622:  
2024-05-14 04:48:59.648753: Epoch 987 
2024-05-14 04:48:59.648854: Current learning rate: 0.0002 
2024-05-14 04:49:48.756241: train_loss -0.8864 
2024-05-14 04:49:48.756420: val_loss -0.8914 
2024-05-14 04:49:48.756481: Pseudo dice [0.9444] 
2024-05-14 04:49:48.756541: Epoch time: 49.11 s 
2024-05-14 04:49:49.781669:  
2024-05-14 04:49:49.781784: Epoch 988 
2024-05-14 04:49:49.781868: Current learning rate: 0.00019 
2024-05-14 04:50:38.884125: train_loss -0.8885 
2024-05-14 04:50:38.884837: val_loss -0.8711 
2024-05-14 04:50:38.884896: Pseudo dice [0.9319] 
2024-05-14 04:50:38.885116: Epoch time: 49.1 s 
2024-05-14 04:50:39.886391:  
2024-05-14 04:50:39.886507: Epoch 989 
2024-05-14 04:50:39.886590: Current learning rate: 0.00017 
2024-05-14 04:51:28.895040: train_loss -0.8874 
2024-05-14 04:51:28.895231: val_loss -0.888 
2024-05-14 04:51:28.895292: Pseudo dice [0.9426] 
2024-05-14 04:51:28.895350: Epoch time: 49.01 s 
2024-05-14 04:51:29.927337:  
2024-05-14 04:51:29.927449: Epoch 990 
2024-05-14 04:51:29.927533: Current learning rate: 0.00016 
2024-05-14 04:52:19.031823: train_loss -0.881 
2024-05-14 04:52:19.031991: val_loss -0.8938 
2024-05-14 04:52:19.032068: Pseudo dice [0.9439] 
2024-05-14 04:52:19.032132: Epoch time: 49.11 s 
2024-05-14 04:52:20.076402:  
2024-05-14 04:52:20.076510: Epoch 991 
2024-05-14 04:52:20.076593: Current learning rate: 0.00014 
2024-05-14 04:53:09.137922: train_loss -0.8884 
2024-05-14 04:53:09.138756: val_loss -0.8859 
2024-05-14 04:53:09.138992: Pseudo dice [0.9408] 
2024-05-14 04:53:09.139161: Epoch time: 49.06 s 
2024-05-14 04:53:10.153055:  
2024-05-14 04:53:10.153163: Epoch 992 
2024-05-14 04:53:10.153248: Current learning rate: 0.00013 
2024-05-14 04:53:59.253914: train_loss -0.8898 
2024-05-14 04:53:59.254095: val_loss -0.8903 
2024-05-14 04:53:59.254157: Pseudo dice [0.9428] 
2024-05-14 04:53:59.254215: Epoch time: 49.1 s 
2024-05-14 04:54:00.243728:  
2024-05-14 04:54:00.243843: Epoch 993 
2024-05-14 04:54:00.243940: Current learning rate: 0.00011 
2024-05-14 04:54:49.367154: train_loss -0.8821 
2024-05-14 04:54:49.367345: val_loss -0.8882 
2024-05-14 04:54:49.367411: Pseudo dice [0.9432] 
2024-05-14 04:54:49.367473: Epoch time: 49.12 s 
2024-05-14 04:54:50.915574:  
2024-05-14 04:54:50.915914: Epoch 994 
2024-05-14 04:54:50.916001: Current learning rate: 0.0001 
2024-05-14 04:55:39.938590: train_loss -0.8841 
2024-05-14 04:55:39.938847: val_loss -0.8793 
2024-05-14 04:55:39.938908: Pseudo dice [0.9438] 
2024-05-14 04:55:39.938961: Epoch time: 49.02 s 
2024-05-14 04:55:40.949127:  
2024-05-14 04:55:40.949253: Epoch 995 
2024-05-14 04:55:40.949343: Current learning rate: 8e-05 
2024-05-14 04:56:30.127876: train_loss -0.8822 
2024-05-14 04:56:30.128068: val_loss -0.8961 
2024-05-14 04:56:30.128130: Pseudo dice [0.9439] 
2024-05-14 04:56:30.128190: Epoch time: 49.18 s 
2024-05-14 04:56:31.119027:  
2024-05-14 04:56:31.119152: Epoch 996 
2024-05-14 04:56:31.119237: Current learning rate: 7e-05 
2024-05-14 04:57:20.209949: train_loss -0.8845 
2024-05-14 04:57:20.210159: val_loss -0.8929 
2024-05-14 04:57:20.210231: Pseudo dice [0.9436] 
2024-05-14 04:57:20.210317: Epoch time: 49.09 s 
2024-05-14 04:57:21.207016:  
2024-05-14 04:57:21.207139: Epoch 997 
2024-05-14 04:57:21.207235: Current learning rate: 5e-05 
2024-05-14 04:58:10.301117: train_loss -0.888 
2024-05-14 04:58:10.301823: val_loss -0.8925 
2024-05-14 04:58:10.301892: Pseudo dice [0.9434] 
2024-05-14 04:58:10.301943: Epoch time: 49.09 s 
2024-05-14 04:58:10.301981: Yayy! New best EMA pseudo Dice: 0.9422 
2024-05-14 04:58:11.667813:  
2024-05-14 04:58:11.667961: Epoch 998 
2024-05-14 04:58:11.668049: Current learning rate: 4e-05 
2024-05-14 04:59:00.830840: train_loss -0.889 
2024-05-14 04:59:00.831032: val_loss -0.8896 
2024-05-14 04:59:00.831118: Pseudo dice [0.9423] 
2024-05-14 04:59:00.831200: Epoch time: 49.16 s 
2024-05-14 04:59:00.831265: Yayy! New best EMA pseudo Dice: 0.9422 
2024-05-14 04:59:02.185034:  
2024-05-14 04:59:02.185162: Epoch 999 
2024-05-14 04:59:02.185264: Current learning rate: 2e-05 
2024-05-14 04:59:51.262492: train_loss -0.8882 
2024-05-14 04:59:51.262665: val_loss -0.8914 
2024-05-14 04:59:51.262744: Pseudo dice [0.9439] 
2024-05-14 04:59:51.262824: Epoch time: 49.08 s 
2024-05-14 04:59:51.262878: Yayy! New best EMA pseudo Dice: 0.9424 
2024-05-14 04:59:52.921656: Training done. 
2024-05-14 04:59:53.264120: Using splits from existing split file: /home/nathanfeldt/Desktop/nnUNet/dataset/nnUNet_preprocessed/Dataset027_COPD_ONLY_1/splits_final.json 
2024-05-14 04:59:53.269435: The split file contains 5 splits. 
2024-05-14 04:59:53.269533: Desired fold for training: 0 
2024-05-14 04:59:53.269565: This split has 5978 training and 1495 validation cases. 
2024-05-14 04:59:53.400258: predicting 10017X_16_2 
2024-05-14 04:59:53.402375: 10017X_16_2, shape torch.Size([1, 48, 213, 275]), rank 0 
2024-05-14 05:00:09.573339: predicting 10052Z_16_2 
2024-05-14 05:00:09.574979: 10052Z_16_2, shape torch.Size([1, 49, 204, 266]), rank 0 
2024-05-14 05:00:15.595321: predicting 10068O_4_3 
2024-05-14 05:00:15.596748: 10068O_4_3, shape torch.Size([1, 42, 206, 272]), rank 0 
2024-05-14 05:00:16.470500: predicting 10077P_4_2 
2024-05-14 05:00:16.472050: 10077P_4_2, shape torch.Size([1, 42, 206, 278]), rank 0 
2024-05-14 05:00:17.341226: predicting 10094P_8_2 
2024-05-14 05:00:17.343878: 10094P_8_2, shape torch.Size([1, 43, 194, 275]), rank 0 
2024-05-14 05:00:18.218766: predicting 10098X_4_3 
2024-05-14 05:00:18.220730: 10098X_4_3, shape torch.Size([1, 48, 195, 263]), rank 0 
2024-05-14 05:00:19.095134: predicting 10100K_8_2 
2024-05-14 05:00:19.097287: 10100K_8_2, shape torch.Size([1, 46, 206, 265]), rank 0 
2024-05-14 05:00:19.974685: predicting 10101M_4_2 
2024-05-14 05:00:19.977717: 10101M_4_2, shape torch.Size([1, 49, 215, 285]), rank 0 
2024-05-14 05:00:21.713571: predicting 10104S_8_3 
2024-05-14 05:00:21.716571: 10104S_8_3, shape torch.Size([1, 52, 192, 273]), rank 0 
2024-05-14 05:00:22.591111: predicting 10107Y_8_2 
2024-05-14 05:00:22.593623: 10107Y_8_2, shape torch.Size([1, 48, 206, 273]), rank 0 
2024-05-14 05:00:23.471266: predicting 10110N_0_0 
2024-05-14 05:00:23.472591: 10110N_0_0, shape torch.Size([1, 48, 206, 273]), rank 0 
2024-05-14 05:00:24.342074: predicting 10132X_4_2 
2024-05-14 05:00:24.345252: 10132X_4_2, shape torch.Size([1, 42, 196, 265]), rank 0 
2024-05-14 05:00:25.223066: predicting 10138J_16_2 
2024-05-14 05:00:25.225892: 10138J_16_2, shape torch.Size([1, 48, 204, 265]), rank 0 
2024-05-14 05:00:26.102867: predicting 10141Y_16_2 
2024-05-14 05:00:26.105848: 10141Y_16_2, shape torch.Size([1, 52, 220, 293]), rank 0 
2024-05-14 05:00:27.844940: predicting 10151B_0_0 
2024-05-14 05:00:27.848140: 10151B_0_0, shape torch.Size([1, 52, 220, 293]), rank 0 
2024-05-14 05:00:29.589653: predicting 10178V_4_2 
2024-05-14 05:00:29.593146: 10178V_4_2, shape torch.Size([1, 42, 204, 273]), rank 0 
2024-05-14 05:00:30.473650: predicting 10182M_16_2 
2024-05-14 05:00:30.476501: 10182M_16_2, shape torch.Size([1, 50, 200, 270]), rank 0 
2024-05-14 05:00:32.218915: predicting 10188Y_0_0 
2024-05-14 05:00:32.221789: 10188Y_0_0, shape torch.Size([1, 37, 205, 274]), rank 0 
2024-05-14 05:00:33.097870: predicting 10193R_0_0 
2024-05-14 05:00:33.098800: 10193R_0_0, shape torch.Size([1, 45, 203, 284]), rank 0 
2024-05-14 05:00:33.973265: predicting 10203U_0_0 
2024-05-14 05:00:33.976133: 10203U_0_0, shape torch.Size([1, 42, 197, 280]), rank 0 
2024-05-14 05:00:34.855343: predicting 10215B_4_3 
2024-05-14 05:00:34.858323: 10215B_4_3, shape torch.Size([1, 46, 213, 282]), rank 0 
2024-05-14 05:00:35.740535: predicting 10216D_8_2 
2024-05-14 05:00:35.743261: 10216D_8_2, shape torch.Size([1, 44, 201, 277]), rank 0 
2024-05-14 05:00:36.624030: predicting 10223A_8_3 
2024-05-14 05:00:36.626629: 10223A_8_3, shape torch.Size([1, 46, 215, 284]), rank 0 
2024-05-14 05:00:37.508562: predicting 10227I_0_0 
2024-05-14 05:00:37.512070: 10227I_0_0, shape torch.Size([1, 47, 214, 277]), rank 0 
2024-05-14 05:00:38.396982: predicting 10230X_16_2 
2024-05-14 05:00:38.400003: 10230X_16_2, shape torch.Size([1, 48, 206, 273]), rank 0 
2024-05-14 05:00:39.278811: predicting 10246M_4_2 
2024-05-14 05:00:39.280100: 10246M_4_2, shape torch.Size([1, 46, 200, 266]), rank 0 
2024-05-14 05:00:40.153978: predicting 10248Q_8_2 
2024-05-14 05:00:40.157423: 10248Q_8_2, shape torch.Size([1, 43, 207, 277]), rank 0 
2024-05-14 05:00:41.041266: predicting 10261I_8_2 
2024-05-14 05:00:41.044247: 10261I_8_2, shape torch.Size([1, 47, 206, 281]), rank 0 
2024-05-14 05:00:41.927857: predicting 10275T_16_2 
2024-05-14 05:00:41.930796: 10275T_16_2, shape torch.Size([1, 49, 205, 274]), rank 0 
2024-05-14 05:00:43.676008: predicting 10298F_16_2 
2024-05-14 05:00:43.678231: 10298F_16_2, shape torch.Size([1, 43, 201, 278]), rank 0 
2024-05-14 05:00:44.560637: predicting 10300S_4_3 
2024-05-14 05:00:44.561991: 10300S_4_3, shape torch.Size([1, 44, 208, 274]), rank 0 
2024-05-14 05:00:45.439024: predicting 10308I_8_2 
2024-05-14 05:00:45.441449: 10308I_8_2, shape torch.Size([1, 39, 216, 280]), rank 0 
2024-05-14 05:00:46.323961: predicting 10314D_8_2 
2024-05-14 05:00:46.325979: 10314D_8_2, shape torch.Size([1, 52, 212, 273]), rank 0 
2024-05-14 05:00:48.068156: predicting 10330B_4_2 
2024-05-14 05:00:48.070156: 10330B_4_2, shape torch.Size([1, 46, 186, 265]), rank 0 
2024-05-14 05:00:48.522030: predicting 10337P_8_2 
2024-05-14 05:00:48.524586: 10337P_8_2, shape torch.Size([1, 48, 207, 272]), rank 0 
2024-05-14 05:00:49.408093: predicting 10340E_16_2 
2024-05-14 05:00:49.409488: 10340E_16_2, shape torch.Size([1, 46, 206, 266]), rank 0 
2024-05-14 05:00:50.286950: predicting 10341G_4_3 
2024-05-14 05:00:50.289355: 10341G_4_3, shape torch.Size([1, 42, 210, 275]), rank 0 
2024-05-14 05:00:51.174305: predicting 10353N_8_3 
2024-05-14 05:00:51.176797: 10353N_8_3, shape torch.Size([1, 39, 194, 264]), rank 0 
2024-05-14 05:00:52.058156: predicting 10355R_4_2 
2024-05-14 05:00:52.060949: 10355R_4_2, shape torch.Size([1, 44, 203, 277]), rank 0 
2024-05-14 05:00:52.946271: predicting 10358X_8_2 
2024-05-14 05:00:52.949180: 10358X_8_2, shape torch.Size([1, 48, 214, 262]), rank 0 
2024-05-14 05:00:53.833763: predicting 10379F_16_2 
2024-05-14 05:00:53.835158: 10379F_16_2, shape torch.Size([1, 51, 195, 269]), rank 0 
2024-05-14 05:00:55.579997: predicting 10395D_0_0 
2024-05-14 05:00:55.583270: 10395D_0_0, shape torch.Size([1, 42, 208, 282]), rank 0 
2024-05-14 05:00:56.468012: predicting 10400W_0_0 
2024-05-14 05:00:56.471021: 10400W_0_0, shape torch.Size([1, 46, 200, 269]), rank 0 
2024-05-14 05:00:57.356898: predicting 10406I_4_2 
2024-05-14 05:00:57.359768: 10406I_4_2, shape torch.Size([1, 43, 195, 271]), rank 0 
2024-05-14 05:00:58.242965: predicting 10415J_8_3 
2024-05-14 05:00:58.246006: 10415J_8_3, shape torch.Size([1, 43, 199, 271]), rank 0 
2024-05-14 05:00:59.131533: predicting 10426O_4_3 
2024-05-14 05:00:59.132515: 10426O_4_3, shape torch.Size([1, 46, 205, 273]), rank 0 
2024-05-14 05:01:00.011483: predicting 10428S_4_2 
2024-05-14 05:01:00.014813: 10428S_4_2, shape torch.Size([1, 42, 192, 270]), rank 0 
2024-05-14 05:01:00.466146: predicting 10459D_8_2 
2024-05-14 05:01:00.469038: 10459D_8_2, shape torch.Size([1, 43, 193, 274]), rank 0 
2024-05-14 05:01:01.354150: predicting 10460O_16_2 
2024-05-14 05:01:01.355511: 10460O_16_2, shape torch.Size([1, 52, 201, 272]), rank 0 
2024-05-14 05:01:03.105209: predicting 10484C_8_2 
2024-05-14 05:01:03.108011: 10484C_8_2, shape torch.Size([1, 48, 197, 279]), rank 0 
2024-05-14 05:01:03.995609: predicting 10523M_8_2 
2024-05-14 05:01:03.998490: 10523M_8_2, shape torch.Size([1, 48, 205, 271]), rank 0 
2024-05-14 05:01:04.884112: predicting 10529Y_16_2 
2024-05-14 05:01:04.886876: 10529Y_16_2, shape torch.Size([1, 52, 196, 266]), rank 0 
2024-05-14 05:01:06.642967: predicting 10536V_8_3 
2024-05-14 05:01:06.645098: 10536V_8_3, shape torch.Size([1, 46, 207, 267]), rank 0 
2024-05-14 05:01:07.534451: predicting 10539B_0_0 
2024-05-14 05:01:07.535776: 10539B_0_0, shape torch.Size([1, 46, 207, 267]), rank 0 
2024-05-14 05:01:08.416979: predicting 10541O_8_3 
2024-05-14 05:01:08.420163: 10541O_8_3, shape torch.Size([1, 48, 191, 274]), rank 0 
2024-05-14 05:01:08.880840: predicting 10542Q_4_3 
2024-05-14 05:01:08.883884: 10542Q_4_3, shape torch.Size([1, 46, 197, 279]), rank 0 
2024-05-14 05:01:09.772397: predicting 10544U_16_2 
2024-05-14 05:01:09.773709: 10544U_16_2, shape torch.Size([1, 52, 214, 275]), rank 0 
2024-05-14 05:01:11.524177: predicting 10546Y_0_0 
2024-05-14 05:01:11.526742: 10546Y_0_0, shape torch.Size([1, 41, 190, 267]), rank 0 
2024-05-14 05:01:11.975568: predicting 10568I_0_0 
2024-05-14 05:01:11.978105: 10568I_0_0, shape torch.Size([1, 52, 202, 272]), rank 0 
2024-05-14 05:01:13.735206: predicting 10572Z_16_2 
2024-05-14 05:01:13.738151: 10572Z_16_2, shape torch.Size([1, 42, 196, 276]), rank 0 
2024-05-14 05:01:14.625751: predicting 10606Q_0_0 
2024-05-14 05:01:14.628792: 10606Q_0_0, shape torch.Size([1, 47, 196, 292]), rank 0 
2024-05-14 05:01:15.517272: predicting 10628A_4_2 
2024-05-14 05:01:15.519639: 10628A_4_2, shape torch.Size([1, 42, 201, 279]), rank 0 
2024-05-14 05:01:16.408306: predicting 10630N_8_3 
2024-05-14 05:01:16.410625: 10630N_8_3, shape torch.Size([1, 50, 199, 274]), rank 0 
2024-05-14 05:01:18.167001: predicting 10645A_8_3 
2024-05-14 05:01:18.169896: 10645A_8_3, shape torch.Size([1, 44, 197, 274]), rank 0 
2024-05-14 05:01:19.057310: predicting 10646C_4_3 
2024-05-14 05:01:19.060157: 10646C_4_3, shape torch.Size([1, 47, 194, 282]), rank 0 
2024-05-14 05:01:19.950533: predicting 10665G_16_2 
2024-05-14 05:01:19.951902: 10665G_16_2, shape torch.Size([1, 50, 202, 274]), rank 0 
2024-05-14 05:01:21.701473: predicting 10679R_8_3 
2024-05-14 05:01:21.703094: 10679R_8_3, shape torch.Size([1, 52, 196, 275]), rank 0 
2024-05-14 05:01:23.453287: predicting 10704Q_4_2 
2024-05-14 05:01:23.456338: 10704Q_4_2, shape torch.Size([1, 49, 196, 284]), rank 0 
2024-05-14 05:01:25.220326: predicting 10705S_0_0 
2024-05-14 05:01:25.222968: 10705S_0_0, shape torch.Size([1, 49, 196, 284]), rank 0 
2024-05-14 05:01:26.981651: predicting 10706U_4_2 
2024-05-14 05:01:26.984520: 10706U_4_2, shape torch.Size([1, 46, 209, 283]), rank 0 
2024-05-14 05:01:27.873757: predicting 10719D_16_2 
2024-05-14 05:01:27.876687: 10719D_16_2, shape torch.Size([1, 46, 202, 281]), rank 0 
2024-05-14 05:01:28.767400: predicting 10731T_4_2 
2024-05-14 05:01:28.769609: 10731T_4_2, shape torch.Size([1, 50, 212, 274]), rank 0 
2024-05-14 05:01:30.528185: predicting 10745E_8_2 
2024-05-14 05:01:30.532169: 10745E_8_2, shape torch.Size([1, 52, 197, 262]), rank 0 
2024-05-14 05:01:32.292143: predicting 10750X_8_3 
2024-05-14 05:01:32.293528: 10750X_8_3, shape torch.Size([1, 40, 211, 282]), rank 0 
2024-05-14 05:01:33.173587: predicting 10772H_4_3 
2024-05-14 05:01:33.176300: 10772H_4_3, shape torch.Size([1, 48, 202, 278]), rank 0 
2024-05-14 05:01:34.061198: predicting 10777R_4_2 
2024-05-14 05:01:34.064178: 10777R_4_2, shape torch.Size([1, 44, 196, 271]), rank 0 
2024-05-14 05:01:34.952537: predicting 10779V_0_0 
2024-05-14 05:01:34.956111: 10779V_0_0, shape torch.Size([1, 44, 196, 271]), rank 0 
2024-05-14 05:01:35.845497: predicting 10842C_8_2 
2024-05-14 05:01:35.849453: 10842C_8_2, shape torch.Size([1, 44, 193, 275]), rank 0 
2024-05-14 05:01:36.749589: predicting 10847M_8_2 
2024-05-14 05:01:36.752121: 10847M_8_2, shape torch.Size([1, 42, 205, 270]), rank 0 
2024-05-14 05:01:37.645116: predicting 10858R_16_2 
2024-05-14 05:01:37.648230: 10858R_16_2, shape torch.Size([1, 46, 209, 273]), rank 0 
2024-05-14 05:01:38.544574: predicting 10896Z_8_3 
2024-05-14 05:01:38.547998: 10896Z_8_3, shape torch.Size([1, 42, 204, 278]), rank 0 
2024-05-14 05:01:39.437227: predicting 10917H_0_0 
2024-05-14 05:01:39.438599: 10917H_0_0, shape torch.Size([1, 46, 206, 268]), rank 0 
2024-05-14 05:01:40.320013: predicting 10961K_16_2 
2024-05-14 05:01:40.324652: 10961K_16_2, shape torch.Size([1, 46, 199, 273]), rank 0 
2024-05-14 05:01:41.225175: predicting 10973R_4_2 
2024-05-14 05:01:41.226566: 10973R_4_2, shape torch.Size([1, 43, 199, 279]), rank 0 
2024-05-14 05:01:42.108935: predicting 10974T_8_2 
2024-05-14 05:01:42.112063: 10974T_8_2, shape torch.Size([1, 52, 213, 265]), rank 0 
2024-05-14 05:01:43.874575: predicting 10981Q_16_2 
2024-05-14 05:01:43.876910: 10981Q_16_2, shape torch.Size([1, 50, 188, 268]), rank 0 
2024-05-14 05:01:44.761284: predicting 10982S_16_2 
2024-05-14 05:01:44.764311: 10982S_16_2, shape torch.Size([1, 43, 198, 266]), rank 0 
2024-05-14 05:01:45.653718: predicting 10984W_4_2 
2024-05-14 05:01:45.657096: 10984W_4_2, shape torch.Size([1, 48, 193, 266]), rank 0 
2024-05-14 05:01:46.543699: predicting 10987C_16_2 
2024-05-14 05:01:46.546701: 10987C_16_2, shape torch.Size([1, 50, 212, 284]), rank 0 
2024-05-14 05:01:48.308072: predicting 11001N_8_3 
2024-05-14 05:01:48.309488: 11001N_8_3, shape torch.Size([1, 51, 203, 280]), rank 0 
2024-05-14 05:01:50.064262: predicting 11002P_4_3 
2024-05-14 05:01:50.067152: 11002P_4_3, shape torch.Size([1, 47, 208, 264]), rank 0 
2024-05-14 05:01:50.958275: predicting 11011Q_0_0 
2024-05-14 05:01:50.960899: 11011Q_0_0, shape torch.Size([1, 51, 197, 265]), rank 0 
2024-05-14 05:01:52.721857: predicting 11022V_8_2 
2024-05-14 05:01:52.724706: 11022V_8_2, shape torch.Size([1, 50, 189, 267]), rank 0 
2024-05-14 05:01:53.615865: predicting 11029J_16_2 
2024-05-14 05:01:53.618036: 11029J_16_2, shape torch.Size([1, 43, 211, 264]), rank 0 
2024-05-14 05:01:54.508474: predicting 11032Y_0_0 
2024-05-14 05:01:54.512067: 11032Y_0_0, shape torch.Size([1, 44, 198, 266]), rank 0 
2024-05-14 05:01:55.410867: predicting 11033A_8_3 
2024-05-14 05:01:55.413009: 11033A_8_3, shape torch.Size([1, 47, 206, 270]), rank 0 
2024-05-14 05:01:56.295199: predicting 11049P_16_2 
2024-05-14 05:01:56.297430: 11049P_16_2, shape torch.Size([1, 52, 205, 269]), rank 0 
2024-05-14 05:01:58.054202: predicting 11059S_16_2 
2024-05-14 05:01:58.057212: 11059S_16_2, shape torch.Size([1, 45, 202, 278]), rank 0 
2024-05-14 05:01:58.945354: predicting 11070G_4_2 
2024-05-14 05:01:58.948337: 11070G_4_2, shape torch.Size([1, 44, 209, 275]), rank 0 
2024-05-14 05:01:59.840037: predicting 11081L_0_0 
2024-05-14 05:01:59.843086: 11081L_0_0, shape torch.Size([1, 46, 199, 270]), rank 0 
2024-05-14 05:02:00.727768: predicting 11084R_8_3 
2024-05-14 05:02:00.730520: 11084R_8_3, shape torch.Size([1, 51, 200, 272]), rank 0 
2024-05-14 05:02:02.490995: predicting 11086V_4_2 
2024-05-14 05:02:02.494014: 11086V_4_2, shape torch.Size([1, 46, 195, 283]), rank 0 
2024-05-14 05:02:03.385474: predicting 11109H_16_2 
2024-05-14 05:02:03.387370: 11109H_16_2, shape torch.Size([1, 43, 209, 271]), rank 0 
2024-05-14 05:02:04.269917: predicting 11125F_8_2 
2024-05-14 05:02:04.271555: 11125F_8_2, shape torch.Size([1, 46, 203, 280]), rank 0 
2024-05-14 05:02:05.154155: predicting 11141D_16_2 
2024-05-14 05:02:05.156929: 11141D_16_2, shape torch.Size([1, 46, 201, 292]), rank 0 
2024-05-14 05:02:06.047892: predicting 11166T_4_3 
2024-05-14 05:02:06.051720: 11166T_4_3, shape torch.Size([1, 44, 186, 262]), rank 0 
2024-05-14 05:02:06.516647: predicting 11169Z_16_2 
2024-05-14 05:02:06.519443: 11169Z_16_2, shape torch.Size([1, 50, 192, 254]), rank 0 
2024-05-14 05:02:13.441152: predicting 11170K_16_2 
2024-05-14 05:02:13.444698: 11170K_16_2, shape torch.Size([1, 52, 214, 273]), rank 0 
2024-05-14 05:02:15.204961: predicting 11203Z_16_2 
2024-05-14 05:02:15.207104: 11203Z_16_2, shape torch.Size([1, 43, 197, 274]), rank 0 
2024-05-14 05:02:16.092289: predicting 11208J_4_3 
2024-05-14 05:02:16.095225: 11208J_4_3, shape torch.Size([1, 48, 200, 290]), rank 0 
2024-05-14 05:02:16.979390: predicting 11232G_0_0 
2024-05-14 05:02:16.982486: 11232G_0_0, shape torch.Size([1, 46, 213, 280]), rank 0 
2024-05-14 05:02:17.866971: predicting 11235M_16_2 
2024-05-14 05:02:17.868366: 11235M_16_2, shape torch.Size([1, 48, 196, 277]), rank 0 
2024-05-14 05:02:18.748548: predicting 11239U_16_2 
2024-05-14 05:02:18.752056: 11239U_16_2, shape torch.Size([1, 50, 200, 270]), rank 0 
2024-05-14 05:02:20.501635: predicting 11243L_4_2 
2024-05-14 05:02:20.504526: 11243L_4_2, shape torch.Size([1, 45, 204, 277]), rank 0 
2024-05-14 05:02:21.392485: predicting 11261N_8_3 
2024-05-14 05:02:21.393498: 11261N_8_3, shape torch.Size([1, 40, 198, 266]), rank 0 
2024-05-14 05:02:22.271101: predicting 11267Z_4_2 
2024-05-14 05:02:22.273630: 11267Z_4_2, shape torch.Size([1, 46, 194, 273]), rank 0 
2024-05-14 05:02:23.159655: predicting 11290U_16_2 
2024-05-14 05:02:23.162337: 11290U_16_2, shape torch.Size([1, 44, 208, 270]), rank 0 
2024-05-14 05:02:24.049041: predicting 11305H_16_2 
2024-05-14 05:02:24.052115: 11305H_16_2, shape torch.Size([1, 44, 205, 286]), rank 0 
2024-05-14 05:02:24.939987: predicting 11319S_4_2 
2024-05-14 05:02:24.942531: 11319S_4_2, shape torch.Size([1, 47, 212, 291]), rank 0 
2024-05-14 05:02:25.831525: predicting 11327R_4_2 
2024-05-14 05:02:25.833005: 11327R_4_2, shape torch.Size([1, 43, 202, 281]), rank 0 
2024-05-14 05:02:26.710979: predicting 11329V_8_3 
2024-05-14 05:02:26.713689: 11329V_8_3, shape torch.Size([1, 33, 205, 282]), rank 0 
2024-05-14 05:02:27.596662: predicting 11330G_16_2 
2024-05-14 05:02:27.599454: 11330G_16_2, shape torch.Size([1, 46, 198, 281]), rank 0 
2024-05-14 05:02:28.486663: predicting 11348Z_16_2 
2024-05-14 05:02:28.489373: 11348Z_16_2, shape torch.Size([1, 46, 206, 279]), rank 0 
2024-05-14 05:02:29.376616: predicting 11359E_8_3 
2024-05-14 05:02:29.377975: 11359E_8_3, shape torch.Size([1, 46, 195, 260]), rank 0 
2024-05-14 05:02:30.255938: predicting 11367D_8_3 
2024-05-14 05:02:30.258521: 11367D_8_3, shape torch.Size([1, 45, 198, 276]), rank 0 
2024-05-14 05:02:31.146405: predicting 11373Y_8_2 
2024-05-14 05:02:31.147415: 11373Y_8_2, shape torch.Size([1, 44, 196, 267]), rank 0 
2024-05-14 05:02:32.026754: predicting 11381X_16_2 
2024-05-14 05:02:32.028294: 11381X_16_2, shape torch.Size([1, 44, 202, 272]), rank 0 
2024-05-14 05:02:32.906906: predicting 11382Z_16_2 
2024-05-14 05:02:32.908524: 11382Z_16_2, shape torch.Size([1, 46, 179, 265]), rank 0 
2024-05-14 05:02:33.353221: predicting 11392C_0_0 
2024-05-14 05:02:33.356580: 11392C_0_0, shape torch.Size([1, 46, 198, 289]), rank 0 
2024-05-14 05:02:34.245558: predicting 11393E_16_2 
2024-05-14 05:02:34.249205: 11393E_16_2, shape torch.Size([1, 45, 197, 278]), rank 0 
2024-05-14 05:02:35.136937: predicting 11397M_16_2 
2024-05-14 05:02:35.139626: 11397M_16_2, shape torch.Size([1, 50, 199, 273]), rank 0 
2024-05-14 05:02:36.896857: predicting 11427V_0_0 
2024-05-14 05:02:36.899987: 11427V_0_0, shape torch.Size([1, 46, 207, 275]), rank 0 
2024-05-14 05:02:37.787487: predicting 11431M_8_2 
2024-05-14 05:02:37.790243: 11431M_8_2, shape torch.Size([1, 50, 204, 269]), rank 0 
2024-05-14 05:02:39.543830: predicting 11433Q_4_3 
2024-05-14 05:02:39.545259: 11433Q_4_3, shape torch.Size([1, 50, 199, 273]), rank 0 
2024-05-14 05:02:41.293181: predicting 11443T_0_0 
2024-05-14 05:02:41.297287: 11443T_0_0, shape torch.Size([1, 48, 187, 281]), rank 0 
2024-05-14 05:02:41.754785: predicting 11480Z_4_3 
2024-05-14 05:02:41.756361: 11480Z_4_3, shape torch.Size([1, 52, 191, 279]), rank 0 
2024-05-14 05:02:42.642955: predicting 11488P_4_3 
2024-05-14 05:02:42.646705: 11488P_4_3, shape torch.Size([1, 48, 200, 267]), rank 0 
2024-05-14 05:02:43.531885: predicting 11500F_8_2 
2024-05-14 05:02:43.533219: 11500F_8_2, shape torch.Size([1, 52, 192, 270]), rank 0 
2024-05-14 05:02:44.412536: predicting 11502J_16_2 
2024-05-14 05:02:44.416037: 11502J_16_2, shape torch.Size([1, 51, 171, 250]), rank 0 
2024-05-14 05:02:44.869970: predicting 11504N_16_2 
2024-05-14 05:02:44.873073: 11504N_16_2, shape torch.Size([1, 52, 192, 272]), rank 0 
2024-05-14 05:02:45.757476: predicting 11515S_16_2 
2024-05-14 05:02:45.760315: 11515S_16_2, shape torch.Size([1, 48, 194, 269]), rank 0 
2024-05-14 05:02:46.645414: predicting 11518Y_16_2 
2024-05-14 05:02:46.646767: 11518Y_16_2, shape torch.Size([1, 46, 203, 282]), rank 0 
2024-05-14 05:02:47.525665: predicting 11529D_4_3 
2024-05-14 05:02:47.528463: 11529D_4_3, shape torch.Size([1, 42, 196, 254]), rank 0 
2024-05-14 05:02:52.868362: predicting 11534W_4_2 
2024-05-14 05:02:52.872248: 11534W_4_2, shape torch.Size([1, 47, 208, 275]), rank 0 
2024-05-14 05:02:53.763746: predicting 11575K_16_2 
2024-05-14 05:02:53.766353: 11575K_16_2, shape torch.Size([1, 51, 191, 278]), rank 0 
2024-05-14 05:02:54.655069: predicting 11578Q_16_2 
2024-05-14 05:02:54.657704: 11578Q_16_2, shape torch.Size([1, 32, 199, 276]), rank 0 
2024-05-14 05:02:55.536305: predicting 11603P_16_2 
2024-05-14 05:02:55.539236: 11603P_16_2, shape torch.Size([1, 50, 198, 281]), rank 0 
2024-05-14 05:02:57.288818: predicting 11605T_16_2 
2024-05-14 05:02:57.290981: 11605T_16_2, shape torch.Size([1, 51, 207, 265]), rank 0 
2024-05-14 05:02:59.041822: predicting 11636E_8_2 
2024-05-14 05:02:59.044323: 11636E_8_2, shape torch.Size([1, 48, 196, 277]), rank 0 
2024-05-14 05:02:59.927994: predicting 11644D_16_2 
2024-05-14 05:02:59.929939: 11644D_16_2, shape torch.Size([1, 43, 197, 273]), rank 0 
2024-05-14 05:03:00.808175: predicting 11651A_0_0 
2024-05-14 05:03:00.810646: 11651A_0_0, shape torch.Size([1, 52, 209, 273]), rank 0 
2024-05-14 05:03:02.563333: predicting 11676Q_16_2 
2024-05-14 05:03:02.566461: 11676Q_16_2, shape torch.Size([1, 48, 209, 277]), rank 0 
2024-05-14 05:03:03.452487: predicting 11690K_8_2 
2024-05-14 05:03:03.455462: 11690K_8_2, shape torch.Size([1, 46, 200, 275]), rank 0 
2024-05-14 05:03:04.341068: predicting 11700N_16_2 
2024-05-14 05:03:04.343989: 11700N_16_2, shape torch.Size([1, 42, 187, 260]), rank 0 
2024-05-14 05:03:04.794548: predicting 11708D_16_2 
2024-05-14 05:03:04.795791: 11708D_16_2, shape torch.Size([1, 50, 204, 278]), rank 0 
2024-05-14 05:03:06.539963: predicting 11731Y_4_3 
2024-05-14 05:03:06.542489: 11731Y_4_3, shape torch.Size([1, 52, 194, 276]), rank 0 
2024-05-14 05:03:08.295308: predicting 11769X_4_3 
2024-05-14 05:03:08.296315: 11769X_4_3, shape torch.Size([1, 46, 200, 287]), rank 0 
2024-05-14 05:03:09.174628: predicting 11776U_16_2 
2024-05-14 05:03:09.177531: 11776U_16_2, shape torch.Size([1, 45, 198, 277]), rank 0 
2024-05-14 05:03:10.062935: predicting 11785V_4_3 
2024-05-14 05:03:10.065797: 11785V_4_3, shape torch.Size([1, 52, 208, 278]), rank 0 
2024-05-14 05:03:11.820373: predicting 11822B_16_2 
2024-05-14 05:03:11.824015: 11822B_16_2, shape torch.Size([1, 41, 201, 267]), rank 0 
2024-05-14 05:03:12.720232: predicting 11848T_0_0 
2024-05-14 05:03:12.722679: 11848T_0_0, shape torch.Size([1, 48, 198, 271]), rank 0 
2024-05-14 05:03:13.607144: predicting 11862N_0_0 
2024-05-14 05:03:13.609447: 11862N_0_0, shape torch.Size([1, 52, 201, 288]), rank 0 
2024-05-14 05:03:15.356752: predicting 11879E_8_3 
2024-05-14 05:03:15.359656: 11879E_8_3, shape torch.Size([1, 43, 205, 282]), rank 0 
2024-05-14 05:03:16.247150: predicting 11882T_8_2 
2024-05-14 05:03:16.249415: 11882T_8_2, shape torch.Size([1, 41, 190, 262]), rank 0 
2024-05-14 05:03:16.701812: predicting 11911A_8_2 
2024-05-14 05:03:16.704624: 11911A_8_2, shape torch.Size([1, 47, 196, 272]), rank 0 
2024-05-14 05:03:17.591220: predicting 11914G_0_0 
2024-05-14 05:03:17.593692: 11914G_0_0, shape torch.Size([1, 47, 196, 272]), rank 0 
2024-05-14 05:03:18.480832: predicting 11922F_16_2 
2024-05-14 05:03:18.483693: 11922F_16_2, shape torch.Size([1, 44, 199, 274]), rank 0 
2024-05-14 05:03:19.373196: predicting 11947V_4_2 
2024-05-14 05:03:19.374580: 11947V_4_2, shape torch.Size([1, 49, 212, 273]), rank 0 
2024-05-14 05:03:21.122195: predicting 11950K_4_3 
2024-05-14 05:03:21.125811: 11950K_4_3, shape torch.Size([1, 46, 197, 276]), rank 0 
2024-05-14 05:03:22.015716: predicting 11955U_16_2 
2024-05-14 05:03:22.017386: 11955U_16_2, shape torch.Size([1, 44, 196, 275]), rank 0 
2024-05-14 05:03:22.894369: predicting 11966Z_4_2 
2024-05-14 05:03:22.897850: 11966Z_4_2, shape torch.Size([1, 52, 198, 273]), rank 0 
2024-05-14 05:03:24.652914: predicting 11974Y_16_2 
2024-05-14 05:03:24.655809: 11974Y_16_2, shape torch.Size([1, 35, 201, 267]), rank 0 
2024-05-14 05:03:25.541226: predicting 11991Y_16_2 
2024-05-14 05:03:25.543919: 11991Y_16_2, shape torch.Size([1, 51, 203, 269]), rank 0 
2024-05-14 05:03:27.298657: predicting 11998M_16_2 
2024-05-14 05:03:27.301709: 11998M_16_2, shape torch.Size([1, 51, 198, 266]), rank 0 
2024-05-14 05:03:29.055255: predicting 12015D_8_2 
2024-05-14 05:03:29.058191: 12015D_8_2, shape torch.Size([1, 43, 197, 270]), rank 0 
2024-05-14 05:03:29.945348: predicting 12017H_8_3 
2024-05-14 05:03:29.948256: 12017H_8_3, shape torch.Size([1, 45, 202, 265]), rank 0 
2024-05-14 05:03:30.837088: predicting 12030Z_4_2 
2024-05-14 05:03:30.840414: 12030Z_4_2, shape torch.Size([1, 48, 198, 278]), rank 0 
2024-05-14 05:03:31.731831: predicting 12032D_8_3 
2024-05-14 05:03:31.734780: 12032D_8_3, shape torch.Size([1, 52, 199, 281]), rank 0 
2024-05-14 05:03:33.490929: predicting 12033F_16_2 
2024-05-14 05:03:33.494004: 12033F_16_2, shape torch.Size([1, 48, 201, 277]), rank 0 
2024-05-14 05:03:34.379226: predicting 12052J_4_2 
2024-05-14 05:03:34.382148: 12052J_4_2, shape torch.Size([1, 49, 203, 297]), rank 0 
2024-05-14 05:03:36.138704: predicting 12067W_8_2 
2024-05-14 05:03:36.141731: 12067W_8_2, shape torch.Size([1, 48, 190, 267]), rank 0 
2024-05-14 05:03:36.596615: predicting 12069A_16_2 
2024-05-14 05:03:36.599479: 12069A_16_2, shape torch.Size([1, 46, 198, 278]), rank 0 
2024-05-14 05:03:37.487430: predicting 12073R_4_3 
2024-05-14 05:03:37.490076: 12073R_4_3, shape torch.Size([1, 46, 196, 268]), rank 0 
2024-05-14 05:03:38.378117: predicting 12074T_4_2 
2024-05-14 05:03:38.380671: 12074T_4_2, shape torch.Size([1, 49, 198, 264]), rank 0 
2024-05-14 05:03:40.138110: predicting 12083U_8_3 
2024-05-14 05:03:40.140764: 12083U_8_3, shape torch.Size([1, 45, 197, 273]), rank 0 
2024-05-14 05:03:41.029704: predicting 12109M_8_2 
2024-05-14 05:03:41.032546: 12109M_8_2, shape torch.Size([1, 50, 209, 282]), rank 0 
2024-05-14 05:03:42.791654: predicting 12112B_4_3 
2024-05-14 05:03:42.792970: 12112B_4_3, shape torch.Size([1, 42, 204, 282]), rank 0 
2024-05-14 05:03:43.672054: predicting 12114F_8_2 
2024-05-14 05:03:43.674705: 12114F_8_2, shape torch.Size([1, 33, 201, 271]), rank 0 
2024-05-14 05:03:44.558555: predicting 12123G_8_2 
2024-05-14 05:03:44.561315: 12123G_8_2, shape torch.Size([1, 42, 198, 278]), rank 0 
2024-05-14 05:03:45.446862: predicting 12126M_16_2 
2024-05-14 05:03:45.448994: 12126M_16_2, shape torch.Size([1, 49, 205, 279]), rank 0 
2024-05-14 05:03:47.200029: predicting 12135N_4_2 
2024-05-14 05:03:47.203262: 12135N_4_2, shape torch.Size([1, 44, 197, 267]), rank 0 
2024-05-14 05:03:48.089856: predicting 12142K_4_2 
2024-05-14 05:03:48.091152: 12142K_4_2, shape torch.Size([1, 44, 197, 271]), rank 0 
2024-05-14 05:03:48.970323: predicting 12147U_16_2 
2024-05-14 05:03:48.972732: 12147U_16_2, shape torch.Size([1, 44, 210, 281]), rank 0 
2024-05-14 05:03:49.861124: predicting 12170P_8_3 
2024-05-14 05:03:49.864030: 12170P_8_3, shape torch.Size([1, 36, 197, 269]), rank 0 
2024-05-14 05:03:50.753418: predicting 12180S_8_3 
2024-05-14 05:03:50.754636: 12180S_8_3, shape torch.Size([1, 51, 197, 276]), rank 0 
2024-05-14 05:03:52.504460: predicting 12203E_4_3 
2024-05-14 05:03:52.507270: 12203E_4_3, shape torch.Size([1, 48, 200, 264]), rank 0 
2024-05-14 05:03:53.393224: predicting 12216N_16_2 
2024-05-14 05:03:53.396185: 12216N_16_2, shape torch.Size([1, 46, 204, 277]), rank 0 
2024-05-14 05:03:54.285982: predicting 12223K_0_0 
2024-05-14 05:03:54.289309: 12223K_0_0, shape torch.Size([1, 44, 206, 268]), rank 0 
2024-05-14 05:03:55.175930: predicting 12224M_16_2 
2024-05-14 05:03:55.178961: 12224M_16_2, shape torch.Size([1, 52, 208, 269]), rank 0 
2024-05-14 05:03:56.935840: predicting 12228U_16_2 
2024-05-14 05:03:56.938806: 12228U_16_2, shape torch.Size([1, 46, 195, 282]), rank 0 
2024-05-14 05:03:57.827865: predicting 12231J_4_2 
2024-05-14 05:03:57.829212: 12231J_4_2, shape torch.Size([1, 48, 210, 275]), rank 0 
2024-05-14 05:03:58.710170: predicting 12249C_8_3 
2024-05-14 05:03:58.713397: 12249C_8_3, shape torch.Size([1, 45, 180, 272]), rank 0 
2024-05-14 05:03:59.165777: predicting 12250N_0_0 
2024-05-14 05:03:59.168670: 12250N_0_0, shape torch.Size([1, 45, 180, 272]), rank 0 
2024-05-14 05:03:59.621299: predicting 12255X_8_3 
2024-05-14 05:03:59.623891: 12255X_8_3, shape torch.Size([1, 50, 192, 264]), rank 0 
2024-05-14 05:04:00.515403: predicting 12257B_16_2 
2024-05-14 05:04:00.518136: 12257B_16_2, shape torch.Size([1, 46, 194, 281]), rank 0 
2024-05-14 05:04:01.407161: predicting 12258D_8_3 
2024-05-14 05:04:01.409948: 12258D_8_3, shape torch.Size([1, 48, 203, 271]), rank 0 
2024-05-14 05:04:02.297732: predicting 12264Y_8_2 
2024-05-14 05:04:02.300253: 12264Y_8_2, shape torch.Size([1, 48, 197, 263]), rank 0 
2024-05-14 05:04:03.187860: predicting 12268G_16_2 
2024-05-14 05:04:03.190368: 12268G_16_2, shape torch.Size([1, 52, 200, 277]), rank 0 
2024-05-14 05:04:04.949422: predicting 12282A_0_0 
2024-05-14 05:04:04.952608: 12282A_0_0, shape torch.Size([1, 46, 199, 269]), rank 0 
2024-05-14 05:04:05.841978: predicting 12296L_4_2 
2024-05-14 05:04:05.844197: 12296L_4_2, shape torch.Size([1, 48, 198, 267]), rank 0 
2024-05-14 05:04:06.724562: predicting 12297N_8_2 
2024-05-14 05:04:06.726132: 12297N_8_2, shape torch.Size([1, 48, 206, 263]), rank 0 
2024-05-14 05:04:07.606386: predicting 12339D_0_0 
2024-05-14 05:04:07.609733: 12339D_0_0, shape torch.Size([1, 46, 205, 273]), rank 0 
2024-05-14 05:04:08.498871: predicting 12345Y_16_2 
2024-05-14 05:04:08.501471: 12345Y_16_2, shape torch.Size([1, 43, 192, 265]), rank 0 
2024-05-14 05:04:08.955782: predicting 12347C_16_2 
2024-05-14 05:04:08.958310: 12347C_16_2, shape torch.Size([1, 38, 208, 270]), rank 0 
2024-05-14 05:04:09.840204: predicting 12355B_0_0 
2024-05-14 05:04:09.843548: 12355B_0_0, shape torch.Size([1, 46, 209, 275]), rank 0 
2024-05-14 05:04:10.733044: predicting 12371Z_0_0 
2024-05-14 05:04:10.735667: 12371Z_0_0, shape torch.Size([1, 52, 201, 277]), rank 0 
2024-05-14 05:04:12.493521: predicting 12388Q_8_3 
2024-05-14 05:04:12.496349: 12388Q_8_3, shape torch.Size([1, 50, 208, 288]), rank 0 
2024-05-14 05:04:14.255054: predicting 12395N_0_0 
2024-05-14 05:04:14.257571: 12395N_0_0, shape torch.Size([1, 43, 193, 274]), rank 0 
2024-05-14 05:04:15.144023: predicting 12407U_16_2 
2024-05-14 05:04:15.147462: 12407U_16_2, shape torch.Size([1, 48, 204, 277]), rank 0 
2024-05-14 05:04:16.034632: predicting 12432T_16_2 
2024-05-14 05:04:16.037108: 12432T_16_2, shape torch.Size([1, 50, 194, 275]), rank 0 
2024-05-14 05:04:17.789911: predicting 12434X_16_2 
2024-05-14 05:04:17.793159: 12434X_16_2, shape torch.Size([1, 44, 198, 278]), rank 0 
2024-05-14 05:04:18.680894: predicting 12435Z_16_2 
2024-05-14 05:04:18.684515: 12435Z_16_2, shape torch.Size([1, 46, 201, 278]), rank 0 
2024-05-14 05:04:19.573593: predicting 12458L_16_2 
2024-05-14 05:04:19.576161: 12458L_16_2, shape torch.Size([1, 44, 210, 280]), rank 0 
2024-05-14 05:04:20.456741: predicting 12463E_8_3 
2024-05-14 05:04:20.459674: 12463E_8_3, shape torch.Size([1, 49, 202, 267]), rank 0 
2024-05-14 05:04:22.217376: predicting 12478R_0_0 
2024-05-14 05:04:22.219603: 12478R_0_0, shape torch.Size([1, 37, 202, 270]), rank 0 
2024-05-14 05:04:23.098182: predicting 12486Q_0_0 
2024-05-14 05:04:23.099463: 12486Q_0_0, shape torch.Size([1, 51, 205, 271]), rank 0 
2024-05-14 05:04:24.851243: predicting 12487S_4_3 
2024-05-14 05:04:24.854208: 12487S_4_3, shape torch.Size([1, 52, 195, 264]), rank 0 
2024-05-14 05:04:26.611875: predicting 12520Q_16_2 
2024-05-14 05:04:26.614818: 12520Q_16_2, shape torch.Size([1, 44, 197, 280]), rank 0 
2024-05-14 05:04:27.502648: predicting 12525A_0_0 
2024-05-14 05:04:27.505329: 12525A_0_0, shape torch.Size([1, 46, 209, 269]), rank 0 
2024-05-14 05:04:28.393847: predicting 12531V_8_2 
2024-05-14 05:04:28.395909: 12531V_8_2, shape torch.Size([1, 48, 187, 251]), rank 0 
2024-05-14 05:04:28.627029: predicting 12537H_4_2 
2024-05-14 05:04:28.629294: 12537H_4_2, shape torch.Size([1, 46, 203, 280]), rank 0 
2024-05-14 05:04:29.518622: predicting 12547K_16_2 
2024-05-14 05:04:29.521286: 12547K_16_2, shape torch.Size([1, 33, 201, 273]), rank 0 
2024-05-14 05:04:30.408892: predicting 12551B_8_2 
2024-05-14 05:04:30.412116: 12551B_8_2, shape torch.Size([1, 52, 200, 276]), rank 0 
2024-05-14 05:04:32.169903: predicting 12556L_8_3 
2024-05-14 05:04:32.172835: 12556L_8_3, shape torch.Size([1, 50, 205, 282]), rank 0 
2024-05-14 05:04:33.931051: predicting 12558P_0_0 
2024-05-14 05:04:33.933641: 12558P_0_0, shape torch.Size([1, 50, 205, 282]), rank 0 
2024-05-14 05:04:35.691852: predicting 12576R_8_2 
2024-05-14 05:04:35.695277: 12576R_8_2, shape torch.Size([1, 50, 187, 267]), rank 0 
2024-05-14 05:04:36.583751: predicting 12578V_4_2 
2024-05-14 05:04:36.587028: 12578V_4_2, shape torch.Size([1, 47, 202, 277]), rank 0 
2024-05-14 05:04:37.476740: predicting 12579X_8_2 
2024-05-14 05:04:37.480486: 12579X_8_2, shape torch.Size([1, 44, 200, 277]), rank 0 
2024-05-14 05:04:38.380749: predicting 12618H_4_2 
2024-05-14 05:04:38.383390: 12618H_4_2, shape torch.Size([1, 46, 204, 276]), rank 0 
2024-05-14 05:04:39.273408: predicting 12619J_4_3 
2024-05-14 05:04:39.276611: 12619J_4_3, shape torch.Size([1, 50, 208, 279]), rank 0 
2024-05-14 05:04:41.035570: predicting 12632B_16_2 
2024-05-14 05:04:41.038844: 12632B_16_2, shape torch.Size([1, 48, 201, 280]), rank 0 
2024-05-14 05:04:41.927011: predicting 12636J_16_2 
2024-05-14 05:04:41.930092: 12636J_16_2, shape torch.Size([1, 44, 198, 278]), rank 0 
2024-05-14 05:04:42.818121: predicting 12651F_0_0 
2024-05-14 05:04:42.821497: 12651F_0_0, shape torch.Size([1, 52, 186, 272]), rank 0 
2024-05-14 05:04:43.714520: predicting 12669Y_0_0 
2024-05-14 05:04:43.717057: 12669Y_0_0, shape torch.Size([1, 44, 208, 276]), rank 0 
2024-05-14 05:04:44.607590: predicting 12671L_8_3 
2024-05-14 05:04:44.610164: 12671L_8_3, shape torch.Size([1, 43, 193, 276]), rank 0 
2024-05-14 05:04:45.498334: predicting 12697D_4_2 
2024-05-14 05:04:45.499623: 12697D_4_2, shape torch.Size([1, 44, 210, 274]), rank 0 
2024-05-14 05:04:46.382588: predicting 12719N_16_2 
2024-05-14 05:04:46.383905: 12719N_16_2, shape torch.Size([1, 46, 208, 270]), rank 0 
2024-05-14 05:04:47.266463: predicting 12720Y_4_2 
2024-05-14 05:04:47.269157: 12720Y_4_2, shape torch.Size([1, 50, 177, 267]), rank 0 
2024-05-14 05:04:48.158617: predicting 12724G_8_2 
2024-05-14 05:04:48.159935: 12724G_8_2, shape torch.Size([1, 35, 207, 266]), rank 0 
2024-05-14 05:04:49.039482: predicting 12746Q_4_3 
2024-05-14 05:04:49.042622: 12746Q_4_3, shape torch.Size([1, 42, 194, 267]), rank 0 
2024-05-14 05:04:49.932617: predicting 12755R_0_0 
2024-05-14 05:04:49.935984: 12755R_0_0, shape torch.Size([1, 42, 198, 268]), rank 0 
2024-05-14 05:04:50.823551: predicting 12757V_8_3 
2024-05-14 05:04:50.826342: 12757V_8_3, shape torch.Size([1, 44, 205, 265]), rank 0 
2024-05-14 05:04:51.723547: predicting 12763Q_4_2 
2024-05-14 05:04:51.726542: 12763Q_4_2, shape torch.Size([1, 50, 202, 268]), rank 0 
2024-05-14 05:04:53.485214: predicting 12766W_0_0 
2024-05-14 05:04:53.488469: 12766W_0_0, shape torch.Size([1, 50, 202, 268]), rank 0 
2024-05-14 05:04:55.247049: predicting 12791V_0_0 
2024-05-14 05:04:55.249523: 12791V_0_0, shape torch.Size([1, 47, 205, 270]), rank 0 
2024-05-14 05:04:56.140883: predicting 12827Q_16_2 
2024-05-14 05:04:56.144170: 12827Q_16_2, shape torch.Size([1, 46, 188, 258]), rank 0 
2024-05-14 05:04:56.602561: predicting 12828S_0_0 
2024-05-14 05:04:56.605302: 12828S_0_0, shape torch.Size([1, 46, 188, 258]), rank 0 
2024-05-14 05:04:57.060186: predicting 12830F_0_0 
2024-05-14 05:04:57.062671: 12830F_0_0, shape torch.Size([1, 48, 206, 277]), rank 0 
2024-05-14 05:04:57.951504: predicting 12833L_4_3 
2024-05-14 05:04:57.953815: 12833L_4_3, shape torch.Size([1, 46, 206, 268]), rank 0 
2024-05-14 05:04:58.845660: predicting 12839X_8_3 
2024-05-14 05:04:58.849121: 12839X_8_3, shape torch.Size([1, 43, 182, 269]), rank 0 
2024-05-14 05:04:59.301844: predicting 12861Q_4_2 
2024-05-14 05:04:59.303951: 12861Q_4_2, shape torch.Size([1, 44, 198, 277]), rank 0 
2024-05-14 05:05:00.187190: predicting 12862S_4_3 
2024-05-14 05:05:00.189375: 12862S_4_3, shape torch.Size([1, 50, 203, 266]), rank 0 
2024-05-14 05:05:01.947499: predicting 12867C_4_3 
2024-05-14 05:05:01.950090: 12867C_4_3, shape torch.Size([1, 50, 215, 285]), rank 0 
2024-05-14 05:05:03.709054: predicting 12871T_4_2 
2024-05-14 05:05:03.710379: 12871T_4_2, shape torch.Size([1, 44, 203, 278]), rank 0 
2024-05-14 05:05:04.592969: predicting 12885E_0_0 
2024-05-14 05:05:04.596290: 12885E_0_0, shape torch.Size([1, 46, 208, 269]), rank 0 
2024-05-14 05:05:05.485198: predicting 12908Q_16_2 
2024-05-14 05:05:05.488397: 12908Q_16_2, shape torch.Size([1, 50, 202, 275]), rank 0 
2024-05-14 05:05:07.249592: predicting 12914L_4_2 
2024-05-14 05:05:07.252744: 12914L_4_2, shape torch.Size([1, 48, 209, 266]), rank 0 
2024-05-14 05:05:08.139961: predicting 12918T_0_0 
2024-05-14 05:05:08.142864: 12918T_0_0, shape torch.Size([1, 48, 209, 266]), rank 0 
2024-05-14 05:05:09.029413: predicting 12929Y_4_3 
2024-05-14 05:05:09.032368: 12929Y_4_3, shape torch.Size([1, 46, 202, 278]), rank 0 
2024-05-14 05:05:09.921180: predicting 12935T_4_2 
2024-05-14 05:05:09.924387: 12935T_4_2, shape torch.Size([1, 46, 209, 275]), rank 0 
2024-05-14 05:05:10.812578: predicting 12939B_16_2 
2024-05-14 05:05:10.816124: 12939B_16_2, shape torch.Size([1, 43, 200, 275]), rank 0 
2024-05-14 05:05:11.704618: predicting 12942Q_16_2 
2024-05-14 05:05:11.707557: 12942Q_16_2, shape torch.Size([1, 44, 190, 257]), rank 0 
2024-05-14 05:05:12.161210: predicting 12956B_8_3 
2024-05-14 05:05:12.164253: 12956B_8_3, shape torch.Size([1, 46, 199, 276]), rank 0 
2024-05-14 05:05:13.052948: predicting 12987M_8_3 
2024-05-14 05:05:13.055907: 12987M_8_3, shape torch.Size([1, 45, 198, 269]), rank 0 
2024-05-14 05:05:13.944089: predicting 12998R_0_0 
2024-05-14 05:05:13.947071: 12998R_0_0, shape torch.Size([1, 47, 202, 264]), rank 0 
2024-05-14 05:05:14.836350: predicting 13007J_16_2 
2024-05-14 05:05:14.838623: 13007J_16_2, shape torch.Size([1, 30, 203, 270]), rank 0 
2024-05-14 05:05:15.716648: predicting 13034M_4_2 
2024-05-14 05:05:15.719170: 13034M_4_2, shape torch.Size([1, 49, 205, 275]), rank 0 
2024-05-14 05:05:17.478712: predicting 13042L_8_2 
2024-05-14 05:05:17.480083: 13042L_8_2, shape torch.Size([1, 46, 215, 274]), rank 0 
2024-05-14 05:05:18.361188: predicting 13047V_16_2 
2024-05-14 05:05:18.363719: 13047V_16_2, shape torch.Size([1, 47, 208, 284]), rank 0 
2024-05-14 05:05:19.253233: predicting 13054S_0_0 
2024-05-14 05:05:19.256070: 13054S_0_0, shape torch.Size([1, 43, 206, 285]), rank 0 
2024-05-14 05:05:20.150976: predicting 13065X_16_2 
2024-05-14 05:05:20.153455: 13065X_16_2, shape torch.Size([1, 48, 207, 273]), rank 0 
2024-05-14 05:05:21.040313: predicting 13066Z_8_3 
2024-05-14 05:05:21.041661: 13066Z_8_3, shape torch.Size([1, 38, 183, 262]), rank 0 
2024-05-14 05:05:21.486451: predicting 13072U_16_2 
2024-05-14 05:05:21.489553: 13072U_16_2, shape torch.Size([1, 39, 195, 261]), rank 0 
2024-05-14 05:05:22.374234: predicting 13076C_8_3 
2024-05-14 05:05:22.377203: 13076C_8_3, shape torch.Size([1, 43, 205, 263]), rank 0 
2024-05-14 05:05:23.263812: predicting 13077E_4_3 
2024-05-14 05:05:23.266318: 13077E_4_3, shape torch.Size([1, 49, 202, 274]), rank 0 
2024-05-14 05:05:25.021835: predicting 13086F_0_0 
2024-05-14 05:05:25.025403: 13086F_0_0, shape torch.Size([1, 50, 202, 286]), rank 0 
2024-05-14 05:05:26.784218: predicting 13087H_16_2 
2024-05-14 05:05:26.786738: 13087H_16_2, shape torch.Size([1, 46, 196, 277]), rank 0 
2024-05-14 05:05:27.677818: predicting 13090W_4_2 
2024-05-14 05:05:27.680912: 13090W_4_2, shape torch.Size([1, 46, 199, 267]), rank 0 
2024-05-14 05:05:28.568988: predicting 13098M_8_3 
2024-05-14 05:05:28.571923: 13098M_8_3, shape torch.Size([1, 43, 196, 286]), rank 0 
2024-05-14 05:05:29.460163: predicting 13107N_0_0 
2024-05-14 05:05:29.463080: 13107N_0_0, shape torch.Size([1, 43, 193, 276]), rank 0 
2024-05-14 05:05:30.351473: predicting 13110C_0_0 
2024-05-14 05:05:30.354333: 13110C_0_0, shape torch.Size([1, 25, 204, 270]), rank 0 
2024-05-14 05:05:31.233471: predicting 13120F_0_0 
2024-05-14 05:05:31.234691: 13120F_0_0, shape torch.Size([1, 50, 202, 287]), rank 0 
2024-05-14 05:05:32.984360: predicting 13131K_4_2 
2024-05-14 05:05:32.988513: 13131K_4_2, shape torch.Size([1, 51, 203, 281]), rank 0 
2024-05-14 05:05:34.747143: predicting 13141N_16_2 
2024-05-14 05:05:34.750498: 13141N_16_2, shape torch.Size([1, 42, 196, 272]), rank 0 
2024-05-14 05:05:35.636970: predicting 13152S_4_2 
2024-05-14 05:05:35.639740: 13152S_4_2, shape torch.Size([1, 42, 212, 284]), rank 0 
2024-05-14 05:05:36.528867: predicting 13191C_4_2 
2024-05-14 05:05:36.531741: 13191C_4_2, shape torch.Size([1, 43, 196, 274]), rank 0 
2024-05-14 05:05:37.418840: predicting 13208T_4_3 
2024-05-14 05:05:37.421404: 13208T_4_3, shape torch.Size([1, 49, 209, 282]), rank 0 
2024-05-14 05:05:39.181120: predicting 13225T_16_2 
2024-05-14 05:05:39.184311: 13225T_16_2, shape torch.Size([1, 46, 207, 264]), rank 0 
2024-05-14 05:05:40.072283: predicting 13230M_8_2 
2024-05-14 05:05:40.074486: 13230M_8_2, shape torch.Size([1, 44, 210, 281]), rank 0 
2024-05-14 05:05:40.964488: predicting 13234U_4_2 
2024-05-14 05:05:40.967450: 13234U_4_2, shape torch.Size([1, 48, 194, 265]), rank 0 
2024-05-14 05:05:41.854399: predicting 13240P_16_2 
2024-05-14 05:05:41.857441: 13240P_16_2, shape torch.Size([1, 45, 214, 281]), rank 0 
2024-05-14 05:05:42.746761: predicting 13244X_0_0 
2024-05-14 05:05:42.749669: 13244X_0_0, shape torch.Size([1, 43, 204, 276]), rank 0 
2024-05-14 05:05:43.636553: predicting 13252W_4_3 
2024-05-14 05:05:43.639525: 13252W_4_3, shape torch.Size([1, 41, 202, 265]), rank 0 
2024-05-14 05:05:44.528273: predicting 13255C_8_3 
2024-05-14 05:05:44.532154: 13255C_8_3, shape torch.Size([1, 48, 211, 290]), rank 0 
2024-05-14 05:05:45.424514: predicting 13259K_16_2 
2024-05-14 05:05:45.427793: 13259K_16_2, shape torch.Size([1, 39, 202, 280]), rank 0 
2024-05-14 05:05:46.314085: predicting 13276K_16_2 
2024-05-14 05:05:46.316981: 13276K_16_2, shape torch.Size([1, 45, 208, 269]), rank 0 
2024-05-14 05:05:47.204839: predicting 13277M_4_2 
2024-05-14 05:05:47.207753: 13277M_4_2, shape torch.Size([1, 42, 195, 275]), rank 0 
2024-05-14 05:05:48.094285: predicting 13283H_4_3 
2024-05-14 05:05:48.097259: 13283H_4_3, shape torch.Size([1, 50, 202, 264]), rank 0 
2024-05-14 05:05:49.854188: predicting 13324V_16_2 
2024-05-14 05:05:49.857116: 13324V_16_2, shape torch.Size([1, 48, 202, 279]), rank 0 
2024-05-14 05:05:50.744871: predicting 13327B_0_0 
2024-05-14 05:05:50.748032: 13327B_0_0, shape torch.Size([1, 42, 213, 282]), rank 0 
2024-05-14 05:05:51.641540: predicting 13329F_4_2 
2024-05-14 05:05:51.644360: 13329F_4_2, shape torch.Size([1, 43, 218, 287]), rank 0 
2024-05-14 05:05:52.534757: predicting 13337E_8_2 
2024-05-14 05:05:52.537581: 13337E_8_2, shape torch.Size([1, 49, 201, 276]), rank 0 
2024-05-14 05:05:54.295045: predicting 13341V_0_0 
2024-05-14 05:05:54.298120: 13341V_0_0, shape torch.Size([1, 41, 206, 266]), rank 0 
2024-05-14 05:05:55.185039: predicting 13343Z_16_2 
2024-05-14 05:05:55.186367: 13343Z_16_2, shape torch.Size([1, 46, 204, 274]), rank 0 
2024-05-14 05:05:56.070127: predicting 13348J_16_2 
2024-05-14 05:05:56.073326: 13348J_16_2, shape torch.Size([1, 46, 204, 274]), rank 0 
2024-05-14 05:05:56.960671: predicting 13361B_4_3 
2024-05-14 05:05:56.964122: 13361B_4_3, shape torch.Size([1, 42, 203, 287]), rank 0 
2024-05-14 05:05:57.861050: predicting 13369R_0_0 
2024-05-14 05:05:57.864131: 13369R_0_0, shape torch.Size([1, 46, 207, 270]), rank 0 
2024-05-14 05:05:58.756218: predicting 13399A_0_0 
2024-05-14 05:05:58.759662: 13399A_0_0, shape torch.Size([1, 50, 192, 275]), rank 0 
2024-05-14 05:05:59.647352: predicting 13401N_0_0 
2024-05-14 05:05:59.650225: 13401N_0_0, shape torch.Size([1, 50, 192, 275]), rank 0 
2024-05-14 05:06:00.537244: predicting 13416A_4_3 
2024-05-14 05:06:00.539769: 13416A_4_3, shape torch.Size([1, 47, 198, 270]), rank 0 
2024-05-14 05:06:01.429644: predicting 13429J_4_3 
2024-05-14 05:06:01.432353: 13429J_4_3, shape torch.Size([1, 51, 215, 273]), rank 0 
2024-05-14 05:06:03.189382: predicting 13441Z_8_2 
2024-05-14 05:06:03.192197: 13441Z_8_2, shape torch.Size([1, 46, 201, 281]), rank 0 
2024-05-14 05:06:04.080326: predicting 13447L_0_0 
2024-05-14 05:06:04.083147: 13447L_0_0, shape torch.Size([1, 48, 207, 275]), rank 0 
2024-05-14 05:06:04.969202: predicting 13458Q_4_2 
2024-05-14 05:06:04.972149: 13458Q_4_2, shape torch.Size([1, 52, 208, 277]), rank 0 
2024-05-14 05:06:06.729354: predicting 13462H_16_2 
2024-05-14 05:06:06.731728: 13462H_16_2, shape torch.Size([1, 52, 194, 276]), rank 0 
2024-05-14 05:06:08.481756: predicting 13465N_8_3 
2024-05-14 05:06:08.484731: 13465N_8_3, shape torch.Size([1, 43, 206, 275]), rank 0 
2024-05-14 05:06:09.373660: predicting 13473M_4_3 
2024-05-14 05:06:09.376824: 13473M_4_3, shape torch.Size([1, 47, 195, 274]), rank 0 
2024-05-14 05:06:10.266388: predicting 13483P_0_0 
2024-05-14 05:06:10.269175: 13483P_0_0, shape torch.Size([1, 50, 190, 272]), rank 0 
2024-05-14 05:06:11.158473: predicting 13485T_4_2 
2024-05-14 05:06:11.161470: 13485T_4_2, shape torch.Size([1, 48, 202, 266]), rank 0 
2024-05-14 05:06:12.048443: predicting 13496Y_8_2 
2024-05-14 05:06:12.051118: 13496Y_8_2, shape torch.Size([1, 44, 203, 270]), rank 0 
2024-05-14 05:06:12.938757: predicting 13498C_4_3 
2024-05-14 05:06:12.941258: 13498C_4_3, shape torch.Size([1, 46, 212, 266]), rank 0 
2024-05-14 05:06:13.831248: predicting 13499E_8_2 
2024-05-14 05:06:13.833843: 13499E_8_2, shape torch.Size([1, 44, 206, 275]), rank 0 
2024-05-14 05:06:14.722591: predicting 13505Z_0_0 
2024-05-14 05:06:14.724552: 13505Z_0_0, shape torch.Size([1, 43, 196, 267]), rank 0 
2024-05-14 05:06:15.606512: predicting 13516E_4_2 
2024-05-14 05:06:15.609039: 13516E_4_2, shape torch.Size([1, 44, 205, 286]), rank 0 
2024-05-14 05:06:16.496961: predicting 13519K_8_3 
2024-05-14 05:06:16.498278: 13519K_8_3, shape torch.Size([1, 48, 208, 267]), rank 0 
2024-05-14 05:06:17.378241: predicting 13520V_4_2 
2024-05-14 05:06:17.381483: 13520V_4_2, shape torch.Size([1, 45, 196, 274]), rank 0 
2024-05-14 05:06:18.268944: predicting 13530Y_8_2 
2024-05-14 05:06:18.272015: 13530Y_8_2, shape torch.Size([1, 48, 205, 276]), rank 0 
2024-05-14 05:06:19.158173: predicting 13536K_8_3 
2024-05-14 05:06:19.161098: 13536K_8_3, shape torch.Size([1, 44, 207, 267]), rank 0 
2024-05-14 05:06:20.048999: predicting 13540B_4_2 
2024-05-14 05:06:20.050288: 13540B_4_2, shape torch.Size([1, 46, 198, 283]), rank 0 
2024-05-14 05:06:20.929916: predicting 13568X_4_3 
2024-05-14 05:06:20.932620: 13568X_4_3, shape torch.Size([1, 52, 195, 267]), rank 0 
2024-05-14 05:06:22.692087: predicting 13576W_16_2 
2024-05-14 05:06:22.694411: 13576W_16_2, shape torch.Size([1, 49, 198, 279]), rank 0 
2024-05-14 05:06:24.446415: predicting 13578A_16_2 
2024-05-14 05:06:24.448127: 13578A_16_2, shape torch.Size([1, 37, 192, 260]), rank 0 
2024-05-14 05:06:24.893012: predicting 13621B_4_2 
2024-05-14 05:06:24.895988: 13621B_4_2, shape torch.Size([1, 52, 211, 277]), rank 0 
2024-05-14 05:06:26.653498: predicting 13642J_0_0 
2024-05-14 05:06:26.654871: 13642J_0_0, shape torch.Size([1, 48, 204, 271]), rank 0 
2024-05-14 05:06:27.535206: predicting 13645P_4_2 
2024-05-14 05:06:27.538038: 13645P_4_2, shape torch.Size([1, 42, 202, 266]), rank 0 
2024-05-14 05:06:28.424441: predicting 13654Q_0_0 
2024-05-14 05:06:28.427332: 13654Q_0_0, shape torch.Size([1, 49, 211, 276]), rank 0 
2024-05-14 05:06:30.183954: predicting 13667Z_8_3 
2024-05-14 05:06:30.186774: 13667Z_8_3, shape torch.Size([1, 44, 201, 273]), rank 0 
2024-05-14 05:06:31.074552: predicting 13707L_0_0 
2024-05-14 05:06:31.075796: 13707L_0_0, shape torch.Size([1, 43, 188, 261]), rank 0 
2024-05-14 05:06:31.521423: predicting 13728T_0_0 
2024-05-14 05:06:31.523892: 13728T_0_0, shape torch.Size([1, 43, 191, 280]), rank 0 
2024-05-14 05:06:31.978500: predicting 13735Q_8_3 
2024-05-14 05:06:31.981502: 13735Q_8_3, shape torch.Size([1, 39, 198, 269]), rank 0 
2024-05-14 05:06:32.869958: predicting 13759E_0_0 
2024-05-14 05:06:32.873171: 13759E_0_0, shape torch.Size([1, 50, 208, 278]), rank 0 
2024-05-14 05:06:34.629397: predicting 13763V_4_3 
2024-05-14 05:06:34.632320: 13763V_4_3, shape torch.Size([1, 50, 205, 274]), rank 0 
2024-05-14 05:06:36.388535: predicting 13765Z_4_2 
2024-05-14 05:06:36.391999: 13765Z_4_2, shape torch.Size([1, 50, 195, 266]), rank 0 
2024-05-14 05:06:38.150209: predicting 13768F_16_2 
2024-05-14 05:06:38.153199: 13768F_16_2, shape torch.Size([1, 46, 208, 264]), rank 0 
2024-05-14 05:06:39.041768: predicting 13769H_4_3 
2024-05-14 05:06:39.045133: 13769H_4_3, shape torch.Size([1, 51, 206, 290]), rank 0 
2024-05-14 05:06:40.803313: predicting 13770S_16_2 
2024-05-14 05:06:40.806289: 13770S_16_2, shape torch.Size([1, 46, 213, 283]), rank 0 
2024-05-14 05:06:41.696128: predicting 13782Z_8_3 
2024-05-14 05:06:41.699228: 13782Z_8_3, shape torch.Size([1, 48, 209, 288]), rank 0 
2024-05-14 05:06:42.586093: predicting 13792C_8_3 
2024-05-14 05:06:42.588878: 13792C_8_3, shape torch.Size([1, 44, 206, 272]), rank 0 
2024-05-14 05:06:43.475747: predicting 13822L_0_0 
2024-05-14 05:06:43.478676: 13822L_0_0, shape torch.Size([1, 44, 202, 275]), rank 0 
2024-05-14 05:06:44.366996: predicting 13834S_0_0 
2024-05-14 05:06:44.369486: 13834S_0_0, shape torch.Size([1, 50, 205, 279]), rank 0 
2024-05-14 05:06:46.124991: predicting 13840N_4_2 
2024-05-14 05:06:46.127452: 13840N_4_2, shape torch.Size([1, 49, 199, 270]), rank 0 
2024-05-14 05:06:47.884490: predicting 13855A_0_0 
2024-05-14 05:06:47.887888: 13855A_0_0, shape torch.Size([1, 52, 213, 272]), rank 0 
2024-05-14 05:06:49.645787: predicting 13856C_4_2 
2024-05-14 05:06:49.648708: 13856C_4_2, shape torch.Size([1, 51, 210, 275]), rank 0 
2024-05-14 05:06:51.405166: predicting 13862X_16_2 
2024-05-14 05:06:51.406528: 13862X_16_2, shape torch.Size([1, 44, 201, 266]), rank 0 
2024-05-14 05:06:52.285831: predicting 13867H_4_2 
2024-05-14 05:06:52.288820: 13867H_4_2, shape torch.Size([1, 44, 200, 268]), rank 0 
2024-05-14 05:06:53.175794: predicting 13883F_8_3 
2024-05-14 05:06:53.178660: 13883F_8_3, shape torch.Size([1, 38, 200, 266]), rank 0 
2024-05-14 05:06:54.063758: predicting 13888P_8_2 
2024-05-14 05:06:54.066734: 13888P_8_2, shape torch.Size([1, 46, 194, 264]), rank 0 
2024-05-14 05:06:54.954404: predicting 13892G_4_2 
2024-05-14 05:06:54.957326: 13892G_4_2, shape torch.Size([1, 46, 200, 275]), rank 0 
2024-05-14 05:06:55.847754: predicting 13894K_8_2 
2024-05-14 05:06:55.850779: 13894K_8_2, shape torch.Size([1, 46, 192, 261]), rank 0 
2024-05-14 05:06:56.304125: predicting 13923R_0_0 
2024-05-14 05:06:56.305276: 13923R_0_0, shape torch.Size([1, 46, 207, 269]), rank 0 
2024-05-14 05:06:57.185536: predicting 13925V_8_3 
2024-05-14 05:06:57.188644: 13925V_8_3, shape torch.Size([1, 46, 189, 264]), rank 0 
2024-05-14 05:06:57.642261: predicting 13929D_8_3 
2024-05-14 05:06:57.645089: 13929D_8_3, shape torch.Size([1, 40, 206, 268]), rank 0 
2024-05-14 05:06:58.530596: predicting 13936A_16_2 
2024-05-14 05:06:58.531881: 13936A_16_2, shape torch.Size([1, 46, 195, 266]), rank 0 
2024-05-14 05:06:59.410821: predicting 13941T_16_2 
2024-05-14 05:06:59.412704: 13941T_16_2, shape torch.Size([1, 44, 198, 282]), rank 0 
2024-05-14 05:07:00.292801: predicting 13949J_4_3 
2024-05-14 05:07:00.296416: 13949J_4_3, shape torch.Size([1, 48, 198, 267]), rank 0 
2024-05-14 05:07:01.181754: predicting 13971C_0_0 
2024-05-14 05:07:01.184726: 13971C_0_0, shape torch.Size([1, 47, 208, 271]), rank 0 
2024-05-14 05:07:02.072447: predicting 13980D_0_0 
2024-05-14 05:07:02.076409: 13980D_0_0, shape torch.Size([1, 42, 188, 274]), rank 0 
2024-05-14 05:07:02.537385: predicting 14011F_0_0 
2024-05-14 05:07:02.540418: 14011F_0_0, shape torch.Size([1, 50, 201, 269]), rank 0 
2024-05-14 05:07:04.301792: predicting 14016P_4_3 
2024-05-14 05:07:04.304860: 14016P_4_3, shape torch.Size([1, 48, 207, 277]), rank 0 
2024-05-14 05:07:05.193362: predicting 14023M_16_2 
2024-05-14 05:07:05.195774: 14023M_16_2, shape torch.Size([1, 43, 202, 271]), rank 0 
2024-05-14 05:07:06.076478: predicting 14066E_16_2 
2024-05-14 05:07:06.080030: 14066E_16_2, shape torch.Size([1, 47, 203, 272]), rank 0 
2024-05-14 05:07:06.973293: predicting 14075F_8_2 
2024-05-14 05:07:06.976080: 14075F_8_2, shape torch.Size([1, 45, 210, 271]), rank 0 
2024-05-14 05:07:07.858036: predicting 14076H_16_2 
2024-05-14 05:07:07.860501: 14076H_16_2, shape torch.Size([1, 43, 192, 270]), rank 0 
2024-05-14 05:07:08.306592: predicting 14080Y_4_3 
2024-05-14 05:07:08.308998: 14080Y_4_3, shape torch.Size([1, 47, 208, 265]), rank 0 
2024-05-14 05:07:09.198097: predicting 14110H_16_2 
2024-05-14 05:07:09.199127: 14110H_16_2, shape torch.Size([1, 45, 210, 277]), rank 0 
2024-05-14 05:07:10.079203: predicting 14125U_8_3 
2024-05-14 05:07:10.082147: 14125U_8_3, shape torch.Size([1, 44, 204, 270]), rank 0 
2024-05-14 05:07:10.968950: predicting 14155D_16_2 
2024-05-14 05:07:10.970279: 14155D_16_2, shape torch.Size([1, 47, 209, 269]), rank 0 
2024-05-14 05:07:11.852352: predicting 14160W_8_3 
2024-05-14 05:07:11.853642: 14160W_8_3, shape torch.Size([1, 42, 195, 283]), rank 0 
2024-05-14 05:07:12.740738: predicting 14168M_4_3 
2024-05-14 05:07:12.743007: 14168M_4_3, shape torch.Size([1, 52, 205, 275]), rank 0 
2024-05-14 05:07:14.493143: predicting 14170Z_16_2 
2024-05-14 05:07:14.496619: 14170Z_16_2, shape torch.Size([1, 43, 196, 266]), rank 0 
2024-05-14 05:07:15.383704: predicting 14185M_8_2 
2024-05-14 05:07:15.386002: 14185M_8_2, shape torch.Size([1, 49, 199, 269]), rank 0 
2024-05-14 05:07:17.137660: predicting 14205S_0_0 
2024-05-14 05:07:17.139007: 14205S_0_0, shape torch.Size([1, 42, 202, 266]), rank 0 
2024-05-14 05:07:18.018029: predicting 14209A_8_3 
2024-05-14 05:07:18.020764: 14209A_8_3, shape torch.Size([1, 52, 210, 280]), rank 0 
2024-05-14 05:07:19.780662: predicting 14218B_8_3 
2024-05-14 05:07:19.783340: 14218B_8_3, shape torch.Size([1, 41, 195, 268]), rank 0 
2024-05-14 05:07:20.671637: predicting 14233X_0_0 
2024-05-14 05:07:20.674319: 14233X_0_0, shape torch.Size([1, 47, 200, 269]), rank 0 
2024-05-14 05:07:21.564277: predicting 14310P_4_3 
2024-05-14 05:07:21.566589: 14310P_4_3, shape torch.Size([1, 46, 203, 282]), rank 0 
2024-05-14 05:07:22.447827: predicting 14337J_0_0 
2024-05-14 05:07:22.450891: 14337J_0_0, shape torch.Size([1, 42, 192, 266]), rank 0 
2024-05-14 05:07:22.904934: predicting 14350B_8_2 
2024-05-14 05:07:22.906996: 14350B_8_2, shape torch.Size([1, 46, 201, 277]), rank 0 
2024-05-14 05:07:23.787017: predicting 14374P_16_2 
2024-05-14 05:07:23.790224: 14374P_16_2, shape torch.Size([1, 49, 204, 271]), rank 0 
2024-05-14 05:07:25.547902: predicting 14375R_0_0 
2024-05-14 05:07:25.551135: 14375R_0_0, shape torch.Size([1, 49, 204, 271]), rank 0 
2024-05-14 05:07:27.308875: predicting 14384S_8_3 
2024-05-14 05:07:27.311549: 14384S_8_3, shape torch.Size([1, 46, 200, 268]), rank 0 
2024-05-14 05:07:28.201462: predicting 14386W_0_0 
2024-05-14 05:07:28.204413: 14386W_0_0, shape torch.Size([1, 46, 200, 268]), rank 0 
2024-05-14 05:07:29.093264: predicting 14390N_0_0 
2024-05-14 05:07:29.095930: 14390N_0_0, shape torch.Size([1, 50, 204, 264]), rank 0 
2024-05-14 05:07:30.853632: predicting 14394V_0_0 
2024-05-14 05:07:30.857161: 14394V_0_0, shape torch.Size([1, 48, 200, 281]), rank 0 
2024-05-14 05:07:31.743782: predicting 14406C_16_2 
2024-05-14 05:07:31.746599: 14406C_16_2, shape torch.Size([1, 47, 197, 274]), rank 0 
2024-05-14 05:07:32.634592: predicting 14425G_16_2 
2024-05-14 05:07:32.637024: 14425G_16_2, shape torch.Size([1, 50, 204, 262]), rank 0 
2024-05-14 05:07:34.393762: predicting 14427K_8_2 
2024-05-14 05:07:34.396229: 14427K_8_2, shape torch.Size([1, 48, 209, 275]), rank 0 
2024-05-14 05:07:35.283828: predicting 14431B_4_2 
2024-05-14 05:07:35.286829: 14431B_4_2, shape torch.Size([1, 44, 197, 270]), rank 0 
2024-05-14 05:07:36.173920: predicting 14453L_16_2 
2024-05-14 05:07:36.176745: 14453L_16_2, shape torch.Size([1, 39, 185, 269]), rank 0 
2024-05-14 05:07:36.630114: predicting 14457T_8_2 
2024-05-14 05:07:36.632852: 14457T_8_2, shape torch.Size([1, 52, 209, 267]), rank 0 
2024-05-14 05:07:38.389958: predicting 14468Y_4_2 
2024-05-14 05:07:38.392291: 14468Y_4_2, shape torch.Size([1, 48, 182, 276]), rank 0 
2024-05-14 05:07:38.852527: predicting 14483U_4_2 
2024-05-14 05:07:38.855345: 14483U_4_2, shape torch.Size([1, 49, 200, 264]), rank 0 
2024-05-14 05:07:40.612099: predicting 14484W_4_2 
2024-05-14 05:07:40.614209: 14484W_4_2, shape torch.Size([1, 44, 209, 271]), rank 0 
2024-05-14 05:07:41.495897: predicting 14501W_4_2 
2024-05-14 05:07:41.497688: 14501W_4_2, shape torch.Size([1, 46, 205, 272]), rank 0 
2024-05-14 05:07:42.377252: predicting 14502Y_16_2 
2024-05-14 05:07:42.380361: 14502Y_16_2, shape torch.Size([1, 40, 199, 265]), rank 0 
2024-05-14 05:07:43.266485: predicting 14504C_16_2 
2024-05-14 05:07:43.269411: 14504C_16_2, shape torch.Size([1, 48, 201, 275]), rank 0 
2024-05-14 05:07:44.156954: predicting 14516J_8_2 
2024-05-14 05:07:44.158348: 14516J_8_2, shape torch.Size([1, 51, 203, 266]), rank 0 
2024-05-14 05:07:45.909007: predicting 14529S_8_2 
2024-05-14 05:07:45.911056: 14529S_8_2, shape torch.Size([1, 42, 204, 278]), rank 0 
2024-05-14 05:07:46.791899: predicting 14535N_8_2 
2024-05-14 05:07:46.794424: 14535N_8_2, shape torch.Size([1, 49, 192, 272]), rank 0 
2024-05-14 05:07:47.681793: predicting 14536P_0_0 
2024-05-14 05:07:47.684678: 14536P_0_0, shape torch.Size([1, 49, 192, 272]), rank 0 
2024-05-14 05:07:48.570022: predicting 14551L_16_2 
2024-05-14 05:07:48.572834: 14551L_16_2, shape torch.Size([1, 46, 201, 266]), rank 0 
2024-05-14 05:07:49.460525: predicting 14552N_8_2 
2024-05-14 05:07:49.463457: 14552N_8_2, shape torch.Size([1, 36, 186, 265]), rank 0 
2024-05-14 05:07:49.914960: predicting 14567A_8_3 
2024-05-14 05:07:49.917433: 14567A_8_3, shape torch.Size([1, 52, 207, 271]), rank 0 
2024-05-14 05:07:51.676402: predicting 14571R_0_0 
2024-05-14 05:07:51.677782: 14571R_0_0, shape torch.Size([1, 52, 207, 271]), rank 0 
2024-05-14 05:07:53.427707: predicting 14576B_8_2 
2024-05-14 05:07:53.430698: 14576B_8_2, shape torch.Size([1, 45, 175, 256]), rank 0 
2024-05-14 05:07:53.665263: predicting 14599N_4_2 
2024-05-14 05:07:53.668443: 14599N_4_2, shape torch.Size([1, 50, 195, 271]), rank 0 
2024-05-14 05:07:55.428489: predicting 14626Q_4_2 
2024-05-14 05:07:55.430999: 14626Q_4_2, shape torch.Size([1, 47, 195, 257]), rank 0 
2024-05-14 05:07:56.318953: predicting 14631J_4_2 
2024-05-14 05:07:56.322013: 14631J_4_2, shape torch.Size([1, 51, 209, 285]), rank 0 
2024-05-14 05:07:58.079555: predicting 14672X_16_2 
2024-05-14 05:07:58.082486: 14672X_16_2, shape torch.Size([1, 52, 206, 267]), rank 0 
2024-05-14 05:07:59.837968: predicting 14684E_8_3 
2024-05-14 05:07:59.841442: 14684E_8_3, shape torch.Size([1, 40, 203, 277]), rank 0 
2024-05-14 05:08:00.729164: predicting 14685G_0_0 
2024-05-14 05:08:00.732566: 14685G_0_0, shape torch.Size([1, 40, 203, 277]), rank 0 
2024-05-14 05:08:01.628609: predicting 14699R_0_0 
2024-05-14 05:08:01.631638: 14699R_0_0, shape torch.Size([1, 44, 209, 289]), rank 0 
2024-05-14 05:08:02.529366: predicting 14710F_0_0 
2024-05-14 05:08:02.532130: 14710F_0_0, shape torch.Size([1, 48, 194, 268]), rank 0 
2024-05-14 05:08:03.419868: predicting 14735V_16_2 
2024-05-14 05:08:03.420885: 14735V_16_2, shape torch.Size([1, 48, 189, 278]), rank 0 
2024-05-14 05:08:03.869226: predicting 14738B_16_2 
2024-05-14 05:08:03.872520: 14738B_16_2, shape torch.Size([1, 46, 193, 267]), rank 0 
2024-05-14 05:08:04.761421: predicting 14764C_4_2 
2024-05-14 05:08:04.762744: 14764C_4_2, shape torch.Size([1, 52, 202, 271]), rank 0 
2024-05-14 05:08:06.511574: predicting 14772B_0_0 
2024-05-14 05:08:06.514748: 14772B_0_0, shape torch.Size([1, 31, 194, 269]), rank 0 
2024-05-14 05:08:07.395300: predicting 14783G_8_2 
2024-05-14 05:08:07.398237: 14783G_8_2, shape torch.Size([1, 50, 186, 270]), rank 0 
2024-05-14 05:08:08.285906: predicting 14800G_16_2 
2024-05-14 05:08:08.288798: 14800G_16_2, shape torch.Size([1, 42, 201, 272]), rank 0 
2024-05-14 05:08:09.176556: predicting 14829E_16_2 
2024-05-14 05:08:09.177845: 14829E_16_2, shape torch.Size([1, 49, 198, 275]), rank 0 
2024-05-14 05:08:10.927131: predicting 14834X_0_0 
2024-05-14 05:08:10.929778: 14834X_0_0, shape torch.Size([1, 48, 213, 275]), rank 0 
2024-05-14 05:08:11.820670: predicting 14836B_0_0 
2024-05-14 05:08:11.824083: 14836B_0_0, shape torch.Size([1, 48, 213, 275]), rank 0 
2024-05-14 05:08:12.723900: predicting 14841U_16_2 
2024-05-14 05:08:12.726917: 14841U_16_2, shape torch.Size([1, 46, 191, 271]), rank 0 
2024-05-14 05:08:13.180831: predicting 14846E_8_3 
2024-05-14 05:08:13.184183: 14846E_8_3, shape torch.Size([1, 50, 188, 267]), rank 0 
2024-05-14 05:08:14.073477: predicting 14847G_0_0 
2024-05-14 05:08:14.076665: 14847G_0_0, shape torch.Size([1, 50, 188, 267]), rank 0 
2024-05-14 05:08:14.966632: predicting 14857J_16_2 
2024-05-14 05:08:14.969577: 14857J_16_2, shape torch.Size([1, 42, 195, 270]), rank 0 
2024-05-14 05:08:15.857385: predicting 14878R_16_2 
2024-05-14 05:08:15.859926: 14878R_16_2, shape torch.Size([1, 48, 212, 269]), rank 0 
2024-05-14 05:08:16.745745: predicting 14886Q_0_0 
2024-05-14 05:08:16.748239: 14886Q_0_0, shape torch.Size([1, 48, 194, 275]), rank 0 
2024-05-14 05:08:17.635548: predicting 14892L_8_2 
2024-05-14 05:08:17.638155: 14892L_8_2, shape torch.Size([1, 44, 206, 290]), rank 0 
2024-05-14 05:08:18.530771: predicting 14898X_8_3 
2024-05-14 05:08:18.533616: 14898X_8_3, shape torch.Size([1, 51, 212, 271]), rank 0 
2024-05-14 05:08:20.290646: predicting 14909C_4_3 
2024-05-14 05:08:20.293153: 14909C_4_3, shape torch.Size([1, 52, 203, 271]), rank 0 
2024-05-14 05:08:22.054051: predicting 14910N_16_2 
2024-05-14 05:08:22.057256: 14910N_16_2, shape torch.Size([1, 36, 205, 265]), rank 0 
2024-05-14 05:08:22.943643: predicting 14912R_0_0 
2024-05-14 05:08:22.946391: 14912R_0_0, shape torch.Size([1, 52, 202, 269]), rank 0 
2024-05-14 05:08:24.709401: predicting 14964K_16_2 
2024-05-14 05:08:24.711922: 14964K_16_2, shape torch.Size([1, 48, 195, 270]), rank 0 
2024-05-14 05:08:25.592100: predicting 14969U_8_2 
2024-05-14 05:08:25.593462: 14969U_8_2, shape torch.Size([1, 50, 206, 280]), rank 0 
2024-05-14 05:08:27.344054: predicting 14981K_0_0 
2024-05-14 05:08:27.347350: 14981K_0_0, shape torch.Size([1, 48, 192, 272]), rank 0 
2024-05-14 05:08:27.800200: predicting 14985S_4_2 
2024-05-14 05:08:27.803349: 14985S_4_2, shape torch.Size([1, 48, 192, 268]), rank 0 
2024-05-14 05:08:28.258685: predicting 14996X_16_2 
2024-05-14 05:08:28.261325: 14996X_16_2, shape torch.Size([1, 44, 200, 273]), rank 0 
2024-05-14 05:08:29.150039: predicting 14998B_16_2 
2024-05-14 05:08:29.152309: 14998B_16_2, shape torch.Size([1, 48, 207, 271]), rank 0 
2024-05-14 05:08:30.040633: predicting 15011K_0_0 
2024-05-14 05:08:30.044316: 15011K_0_0, shape torch.Size([1, 43, 199, 268]), rank 0 
2024-05-14 05:08:30.932658: predicting 15020L_4_2 
2024-05-14 05:08:30.936256: 15020L_4_2, shape torch.Size([1, 46, 195, 274]), rank 0 
2024-05-14 05:08:31.825969: predicting 15023R_16_2 
2024-05-14 05:08:31.829023: 15023R_16_2, shape torch.Size([1, 38, 207, 279]), rank 0 
2024-05-14 05:08:32.715822: predicting 15040R_8_3 
2024-05-14 05:08:32.718099: 15040R_8_3, shape torch.Size([1, 44, 201, 277]), rank 0 
2024-05-14 05:08:33.606677: predicting 15046D_0_0 
2024-05-14 05:08:33.608035: 15046D_0_0, shape torch.Size([1, 48, 202, 270]), rank 0 
2024-05-14 05:08:34.487530: predicting 15058K_4_3 
2024-05-14 05:08:34.490764: 15058K_4_3, shape torch.Size([1, 48, 191, 273]), rank 0 
2024-05-14 05:08:34.944428: predicting 15061Z_8_2 
2024-05-14 05:08:34.947180: 15061Z_8_2, shape torch.Size([1, 44, 211, 278]), rank 0 
2024-05-14 05:08:35.836842: predicting 15078Q_16_2 
2024-05-14 05:08:35.840390: 15078Q_16_2, shape torch.Size([1, 47, 193, 265]), rank 0 
2024-05-14 05:08:36.727899: predicting 15084L_8_2 
2024-05-14 05:08:36.730321: 15084L_8_2, shape torch.Size([1, 48, 191, 270]), rank 0 
2024-05-14 05:08:37.186234: predicting 15107X_4_2 
2024-05-14 05:08:37.189095: 15107X_4_2, shape torch.Size([1, 48, 182, 259]), rank 0 
2024-05-14 05:08:37.641872: predicting 15123V_16_2 
2024-05-14 05:08:37.643167: 15123V_16_2, shape torch.Size([1, 50, 197, 273]), rank 0 
2024-05-14 05:08:39.393466: predicting 15154G_4_3 
2024-05-14 05:08:39.396973: 15154G_4_3, shape torch.Size([1, 47, 200, 276]), rank 0 
2024-05-14 05:08:40.285384: predicting 15159Q_0_0 
2024-05-14 05:08:40.288388: 15159Q_0_0, shape torch.Size([1, 45, 203, 272]), rank 0 
2024-05-14 05:08:41.177320: predicting 15163H_16_2 
2024-05-14 05:08:41.180462: 15163H_16_2, shape torch.Size([1, 44, 198, 267]), rank 0 
2024-05-14 05:08:42.068327: predicting 15165L_4_2 
2024-05-14 05:08:42.069643: 15165L_4_2, shape torch.Size([1, 43, 213, 277]), rank 0 
2024-05-14 05:08:42.949434: predicting 15183N_8_3 
2024-05-14 05:08:42.952324: 15183N_8_3, shape torch.Size([1, 42, 205, 267]), rank 0 
2024-05-14 05:08:43.840000: predicting 15193Q_4_3 
2024-05-14 05:08:43.842508: 15193Q_4_3, shape torch.Size([1, 44, 200, 283]), rank 0 
2024-05-14 05:08:44.732225: predicting 15196W_8_2 
2024-05-14 05:08:44.734788: 15196W_8_2, shape torch.Size([1, 46, 199, 263]), rank 0 
2024-05-14 05:08:45.622988: predicting 15197Y_16_2 
2024-05-14 05:08:45.625917: 15197Y_16_2, shape torch.Size([1, 42, 187, 281]), rank 0 
2024-05-14 05:08:46.080066: predicting 15213W_16_2 
2024-05-14 05:08:46.082933: 15213W_16_2, shape torch.Size([1, 44, 199, 276]), rank 0 
2024-05-14 05:08:46.969858: predicting 15230W_0_0 
2024-05-14 05:08:46.972884: 15230W_0_0, shape torch.Size([1, 48, 212, 276]), rank 0 
2024-05-14 05:08:47.858910: predicting 15233C_8_2 
2024-05-14 05:08:47.861430: 15233C_8_2, shape torch.Size([1, 46, 204, 285]), rank 0 
2024-05-14 05:08:48.750029: predicting 15237K_4_2 
2024-05-14 05:08:48.753144: 15237K_4_2, shape torch.Size([1, 51, 205, 275]), rank 0 
2024-05-14 05:08:50.514806: predicting 15246L_16_2 
2024-05-14 05:08:50.517402: 15246L_16_2, shape torch.Size([1, 44, 194, 259]), rank 0 
2024-05-14 05:08:51.405143: predicting 15255M_4_3 
2024-05-14 05:08:51.407792: 15255M_4_3, shape torch.Size([1, 50, 199, 273]), rank 0 
2024-05-14 05:08:53.162057: predicting 15261H_4_2 
2024-05-14 05:08:53.164940: 15261H_4_2, shape torch.Size([1, 46, 192, 278]), rank 0 
2024-05-14 05:08:53.620260: predicting 15271K_8_2 
2024-05-14 05:08:53.623849: 15271K_8_2, shape torch.Size([1, 44, 203, 282]), rank 0 
2024-05-14 05:08:54.520983: predicting 15272M_4_3 
2024-05-14 05:08:54.523947: 15272M_4_3, shape torch.Size([1, 47, 197, 269]), rank 0 
2024-05-14 05:08:55.412404: predicting 15278Y_4_2 
2024-05-14 05:08:55.413821: 15278Y_4_2, shape torch.Size([1, 46, 207, 276]), rank 0 
2024-05-14 05:08:56.293074: predicting 15285V_16_2 
2024-05-14 05:08:56.296202: 15285V_16_2, shape torch.Size([1, 48, 201, 273]), rank 0 
2024-05-14 05:08:57.182792: predicting 15286X_16_2 
2024-05-14 05:08:57.185708: 15286X_16_2, shape torch.Size([1, 44, 193, 279]), rank 0 
2024-05-14 05:08:58.073740: predicting 15292S_16_2 
2024-05-14 05:08:58.076456: 15292S_16_2, shape torch.Size([1, 47, 190, 264]), rank 0 
2024-05-14 05:08:58.529776: predicting 15325H_0_0 
2024-05-14 05:08:58.532668: 15325H_0_0, shape torch.Size([1, 45, 196, 269]), rank 0 
2024-05-14 05:08:59.419368: predicting 15339S_16_2 
2024-05-14 05:08:59.422258: 15339S_16_2, shape torch.Size([1, 46, 209, 274]), rank 0 
2024-05-14 05:09:00.309427: predicting 15373S_8_2 
2024-05-14 05:09:00.312193: 15373S_8_2, shape torch.Size([1, 41, 199, 275]), rank 0 
2024-05-14 05:09:01.193263: predicting 15385Z_0_0 
2024-05-14 05:09:01.194875: 15385Z_0_0, shape torch.Size([1, 49, 195, 274]), rank 0 
2024-05-14 05:09:02.942805: predicting 15392W_4_2 
2024-05-14 05:09:02.945965: 15392W_4_2, shape torch.Size([1, 50, 191, 268]), rank 0 
2024-05-14 05:09:03.834539: predicting 15400V_4_3 
2024-05-14 05:09:03.837684: 15400V_4_3, shape torch.Size([1, 46, 197, 277]), rank 0 
2024-05-14 05:09:04.726369: predicting 15401X_8_3 
2024-05-14 05:09:04.728767: 15401X_8_3, shape torch.Size([1, 49, 208, 290]), rank 0 
2024-05-14 05:09:06.483545: predicting 15424J_8_2 
2024-05-14 05:09:06.486152: 15424J_8_2, shape torch.Size([1, 42, 209, 282]), rank 0 
2024-05-14 05:09:07.374946: predicting 15440H_4_3 
2024-05-14 05:09:07.375957: 15440H_4_3, shape torch.Size([1, 46, 205, 277]), rank 0 
2024-05-14 05:09:08.255925: predicting 15441J_0_0 
2024-05-14 05:09:08.258906: 15441J_0_0, shape torch.Size([1, 46, 205, 277]), rank 0 
2024-05-14 05:09:09.146893: predicting 15442L_4_3 
2024-05-14 05:09:09.148273: 15442L_4_3, shape torch.Size([1, 46, 205, 272]), rank 0 
2024-05-14 05:09:10.027950: predicting 15444P_16_2 
2024-05-14 05:09:10.031303: 15444P_16_2, shape torch.Size([1, 47, 203, 281]), rank 0 
2024-05-14 05:09:10.919845: predicting 15456W_8_3 
2024-05-14 05:09:10.922794: 15456W_8_3, shape torch.Size([1, 42, 195, 263]), rank 0 
2024-05-14 05:09:11.808835: predicting 15463T_16_2 
2024-05-14 05:09:11.811907: 15463T_16_2, shape torch.Size([1, 43, 200, 265]), rank 0 
2024-05-14 05:09:12.705260: predicting 15473W_4_2 
2024-05-14 05:09:12.707532: 15473W_4_2, shape torch.Size([1, 46, 189, 282]), rank 0 
2024-05-14 05:09:13.153841: predicting 15485D_0_0 
2024-05-14 05:09:13.156379: 15485D_0_0, shape torch.Size([1, 52, 202, 266]), rank 0 
2024-05-14 05:09:14.912717: predicting 15491Y_8_2 
2024-05-14 05:09:14.915736: 15491Y_8_2, shape torch.Size([1, 49, 206, 272]), rank 0 
2024-05-14 05:09:16.671891: predicting 15509R_0_0 
2024-05-14 05:09:16.674409: 15509R_0_0, shape torch.Size([1, 36, 206, 277]), rank 0 
2024-05-14 05:09:17.559643: predicting 15531K_0_0 
2024-05-14 05:09:17.562140: 15531K_0_0, shape torch.Size([1, 29, 187, 261]), rank 0 
2024-05-14 05:09:18.008835: predicting 15548B_4_2 
2024-05-14 05:09:18.011609: 15548B_4_2, shape torch.Size([1, 48, 193, 276]), rank 0 
2024-05-14 05:09:18.898755: predicting 15551Q_8_3 
2024-05-14 05:09:18.900985: 15551Q_8_3, shape torch.Size([1, 44, 196, 271]), rank 0 
2024-05-14 05:09:19.787797: predicting 15557C_0_0 
2024-05-14 05:09:19.790048: 15557C_0_0, shape torch.Size([1, 48, 189, 265]), rank 0 
2024-05-14 05:09:20.244765: predicting 15558E_0_0 
2024-05-14 05:09:20.247262: 15558E_0_0, shape torch.Size([1, 48, 189, 265]), rank 0 
2024-05-14 05:09:20.702618: predicting 15563X_16_2 
2024-05-14 05:09:20.705556: 15563X_16_2, shape torch.Size([1, 42, 189, 276]), rank 0 
2024-05-14 05:09:21.158665: predicting 15567F_0_0 
2024-05-14 05:09:21.160764: 15567F_0_0, shape torch.Size([1, 42, 189, 276]), rank 0 
2024-05-14 05:09:21.607459: predicting 15580X_8_2 
2024-05-14 05:09:21.610484: 15580X_8_2, shape torch.Size([1, 51, 201, 285]), rank 0 
2024-05-14 05:09:23.368399: predicting 15585H_8_2 
2024-05-14 05:09:23.370789: 15585H_8_2, shape torch.Size([1, 48, 213, 270]), rank 0 
2024-05-14 05:09:24.258015: predicting 15602H_16_2 
2024-05-14 05:09:24.260588: 15602H_16_2, shape torch.Size([1, 46, 210, 270]), rank 0 
2024-05-14 05:09:25.150875: predicting 15616S_16_2 
2024-05-14 05:09:25.151879: 15616S_16_2, shape torch.Size([1, 38, 203, 260]), rank 0 
2024-05-14 05:09:26.031494: predicting 15651U_8_2 
2024-05-14 05:09:26.034194: 15651U_8_2, shape torch.Size([1, 50, 202, 272]), rank 0 
2024-05-14 05:09:27.791119: predicting 15661X_0_0 
2024-05-14 05:09:27.793715: 15661X_0_0, shape torch.Size([1, 44, 200, 273]), rank 0 
2024-05-14 05:09:28.681061: predicting 15676K_4_2 
2024-05-14 05:09:28.683701: 15676K_4_2, shape torch.Size([1, 45, 187, 265]), rank 0 
2024-05-14 05:09:29.133585: predicting 15680B_4_3 
2024-05-14 05:09:29.136575: 15680B_4_3, shape torch.Size([1, 42, 202, 265]), rank 0 
2024-05-14 05:09:30.022454: predicting 15699W_8_2 
2024-05-14 05:09:30.024988: 15699W_8_2, shape torch.Size([1, 41, 197, 276]), rank 0 
2024-05-14 05:09:30.912079: predicting 15702L_16_2 
2024-05-14 05:09:30.914264: 15702L_16_2, shape torch.Size([1, 43, 196, 271]), rank 0 
2024-05-14 05:09:31.801715: predicting 15703N_8_3 
2024-05-14 05:09:31.804227: 15703N_8_3, shape torch.Size([1, 45, 203, 285]), rank 0 
2024-05-14 05:09:32.690044: predicting 15704P_16_2 
2024-05-14 05:09:32.692878: 15704P_16_2, shape torch.Size([1, 42, 203, 277]), rank 0 
2024-05-14 05:09:33.578804: predicting 15710K_16_2 
2024-05-14 05:09:33.581893: 15710K_16_2, shape torch.Size([1, 44, 205, 274]), rank 0 
2024-05-14 05:09:34.470614: predicting 15747H_8_2 
2024-05-14 05:09:34.473120: 15747H_8_2, shape torch.Size([1, 44, 196, 266]), rank 0 
2024-05-14 05:09:35.360265: predicting 15750W_4_3 
2024-05-14 05:09:35.362400: 15750W_4_3, shape torch.Size([1, 51, 180, 269]), rank 0 
2024-05-14 05:09:36.251088: predicting 15766L_16_2 
2024-05-14 05:09:36.253892: 15766L_16_2, shape torch.Size([1, 42, 205, 267]), rank 0 
2024-05-14 05:09:37.141237: predicting 15781H_8_2 
2024-05-14 05:09:37.144151: 15781H_8_2, shape torch.Size([1, 44, 201, 266]), rank 0 
2024-05-14 05:09:38.037332: predicting 15791K_16_2 
2024-05-14 05:09:38.039965: 15791K_16_2, shape torch.Size([1, 50, 213, 294]), rank 0 
2024-05-14 05:09:39.798507: predicting 15808B_4_2 
2024-05-14 05:09:39.801641: 15808B_4_2, shape torch.Size([1, 48, 200, 269]), rank 0 
2024-05-14 05:09:40.687946: predicting 15833A_8_3 
2024-05-14 05:09:40.690639: 15833A_8_3, shape torch.Size([1, 39, 186, 269]), rank 0 
2024-05-14 05:09:41.142549: predicting 15840X_16_2 
2024-05-14 05:09:41.145064: 15840X_16_2, shape torch.Size([1, 48, 209, 276]), rank 0 
2024-05-14 05:09:42.031676: predicting 15850A_0_0 
2024-05-14 05:09:42.034742: 15850A_0_0, shape torch.Size([1, 50, 192, 267]), rank 0 
2024-05-14 05:09:42.921611: predicting 15855K_16_2 
2024-05-14 05:09:42.924578: 15855K_16_2, shape torch.Size([1, 47, 208, 276]), rank 0 
2024-05-14 05:09:43.813976: predicting 15863J_0_0 
2024-05-14 05:09:43.817153: 15863J_0_0, shape torch.Size([1, 51, 212, 266]), rank 0 
2024-05-14 05:09:45.574928: predicting 15883P_16_2 
2024-05-14 05:09:45.577861: 15883P_16_2, shape torch.Size([1, 47, 188, 275]), rank 0 
2024-05-14 05:09:46.033175: predicting 15885T_16_2 
2024-05-14 05:09:46.036404: 15885T_16_2, shape torch.Size([1, 38, 197, 284]), rank 0 
2024-05-14 05:09:46.922025: predicting 15898C_8_3 
2024-05-14 05:09:46.924553: 15898C_8_3, shape torch.Size([1, 48, 204, 276]), rank 0 
2024-05-14 05:09:47.810633: predicting 15905Z_4_2 
2024-05-14 05:09:47.813592: 15905Z_4_2, shape torch.Size([1, 44, 205, 273]), rank 0 
2024-05-14 05:09:48.702267: predicting 15922Z_4_2 
2024-05-14 05:09:48.704408: 15922Z_4_2, shape torch.Size([1, 49, 197, 268]), rank 0 
2024-05-14 05:09:50.460866: predicting 15933E_16_2 
2024-05-14 05:09:50.463721: 15933E_16_2, shape torch.Size([1, 36, 194, 265]), rank 0 
2024-05-14 05:09:51.347269: predicting 15934G_8_2 
2024-05-14 05:09:51.349609: 15934G_8_2, shape torch.Size([1, 44, 210, 289]), rank 0 
2024-05-14 05:09:52.239154: predicting 15939Q_8_2 
2024-05-14 05:09:52.242418: 15939Q_8_2, shape torch.Size([1, 48, 192, 277]), rank 0 
2024-05-14 05:09:52.696208: predicting 15949T_16_2 
2024-05-14 05:09:52.699254: 15949T_16_2, shape torch.Size([1, 42, 208, 279]), rank 0 
2024-05-14 05:09:53.586812: predicting 15965R_4_3 
2024-05-14 05:09:53.589879: 15965R_4_3, shape torch.Size([1, 50, 218, 271]), rank 0 
2024-05-14 05:09:55.345712: predicting 15977Y_0_0 
2024-05-14 05:09:55.348847: 15977Y_0_0, shape torch.Size([1, 50, 218, 271]), rank 0 
2024-05-14 05:09:57.105130: predicting 15997E_4_3 
2024-05-14 05:09:57.107917: 15997E_4_3, shape torch.Size([1, 50, 193, 269]), rank 0 
2024-05-14 05:09:58.856509: predicting 15998G_0_0 
2024-05-14 05:09:58.860423: 15998G_0_0, shape torch.Size([1, 50, 193, 269]), rank 0 
2024-05-14 05:10:00.618540: predicting 16018D_8_2 
2024-05-14 05:10:00.621042: 16018D_8_2, shape torch.Size([1, 49, 204, 277]), rank 0 
2024-05-14 05:10:02.378798: predicting 16025A_8_2 
2024-05-14 05:10:02.381714: 16025A_8_2, shape torch.Size([1, 48, 201, 271]), rank 0 
2024-05-14 05:10:03.268035: predicting 16052D_8_2 
2024-05-14 05:10:03.271678: 16052D_8_2, shape torch.Size([1, 46, 201, 279]), rank 0 
2024-05-14 05:10:04.171982: predicting 16072J_0_0 
2024-05-14 05:10:04.174602: 16072J_0_0, shape torch.Size([1, 48, 198, 276]), rank 0 
2024-05-14 05:10:05.061550: predicting 16122Y_4_2 
2024-05-14 05:10:05.064554: 16122Y_4_2, shape torch.Size([1, 50, 209, 270]), rank 0 
2024-05-14 05:10:06.823157: predicting 16137L_16_2 
2024-05-14 05:10:06.825437: 16137L_16_2, shape torch.Size([1, 40, 210, 277]), rank 0 
2024-05-14 05:10:07.705408: predicting 16141C_0_0 
2024-05-14 05:10:07.707723: 16141C_0_0, shape torch.Size([1, 47, 211, 288]), rank 0 
2024-05-14 05:10:08.597707: predicting 16143G_8_3 
2024-05-14 05:10:08.600291: 16143G_8_3, shape torch.Size([1, 49, 196, 278]), rank 0 
2024-05-14 05:10:10.355965: predicting 16155N_4_2 
2024-05-14 05:10:10.358715: 16155N_4_2, shape torch.Size([1, 37, 211, 276]), rank 0 
2024-05-14 05:10:11.247874: predicting 16159V_0_0 
2024-05-14 05:10:11.251026: 16159V_0_0, shape torch.Size([1, 51, 216, 277]), rank 0 
2024-05-14 05:10:13.007502: predicting 16168W_0_0 
2024-05-14 05:10:13.008575: 16168W_0_0, shape torch.Size([1, 48, 190, 261]), rank 0 
2024-05-14 05:10:13.453518: predicting 16186Y_4_2 
2024-05-14 05:10:13.487700: 16186Y_4_2, shape torch.Size([1, 48, 203, 292]), rank 0 
2024-05-14 05:10:14.376993: predicting 16187A_0_0 
2024-05-14 05:10:14.381064: 16187A_0_0, shape torch.Size([1, 48, 203, 292]), rank 0 
2024-05-14 05:10:15.268125: predicting 16196B_16_2 
2024-05-14 05:10:15.270686: 16196B_16_2, shape torch.Size([1, 30, 200, 266]), rank 0 
2024-05-14 05:10:16.153656: predicting 16223E_4_3 
2024-05-14 05:10:16.154858: 16223E_4_3, shape torch.Size([1, 48, 192, 255]), rank 0 
2024-05-14 05:10:16.383195: predicting 16227M_16_2 
2024-05-14 05:10:16.385520: 16227M_16_2, shape torch.Size([1, 49, 193, 280]), rank 0 
2024-05-14 05:10:18.139951: predicting 16231D_4_3 
2024-05-14 05:10:18.142487: 16231D_4_3, shape torch.Size([1, 44, 203, 262]), rank 0 
2024-05-14 05:10:19.031112: predicting 16233H_4_2 
2024-05-14 05:10:19.032369: 16233H_4_2, shape torch.Size([1, 46, 194, 278]), rank 0 
2024-05-14 05:10:19.911392: predicting 16244M_8_3 
2024-05-14 05:10:19.913993: 16244M_8_3, shape torch.Size([1, 48, 192, 270]), rank 0 
2024-05-14 05:10:20.366197: predicting 16259Z_16_2 
2024-05-14 05:10:20.368757: 16259Z_16_2, shape torch.Size([1, 46, 209, 267]), rank 0 
2024-05-14 05:10:21.258476: predicting 16266W_0_0 
2024-05-14 05:10:21.259481: 16266W_0_0, shape torch.Size([1, 44, 197, 281]), rank 0 
2024-05-14 05:10:22.139777: predicting 16316L_0_0 
2024-05-14 05:10:22.142723: 16316L_0_0, shape torch.Size([1, 44, 194, 261]), rank 0 
2024-05-14 05:10:23.028887: predicting 16320C_4_2 
2024-05-14 05:10:23.031381: 16320C_4_2, shape torch.Size([1, 44, 213, 271]), rank 0 
2024-05-14 05:10:23.919096: predicting 16324K_8_3 
2024-05-14 05:10:23.921746: 16324K_8_3, shape torch.Size([1, 41, 211, 270]), rank 0 
2024-05-14 05:10:24.808251: predicting 16342M_0_0 
2024-05-14 05:10:24.811240: 16342M_0_0, shape torch.Size([1, 45, 198, 273]), rank 0 
2024-05-14 05:10:25.698763: predicting 16344Q_0_0 
2024-05-14 05:10:25.701549: 16344Q_0_0, shape torch.Size([1, 45, 198, 273]), rank 0 
2024-05-14 05:10:26.589227: predicting 16356X_4_3 
2024-05-14 05:10:26.592158: 16356X_4_3, shape torch.Size([1, 46, 215, 284]), rank 0 
2024-05-14 05:10:27.482194: predicting 16361Q_0_0 
2024-05-14 05:10:27.485007: 16361Q_0_0, shape torch.Size([1, 46, 215, 284]), rank 0 
2024-05-14 05:10:28.375651: predicting 16375B_0_0 
2024-05-14 05:10:28.377023: 16375B_0_0, shape torch.Size([1, 48, 193, 273]), rank 0 
2024-05-14 05:10:29.256494: predicting 16384C_8_3 
2024-05-14 05:10:29.259434: 16384C_8_3, shape torch.Size([1, 34, 199, 275]), rank 0 
2024-05-14 05:10:30.143432: predicting 16394F_4_2 
2024-05-14 05:10:30.146276: 16394F_4_2, shape torch.Size([1, 47, 191, 265]), rank 0 
2024-05-14 05:10:30.599596: predicting 16395H_8_3 
2024-05-14 05:10:30.602166: 16395H_8_3, shape torch.Size([1, 46, 206, 274]), rank 0 
2024-05-14 05:10:31.490510: predicting 16422K_4_2 
2024-05-14 05:10:31.492915: 16422K_4_2, shape torch.Size([1, 46, 200, 278]), rank 0 
2024-05-14 05:10:32.382578: predicting 16434R_0_0 
2024-05-14 05:10:32.384598: 16434R_0_0, shape torch.Size([1, 43, 197, 272]), rank 0 
2024-05-14 05:10:33.264538: predicting 16435T_4_3 
2024-05-14 05:10:33.267184: 16435T_4_3, shape torch.Size([1, 43, 196, 269]), rank 0 
2024-05-14 05:10:34.153993: predicting 16440M_4_2 
2024-05-14 05:10:34.157305: 16440M_4_2, shape torch.Size([1, 49, 205, 291]), rank 0 
2024-05-14 05:10:35.914114: predicting 16463Y_16_2 
2024-05-14 05:10:35.917111: 16463Y_16_2, shape torch.Size([1, 50, 204, 261]), rank 0 
2024-05-14 05:10:37.671328: predicting 16490B_8_2 
2024-05-14 05:10:37.674115: 16490B_8_2, shape torch.Size([1, 46, 196, 274]), rank 0 
2024-05-14 05:10:38.562204: predicting 16515R_8_2 
2024-05-14 05:10:38.564394: 16515R_8_2, shape torch.Size([1, 46, 190, 268]), rank 0 
2024-05-14 05:10:39.010314: predicting 16545A_4_3 
2024-05-14 05:10:39.013209: 16545A_4_3, shape torch.Size([1, 50, 200, 282]), rank 0 
2024-05-14 05:10:40.770931: predicting 16546C_16_2 
2024-05-14 05:10:40.773807: 16546C_16_2, shape torch.Size([1, 52, 193, 271]), rank 0 
2024-05-14 05:10:42.532088: predicting 16576L_8_2 
2024-05-14 05:10:42.535130: 16576L_8_2, shape torch.Size([1, 46, 195, 262]), rank 0 
2024-05-14 05:10:43.424573: predicting 16589U_16_2 
2024-05-14 05:10:43.427851: 16589U_16_2, shape torch.Size([1, 50, 191, 272]), rank 0 
2024-05-14 05:10:44.314844: predicting 16594N_8_3 
2024-05-14 05:10:44.317707: 16594N_8_3, shape torch.Size([1, 41, 190, 279]), rank 0 
2024-05-14 05:10:44.770767: predicting 16610L_8_2 
2024-05-14 05:10:44.773723: 16610L_8_2, shape torch.Size([1, 48, 197, 280]), rank 0 
2024-05-14 05:10:45.659146: predicting 16631T_16_2 
2024-05-14 05:10:45.661958: 16631T_16_2, shape torch.Size([1, 37, 195, 278]), rank 0 
2024-05-14 05:10:46.547629: predicting 16634Z_4_2 
2024-05-14 05:10:46.549917: 16634Z_4_2, shape torch.Size([1, 48, 206, 278]), rank 0 
2024-05-14 05:10:47.435476: predicting 16645E_4_2 
2024-05-14 05:10:47.436865: 16645E_4_2, shape torch.Size([1, 44, 205, 273]), rank 0 
2024-05-14 05:10:48.317657: predicting 16661C_8_3 
2024-05-14 05:10:48.320734: 16661C_8_3, shape torch.Size([1, 46, 202, 270]), rank 0 
2024-05-14 05:10:49.209049: predicting 16682K_4_3 
2024-05-14 05:10:49.212079: 16682K_4_3, shape torch.Size([1, 44, 189, 263]), rank 0 
2024-05-14 05:10:49.665670: predicting 16723Y_8_3 
2024-05-14 05:10:49.668048: 16723Y_8_3, shape torch.Size([1, 43, 198, 274]), rank 0 
2024-05-14 05:10:50.556280: predicting 16731X_8_2 
2024-05-14 05:10:50.558781: 16731X_8_2, shape torch.Size([1, 37, 201, 272]), rank 0 
2024-05-14 05:10:51.448487: predicting 16733B_8_3 
2024-05-14 05:10:51.450844: 16733B_8_3, shape torch.Size([1, 51, 200, 271]), rank 0 
2024-05-14 05:10:53.208757: predicting 16739N_4_3 
2024-05-14 05:10:53.212299: 16739N_4_3, shape torch.Size([1, 43, 195, 275]), rank 0 
2024-05-14 05:10:54.100728: predicting 16740Y_0_0 
2024-05-14 05:10:54.103262: 16740Y_0_0, shape torch.Size([1, 43, 195, 275]), rank 0 
2024-05-14 05:10:54.990122: predicting 16774P_4_3 
2024-05-14 05:10:54.992633: 16774P_4_3, shape torch.Size([1, 46, 201, 285]), rank 0 
2024-05-14 05:10:55.881735: predicting 16778X_16_2 
2024-05-14 05:10:55.884508: 16778X_16_2, shape torch.Size([1, 38, 195, 262]), rank 0 
2024-05-14 05:10:56.770026: predicting 16805A_8_3 
2024-05-14 05:10:56.772495: 16805A_8_3, shape torch.Size([1, 43, 201, 272]), rank 0 
2024-05-14 05:10:57.660934: predicting 16817H_0_0 
2024-05-14 05:10:57.663943: 16817H_0_0, shape torch.Size([1, 50, 192, 266]), rank 0 
2024-05-14 05:10:58.552946: predicting 16818J_0_0 
2024-05-14 05:10:58.555773: 16818J_0_0, shape torch.Size([1, 50, 192, 266]), rank 0 
2024-05-14 05:10:59.441796: predicting 16820W_4_3 
2024-05-14 05:10:59.443984: 16820W_4_3, shape torch.Size([1, 44, 200, 276]), rank 0 
2024-05-14 05:11:00.325113: predicting 16864Q_0_0 
2024-05-14 05:11:00.328125: 16864Q_0_0, shape torch.Size([1, 50, 190, 268]), rank 0 
2024-05-14 05:11:01.216369: predicting 16873R_16_2 
2024-05-14 05:11:01.219201: 16873R_16_2, shape torch.Size([1, 45, 201, 274]), rank 0 
2024-05-14 05:11:02.107414: predicting 16914F_0_0 
2024-05-14 05:11:02.110403: 16914F_0_0, shape torch.Size([1, 50, 201, 273]), rank 0 
2024-05-14 05:11:03.865431: predicting 16918N_16_2 
2024-05-14 05:11:03.867959: 16918N_16_2, shape torch.Size([1, 48, 196, 275]), rank 0 
2024-05-14 05:11:04.760207: predicting 16922E_4_3 
2024-05-14 05:11:04.763118: 16922E_4_3, shape torch.Size([1, 48, 200, 266]), rank 0 
2024-05-14 05:11:05.649514: predicting 16928Q_16_2 
2024-05-14 05:11:05.652374: 16928Q_16_2, shape torch.Size([1, 39, 212, 272]), rank 0 
2024-05-14 05:11:06.538989: predicting 16930D_16_2 
2024-05-14 05:11:06.541547: 16930D_16_2, shape torch.Size([1, 37, 207, 267]), rank 0 
2024-05-14 05:11:07.426803: predicting 16935N_8_2 
2024-05-14 05:11:07.429975: 16935N_8_2, shape torch.Size([1, 44, 204, 264]), rank 0 
2024-05-14 05:11:08.316264: predicting 16956V_0_0 
2024-05-14 05:11:08.319945: 16956V_0_0, shape torch.Size([1, 50, 187, 259]), rank 0 
2024-05-14 05:11:09.216408: predicting 16957X_16_2 
2024-05-14 05:11:09.220148: 16957X_16_2, shape torch.Size([1, 50, 204, 273]), rank 0 
2024-05-14 05:11:10.979514: predicting 16958Z_8_3 
2024-05-14 05:11:10.982564: 16958Z_8_3, shape torch.Size([1, 48, 206, 262]), rank 0 
2024-05-14 05:11:11.867388: predicting 16962Q_8_3 
2024-05-14 05:11:11.868401: 16962Q_8_3, shape torch.Size([1, 41, 203, 275]), rank 0 
2024-05-14 05:11:12.745442: predicting 16964U_8_3 
2024-05-14 05:11:12.747019: 16964U_8_3, shape torch.Size([1, 45, 195, 269]), rank 0 
2024-05-14 05:11:13.627714: predicting 16966Y_4_3 
2024-05-14 05:11:13.629913: 16966Y_4_3, shape torch.Size([1, 43, 200, 277]), rank 0 
2024-05-14 05:11:14.509138: predicting 16980S_4_2 
2024-05-14 05:11:14.512194: 16980S_4_2, shape torch.Size([1, 43, 207, 261]), rank 0 
2024-05-14 05:11:15.405403: predicting 16983Y_16_2 
2024-05-14 05:11:15.407986: 16983Y_16_2, shape torch.Size([1, 48, 198, 267]), rank 0 
2024-05-14 05:11:16.294111: predicting 16997J_16_2 
2024-05-14 05:11:16.296708: 16997J_16_2, shape torch.Size([1, 44, 203, 275]), rank 0 
2024-05-14 05:11:17.184924: predicting 17021X_4_2 
2024-05-14 05:11:17.189023: 17021X_4_2, shape torch.Size([1, 51, 197, 270]), rank 0 
2024-05-14 05:11:18.959192: predicting 17022Z_8_2 
2024-05-14 05:11:18.961865: 17022Z_8_2, shape torch.Size([1, 48, 204, 270]), rank 0 
2024-05-14 05:11:19.848807: predicting 17023B_8_2 
2024-05-14 05:11:19.851285: 17023B_8_2, shape torch.Size([1, 47, 201, 270]), rank 0 
2024-05-14 05:11:20.741315: predicting 17036K_4_2 
2024-05-14 05:11:20.743836: 17036K_4_2, shape torch.Size([1, 51, 189, 263]), rank 0 
2024-05-14 05:11:21.633159: predicting 17070K_16_2 
2024-05-14 05:11:21.634508: 17070K_16_2, shape torch.Size([1, 46, 203, 277]), rank 0 
2024-05-14 05:11:22.521899: predicting 17076W_8_2 
2024-05-14 05:11:22.524660: 17076W_8_2, shape torch.Size([1, 50, 203, 270]), rank 0 
2024-05-14 05:11:24.280669: predicting 17077Y_16_2 
2024-05-14 05:11:24.283353: 17077Y_16_2, shape torch.Size([1, 45, 202, 276]), rank 0 
2024-05-14 05:11:25.172830: predicting 17082R_4_2 
2024-05-14 05:11:25.175371: 17082R_4_2, shape torch.Size([1, 46, 199, 270]), rank 0 
2024-05-14 05:11:26.064793: predicting 17083T_16_2 
2024-05-14 05:11:26.067922: 17083T_16_2, shape torch.Size([1, 50, 195, 275]), rank 0 
2024-05-14 05:11:27.827590: predicting 17089F_4_3 
2024-05-14 05:11:27.830568: 17089F_4_3, shape torch.Size([1, 43, 208, 288]), rank 0 
2024-05-14 05:11:28.720408: predicting 17091S_16_2 
2024-05-14 05:11:28.723136: 17091S_16_2, shape torch.Size([1, 48, 206, 278]), rank 0 
2024-05-14 05:11:29.609597: predicting 17094Y_8_2 
2024-05-14 05:11:29.612645: 17094Y_8_2, shape torch.Size([1, 49, 204, 280]), rank 0 
2024-05-14 05:11:31.368421: predicting 17095A_16_2 
2024-05-14 05:11:31.371847: 17095A_16_2, shape torch.Size([1, 46, 206, 263]), rank 0 
2024-05-14 05:11:32.261131: predicting 17149X_8_3 
2024-05-14 05:11:32.264057: 17149X_8_3, shape torch.Size([1, 49, 202, 271]), rank 0 
2024-05-14 05:11:34.020867: predicting 17152M_8_3 
2024-05-14 05:11:34.023827: 17152M_8_3, shape torch.Size([1, 44, 202, 275]), rank 0 
2024-05-14 05:11:34.911564: predicting 17154Q_16_2 
2024-05-14 05:11:34.914836: 17154Q_16_2, shape torch.Size([1, 46, 199, 274]), rank 0 
2024-05-14 05:11:35.803133: predicting 17157W_4_2 
2024-05-14 05:11:35.805567: 17157W_4_2, shape torch.Size([1, 52, 184, 258]), rank 0 
2024-05-14 05:11:36.694867: predicting 17187F_4_2 
2024-05-14 05:11:36.697439: 17187F_4_2, shape torch.Size([1, 51, 205, 292]), rank 0 
2024-05-14 05:11:38.455466: predicting 17188H_16_2 
2024-05-14 05:11:38.457795: 17188H_16_2, shape torch.Size([1, 41, 185, 264]), rank 0 
2024-05-14 05:11:38.906492: predicting 17195E_8_3 
2024-05-14 05:11:38.908855: 17195E_8_3, shape torch.Size([1, 42, 202, 276]), rank 0 
2024-05-14 05:11:39.795935: predicting 17215K_16_2 
2024-05-14 05:11:39.798457: 17215K_16_2, shape torch.Size([1, 44, 190, 263]), rank 0 
2024-05-14 05:11:40.252244: predicting 17216M_16_2 
2024-05-14 05:11:40.254982: 17216M_16_2, shape torch.Size([1, 51, 201, 263]), rank 0 
2024-05-14 05:11:42.008120: predicting 17223J_16_2 
2024-05-14 05:11:42.011067: 17223J_16_2, shape torch.Size([1, 48, 198, 276]), rank 0 
2024-05-14 05:11:42.897164: predicting 17227R_16_2 
2024-05-14 05:11:42.899923: 17227R_16_2, shape torch.Size([1, 50, 180, 262]), rank 0 
2024-05-14 05:11:43.793356: predicting 17236S_16_2 
2024-05-14 05:11:43.796205: 17236S_16_2, shape torch.Size([1, 47, 196, 281]), rank 0 
2024-05-14 05:11:44.684842: predicting 17240J_16_2 
2024-05-14 05:11:44.687497: 17240J_16_2, shape torch.Size([1, 50, 206, 267]), rank 0 
2024-05-14 05:11:46.445652: predicting 17256Y_16_2 
2024-05-14 05:11:46.448677: 17256Y_16_2, shape torch.Size([1, 48, 200, 269]), rank 0 
2024-05-14 05:11:47.335707: predicting 17261R_0_0 
2024-05-14 05:11:47.338290: 17261R_0_0, shape torch.Size([1, 49, 193, 266]), rank 0 
2024-05-14 05:11:49.095592: predicting 17264X_0_0 
2024-05-14 05:11:49.097763: 17264X_0_0, shape torch.Size([1, 40, 197, 278]), rank 0 
2024-05-14 05:11:49.985237: predicting 17306N_0_0 
2024-05-14 05:11:49.988595: 17306N_0_0, shape torch.Size([1, 49, 201, 265]), rank 0 
2024-05-14 05:11:51.745131: predicting 17310E_0_0 
2024-05-14 05:11:51.747788: 17310E_0_0, shape torch.Size([1, 49, 201, 265]), rank 0 
2024-05-14 05:11:53.503667: predicting 17311G_4_2 
2024-05-14 05:11:53.506685: 17311G_4_2, shape torch.Size([1, 51, 203, 266]), rank 0 
2024-05-14 05:11:55.264420: predicting 17316Q_4_3 
2024-05-14 05:11:55.266959: 17316Q_4_3, shape torch.Size([1, 48, 210, 283]), rank 0 
2024-05-14 05:11:56.154084: predicting 17319W_8_2 
2024-05-14 05:11:56.157019: 17319W_8_2, shape torch.Size([1, 40, 191, 268]), rank 0 
2024-05-14 05:11:56.608440: predicting 17328X_4_3 
2024-05-14 05:11:56.611547: 17328X_4_3, shape torch.Size([1, 49, 207, 264]), rank 0 
2024-05-14 05:11:58.368017: predicting 17329Z_16_2 
2024-05-14 05:11:58.371145: 17329Z_16_2, shape torch.Size([1, 47, 201, 274]), rank 0 
2024-05-14 05:11:59.259069: predicting 17355A_8_3 
2024-05-14 05:11:59.262165: 17355A_8_3, shape torch.Size([1, 47, 205, 270]), rank 0 
2024-05-14 05:12:00.150904: predicting 17358G_0_0 
2024-05-14 05:12:00.153934: 17358G_0_0, shape torch.Size([1, 47, 205, 270]), rank 0 
2024-05-14 05:12:01.042766: predicting 17371Y_4_2 
2024-05-14 05:12:01.044118: 17371Y_4_2, shape torch.Size([1, 48, 193, 268]), rank 0 
2024-05-14 05:12:01.925040: predicting 17375G_8_3 
2024-05-14 05:12:01.928450: 17375G_8_3, shape torch.Size([1, 48, 199, 274]), rank 0 
2024-05-14 05:12:02.821470: predicting 17377K_8_3 
2024-05-14 05:12:02.824661: 17377K_8_3, shape torch.Size([1, 52, 204, 279]), rank 0 
2024-05-14 05:12:04.581176: predicting 17382D_8_3 
2024-05-14 05:12:04.584296: 17382D_8_3, shape torch.Size([1, 46, 195, 269]), rank 0 
2024-05-14 05:12:05.472198: predicting 17390C_8_2 
2024-05-14 05:12:05.474682: 17390C_8_2, shape torch.Size([1, 42, 207, 277]), rank 0 
2024-05-14 05:12:06.362163: predicting 17397Q_16_2 
2024-05-14 05:12:06.363491: 17397Q_16_2, shape torch.Size([1, 51, 207, 270]), rank 0 
2024-05-14 05:12:08.111711: predicting 17411K_0_0 
2024-05-14 05:12:08.114179: 17411K_0_0, shape torch.Size([1, 45, 202, 264]), rank 0 
2024-05-14 05:12:08.994473: predicting 17427Z_16_2 
2024-05-14 05:12:08.997436: 17427Z_16_2, shape torch.Size([1, 46, 202, 276]), rank 0 
2024-05-14 05:12:09.884878: predicting 17442V_16_2 
2024-05-14 05:12:09.887449: 17442V_16_2, shape torch.Size([1, 42, 211, 266]), rank 0 
2024-05-14 05:12:10.775484: predicting 17454C_8_2 
2024-05-14 05:12:10.778631: 17454C_8_2, shape torch.Size([1, 48, 198, 278]), rank 0 
2024-05-14 05:12:11.664170: predicting 17464F_16_2 
2024-05-14 05:12:11.667076: 17464F_16_2, shape torch.Size([1, 48, 213, 294]), rank 0 
2024-05-14 05:12:12.553577: predicting 17468N_8_3 
2024-05-14 05:12:12.554878: 17468N_8_3, shape torch.Size([1, 50, 199, 262]), rank 0 
2024-05-14 05:12:14.304571: predicting 17479S_8_3 
2024-05-14 05:12:14.307813: 17479S_8_3, shape torch.Size([1, 44, 188, 271]), rank 0 
2024-05-14 05:12:14.761860: predicting 17492K_0_0 
2024-05-14 05:12:14.764600: 17492K_0_0, shape torch.Size([1, 48, 208, 277]), rank 0 
2024-05-14 05:12:15.651949: predicting 17508Z_8_2 
2024-05-14 05:12:15.654162: 17508Z_8_2, shape torch.Size([1, 45, 186, 263]), rank 0 
2024-05-14 05:12:16.109350: predicting 17514U_4_3 
2024-05-14 05:12:16.110496: 17514U_4_3, shape torch.Size([1, 44, 191, 264]), rank 0 
2024-05-14 05:12:16.556922: predicting 17518C_16_2 
2024-05-14 05:12:16.559955: 17518C_16_2, shape torch.Size([1, 43, 206, 272]), rank 0 
2024-05-14 05:12:17.454648: predicting 17530S_8_2 
2024-05-14 05:12:17.457269: 17530S_8_2, shape torch.Size([1, 52, 209, 274]), rank 0 
2024-05-14 05:12:19.215627: predicting 17532W_0_0 
2024-05-14 05:12:19.218291: 17532W_0_0, shape torch.Size([1, 52, 209, 274]), rank 0 
2024-05-14 05:12:20.976279: predicting 17573K_4_2 
2024-05-14 05:12:20.978814: 17573K_4_2, shape torch.Size([1, 44, 206, 271]), rank 0 
2024-05-14 05:12:21.868210: predicting 17599C_4_3 
2024-05-14 05:12:21.871317: 17599C_4_3, shape torch.Size([1, 48, 200, 265]), rank 0 
2024-05-14 05:12:22.758631: predicting 17601P_16_2 
2024-05-14 05:12:22.761115: 17601P_16_2, shape torch.Size([1, 48, 188, 266]), rank 0 
2024-05-14 05:12:23.208706: predicting 17611S_8_3 
2024-05-14 05:12:23.211938: 17611S_8_3, shape torch.Size([1, 42, 191, 270]), rank 0 
2024-05-14 05:12:23.664876: predicting 17633C_0_0 
2024-05-14 05:12:23.667831: 17633C_0_0, shape torch.Size([1, 45, 205, 266]), rank 0 
2024-05-14 05:12:24.564333: predicting 17634E_0_0 
2024-05-14 05:12:24.567661: 17634E_0_0, shape torch.Size([1, 45, 205, 266]), rank 0 
2024-05-14 05:12:25.454379: predicting 17641B_16_2 
2024-05-14 05:12:25.456234: 17641B_16_2, shape torch.Size([1, 46, 208, 265]), rank 0 
2024-05-14 05:12:26.337982: predicting 17645J_16_2 
2024-05-14 05:12:26.339942: 17645J_16_2, shape torch.Size([1, 41, 198, 265]), rank 0 
2024-05-14 05:12:27.219429: predicting 17649R_8_2 
2024-05-14 05:12:27.221973: 17649R_8_2, shape torch.Size([1, 52, 193, 278]), rank 0 
2024-05-14 05:12:28.977873: predicting 17655M_4_3 
2024-05-14 05:12:28.980821: 17655M_4_3, shape torch.Size([1, 52, 208, 278]), rank 0 
2024-05-14 05:12:30.736943: predicting 17661H_0_0 
2024-05-14 05:12:30.738303: 17661H_0_0, shape torch.Size([1, 43, 195, 267]), rank 0 
2024-05-14 05:12:31.617049: predicting 17676U_16_2 
2024-05-14 05:12:31.618556: 17676U_16_2, shape torch.Size([1, 46, 192, 268]), rank 0 
2024-05-14 05:12:32.064216: predicting 17688B_0_0 
2024-05-14 05:12:32.095854: 17688B_0_0, shape torch.Size([1, 37, 194, 268]), rank 0 
2024-05-14 05:12:32.983886: predicting 17708H_8_3 
2024-05-14 05:12:32.987619: 17708H_8_3, shape torch.Size([1, 42, 201, 278]), rank 0 
2024-05-14 05:12:33.875686: predicting 17725H_4_2 
2024-05-14 05:12:33.878169: 17725H_4_2, shape torch.Size([1, 46, 201, 272]), rank 0 
2024-05-14 05:12:34.766831: predicting 17731C_16_2 
2024-05-14 05:12:34.769772: 17731C_16_2, shape torch.Size([1, 48, 195, 267]), rank 0 
2024-05-14 05:12:35.655534: predicting 17735K_4_2 
2024-05-14 05:12:35.658597: 17735K_4_2, shape torch.Size([1, 49, 206, 267]), rank 0 
2024-05-14 05:12:37.415318: predicting 17763P_0_0 
2024-05-14 05:12:37.418238: 17763P_0_0, shape torch.Size([1, 46, 196, 279]), rank 0 
2024-05-14 05:12:38.306260: predicting 17782T_0_0 
2024-05-14 05:12:38.308896: 17782T_0_0, shape torch.Size([1, 43, 202, 282]), rank 0 
2024-05-14 05:12:39.198962: predicting 17796E_16_2 
2024-05-14 05:12:39.201914: 17796E_16_2, shape torch.Size([1, 48, 193, 283]), rank 0 
2024-05-14 05:12:40.089741: predicting 17812C_8_3 
2024-05-14 05:12:40.091098: 17812C_8_3, shape torch.Size([1, 48, 204, 270]), rank 0 
2024-05-14 05:12:40.971311: predicting 17833K_0_0 
2024-05-14 05:12:40.973757: 17833K_0_0, shape torch.Size([1, 52, 189, 268]), rank 0 
2024-05-14 05:12:41.864151: predicting 17839W_0_0 
2024-05-14 05:12:41.866567: 17839W_0_0, shape torch.Size([1, 44, 211, 288]), rank 0 
2024-05-14 05:12:42.756793: predicting 17845R_4_2 
2024-05-14 05:12:42.760412: 17845R_4_2, shape torch.Size([1, 45, 209, 282]), rank 0 
2024-05-14 05:12:43.649719: predicting 17870Q_8_3 
2024-05-14 05:12:43.652681: 17870Q_8_3, shape torch.Size([1, 44, 194, 275]), rank 0 
2024-05-14 05:12:44.542975: predicting 17871S_16_2 
2024-05-14 05:12:44.545465: 17871S_16_2, shape torch.Size([1, 52, 214, 285]), rank 0 
2024-05-14 05:12:46.301280: predicting 17878G_4_2 
2024-05-14 05:12:46.304591: 17878G_4_2, shape torch.Size([1, 51, 218, 283]), rank 0 
2024-05-14 05:12:48.068111: predicting 17894E_8_3 
2024-05-14 05:12:48.070330: 17894E_8_3, shape torch.Size([1, 52, 206, 275]), rank 0 
2024-05-14 05:12:49.828284: predicting 17908P_4_2 
2024-05-14 05:12:49.831208: 17908P_4_2, shape torch.Size([1, 49, 206, 265]), rank 0 
2024-05-14 05:12:51.586044: predicting 17918S_0_0 
2024-05-14 05:12:51.587397: 17918S_0_0, shape torch.Size([1, 36, 214, 278]), rank 0 
2024-05-14 05:12:52.466785: predicting 17924N_4_3 
2024-05-14 05:12:52.470041: 17924N_4_3, shape torch.Size([1, 52, 196, 274]), rank 0 
2024-05-14 05:12:54.225906: predicting 17945V_8_3 
2024-05-14 05:12:54.228740: 17945V_8_3, shape torch.Size([1, 44, 198, 275]), rank 0 
2024-05-14 05:12:55.117951: predicting 17953U_0_0 
2024-05-14 05:12:55.121061: 17953U_0_0, shape torch.Size([1, 46, 204, 264]), rank 0 
2024-05-14 05:12:56.009646: predicting 17959G_16_2 
2024-05-14 05:12:56.010911: 17959G_16_2, shape torch.Size([1, 44, 199, 280]), rank 0 
2024-05-14 05:12:56.890484: predicting 17963X_4_3 
2024-05-14 05:12:56.893772: 17963X_4_3, shape torch.Size([1, 50, 209, 278]), rank 0 
2024-05-14 05:12:58.650540: predicting 17968H_8_2 
2024-05-14 05:12:58.653197: 17968H_8_2, shape torch.Size([1, 44, 197, 268]), rank 0 
2024-05-14 05:12:59.541945: predicting 17980X_0_0 
2024-05-14 05:12:59.544444: 17980X_0_0, shape torch.Size([1, 50, 199, 269]), rank 0 
2024-05-14 05:13:01.301559: predicting 17987L_16_2 
2024-05-14 05:13:01.302595: 17987L_16_2, shape torch.Size([1, 43, 204, 266]), rank 0 
2024-05-14 05:13:02.185086: predicting 17995K_0_0 
2024-05-14 05:13:02.187541: 17995K_0_0, shape torch.Size([1, 32, 186, 261]), rank 0 
2024-05-14 05:13:02.637511: predicting 18006G_4_2 
2024-05-14 05:13:02.640143: 18006G_4_2, shape torch.Size([1, 51, 185, 271]), rank 0 
2024-05-14 05:13:03.527940: predicting 18016J_16_2 
2024-05-14 05:13:03.530904: 18016J_16_2, shape torch.Size([1, 40, 203, 283]), rank 0 
2024-05-14 05:13:04.416769: predicting 18045Q_0_0 
2024-05-14 05:13:04.419234: 18045Q_0_0, shape torch.Size([1, 50, 192, 269]), rank 0 
2024-05-14 05:13:05.306134: predicting 18054R_4_2 
2024-05-14 05:13:05.309126: 18054R_4_2, shape torch.Size([1, 45, 206, 280]), rank 0 
2024-05-14 05:13:06.198840: predicting 18063S_4_3 
2024-05-14 05:13:06.201767: 18063S_4_3, shape torch.Size([1, 44, 202, 268]), rank 0 
2024-05-14 05:13:07.089596: predicting 18065W_16_2 
2024-05-14 05:13:07.092300: 18065W_16_2, shape torch.Size([1, 51, 218, 277]), rank 0 
2024-05-14 05:13:08.850869: predicting 18078F_4_3 
2024-05-14 05:13:08.853608: 18078F_4_3, shape torch.Size([1, 52, 210, 279]), rank 0 
2024-05-14 05:13:10.612813: predicting 18080S_0_0 
2024-05-14 05:13:10.616127: 18080S_0_0, shape torch.Size([1, 51, 201, 273]), rank 0 
2024-05-14 05:13:12.379699: predicting 18099N_4_2 
2024-05-14 05:13:12.382190: 18099N_4_2, shape torch.Size([1, 44, 192, 275]), rank 0 
2024-05-14 05:13:12.836483: predicting 18104G_8_2 
2024-05-14 05:13:12.839196: 18104G_8_2, shape torch.Size([1, 51, 192, 274]), rank 0 
2024-05-14 05:13:13.724128: predicting 18114J_8_2 
2024-05-14 05:13:13.725517: 18114J_8_2, shape torch.Size([1, 50, 194, 272]), rank 0 
2024-05-14 05:13:15.476570: predicting 18121G_4_2 
2024-05-14 05:13:15.479463: 18121G_4_2, shape torch.Size([1, 43, 198, 272]), rank 0 
2024-05-14 05:13:16.366893: predicting 18123K_16_2 
2024-05-14 05:13:16.369799: 18123K_16_2, shape torch.Size([1, 46, 191, 274]), rank 0 
2024-05-14 05:13:16.824057: predicting 18124M_4_2 
2024-05-14 05:13:16.825031: 18124M_4_2, shape torch.Size([1, 52, 203, 272]), rank 0 
2024-05-14 05:13:18.574483: predicting 18131J_8_3 
2024-05-14 05:13:18.577039: 18131J_8_3, shape torch.Size([1, 43, 194, 282]), rank 0 
2024-05-14 05:13:19.464136: predicting 18133N_8_2 
2024-05-14 05:13:19.466672: 18133N_8_2, shape torch.Size([1, 44, 196, 274]), rank 0 
2024-05-14 05:13:20.354976: predicting 18146W_8_2 
2024-05-14 05:13:20.357398: 18146W_8_2, shape torch.Size([1, 50, 197, 278]), rank 0 
2024-05-14 05:13:22.114221: predicting 18147Y_4_2 
2024-05-14 05:13:22.116675: 18147Y_4_2, shape torch.Size([1, 46, 195, 273]), rank 0 
2024-05-14 05:13:23.004332: predicting 18162U_16_2 
2024-05-14 05:13:23.007992: 18162U_16_2, shape torch.Size([1, 48, 210, 268]), rank 0 
2024-05-14 05:13:23.902888: predicting 18180W_0_0 
2024-05-14 05:13:23.904732: 18180W_0_0, shape torch.Size([1, 43, 190, 270]), rank 0 
2024-05-14 05:13:24.353532: predicting 18188M_0_0 
2024-05-14 05:13:24.356828: 18188M_0_0, shape torch.Size([1, 31, 204, 265]), rank 0 
2024-05-14 05:13:25.240912: predicting 18202G_0_0 
2024-05-14 05:13:25.242129: 18202G_0_0, shape torch.Size([1, 41, 199, 271]), rank 0 
2024-05-14 05:13:26.120735: predicting 18215P_4_3 
2024-05-14 05:13:26.123523: 18215P_4_3, shape torch.Size([1, 46, 199, 268]), rank 0 
2024-05-14 05:13:27.011961: predicting 18218V_4_2 
2024-05-14 05:13:27.014129: 18218V_4_2, shape torch.Size([1, 44, 198, 273]), rank 0 
2024-05-14 05:13:27.903059: predicting 18224Q_16_2 
2024-05-14 05:13:27.905725: 18224Q_16_2, shape torch.Size([1, 44, 208, 276]), rank 0 
2024-05-14 05:13:28.793615: predicting 18251T_4_3 
2024-05-14 05:13:28.796921: 18251T_4_3, shape torch.Size([1, 45, 196, 272]), rank 0 
2024-05-14 05:13:29.692235: predicting 18262Y_16_2 
2024-05-14 05:13:29.694631: 18262Y_16_2, shape torch.Size([1, 31, 205, 274]), rank 0 
2024-05-14 05:13:30.577164: predicting 18270X_8_3 
2024-05-14 05:13:30.580479: 18270X_8_3, shape torch.Size([1, 48, 201, 281]), rank 0 
2024-05-14 05:13:31.466166: predicting 18290D_16_2 
2024-05-14 05:13:31.468778: 18290D_16_2, shape torch.Size([1, 51, 201, 267]), rank 0 
2024-05-14 05:13:33.224501: predicting 18294L_0_0 
2024-05-14 05:13:33.227947: 18294L_0_0, shape torch.Size([1, 43, 196, 269]), rank 0 
2024-05-14 05:13:34.128355: predicting 18307U_0_0 
2024-05-14 05:13:34.130617: 18307U_0_0, shape torch.Size([1, 49, 196, 280]), rank 0 
2024-05-14 05:13:35.877617: predicting 18327A_4_2 
2024-05-14 05:13:35.881114: 18327A_4_2, shape torch.Size([1, 42, 192, 273]), rank 0 
2024-05-14 05:13:36.334069: predicting 18347G_16_2 
2024-05-14 05:13:36.336749: 18347G_16_2, shape torch.Size([1, 47, 203, 283]), rank 0 
2024-05-14 05:13:37.225897: predicting 18359N_0_0 
2024-05-14 05:13:37.228892: 18359N_0_0, shape torch.Size([1, 46, 194, 267]), rank 0 
2024-05-14 05:13:38.116828: predicting 18363E_16_2 
2024-05-14 05:13:38.119684: 18363E_16_2, shape torch.Size([1, 52, 193, 279]), rank 0 
2024-05-14 05:13:39.875845: predicting 18396T_0_0 
2024-05-14 05:13:39.878376: 18396T_0_0, shape torch.Size([1, 50, 194, 273]), rank 0 
2024-05-14 05:13:41.635164: predicting 18401M_4_3 
2024-05-14 05:13:41.638593: 18401M_4_3, shape torch.Size([1, 46, 202, 275]), rank 0 
2024-05-14 05:13:42.528186: predicting 18414V_0_0 
2024-05-14 05:13:42.530399: 18414V_0_0, shape torch.Size([1, 45, 196, 279]), rank 0 
2024-05-14 05:13:43.419321: predicting 18438J_8_3 
2024-05-14 05:13:43.420697: 18438J_8_3, shape torch.Size([1, 43, 198, 268]), rank 0 
2024-05-14 05:13:44.299347: predicting 18453F_4_2 
2024-05-14 05:13:44.302075: 18453F_4_2, shape torch.Size([1, 46, 187, 271]), rank 0 
2024-05-14 05:13:44.757430: predicting 18481K_16_2 
2024-05-14 05:13:44.760494: 18481K_16_2, shape torch.Size([1, 52, 199, 279]), rank 0 
2024-05-14 05:13:46.517550: predicting 18482M_8_2 
2024-05-14 05:13:46.520546: 18482M_8_2, shape torch.Size([1, 51, 206, 269]), rank 0 
2024-05-14 05:13:48.277128: predicting 18488Y_8_2 
2024-05-14 05:13:48.279945: 18488Y_8_2, shape torch.Size([1, 50, 195, 274]), rank 0 
2024-05-14 05:13:50.036751: predicting 18493R_0_0 
2024-05-14 05:13:50.039598: 18493R_0_0, shape torch.Size([1, 33, 197, 255]), rank 0 
2024-05-14 05:13:50.496429: predicting 18495V_8_3 
2024-05-14 05:13:50.499769: 18495V_8_3, shape torch.Size([1, 43, 210, 274]), rank 0 
2024-05-14 05:13:51.395693: predicting 18515B_8_3 
2024-05-14 05:13:51.397082: 18515B_8_3, shape torch.Size([1, 47, 212, 272]), rank 0 
2024-05-14 05:13:52.276902: predicting 18530X_8_2 
2024-05-14 05:13:52.280183: 18530X_8_2, shape torch.Size([1, 43, 190, 275]), rank 0 
2024-05-14 05:13:52.733297: predicting 18531Z_0_0 
2024-05-14 05:13:52.736041: 18531Z_0_0, shape torch.Size([1, 43, 190, 275]), rank 0 
2024-05-14 05:13:53.189243: predicting 18534F_0_0 
2024-05-14 05:13:53.190173: 18534F_0_0, shape torch.Size([1, 48, 199, 272]), rank 0 
2024-05-14 05:13:54.070595: predicting 18539P_4_2 
2024-05-14 05:13:54.073942: 18539P_4_2, shape torch.Size([1, 44, 199, 278]), rank 0 
2024-05-14 05:13:54.961514: predicting 18541C_16_2 
2024-05-14 05:13:54.964392: 18541C_16_2, shape torch.Size([1, 52, 197, 279]), rank 0 
2024-05-14 05:13:56.720781: predicting 18548Q_0_0 
2024-05-14 05:13:56.723958: 18548Q_0_0, shape torch.Size([1, 49, 195, 263]), rank 0 
2024-05-14 05:13:58.477015: predicting 18549S_4_2 
2024-05-14 05:13:58.480217: 18549S_4_2, shape torch.Size([1, 48, 195, 275]), rank 0 
2024-05-14 05:13:59.365987: predicting 18557R_0_0 
2024-05-14 05:13:59.368953: 18557R_0_0, shape torch.Size([1, 46, 207, 269]), rank 0 
2024-05-14 05:14:00.258180: predicting 18559V_4_3 
2024-05-14 05:14:00.259542: 18559V_4_3, shape torch.Size([1, 48, 205, 271]), rank 0 
2024-05-14 05:14:01.139554: predicting 18593V_8_3 
2024-05-14 05:14:01.142594: 18593V_8_3, shape torch.Size([1, 50, 203, 273]), rank 0 
2024-05-14 05:14:02.897998: predicting 18595Z_8_3 
2024-05-14 05:14:02.900887: 18595Z_8_3, shape torch.Size([1, 46, 189, 265]), rank 0 
2024-05-14 05:14:03.355833: predicting 18605C_0_0 
2024-05-14 05:14:03.358155: 18605C_0_0, shape torch.Size([1, 46, 192, 268]), rank 0 
2024-05-14 05:14:03.804225: predicting 18614D_16_2 
2024-05-14 05:14:03.807052: 18614D_16_2, shape torch.Size([1, 50, 201, 265]), rank 0 
2024-05-14 05:14:05.561359: predicting 18615F_0_0 
2024-05-14 05:14:05.564023: 18615F_0_0, shape torch.Size([1, 50, 201, 265]), rank 0 
2024-05-14 05:14:07.321435: predicting 18618L_4_3 
2024-05-14 05:14:07.324649: 18618L_4_3, shape torch.Size([1, 50, 206, 272]), rank 0 
2024-05-14 05:14:09.080633: predicting 18620Y_4_3 
2024-05-14 05:14:09.083900: 18620Y_4_3, shape torch.Size([1, 48, 191, 271]), rank 0 
2024-05-14 05:14:09.539303: predicting 18635L_16_2 
2024-05-14 05:14:09.542274: 18635L_16_2, shape torch.Size([1, 52, 198, 275]), rank 0 
2024-05-14 05:14:11.297546: predicting 18637P_16_2 
2024-05-14 05:14:11.301084: 18637P_16_2, shape torch.Size([1, 46, 199, 274]), rank 0 
2024-05-14 05:14:12.190042: predicting 18657V_8_2 
2024-05-14 05:14:12.193062: 18657V_8_2, shape torch.Size([1, 47, 194, 270]), rank 0 
2024-05-14 05:14:13.082071: predicting 18669C_0_0 
2024-05-14 05:14:13.085023: 18669C_0_0, shape torch.Size([1, 47, 197, 282]), rank 0 
2024-05-14 05:14:13.974115: predicting 18685A_8_3 
2024-05-14 05:14:13.977330: 18685A_8_3, shape torch.Size([1, 42, 199, 277]), rank 0 
2024-05-14 05:14:14.864410: predicting 18686C_0_0 
2024-05-14 05:14:14.866924: 18686C_0_0, shape torch.Size([1, 42, 199, 277]), rank 0 
2024-05-14 05:14:15.753883: predicting 18704E_0_0 
2024-05-14 05:14:15.756879: 18704E_0_0, shape torch.Size([1, 50, 201, 279]), rank 0 
2024-05-14 05:14:17.513298: predicting 18713F_4_3 
2024-05-14 05:14:17.516968: 18713F_4_3, shape torch.Size([1, 48, 189, 273]), rank 0 
2024-05-14 05:14:17.978558: predicting 18714H_4_3 
2024-05-14 05:14:17.981692: 18714H_4_3, shape torch.Size([1, 44, 200, 271]), rank 0 
2024-05-14 05:14:18.869941: predicting 18716L_8_2 
2024-05-14 05:14:18.871294: 18716L_8_2, shape torch.Size([1, 48, 203, 275]), rank 0 
2024-05-14 05:14:19.750182: predicting 18719R_4_3 
2024-05-14 05:14:19.753282: 18719R_4_3, shape torch.Size([1, 51, 202, 278]), rank 0 
2024-05-14 05:14:21.509378: predicting 18727Q_0_0 
2024-05-14 05:14:21.512370: 18727Q_0_0, shape torch.Size([1, 50, 202, 276]), rank 0 
2024-05-14 05:14:23.268286: predicting 18729U_4_2 
2024-05-14 05:14:23.271315: 18729U_4_2, shape torch.Size([1, 48, 201, 268]), rank 0 
2024-05-14 05:14:24.157494: predicting 18730F_8_2 
2024-05-14 05:14:24.160676: 18730F_8_2, shape torch.Size([1, 51, 199, 271]), rank 0 
2024-05-14 05:14:25.915908: predicting 18735P_8_3 
2024-05-14 05:14:25.917343: 18735P_8_3, shape torch.Size([1, 48, 199, 271]), rank 0 
2024-05-14 05:14:26.794803: predicting 18736R_8_3 
2024-05-14 05:14:26.796186: 18736R_8_3, shape torch.Size([1, 47, 206, 260]), rank 0 
2024-05-14 05:14:27.678260: predicting 18749A_8_3 
2024-05-14 05:14:27.682757: 18749A_8_3, shape torch.Size([1, 44, 204, 261]), rank 0 
2024-05-14 05:14:28.569241: predicting 18757Z_0_0 
2024-05-14 05:14:28.571694: 18757Z_0_0, shape torch.Size([1, 42, 190, 271]), rank 0 
2024-05-14 05:14:29.026362: predicting 18762S_4_2 
2024-05-14 05:14:29.028902: 18762S_4_2, shape torch.Size([1, 50, 197, 271]), rank 0 
2024-05-14 05:14:30.783423: predicting 18768E_16_2 
2024-05-14 05:14:30.786247: 18768E_16_2, shape torch.Size([1, 37, 201, 278]), rank 0 
2024-05-14 05:14:31.671196: predicting 18770R_0_0 
2024-05-14 05:14:31.674646: 18770R_0_0, shape torch.Size([1, 46, 200, 268]), rank 0 
2024-05-14 05:14:32.562293: predicting 18794F_8_3 
2024-05-14 05:14:32.565299: 18794F_8_3, shape torch.Size([1, 48, 203, 272]), rank 0 
2024-05-14 05:14:33.451769: predicting 18797L_8_3 
2024-05-14 05:14:33.454782: 18797L_8_3, shape torch.Size([1, 52, 194, 279]), rank 0 
2024-05-14 05:14:35.207917: predicting 18800A_4_2 
2024-05-14 05:14:35.210886: 18800A_4_2, shape torch.Size([1, 48, 207, 274]), rank 0 
2024-05-14 05:14:36.097802: predicting 18808Q_8_2 
2024-05-14 05:14:36.098856: 18808Q_8_2, shape torch.Size([1, 45, 203, 266]), rank 0 
2024-05-14 05:14:36.978045: predicting 18818T_0_0 
2024-05-14 05:14:36.980557: 18818T_0_0, shape torch.Size([1, 50, 211, 275]), rank 0 
2024-05-14 05:14:38.729107: predicting 18822K_4_3 
2024-05-14 05:14:38.732228: 18822K_4_3, shape torch.Size([1, 48, 198, 270]), rank 0 
2024-05-14 05:14:39.620530: predicting 18826S_4_3 
2024-05-14 05:14:39.622703: 18826S_4_3, shape torch.Size([1, 43, 205, 272]), rank 0 
2024-05-14 05:14:40.502254: predicting 18851R_16_2 
2024-05-14 05:14:40.505198: 18851R_16_2, shape torch.Size([1, 36, 196, 278]), rank 0 
2024-05-14 05:14:41.390609: predicting 18870V_8_3 
2024-05-14 05:14:41.393077: 18870V_8_3, shape torch.Size([1, 46, 196, 272]), rank 0 
2024-05-14 05:14:42.280502: predicting 18874D_8_3 
2024-05-14 05:14:42.283279: 18874D_8_3, shape torch.Size([1, 44, 207, 266]), rank 0 
2024-05-14 05:14:43.170040: predicting 18892F_16_2 
2024-05-14 05:14:43.172959: 18892F_16_2, shape torch.Size([1, 46, 181, 262]), rank 0 
2024-05-14 05:14:43.625741: predicting 18913N_4_2 
2024-05-14 05:14:43.627567: 18913N_4_2, shape torch.Size([1, 46, 207, 266]), rank 0 
2024-05-14 05:14:44.508140: predicting 18924S_0_0 
2024-05-14 05:14:44.511147: 18924S_0_0, shape torch.Size([1, 45, 192, 266]), rank 0 
2024-05-14 05:14:44.964397: predicting 18926W_4_3 
2024-05-14 05:14:44.966646: 18926W_4_3, shape torch.Size([1, 44, 205, 277]), rank 0 
2024-05-14 05:14:45.847559: predicting 18927Y_0_0 
2024-05-14 05:14:45.850534: 18927Y_0_0, shape torch.Size([1, 44, 205, 277]), rank 0 
2024-05-14 05:14:46.738517: predicting 18937B_16_2 
2024-05-14 05:14:46.741385: 18937B_16_2, shape torch.Size([1, 44, 197, 274]), rank 0 
2024-05-14 05:14:47.628438: predicting 18940Q_0_0 
2024-05-14 05:14:47.630190: 18940Q_0_0, shape torch.Size([1, 40, 202, 271]), rank 0 
2024-05-14 05:14:48.512630: predicting 18951V_16_2 
2024-05-14 05:14:48.516048: 18951V_16_2, shape torch.Size([1, 48, 202, 262]), rank 0 
2024-05-14 05:14:49.401866: predicting 18957H_8_3 
2024-05-14 05:14:49.404742: 18957H_8_3, shape torch.Size([1, 48, 205, 278]), rank 0 
2024-05-14 05:14:50.292484: predicting 18958J_8_2 
2024-05-14 05:14:50.295032: 18958J_8_2, shape torch.Size([1, 50, 199, 274]), rank 0 
2024-05-14 05:14:52.052062: predicting 18959L_16_2 
2024-05-14 05:14:52.054662: 18959L_16_2, shape torch.Size([1, 47, 201, 270]), rank 0 
2024-05-14 05:14:52.942428: predicting 18967K_8_2 
2024-05-14 05:14:52.944909: 18967K_8_2, shape torch.Size([1, 48, 197, 277]), rank 0 
2024-05-14 05:14:53.831999: predicting 18972D_16_2 
2024-05-14 05:14:53.834787: 18972D_16_2, shape torch.Size([1, 49, 203, 277]), rank 0 
2024-05-14 05:14:55.590625: predicting 18974H_8_3 
2024-05-14 05:14:55.591986: 18974H_8_3, shape torch.Size([1, 37, 195, 267]), rank 0 
2024-05-14 05:14:56.470210: predicting 19000Z_16_2 
2024-05-14 05:14:56.473037: 19000Z_16_2, shape torch.Size([1, 50, 199, 262]), rank 0 
2024-05-14 05:14:58.228506: predicting 19020F_8_2 
2024-05-14 05:14:58.229868: 19020F_8_2, shape torch.Size([1, 52, 209, 284]), rank 0 
2024-05-14 05:14:59.978290: predicting 19025P_8_2 
2024-05-14 05:14:59.981282: 19025P_8_2, shape torch.Size([1, 40, 197, 266]), rank 0 
2024-05-14 05:15:00.868588: predicting 19043R_4_2 
2024-05-14 05:15:00.870935: 19043R_4_2, shape torch.Size([1, 47, 206, 277]), rank 0 
2024-05-14 05:15:01.752698: predicting 19045V_8_2 
2024-05-14 05:15:01.755991: 19045V_8_2, shape torch.Size([1, 48, 191, 274]), rank 0 
2024-05-14 05:15:02.222687: predicting 19047Z_4_2 
2024-05-14 05:15:02.225749: 19047Z_4_2, shape torch.Size([1, 44, 202, 266]), rank 0 
2024-05-14 05:15:03.113493: predicting 19053U_16_2 
2024-05-14 05:15:03.116375: 19053U_16_2, shape torch.Size([1, 48, 195, 277]), rank 0 
2024-05-14 05:15:04.007938: predicting 19059G_0_0 
2024-05-14 05:15:04.010718: 19059G_0_0, shape torch.Size([1, 50, 209, 269]), rank 0 
2024-05-14 05:15:05.768756: predicting 19060R_4_3 
2024-05-14 05:15:05.770095: 19060R_4_3, shape torch.Size([1, 43, 206, 276]), rank 0 
2024-05-14 05:15:06.649624: predicting 19062V_0_0 
2024-05-14 05:15:06.651240: 19062V_0_0, shape torch.Size([1, 43, 206, 276]), rank 0 
2024-05-14 05:15:07.532386: predicting 19065B_8_3 
2024-05-14 05:15:07.535291: 19065B_8_3, shape torch.Size([1, 48, 203, 291]), rank 0 
2024-05-14 05:15:08.422028: predicting 19068H_4_2 
2024-05-14 05:15:08.424954: 19068H_4_2, shape torch.Size([1, 44, 193, 272]), rank 0 
2024-05-14 05:15:09.312533: predicting 19069J_16_2 
2024-05-14 05:15:09.315410: 19069J_16_2, shape torch.Size([1, 48, 192, 266]), rank 0 
2024-05-14 05:15:09.768212: predicting 19072Y_4_3 
2024-05-14 05:15:09.771001: 19072Y_4_3, shape torch.Size([1, 52, 182, 258]), rank 0 
2024-05-14 05:15:10.659445: predicting 19096M_8_3 
2024-05-14 05:15:10.662664: 19096M_8_3, shape torch.Size([1, 50, 199, 276]), rank 0 
2024-05-14 05:15:12.421032: predicting 19099S_4_3 
2024-05-14 05:15:12.423974: 19099S_4_3, shape torch.Size([1, 48, 197, 265]), rank 0 
2024-05-14 05:15:13.310868: predicting 19103J_4_2 
2024-05-14 05:15:13.313820: 19103J_4_2, shape torch.Size([1, 50, 209, 291]), rank 0 
2024-05-14 05:15:15.070369: predicting 19140P_4_3 
2024-05-14 05:15:15.073356: 19140P_4_3, shape torch.Size([1, 42, 198, 260]), rank 0 
2024-05-14 05:15:15.960610: predicting 19153Y_4_2 
2024-05-14 05:15:15.962220: 19153Y_4_2, shape torch.Size([1, 42, 190, 269]), rank 0 
2024-05-14 05:15:16.415712: predicting 19164D_8_2 
2024-05-14 05:15:16.417886: 19164D_8_2, shape torch.Size([1, 46, 206, 279]), rank 0 
2024-05-14 05:15:17.298753: predicting 19193K_8_3 
2024-05-14 05:15:17.301319: 19193K_8_3, shape torch.Size([1, 35, 195, 264]), rank 0 
2024-05-14 05:15:18.186000: predicting 19194M_8_2 
2024-05-14 05:15:18.187948: 19194M_8_2, shape torch.Size([1, 48, 194, 266]), rank 0 
2024-05-14 05:15:19.067391: predicting 19218A_8_3 
2024-05-14 05:15:19.070588: 19218A_8_3, shape torch.Size([1, 43, 202, 271]), rank 0 
2024-05-14 05:15:19.959657: predicting 19219C_16_2 
2024-05-14 05:15:19.961882: 19219C_16_2, shape torch.Size([1, 42, 201, 264]), rank 0 
2024-05-14 05:15:20.850145: predicting 19227B_4_3 
2024-05-14 05:15:20.853285: 19227B_4_3, shape torch.Size([1, 45, 191, 271]), rank 0 
2024-05-14 05:15:21.307648: predicting 19233W_16_2 
2024-05-14 05:15:21.310446: 19233W_16_2, shape torch.Size([1, 48, 197, 283]), rank 0 
2024-05-14 05:15:22.196837: predicting 19236C_0_0 
2024-05-14 05:15:22.199879: 19236C_0_0, shape torch.Size([1, 42, 207, 274]), rank 0 
2024-05-14 05:15:23.088652: predicting 19246F_4_3 
2024-05-14 05:15:23.091966: 19246F_4_3, shape torch.Size([1, 48, 201, 287]), rank 0 
2024-05-14 05:15:23.992949: predicting 19253C_4_3 
2024-05-14 05:15:23.995899: 19253C_4_3, shape torch.Size([1, 52, 199, 272]), rank 0 
2024-05-14 05:15:25.751011: predicting 19262D_4_2 
2024-05-14 05:15:25.753903: 19262D_4_2, shape torch.Size([1, 49, 182, 261]), rank 0 
2024-05-14 05:15:26.643024: predicting 19267N_0_0 
2024-05-14 05:15:26.645638: 19267N_0_0, shape torch.Size([1, 46, 194, 281]), rank 0 
2024-05-14 05:15:27.534002: predicting 19282J_4_2 
2024-05-14 05:15:27.535326: 19282J_4_2, shape torch.Size([1, 44, 192, 274]), rank 0 
2024-05-14 05:15:27.982003: predicting 19286R_4_2 
2024-05-14 05:15:27.985079: 19286R_4_2, shape torch.Size([1, 44, 185, 276]), rank 0 
2024-05-14 05:15:28.438148: predicting 19287T_16_2 
2024-05-14 05:15:28.440768: 19287T_16_2, shape torch.Size([1, 48, 195, 264]), rank 0 
2024-05-14 05:15:29.325306: predicting 19294Q_0_0 
2024-05-14 05:15:29.329136: 19294Q_0_0, shape torch.Size([1, 47, 201, 263]), rank 0 
2024-05-14 05:15:30.217911: predicting 19301N_8_3 
2024-05-14 05:15:30.221178: 19301N_8_3, shape torch.Size([1, 42, 197, 264]), rank 0 
2024-05-14 05:15:31.105947: predicting 19305V_8_2 
2024-05-14 05:15:31.109419: 19305V_8_2, shape torch.Size([1, 50, 200, 281]), rank 0 
2024-05-14 05:15:32.864585: predicting 19309D_4_3 
2024-05-14 05:15:32.867903: 19309D_4_3, shape torch.Size([1, 50, 205, 269]), rank 0 
2024-05-14 05:15:34.625290: predicting 19322V_4_3 
2024-05-14 05:15:34.628363: 19322V_4_3, shape torch.Size([1, 51, 202, 278]), rank 0 
2024-05-14 05:15:36.394140: predicting 19333A_0_0 
2024-05-14 05:15:36.395550: 19333A_0_0, shape torch.Size([1, 48, 199, 276]), rank 0 
2024-05-14 05:15:37.274680: predicting 19334C_0_0 
2024-05-14 05:15:37.277434: 19334C_0_0, shape torch.Size([1, 48, 199, 276]), rank 0 
2024-05-14 05:15:38.165856: predicting 19339M_16_2 
2024-05-14 05:15:38.168546: 19339M_16_2, shape torch.Size([1, 47, 186, 265]), rank 0 
2024-05-14 05:15:38.623304: predicting 19353G_4_3 
2024-05-14 05:15:38.626131: 19353G_4_3, shape torch.Size([1, 44, 202, 263]), rank 0 
2024-05-14 05:15:39.513758: predicting 19369V_4_2 
2024-05-14 05:15:39.516242: 19369V_4_2, shape torch.Size([1, 45, 204, 281]), rank 0 
2024-05-14 05:15:40.405167: predicting 19373M_8_3 
2024-05-14 05:15:40.408358: 19373M_8_3, shape torch.Size([1, 45, 205, 276]), rank 0 
2024-05-14 05:15:41.297943: predicting 19377U_4_2 
2024-05-14 05:15:41.300483: 19377U_4_2, shape torch.Size([1, 47, 204, 277]), rank 0 
2024-05-14 05:15:42.190174: predicting 19399E_16_2 
2024-05-14 05:15:42.193175: 19399E_16_2, shape torch.Size([1, 40, 200, 278]), rank 0 
2024-05-14 05:15:43.080488: predicting 19402T_16_2 
2024-05-14 05:15:43.083165: 19402T_16_2, shape torch.Size([1, 43, 190, 258]), rank 0 
2024-05-14 05:15:43.536147: predicting 19410S_4_3 
2024-05-14 05:15:43.538794: 19410S_4_3, shape torch.Size([1, 52, 203, 271]), rank 0 
2024-05-14 05:15:45.296176: predicting 19414A_0_0 
2024-05-14 05:15:45.299461: 19414A_0_0, shape torch.Size([1, 52, 200, 272]), rank 0 
2024-05-14 05:15:47.054174: predicting 19416E_8_3 
2024-05-14 05:15:47.056997: 19416E_8_3, shape torch.Size([1, 50, 189, 270]), rank 0 
2024-05-14 05:15:47.946464: predicting 19421X_0_0 
2024-05-14 05:15:47.949912: 19421X_0_0, shape torch.Size([1, 50, 189, 270]), rank 0 
2024-05-14 05:15:48.840297: predicting 19458U_4_3 
2024-05-14 05:15:48.842840: 19458U_4_3, shape torch.Size([1, 46, 210, 277]), rank 0 
2024-05-14 05:15:49.732821: predicting 19461J_16_2 
2024-05-14 05:15:49.734816: 19461J_16_2, shape torch.Size([1, 44, 202, 272]), rank 0 
2024-05-14 05:15:50.615906: predicting 19462L_0_0 
2024-05-14 05:15:50.618614: 19462L_0_0, shape torch.Size([1, 44, 202, 272]), rank 0 
2024-05-14 05:15:51.506283: predicting 19473Q_16_2 
2024-05-14 05:15:51.508773: 19473Q_16_2, shape torch.Size([1, 46, 210, 276]), rank 0 
2024-05-14 05:15:52.399012: predicting 19486Z_4_2 
2024-05-14 05:15:52.401465: 19486Z_4_2, shape torch.Size([1, 44, 200, 264]), rank 0 
2024-05-14 05:15:53.288885: predicting 19490Q_16_2 
2024-05-14 05:15:53.292131: 19490Q_16_2, shape torch.Size([1, 41, 201, 268]), rank 0 
2024-05-14 05:15:54.184302: predicting 19495A_4_3 
2024-05-14 05:15:54.187926: 19495A_4_3, shape torch.Size([1, 50, 205, 282]), rank 0 
2024-05-14 05:15:55.956133: predicting 19502X_4_3 
2024-05-14 05:15:55.957189: 19502X_4_3, shape torch.Size([1, 44, 209, 276]), rank 0 
2024-05-14 05:15:56.836709: predicting 19505D_0_0 
2024-05-14 05:15:56.839655: 19505D_0_0, shape torch.Size([1, 47, 200, 273]), rank 0 
2024-05-14 05:15:57.738844: predicting 19512A_8_3 
2024-05-14 05:15:57.741976: 19512A_8_3, shape torch.Size([1, 50, 196, 266]), rank 0 
2024-05-14 05:15:59.495675: predicting 19540F_0_0 
2024-05-14 05:15:59.498484: 19540F_0_0, shape torch.Size([1, 48, 187, 272]), rank 0 
2024-05-14 05:15:59.952841: predicting 19543L_16_2 
2024-05-14 05:15:59.955828: 19543L_16_2, shape torch.Size([1, 42, 203, 264]), rank 0 
2024-05-14 05:16:00.851562: predicting 19564T_0_0 
2024-05-14 05:16:00.854512: 19564T_0_0, shape torch.Size([1, 42, 187, 264]), rank 0 
2024-05-14 05:16:01.306948: predicting 19569D_8_2 
2024-05-14 05:16:01.309051: 19569D_8_2, shape torch.Size([1, 47, 203, 270]), rank 0 
2024-05-14 05:16:02.197938: predicting 19584Z_8_3 
2024-05-14 05:16:02.200732: 19584Z_8_3, shape torch.Size([1, 37, 200, 283]), rank 0 
2024-05-14 05:16:03.086493: predicting 19585B_4_2 
2024-05-14 05:16:03.088961: 19585B_4_2, shape torch.Size([1, 50, 205, 272]), rank 0 
2024-05-14 05:16:04.843973: predicting 19588H_4_3 
2024-05-14 05:16:04.847114: 19588H_4_3, shape torch.Size([1, 45, 197, 265]), rank 0 
2024-05-14 05:16:05.734962: predicting 19592Y_0_0 
2024-05-14 05:16:05.737952: 19592Y_0_0, shape torch.Size([1, 45, 197, 265]), rank 0 
2024-05-14 05:16:06.625082: predicting 19599M_16_2 
2024-05-14 05:16:06.628125: 19599M_16_2, shape torch.Size([1, 46, 194, 270]), rank 0 
2024-05-14 05:16:07.514771: predicting 19601Z_16_2 
2024-05-14 05:16:07.517546: 19601Z_16_2, shape torch.Size([1, 39, 198, 258]), rank 0 
2024-05-14 05:16:08.401656: predicting 19619S_4_2 
2024-05-14 05:16:08.404447: 19619S_4_2, shape torch.Size([1, 44, 195, 278]), rank 0 
2024-05-14 05:16:09.290290: predicting 19620D_8_3 
2024-05-14 05:16:09.293023: 19620D_8_3, shape torch.Size([1, 45, 198, 273]), rank 0 
2024-05-14 05:16:10.182241: predicting 19621F_8_2 
2024-05-14 05:16:10.184656: 19621F_8_2, shape torch.Size([1, 42, 188, 275]), rank 0 
2024-05-14 05:16:10.639560: predicting 19622H_16_2 
2024-05-14 05:16:10.642291: 19622H_16_2, shape torch.Size([1, 52, 197, 268]), rank 0 
2024-05-14 05:16:12.398655: predicting 19627R_16_2 
2024-05-14 05:16:12.401274: 19627R_16_2, shape torch.Size([1, 48, 192, 270]), rank 0 
2024-05-14 05:16:12.854464: predicting 19645T_16_2 
2024-05-14 05:16:12.857341: 19645T_16_2, shape torch.Size([1, 37, 195, 271]), rank 0 
2024-05-14 05:16:13.742363: predicting 19650M_8_3 
2024-05-14 05:16:13.745131: 19650M_8_3, shape torch.Size([1, 43, 192, 268]), rank 0 
2024-05-14 05:16:14.198223: predicting 19661R_8_2 
2024-05-14 05:16:14.200351: 19661R_8_2, shape torch.Size([1, 46, 197, 262]), rank 0 
2024-05-14 05:16:15.087889: predicting 19665Z_16_2 
2024-05-14 05:16:15.090549: 19665Z_16_2, shape torch.Size([1, 43, 201, 269]), rank 0 
2024-05-14 05:16:15.977885: predicting 19679K_4_3 
2024-05-14 05:16:15.979212: 19679K_4_3, shape torch.Size([1, 49, 196, 270]), rank 0 
2024-05-14 05:16:17.728597: predicting 19681X_8_3 
2024-05-14 05:16:17.732616: 19681X_8_3, shape torch.Size([1, 47, 199, 276]), rank 0 
2024-05-14 05:16:18.623371: predicting 19683B_8_3 
2024-05-14 05:16:18.626400: 19683B_8_3, shape torch.Size([1, 43, 208, 268]), rank 0 
2024-05-14 05:16:19.514101: predicting 19686H_4_3 
2024-05-14 05:16:19.517338: 19686H_4_3, shape torch.Size([1, 46, 212, 273]), rank 0 
2024-05-14 05:16:20.406764: predicting 19688L_4_3 
2024-05-14 05:16:20.408906: 19688L_4_3, shape torch.Size([1, 48, 196, 276]), rank 0 
2024-05-14 05:16:21.290092: predicting 19711G_0_0 
2024-05-14 05:16:21.293093: 19711G_0_0, shape torch.Size([1, 50, 211, 265]), rank 0 
2024-05-14 05:16:23.049040: predicting 19730K_8_3 
2024-05-14 05:16:23.052120: 19730K_8_3, shape torch.Size([1, 51, 204, 274]), rank 0 
2024-05-14 05:16:24.814291: predicting 19737Y_16_2 
2024-05-14 05:16:24.817159: 19737Y_16_2, shape torch.Size([1, 44, 199, 280]), rank 0 
2024-05-14 05:16:25.704602: predicting 19739C_8_3 
2024-05-14 05:16:25.707527: 19739C_8_3, shape torch.Size([1, 48, 193, 272]), rank 0 
2024-05-14 05:16:26.594369: predicting 19743T_4_2 
2024-05-14 05:16:26.597374: 19743T_4_2, shape torch.Size([1, 42, 186, 259]), rank 0 
2024-05-14 05:16:27.049935: predicting 19762X_0_0 
2024-05-14 05:16:27.053080: 19762X_0_0, shape torch.Size([1, 49, 188, 273]), rank 0 
2024-05-14 05:16:27.941083: predicting 19772A_4_3 
2024-05-14 05:16:27.943882: 19772A_4_3, shape torch.Size([1, 50, 196, 280]), rank 0 
2024-05-14 05:16:29.699247: predicting 19786L_8_2 
2024-05-14 05:16:29.701973: 19786L_8_2, shape torch.Size([1, 48, 209, 272]), rank 0 
2024-05-14 05:16:30.589475: predicting 19789R_4_2 
2024-05-14 05:16:30.592205: 19789R_4_2, shape torch.Size([1, 51, 196, 275]), rank 0 
2024-05-14 05:16:32.349336: predicting 19804N_4_2 
2024-05-14 05:16:32.352856: 19804N_4_2, shape torch.Size([1, 47, 193, 267]), rank 0 
2024-05-14 05:16:33.240896: predicting 19809X_4_2 
2024-05-14 05:16:33.243592: 19809X_4_2, shape torch.Size([1, 46, 183, 270]), rank 0 
2024-05-14 05:16:33.698293: predicting 19837C_16_2 
2024-05-14 05:16:33.701035: 19837C_16_2, shape torch.Size([1, 42, 194, 265]), rank 0 
2024-05-14 05:16:34.588625: predicting 19852Y_4_2 
2024-05-14 05:16:34.589912: 19852Y_4_2, shape torch.Size([1, 52, 200, 266]), rank 0 
2024-05-14 05:16:36.338453: predicting 19855E_16_2 
2024-05-14 05:16:36.341830: 19855E_16_2, shape torch.Size([1, 50, 191, 267]), rank 0 
2024-05-14 05:16:37.229269: predicting 19863D_16_2 
2024-05-14 05:16:37.232159: 19863D_16_2, shape torch.Size([1, 46, 200, 279]), rank 0 
2024-05-14 05:16:38.120788: predicting 19873G_0_0 
2024-05-14 05:16:38.123760: 19873G_0_0, shape torch.Size([1, 38, 193, 267]), rank 0 
2024-05-14 05:16:39.007946: predicting 19887R_16_2 
2024-05-14 05:16:39.011579: 19887R_16_2, shape torch.Size([1, 48, 202, 270]), rank 0 
2024-05-14 05:16:39.903677: predicting 19918C_4_3 
2024-05-14 05:16:39.905865: 19918C_4_3, shape torch.Size([1, 48, 210, 278]), rank 0 
2024-05-14 05:16:40.786539: predicting 19919E_0_0 
2024-05-14 05:16:40.789559: 19919E_0_0, shape torch.Size([1, 48, 210, 278]), rank 0 
2024-05-14 05:16:41.679262: predicting 19943B_16_2 
2024-05-14 05:16:41.681891: 19943B_16_2, shape torch.Size([1, 45, 198, 272]), rank 0 
2024-05-14 05:16:42.569775: predicting 19947J_0_0 
2024-05-14 05:16:42.572770: 19947J_0_0, shape torch.Size([1, 49, 202, 276]), rank 0 
2024-05-14 05:16:44.329021: predicting 19950Y_4_2 
2024-05-14 05:16:44.331942: 19950Y_4_2, shape torch.Size([1, 44, 200, 273]), rank 0 
2024-05-14 05:16:45.220587: predicting 19952C_16_2 
2024-05-14 05:16:45.224113: 19952C_16_2, shape torch.Size([1, 46, 194, 270]), rank 0 
2024-05-14 05:16:46.113152: predicting 19988X_4_2 
2024-05-14 05:16:46.115925: 19988X_4_2, shape torch.Size([1, 50, 198, 265]), rank 0 
2024-05-14 05:16:47.877841: predicting 19993Q_0_0 
2024-05-14 05:16:47.880497: 19993Q_0_0, shape torch.Size([1, 46, 216, 266]), rank 0 
2024-05-14 05:16:48.770071: predicting 19994S_16_2 
2024-05-14 05:16:48.773057: 19994S_16_2, shape torch.Size([1, 48, 203, 266]), rank 0 
2024-05-14 05:16:49.659841: predicting 19997Y_16_2 
2024-05-14 05:16:49.662532: 19997Y_16_2, shape torch.Size([1, 42, 205, 265]), rank 0 
2024-05-14 05:16:50.549091: predicting 20033B_16_2 
2024-05-14 05:16:50.552223: 20033B_16_2, shape torch.Size([1, 44, 186, 269]), rank 0 
2024-05-14 05:16:51.011439: predicting 20038L_16_2 
2024-05-14 05:16:51.013934: 20038L_16_2, shape torch.Size([1, 46, 197, 275]), rank 0 
2024-05-14 05:16:51.902226: predicting 20050B_16_2 
2024-05-14 05:16:51.905402: 20050B_16_2, shape torch.Size([1, 48, 200, 261]), rank 0 
2024-05-14 05:16:52.790870: predicting 20058R_8_3 
2024-05-14 05:16:52.793751: 20058R_8_3, shape torch.Size([1, 46, 196, 274]), rank 0 
2024-05-14 05:16:53.681703: predicting 20059T_4_2 
2024-05-14 05:16:53.684519: 20059T_4_2, shape torch.Size([1, 44, 204, 265]), rank 0 
2024-05-14 05:16:54.572877: predicting 20076T_4_3 
2024-05-14 05:16:54.575073: 20076T_4_3, shape torch.Size([1, 47, 206, 280]), rank 0 
2024-05-14 05:16:55.457606: predicting 20078X_16_2 
2024-05-14 05:16:55.460544: 20078X_16_2, shape torch.Size([1, 43, 203, 272]), rank 0 
2024-05-14 05:16:56.350123: predicting 20089C_16_2 
2024-05-14 05:16:56.353078: 20089C_16_2, shape torch.Size([1, 52, 193, 281]), rank 0 
2024-05-14 05:16:58.117428: predicting 20092R_4_2 
2024-05-14 05:16:58.120559: 20092R_4_2, shape torch.Size([1, 50, 197, 267]), rank 0 
2024-05-14 05:16:59.876064: predicting 20107E_8_2 
2024-05-14 05:16:59.877296: 20107E_8_2, shape torch.Size([1, 52, 194, 267]), rank 0 
2024-05-14 05:17:01.625353: predicting 20118J_16_2 
2024-05-14 05:17:01.627944: 20118J_16_2, shape torch.Size([1, 46, 194, 253]), rank 0 
2024-05-14 05:17:02.081767: predicting 20125G_8_3 
2024-05-14 05:17:02.084157: 20125G_8_3, shape torch.Size([1, 51, 203, 281]), rank 0 
2024-05-14 05:17:03.841933: predicting 20139R_8_2 
2024-05-14 05:17:03.844409: 20139R_8_2, shape torch.Size([1, 42, 198, 270]), rank 0 
2024-05-14 05:17:04.731924: predicting 20151H_4_3 
2024-05-14 05:17:04.734779: 20151H_4_3, shape torch.Size([1, 52, 202, 267]), rank 0 
2024-05-14 05:17:06.491227: predicting 20161K_0_0 
2024-05-14 05:17:06.494004: 20161K_0_0, shape torch.Size([1, 50, 196, 276]), rank 0 
2024-05-14 05:17:08.251068: predicting 20168Y_16_2 
2024-05-14 05:17:08.253875: 20168Y_16_2, shape torch.Size([1, 46, 192, 275]), rank 0 
2024-05-14 05:17:08.721027: predicting 20191T_4_2 
2024-05-14 05:17:08.723909: 20191T_4_2, shape torch.Size([1, 49, 208, 272]), rank 0 
2024-05-14 05:17:10.482666: predicting 20193X_4_3 
2024-05-14 05:17:10.485419: 20193X_4_3, shape torch.Size([1, 48, 205, 275]), rank 0 
2024-05-14 05:17:11.372642: predicting 20204C_8_2 
2024-05-14 05:17:11.375875: 20204C_8_2, shape torch.Size([1, 43, 200, 269]), rank 0 
2024-05-14 05:17:12.263994: predicting 20209M_16_2 
2024-05-14 05:17:12.266352: 20209M_16_2, shape torch.Size([1, 46, 206, 278]), rank 0 
2024-05-14 05:17:13.149572: predicting 20219P_16_2 
2024-05-14 05:17:13.152441: 20219P_16_2, shape torch.Size([1, 48, 205, 283]), rank 0 
2024-05-14 05:17:14.041504: predicting 20238T_4_3 
2024-05-14 05:17:14.044523: 20238T_4_3, shape torch.Size([1, 50, 179, 269]), rank 0 
2024-05-14 05:17:14.936133: predicting 20259B_8_2 
2024-05-14 05:17:14.938936: 20259B_8_2, shape torch.Size([1, 51, 200, 272]), rank 0 
2024-05-14 05:17:16.697324: predicting 20260M_8_2 
2024-05-14 05:17:16.698681: 20260M_8_2, shape torch.Size([1, 39, 202, 273]), rank 0 
2024-05-14 05:17:17.577585: predicting 20287G_16_2 
2024-05-14 05:17:17.582002: 20287G_16_2, shape torch.Size([1, 41, 195, 264]), rank 0 
2024-05-14 05:17:18.482118: predicting 20289K_16_2 
2024-05-14 05:17:18.485175: 20289K_16_2, shape torch.Size([1, 35, 207, 257]), rank 0 
2024-05-14 05:17:19.369377: predicting 20323K_16_2 
2024-05-14 05:17:19.370646: 20323K_16_2, shape torch.Size([1, 45, 200, 272]), rank 0 
2024-05-14 05:17:20.250253: predicting 20327S_16_2 
2024-05-14 05:17:20.253388: 20327S_16_2, shape torch.Size([1, 46, 196, 273]), rank 0 
2024-05-14 05:17:21.140980: predicting 20330H_0_0 
2024-05-14 05:17:21.144140: 20330H_0_0, shape torch.Size([1, 46, 196, 273]), rank 0 
2024-05-14 05:17:22.032263: predicting 20332L_4_3 
2024-05-14 05:17:22.034762: 20332L_4_3, shape torch.Size([1, 50, 201, 272]), rank 0 
2024-05-14 05:17:23.790571: predicting 20335R_16_2 
2024-05-14 05:17:23.793106: 20335R_16_2, shape torch.Size([1, 45, 195, 277]), rank 0 
2024-05-14 05:17:24.681218: predicting 20339Z_16_2 
2024-05-14 05:17:24.684585: 20339Z_16_2, shape torch.Size([1, 39, 195, 277]), rank 0 
2024-05-14 05:17:25.570529: predicting 20362U_4_2 
2024-05-14 05:17:25.573027: 20362U_4_2, shape torch.Size([1, 46, 199, 281]), rank 0 
2024-05-14 05:17:26.461719: predicting 20375D_8_2 
2024-05-14 05:17:26.464292: 20375D_8_2, shape torch.Size([1, 46, 189, 268]), rank 0 
2024-05-14 05:17:26.918380: predicting 20398P_4_3 
2024-05-14 05:17:26.920269: 20398P_4_3, shape torch.Size([1, 43, 203, 281]), rank 0 
2024-05-14 05:17:27.807084: predicting 20399R_4_3 
2024-05-14 05:17:27.809373: 20399R_4_3, shape torch.Size([1, 52, 185, 269]), rank 0 
2024-05-14 05:17:28.690863: predicting 20400C_16_2 
2024-05-14 05:17:28.693314: 20400C_16_2, shape torch.Size([1, 45, 197, 274]), rank 0 
2024-05-14 05:17:29.582488: predicting 20422M_8_2 
2024-05-14 05:17:29.583492: 20422M_8_2, shape torch.Size([1, 47, 198, 269]), rank 0 
2024-05-14 05:17:30.464281: predicting 20426U_8_2 
2024-05-14 05:17:30.465544: 20426U_8_2, shape torch.Size([1, 46, 199, 278]), rank 0 
2024-05-14 05:17:31.347918: predicting 20433R_16_2 
2024-05-14 05:17:31.350546: 20433R_16_2, shape torch.Size([1, 46, 184, 252]), rank 0 
2024-05-14 05:17:31.586751: predicting 20445Y_4_2 
2024-05-14 05:17:31.590268: 20445Y_4_2, shape torch.Size([1, 46, 193, 273]), rank 0 
2024-05-14 05:17:32.472960: predicting 20446A_4_3 
2024-05-14 05:17:32.475492: 20446A_4_3, shape torch.Size([1, 46, 200, 272]), rank 0 
2024-05-14 05:17:33.363894: predicting 20477L_0_0 
2024-05-14 05:17:33.364864: 20477L_0_0, shape torch.Size([1, 48, 197, 283]), rank 0 
2024-05-14 05:17:34.243954: predicting 20508W_4_2 
2024-05-14 05:17:34.247085: 20508W_4_2, shape torch.Size([1, 45, 196, 267]), rank 0 
2024-05-14 05:17:35.134452: predicting 20529E_8_3 
2024-05-14 05:17:35.137265: 20529E_8_3, shape torch.Size([1, 46, 202, 277]), rank 0 
2024-05-14 05:17:36.026692: predicting 20537D_0_0 
2024-05-14 05:17:36.028784: 20537D_0_0, shape torch.Size([1, 46, 202, 279]), rank 0 
2024-05-14 05:17:36.909816: predicting 20545C_8_2 
2024-05-14 05:17:36.913206: 20545C_8_2, shape torch.Size([1, 50, 215, 278]), rank 0 
2024-05-14 05:17:38.677458: predicting 20547G_16_2 
2024-05-14 05:17:38.680265: 20547G_16_2, shape torch.Size([1, 44, 197, 275]), rank 0 
2024-05-14 05:17:39.567223: predicting 20556H_0_0 
2024-05-14 05:17:39.569706: 20556H_0_0, shape torch.Size([1, 51, 203, 274]), rank 0 
2024-05-14 05:17:41.324560: predicting 20559N_8_2 
2024-05-14 05:17:41.327475: 20559N_8_2, shape torch.Size([1, 44, 199, 272]), rank 0 
2024-05-14 05:17:42.215880: predicting 20579T_8_2 
2024-05-14 05:17:42.218059: 20579T_8_2, shape torch.Size([1, 43, 195, 272]), rank 0 
2024-05-14 05:17:43.105212: predicting 20586Q_4_2 
2024-05-14 05:17:43.108114: 20586Q_4_2, shape torch.Size([1, 52, 199, 266]), rank 0 
2024-05-14 05:17:44.875953: predicting 20591J_0_0 
2024-05-14 05:17:44.879563: 20591J_0_0, shape torch.Size([1, 48, 199, 282]), rank 0 
2024-05-14 05:17:45.777483: predicting 20597V_8_2 
2024-05-14 05:17:45.778879: 20597V_8_2, shape torch.Size([1, 44, 205, 274]), rank 0 
2024-05-14 05:17:46.658999: predicting 20600K_16_2 
2024-05-14 05:17:46.661682: 20600K_16_2, shape torch.Size([1, 50, 197, 263]), rank 0 
2024-05-14 05:17:48.417076: predicting 20609C_8_3 
2024-05-14 05:17:48.420332: 20609C_8_3, shape torch.Size([1, 51, 199, 270]), rank 0 
2024-05-14 05:17:50.178415: predicting 20611P_8_2 
2024-05-14 05:17:50.181359: 20611P_8_2, shape torch.Size([1, 44, 199, 279]), rank 0 
2024-05-14 05:17:51.069747: predicting 20623W_0_0 
2024-05-14 05:17:51.072390: 20623W_0_0, shape torch.Size([1, 46, 200, 271]), rank 0 
2024-05-14 05:17:51.961818: predicting 20628G_4_3 
2024-05-14 05:17:51.963159: 20628G_4_3, shape torch.Size([1, 48, 193, 275]), rank 0 
2024-05-14 05:17:52.842950: predicting 20659R_16_2 
2024-05-14 05:17:52.845852: 20659R_16_2, shape torch.Size([1, 41, 198, 277]), rank 0 
2024-05-14 05:17:53.732748: predicting 20674N_0_0 
2024-05-14 05:17:53.735414: 20674N_0_0, shape torch.Size([1, 42, 209, 277]), rank 0 
2024-05-14 05:17:54.624088: predicting 20678V_16_2 
2024-05-14 05:17:54.626715: 20678V_16_2, shape torch.Size([1, 49, 206, 267]), rank 0 
2024-05-14 05:17:56.382326: predicting 20679X_4_3 
2024-05-14 05:17:56.385462: 20679X_4_3, shape torch.Size([1, 50, 202, 276]), rank 0 
2024-05-14 05:17:58.141638: predicting 20689A_0_0 
2024-05-14 05:17:58.144552: 20689A_0_0, shape torch.Size([1, 48, 219, 269]), rank 0 
2024-05-14 05:17:59.034080: predicting 20715B_0_0 
2024-05-14 05:17:59.037135: 20715B_0_0, shape torch.Size([1, 45, 209, 275]), rank 0 
2024-05-14 05:17:59.925839: predicting 20717F_8_2 
2024-05-14 05:17:59.928707: 20717F_8_2, shape torch.Size([1, 50, 193, 268]), rank 0 
2024-05-14 05:18:01.685163: predicting 20719J_4_3 
2024-05-14 05:18:01.687824: 20719J_4_3, shape torch.Size([1, 42, 204, 268]), rank 0 
2024-05-14 05:18:02.574159: predicting 20734F_0_0 
2024-05-14 05:18:02.576409: 20734F_0_0, shape torch.Size([1, 39, 193, 263]), rank 0 
2024-05-14 05:18:03.454586: predicting 20742E_16_2 
2024-05-14 05:18:03.457753: 20742E_16_2, shape torch.Size([1, 46, 193, 275]), rank 0 
2024-05-14 05:18:04.345165: predicting 20745K_8_3 
2024-05-14 05:18:04.348158: 20745K_8_3, shape torch.Size([1, 46, 201, 281]), rank 0 
2024-05-14 05:18:05.237206: predicting 20753J_16_2 
2024-05-14 05:18:05.239953: 20753J_16_2, shape torch.Size([1, 43, 206, 272]), rank 0 
2024-05-14 05:18:06.127197: predicting 20757R_0_0 
2024-05-14 05:18:06.129583: 20757R_0_0, shape torch.Size([1, 43, 206, 272]), rank 0 
2024-05-14 05:18:07.016257: predicting 20762K_0_0 
2024-05-14 05:18:07.018668: 20762K_0_0, shape torch.Size([1, 43, 202, 281]), rank 0 
2024-05-14 05:18:07.906685: predicting 20766S_4_2 
2024-05-14 05:18:07.909398: 20766S_4_2, shape torch.Size([1, 50, 206, 281]), rank 0 
2024-05-14 05:18:09.666808: predicting 20770J_0_0 
2024-05-14 05:18:09.669710: 20770J_0_0, shape torch.Size([1, 45, 196, 265]), rank 0 
2024-05-14 05:18:10.555976: predicting 20778Z_16_2 
2024-05-14 05:18:10.559094: 20778Z_16_2, shape torch.Size([1, 52, 212, 273]), rank 0 
2024-05-14 05:18:12.314819: predicting 20829Q_16_2 
2024-05-14 05:18:12.317784: 20829Q_16_2, shape torch.Size([1, 52, 198, 261]), rank 0 
2024-05-14 05:18:14.072665: predicting 20832F_8_2 
2024-05-14 05:18:14.073981: 20832F_8_2, shape torch.Size([1, 48, 196, 278]), rank 0 
2024-05-14 05:18:14.952903: predicting 20844M_4_3 
2024-05-14 05:18:14.954556: 20844M_4_3, shape torch.Size([1, 50, 194, 270]), rank 0 
2024-05-14 05:18:16.705405: predicting 20867Y_0_0 
2024-05-14 05:18:16.708214: 20867Y_0_0, shape torch.Size([1, 52, 208, 280]), rank 0 
2024-05-14 05:18:18.464535: predicting 20870N_8_2 
2024-05-14 05:18:18.465972: 20870N_8_2, shape torch.Size([1, 52, 185, 274]), rank 0 
2024-05-14 05:18:19.346989: predicting 20871P_8_3 
2024-05-14 05:18:19.348944: 20871P_8_3, shape torch.Size([1, 45, 196, 262]), rank 0 
2024-05-14 05:18:20.229069: predicting 20872R_8_3 
2024-05-14 05:18:20.232106: 20872R_8_3, shape torch.Size([1, 45, 196, 279]), rank 0 
2024-05-14 05:18:21.120345: predicting 20873T_8_2 
2024-05-14 05:18:21.123292: 20873T_8_2, shape torch.Size([1, 44, 194, 267]), rank 0 
2024-05-14 05:18:22.011182: predicting 20905G_4_2 
2024-05-14 05:18:22.013410: 20905G_4_2, shape torch.Size([1, 44, 206, 268]), rank 0 
2024-05-14 05:18:22.896055: predicting 20908M_16_2 
2024-05-14 05:18:22.898618: 20908M_16_2, shape torch.Size([1, 50, 187, 267]), rank 0 
2024-05-14 05:18:23.787436: predicting 20912D_0_0 
2024-05-14 05:18:23.790267: 20912D_0_0, shape torch.Size([1, 50, 187, 267]), rank 0 
2024-05-14 05:18:24.678179: predicting 20928S_4_3 
2024-05-14 05:18:24.681369: 20928S_4_3, shape torch.Size([1, 47, 190, 264]), rank 0 
2024-05-14 05:18:25.135069: predicting 20936R_16_2 
2024-05-14 05:18:25.137963: 20936R_16_2, shape torch.Size([1, 45, 212, 295]), rank 0 
2024-05-14 05:18:26.028669: predicting 20947W_8_2 
2024-05-14 05:18:26.031690: 20947W_8_2, shape torch.Size([1, 47, 197, 265]), rank 0 
2024-05-14 05:18:26.920582: predicting 20965Y_0_0 
2024-05-14 05:18:26.922806: 20965Y_0_0, shape torch.Size([1, 50, 203, 287]), rank 0 
2024-05-14 05:18:28.671533: predicting 20974Z_8_3 
2024-05-14 05:18:28.674495: 20974Z_8_3, shape torch.Size([1, 49, 189, 278]), rank 0 
2024-05-14 05:18:29.563443: predicting 20977F_8_2 
2024-05-14 05:18:29.565766: 20977F_8_2, shape torch.Size([1, 47, 192, 278]), rank 0 
2024-05-14 05:18:30.011617: predicting 21005B_0_0 
2024-05-14 05:18:30.013962: 21005B_0_0, shape torch.Size([1, 48, 202, 263]), rank 0 
2024-05-14 05:18:30.899809: predicting 21012Y_0_0 
2024-05-14 05:18:30.902524: 21012Y_0_0, shape torch.Size([1, 36, 194, 280]), rank 0 
2024-05-14 05:18:31.788372: predicting 21014C_0_0 
2024-05-14 05:18:31.790966: 21014C_0_0, shape torch.Size([1, 36, 194, 280]), rank 0 
2024-05-14 05:18:32.676455: predicting 21020X_0_0 
2024-05-14 05:18:32.678880: 21020X_0_0, shape torch.Size([1, 36, 194, 280]), rank 0 
2024-05-14 05:18:33.564803: predicting 21023D_0_0 
2024-05-14 05:18:33.567658: 21023D_0_0, shape torch.Size([1, 36, 194, 280]), rank 0 
2024-05-14 05:18:34.452146: predicting 21026J_4_2 
2024-05-14 05:18:34.455032: 21026J_4_2, shape torch.Size([1, 52, 196, 278]), rank 0 
2024-05-14 05:18:36.210454: predicting 21041F_8_2 
2024-05-14 05:18:36.213388: 21041F_8_2, shape torch.Size([1, 50, 198, 280]), rank 0 
2024-05-14 05:18:37.970365: predicting 21066V_16_2 
2024-05-14 05:18:37.972793: 21066V_16_2, shape torch.Size([1, 44, 188, 266]), rank 0 
2024-05-14 05:18:38.425935: predicting 21069B_0_0 
2024-05-14 05:18:38.429148: 21069B_0_0, shape torch.Size([1, 50, 196, 275]), rank 0 
2024-05-14 05:18:40.183757: predicting 21084X_16_2 
2024-05-14 05:18:40.185806: 21084X_16_2, shape torch.Size([1, 45, 204, 260]), rank 0 
2024-05-14 05:18:41.068290: predicting 21088F_8_3 
2024-05-14 05:18:41.071513: 21088F_8_3, shape torch.Size([1, 41, 206, 265]), rank 0 
2024-05-14 05:18:41.956993: predicting 21092W_0_0 
2024-05-14 05:18:41.959787: 21092W_0_0, shape torch.Size([1, 45, 192, 266]), rank 0 
2024-05-14 05:18:42.413378: predicting 21108L_4_2 
2024-05-14 05:18:42.416589: 21108L_4_2, shape torch.Size([1, 50, 202, 274]), rank 0 
2024-05-14 05:18:44.170875: predicting 21112C_0_0 
2024-05-14 05:18:44.173059: 21112C_0_0, shape torch.Size([1, 44, 204, 270]), rank 0 
2024-05-14 05:18:45.055142: predicting 21134M_16_2 
2024-05-14 05:18:45.058162: 21134M_16_2, shape torch.Size([1, 46, 196, 282]), rank 0 
2024-05-14 05:18:45.946682: predicting 21139W_8_3 
2024-05-14 05:18:45.949511: 21139W_8_3, shape torch.Size([1, 28, 204, 281]), rank 0 
2024-05-14 05:18:46.832309: predicting 21140H_4_2 
2024-05-14 05:18:46.833203: 21140H_4_2, shape torch.Size([1, 38, 192, 264]), rank 0 
2024-05-14 05:18:47.277871: predicting 21141J_16_2 
2024-05-14 05:18:47.280712: 21141J_16_2, shape torch.Size([1, 42, 212, 282]), rank 0 
2024-05-14 05:18:48.168266: predicting 21151M_8_2 
2024-05-14 05:18:48.170183: 21151M_8_2, shape torch.Size([1, 51, 207, 281]), rank 0 
2024-05-14 05:18:49.920944: predicting 21153Q_0_0 
2024-05-14 05:18:49.924659: 21153Q_0_0, shape torch.Size([1, 51, 207, 281]), rank 0 
2024-05-14 05:18:51.685087: predicting 21157Y_8_3 
2024-05-14 05:18:51.688316: 21157Y_8_3, shape torch.Size([1, 48, 198, 265]), rank 0 
2024-05-14 05:18:52.573591: predicting 21171S_8_2 
2024-05-14 05:18:52.576132: 21171S_8_2, shape torch.Size([1, 46, 191, 275]), rank 0 
2024-05-14 05:18:53.031411: predicting 21178G_16_2 
2024-05-14 05:18:53.034528: 21178G_16_2, shape torch.Size([1, 44, 217, 267]), rank 0 
2024-05-14 05:18:53.922562: predicting 21186F_4_2 
2024-05-14 05:18:53.925667: 21186F_4_2, shape torch.Size([1, 42, 207, 266]), rank 0 
2024-05-14 05:18:54.813452: predicting 21187H_16_2 
2024-05-14 05:18:54.816365: 21187H_16_2, shape torch.Size([1, 52, 196, 271]), rank 0 
2024-05-14 05:18:56.572012: predicting 21190W_0_0 
2024-05-14 05:18:56.574713: 21190W_0_0, shape torch.Size([1, 48, 204, 278]), rank 0 
2024-05-14 05:18:57.461827: predicting 21191Y_8_2 
2024-05-14 05:18:57.464690: 21191Y_8_2, shape torch.Size([1, 44, 193, 263]), rank 0 
2024-05-14 05:18:58.353962: predicting 21193C_0_0 
2024-05-14 05:18:58.356952: 21193C_0_0, shape torch.Size([1, 44, 193, 263]), rank 0 
2024-05-14 05:18:59.243610: predicting 21197K_8_3 
2024-05-14 05:18:59.246553: 21197K_8_3, shape torch.Size([1, 46, 212, 280]), rank 0 
2024-05-14 05:19:00.135686: predicting 21202D_8_2 
2024-05-14 05:19:00.138050: 21202D_8_2, shape torch.Size([1, 46, 210, 265]), rank 0 
2024-05-14 05:19:01.019313: predicting 21208P_8_3 
2024-05-14 05:19:01.022273: 21208P_8_3, shape torch.Size([1, 42, 210, 275]), rank 0 
2024-05-14 05:19:01.909593: predicting 21212G_4_2 
2024-05-14 05:19:01.912623: 21212G_4_2, shape torch.Size([1, 48, 194, 274]), rank 0 
2024-05-14 05:19:02.798851: predicting 21229X_0_0 
2024-05-14 05:19:02.801315: 21229X_0_0, shape torch.Size([1, 46, 190, 260]), rank 0 
2024-05-14 05:19:03.255571: predicting 21237W_4_3 
2024-05-14 05:19:03.258378: 21237W_4_3, shape torch.Size([1, 44, 193, 274]), rank 0 
2024-05-14 05:19:04.145624: predicting 21247Z_8_2 
2024-05-14 05:19:04.148041: 21247Z_8_2, shape torch.Size([1, 51, 210, 273]), rank 0 
2024-05-14 05:19:05.905753: predicting 21248B_8_2 
2024-05-14 05:19:05.908660: 21248B_8_2, shape torch.Size([1, 52, 203, 279]), rank 0 
2024-05-14 05:19:07.665246: predicting 21259G_16_2 
2024-05-14 05:19:07.668545: 21259G_16_2, shape torch.Size([1, 43, 194, 263]), rank 0 
2024-05-14 05:19:08.555419: predicting 21260R_16_2 
2024-05-14 05:19:08.558230: 21260R_16_2, shape torch.Size([1, 39, 202, 263]), rank 0 
2024-05-14 05:19:09.444180: predicting 21262V_16_2 
2024-05-14 05:19:09.447807: 21262V_16_2, shape torch.Size([1, 44, 201, 282]), rank 0 
2024-05-14 05:19:10.345115: predicting 21279M_0_0 
2024-05-14 05:19:10.347640: 21279M_0_0, shape torch.Size([1, 51, 208, 275]), rank 0 
2024-05-14 05:19:12.103861: predicting 21285H_16_2 
2024-05-14 05:19:12.106098: 21285H_16_2, shape torch.Size([1, 50, 204, 270]), rank 0 
2024-05-14 05:19:13.856710: predicting 21291C_8_2 
2024-05-14 05:19:13.859347: 21291C_8_2, shape torch.Size([1, 43, 200, 275]), rank 0 
2024-05-14 05:19:14.748890: predicting 21299S_0_0 
2024-05-14 05:19:14.751855: 21299S_0_0, shape torch.Size([1, 50, 211, 268]), rank 0 
2024-05-14 05:19:16.508753: predicting 21325T_8_2 
2024-05-14 05:19:16.511356: 21325T_8_2, shape torch.Size([1, 46, 212, 280]), rank 0 
2024-05-14 05:19:17.403893: predicting 21342T_4_2 
2024-05-14 05:19:17.406402: 21342T_4_2, shape torch.Size([1, 48, 211, 282]), rank 0 
2024-05-14 05:19:18.293719: predicting 21361X_8_3 
2024-05-14 05:19:18.296635: 21361X_8_3, shape torch.Size([1, 45, 205, 277]), rank 0 
2024-05-14 05:19:19.185878: predicting 21380B_16_2 
2024-05-14 05:19:19.188427: 21380B_16_2, shape torch.Size([1, 43, 201, 274]), rank 0 
2024-05-14 05:19:20.075657: predicting 21388R_16_2 
2024-05-14 05:19:20.078393: 21388R_16_2, shape torch.Size([1, 42, 195, 275]), rank 0 
2024-05-14 05:19:20.966562: predicting 21406T_4_2 
2024-05-14 05:19:20.967846: 21406T_4_2, shape torch.Size([1, 52, 195, 271]), rank 0 
2024-05-14 05:19:22.716479: predicting 21411M_0_0 
2024-05-14 05:19:22.719016: 21411M_0_0, shape torch.Size([1, 44, 206, 275]), rank 0 
2024-05-14 05:19:23.606750: predicting 21444B_8_3 
2024-05-14 05:19:23.609666: 21444B_8_3, shape torch.Size([1, 44, 200, 268]), rank 0 
2024-05-14 05:19:24.497057: predicting 21447H_4_2 
2024-05-14 05:19:24.499744: 21447H_4_2, shape torch.Size([1, 48, 200, 264]), rank 0 
2024-05-14 05:19:25.390668: predicting 21454E_0_0 
2024-05-14 05:19:25.393894: 21454E_0_0, shape torch.Size([1, 43, 205, 273]), rank 0 
2024-05-14 05:19:26.281530: predicting 21463F_16_2 
2024-05-14 05:19:26.284027: 21463F_16_2, shape torch.Size([1, 48, 207, 282]), rank 0 
2024-05-14 05:19:27.171124: predicting 21468P_0_0 
2024-05-14 05:19:27.174006: 21468P_0_0, shape torch.Size([1, 52, 204, 272]), rank 0 
2024-05-14 05:19:28.931037: predicting 21478S_4_2 
2024-05-14 05:19:28.933893: 21478S_4_2, shape torch.Size([1, 50, 192, 265]), rank 0 
2024-05-14 05:19:29.820373: predicting 21479U_0_0 
2024-05-14 05:19:29.821698: 21479U_0_0, shape torch.Size([1, 50, 192, 265]), rank 0 
2024-05-14 05:19:30.703901: predicting 21485P_0_0 
2024-05-14 05:19:30.706375: 21485P_0_0, shape torch.Size([1, 47, 199, 264]), rank 0 
2024-05-14 05:19:31.594243: predicting 21503R_8_3 
2024-05-14 05:19:31.597289: 21503R_8_3, shape torch.Size([1, 49, 195, 275]), rank 0 
2024-05-14 05:19:33.352557: predicting 21508B_4_2 
2024-05-14 05:19:33.355501: 21508B_4_2, shape torch.Size([1, 48, 199, 262]), rank 0 
2024-05-14 05:19:34.242991: predicting 21533A_8_3 
2024-05-14 05:19:34.245431: 21533A_8_3, shape torch.Size([1, 48, 210, 278]), rank 0 
2024-05-14 05:19:35.133864: predicting 21535E_16_2 
2024-05-14 05:19:35.136744: 21535E_16_2, shape torch.Size([1, 42, 203, 266]), rank 0 
2024-05-14 05:19:36.024738: predicting 21536G_0_0 
2024-05-14 05:19:36.026044: 21536G_0_0, shape torch.Size([1, 42, 203, 266]), rank 0 
2024-05-14 05:19:36.907699: predicting 21558Q_16_2 
2024-05-14 05:19:36.910136: 21558Q_16_2, shape torch.Size([1, 44, 204, 272]), rank 0 
2024-05-14 05:19:37.791200: predicting 21592Q_16_2 
2024-05-14 05:19:37.794233: 21592Q_16_2, shape torch.Size([1, 48, 195, 271]), rank 0 
2024-05-14 05:19:38.680112: predicting 21603V_0_0 
2024-05-14 05:19:38.682791: 21603V_0_0, shape torch.Size([1, 47, 205, 277]), rank 0 
2024-05-14 05:19:39.572667: predicting 21604X_8_2 
2024-05-14 05:19:39.575818: 21604X_8_2, shape torch.Size([1, 44, 198, 271]), rank 0 
2024-05-14 05:19:40.464291: predicting 21619K_8_2 
2024-05-14 05:19:40.467176: 21619K_8_2, shape torch.Size([1, 41, 204, 271]), rank 0 
2024-05-14 05:19:41.354856: predicting 21626H_4_2 
2024-05-14 05:19:41.357071: 21626H_4_2, shape torch.Size([1, 52, 200, 274]), rank 0 
2024-05-14 05:19:43.114286: predicting 21641D_4_2 
2024-05-14 05:19:43.117423: 21641D_4_2, shape torch.Size([1, 48, 200, 272]), rank 0 
2024-05-14 05:19:44.003915: predicting 21653K_0_0 
2024-05-14 05:19:44.005249: 21653K_0_0, shape torch.Size([1, 45, 207, 271]), rank 0 
2024-05-14 05:19:44.884717: predicting 21671M_16_2 
2024-05-14 05:19:44.887768: 21671M_16_2, shape torch.Size([1, 51, 199, 269]), rank 0 
2024-05-14 05:19:46.642968: predicting 21683T_4_3 
2024-05-14 05:19:46.645852: 21683T_4_3, shape torch.Size([1, 51, 207, 276]), rank 0 
2024-05-14 05:19:48.403441: predicting 21688D_8_3 
2024-05-14 05:19:48.406239: 21688D_8_3, shape torch.Size([1, 50, 212, 264]), rank 0 
2024-05-14 05:19:50.167918: predicting 21690Q_0_0 
2024-05-14 05:19:50.170809: 21690Q_0_0, shape torch.Size([1, 50, 212, 264]), rank 0 
2024-05-14 05:19:51.927184: predicting 21693W_0_0 
2024-05-14 05:19:51.929632: 21693W_0_0, shape torch.Size([1, 48, 210, 274]), rank 0 
2024-05-14 05:19:52.817182: predicting 21696C_4_3 
2024-05-14 05:19:52.819911: 21696C_4_3, shape torch.Size([1, 49, 216, 275]), rank 0 
2024-05-14 05:19:54.576528: predicting 21704B_8_2 
2024-05-14 05:19:54.579490: 21704B_8_2, shape torch.Size([1, 45, 197, 270]), rank 0 
2024-05-14 05:19:55.468006: predicting 21723F_16_2 
2024-05-14 05:19:55.471057: 21723F_16_2, shape torch.Size([1, 52, 211, 263]), rank 0 
2024-05-14 05:19:57.227788: predicting 21730C_4_3 
2024-05-14 05:19:57.230072: 21730C_4_3, shape torch.Size([1, 42, 195, 280]), rank 0 
2024-05-14 05:19:58.118478: predicting 21737Q_4_2 
2024-05-14 05:19:58.121421: 21737Q_4_2, shape torch.Size([1, 50, 197, 273]), rank 0 
2024-05-14 05:19:59.877518: predicting 21739U_16_2 
2024-05-14 05:19:59.880446: 21739U_16_2, shape torch.Size([1, 33, 198, 270]), rank 0 
2024-05-14 05:20:00.764670: predicting 21740F_4_3 
2024-05-14 05:20:00.767718: 21740F_4_3, shape torch.Size([1, 47, 199, 269]), rank 0 
2024-05-14 05:20:01.655783: predicting 21748V_4_2 
2024-05-14 05:20:01.658746: 21748V_4_2, shape torch.Size([1, 48, 207, 279]), rank 0 
2024-05-14 05:20:02.545027: predicting 21780R_4_3 
2024-05-14 05:20:02.547703: 21780R_4_3, shape torch.Size([1, 52, 203, 289]), rank 0 
2024-05-14 05:20:04.304201: predicting 21801Z_16_2 
2024-05-14 05:20:04.311557: 21801Z_16_2, shape torch.Size([1, 51, 200, 262]), rank 0 
2024-05-14 05:20:06.072982: predicting 21821F_4_2 
2024-05-14 05:20:06.075866: 21821F_4_2, shape torch.Size([1, 50, 205, 267]), rank 0 
2024-05-14 05:20:07.838256: predicting 21824L_4_2 
2024-05-14 05:20:07.840093: 21824L_4_2, shape torch.Size([1, 42, 203, 281]), rank 0 
2024-05-14 05:20:08.722066: predicting 21842N_16_2 
2024-05-14 05:20:08.725001: 21842N_16_2, shape torch.Size([1, 46, 204, 271]), rank 0 
2024-05-14 05:20:09.614275: predicting 21846V_8_3 
2024-05-14 05:20:09.617179: 21846V_8_3, shape torch.Size([1, 50, 189, 275]), rank 0 
2024-05-14 05:20:10.506349: predicting 21869H_8_2 
2024-05-14 05:20:10.508907: 21869H_8_2, shape torch.Size([1, 44, 191, 268]), rank 0 
2024-05-14 05:20:10.963037: predicting 21881X_16_2 
2024-05-14 05:20:10.965851: 21881X_16_2, shape torch.Size([1, 51, 210, 268]), rank 0 
2024-05-14 05:20:12.722056: predicting 21920H_8_2 
2024-05-14 05:20:12.725063: 21920H_8_2, shape torch.Size([1, 44, 189, 282]), rank 0 
2024-05-14 05:20:13.180119: predicting 21922L_4_3 
2024-05-14 05:20:13.183026: 21922L_4_3, shape torch.Size([1, 50, 199, 275]), rank 0 
2024-05-14 05:20:14.939306: predicting 21962X_16_2 
2024-05-14 05:20:14.942103: 21962X_16_2, shape torch.Size([1, 44, 194, 282]), rank 0 
2024-05-14 05:20:15.831044: predicting 21963Z_16_2 
2024-05-14 05:20:15.833492: 21963Z_16_2, shape torch.Size([1, 48, 202, 269]), rank 0 
2024-05-14 05:20:16.721101: predicting 22049A_4_3 
2024-05-14 05:20:16.723485: 22049A_4_3, shape torch.Size([1, 45, 207, 275]), rank 0 
2024-05-14 05:20:17.611637: predicting 22100A_8_3 
2024-05-14 05:20:17.613972: 22100A_8_3, shape torch.Size([1, 42, 197, 273]), rank 0 
2024-05-14 05:20:18.492667: predicting 22101C_0_0 
2024-05-14 05:20:18.495192: 22101C_0_0, shape torch.Size([1, 42, 197, 273]), rank 0 
2024-05-14 05:20:19.381575: predicting 22134R_4_3 
2024-05-14 05:20:19.384842: 22134R_4_3, shape torch.Size([1, 50, 202, 273]), rank 0 
2024-05-14 05:20:21.138148: predicting 22151R_0_0 
2024-05-14 05:20:21.140949: 22151R_0_0, shape torch.Size([1, 50, 208, 276]), rank 0 
2024-05-14 05:20:22.897641: predicting 22162W_8_3 
2024-05-14 05:20:22.900215: 22162W_8_3, shape torch.Size([1, 47, 198, 272]), rank 0 
2024-05-14 05:20:23.789874: predicting 22167G_8_2 
2024-05-14 05:20:23.792833: 22167G_8_2, shape torch.Size([1, 42, 212, 265]), rank 0 
2024-05-14 05:20:24.680786: predicting 22169K_0_0 
2024-05-14 05:20:24.683193: 22169K_0_0, shape torch.Size([1, 42, 212, 265]), rank 0 
2024-05-14 05:20:25.571697: predicting 22191D_0_0 
2024-05-14 05:20:25.574741: 22191D_0_0, shape torch.Size([1, 48, 206, 270]), rank 0 
2024-05-14 05:20:26.461585: predicting 22212L_4_2 
2024-05-14 05:20:26.463512: 22212L_4_2, shape torch.Size([1, 50, 194, 283]), rank 0 
2024-05-14 05:20:28.211752: predicting 22250T_8_3 
2024-05-14 05:20:28.214707: 22250T_8_3, shape torch.Size([1, 52, 202, 271]), rank 0 
2024-05-14 05:20:29.970775: predicting 22257H_4_2 
2024-05-14 05:20:29.973668: 22257H_4_2, shape torch.Size([1, 47, 204, 279]), rank 0 
2024-05-14 05:20:30.862761: predicting 22258J_0_0 
2024-05-14 05:20:30.864110: 22258J_0_0, shape torch.Size([1, 47, 204, 279]), rank 0 
2024-05-14 05:20:31.745145: predicting 22259L_8_3 
2024-05-14 05:20:31.748937: 22259L_8_3, shape torch.Size([1, 35, 212, 278]), rank 0 
2024-05-14 05:20:32.634107: predicting 22280C_16_2 
2024-05-14 05:20:32.637218: 22280C_16_2, shape torch.Size([1, 46, 193, 265]), rank 0 
2024-05-14 05:20:33.525352: predicting 22282G_16_2 
2024-05-14 05:20:33.528168: 22282G_16_2, shape torch.Size([1, 42, 208, 282]), rank 0 
2024-05-14 05:20:34.415979: predicting 22294N_4_3 
2024-05-14 05:20:34.418507: 22294N_4_3, shape torch.Size([1, 46, 202, 273]), rank 0 
2024-05-14 05:20:35.307731: predicting 22295P_16_2 
2024-05-14 05:20:35.310667: 22295P_16_2, shape torch.Size([1, 44, 197, 263]), rank 0 
2024-05-14 05:20:36.197815: predicting 22297T_0_0 
2024-05-14 05:20:36.200813: 22297T_0_0, shape torch.Size([1, 44, 197, 263]), rank 0 
2024-05-14 05:20:37.089192: predicting 22307W_8_3 
2024-05-14 05:20:37.092018: 22307W_8_3, shape torch.Size([1, 48, 200, 278]), rank 0 
2024-05-14 05:20:37.978467: predicting 22321Q_16_2 
2024-05-14 05:20:37.980876: 22321Q_16_2, shape torch.Size([1, 49, 202, 270]), rank 0 
2024-05-14 05:20:39.737646: predicting 22322S_16_2 
2024-05-14 05:20:39.740201: 22322S_16_2, shape torch.Size([1, 47, 208, 268]), rank 0 
2024-05-14 05:20:40.629527: predicting 22362E_0_0 
2024-05-14 05:20:40.632470: 22362E_0_0, shape torch.Size([1, 48, 199, 282]), rank 0 
2024-05-14 05:20:41.520138: predicting 22365K_16_2 
2024-05-14 05:20:41.522432: 22365K_16_2, shape torch.Size([1, 44, 210, 278]), rank 0 
2024-05-14 05:20:42.411568: predicting 22376P_8_3 
2024-05-14 05:20:42.412928: 22376P_8_3, shape torch.Size([1, 45, 210, 265]), rank 0 
2024-05-14 05:20:43.292363: predicting 22397X_8_2 
2024-05-14 05:20:43.295726: 22397X_8_2, shape torch.Size([1, 50, 196, 267]), rank 0 
2024-05-14 05:20:45.052707: predicting 22403S_8_2 
2024-05-14 05:20:45.054938: 22403S_8_2, shape torch.Size([1, 43, 196, 271]), rank 0 
2024-05-14 05:20:45.942756: predicting 22407A_8_2 
2024-05-14 05:20:45.945674: 22407A_8_2, shape torch.Size([1, 44, 198, 265]), rank 0 
2024-05-14 05:20:46.832438: predicting 22424A_16_2 
2024-05-14 05:20:46.835151: 22424A_16_2, shape torch.Size([1, 44, 205, 271]), rank 0 
2024-05-14 05:20:47.723925: predicting 22425C_4_2 
2024-05-14 05:20:47.726815: 22425C_4_2, shape torch.Size([1, 46, 201, 271]), rank 0 
2024-05-14 05:20:48.615789: predicting 22455L_4_2 
2024-05-14 05:20:48.617890: 22455L_4_2, shape torch.Size([1, 48, 188, 271]), rank 0 
2024-05-14 05:20:49.073444: predicting 22484S_16_2 
2024-05-14 05:20:49.076276: 22484S_16_2, shape torch.Size([1, 52, 209, 276]), rank 0 
2024-05-14 05:20:50.834268: predicting 22487Y_8_3 
2024-05-14 05:20:50.837101: 22487Y_8_3, shape torch.Size([1, 44, 191, 277]), rank 0 
2024-05-14 05:20:51.290862: predicting 22490N_0_0 
2024-05-14 05:20:51.292887: 22490N_0_0, shape torch.Size([1, 50, 204, 275]), rank 0 
2024-05-14 05:20:53.057651: predicting 22515D_4_3 
2024-05-14 05:20:53.060986: 22515D_4_3, shape torch.Size([1, 43, 200, 277]), rank 0 
2024-05-14 05:20:53.950627: predicting 22535J_4_2 
2024-05-14 05:20:53.953584: 22535J_4_2, shape torch.Size([1, 44, 209, 279]), rank 0 
2024-05-14 05:20:54.842425: predicting 22549U_8_2 
2024-05-14 05:20:54.845421: 22549U_8_2, shape torch.Size([1, 50, 203, 277]), rank 0 
2024-05-14 05:20:56.602426: predicting 22552J_4_2 
2024-05-14 05:20:56.604666: 22552J_4_2, shape torch.Size([1, 52, 208, 277]), rank 0 
2024-05-14 05:20:58.363697: predicting 22561K_4_3 
2024-05-14 05:20:58.366313: 22561K_4_3, shape torch.Size([1, 50, 207, 269]), rank 0 
2024-05-14 05:21:00.125049: predicting 22562M_16_2 
2024-05-14 05:21:00.127927: 22562M_16_2, shape torch.Size([1, 50, 202, 279]), rank 0 
2024-05-14 05:21:01.884740: predicting 22594Z_16_2 
2024-05-14 05:21:01.888094: 22594Z_16_2, shape torch.Size([1, 50, 196, 262]), rank 0 
2024-05-14 05:21:03.649352: predicting 22601W_0_0 
2024-05-14 05:21:03.651600: 22601W_0_0, shape torch.Size([1, 49, 194, 271]), rank 0 
2024-05-14 05:21:05.399818: predicting 22602Y_0_0 
2024-05-14 05:21:05.402606: 22602Y_0_0, shape torch.Size([1, 49, 194, 271]), rank 0 
2024-05-14 05:21:07.159163: predicting 22603A_16_2 
2024-05-14 05:21:07.161906: 22603A_16_2, shape torch.Size([1, 50, 191, 263]), rank 0 
2024-05-14 05:21:08.051431: predicting 22623G_0_0 
2024-05-14 05:21:08.054321: 22623G_0_0, shape torch.Size([1, 48, 188, 264]), rank 0 
2024-05-14 05:21:08.508890: predicting 22640G_4_2 
2024-05-14 05:21:08.511017: 22640G_4_2, shape torch.Size([1, 50, 201, 282]), rank 0 
2024-05-14 05:21:10.267693: predicting 22678F_16_2 
2024-05-14 05:21:10.270872: 22678F_16_2, shape torch.Size([1, 43, 205, 279]), rank 0 
2024-05-14 05:21:11.158686: predicting 22680S_8_2 
2024-05-14 05:21:11.159958: 22680S_8_2, shape torch.Size([1, 49, 195, 265]), rank 0 
2024-05-14 05:21:12.908731: predicting 22691X_16_2 
2024-05-14 05:21:12.912163: 22691X_16_2, shape torch.Size([1, 46, 204, 279]), rank 0 
2024-05-14 05:21:13.801091: predicting 22697J_4_2 
2024-05-14 05:21:13.803997: 22697J_4_2, shape torch.Size([1, 50, 201, 268]), rank 0 
2024-05-14 05:21:15.560142: predicting 22723K_8_2 
2024-05-14 05:21:15.562756: 22723K_8_2, shape torch.Size([1, 43, 194, 269]), rank 0 
2024-05-14 05:21:16.451479: predicting 22726Q_16_2 
2024-05-14 05:21:16.454351: 22726Q_16_2, shape torch.Size([1, 40, 193, 276]), rank 0 
2024-05-14 05:21:17.340525: predicting 22745U_8_2 
2024-05-14 05:21:17.343349: 22745U_8_2, shape torch.Size([1, 52, 198, 269]), rank 0 
2024-05-14 05:21:19.100661: predicting 22747Y_4_2 
2024-05-14 05:21:19.103101: 22747Y_4_2, shape torch.Size([1, 49, 204, 282]), rank 0 
2024-05-14 05:21:20.860837: predicting 22753T_4_3 
2024-05-14 05:21:20.863296: 22753T_4_3, shape torch.Size([1, 46, 196, 284]), rank 0 
2024-05-14 05:21:21.744090: predicting 22800C_0_0 
2024-05-14 05:21:21.746752: 22800C_0_0, shape torch.Size([1, 52, 198, 267]), rank 0 
2024-05-14 05:21:23.502604: predicting 22828Y_16_2 
2024-05-14 05:21:23.505522: 22828Y_16_2, shape torch.Size([1, 48, 198, 280]), rank 0 
2024-05-14 05:21:24.391757: predicting 22832P_0_0 
2024-05-14 05:21:24.394067: 22832P_0_0, shape torch.Size([1, 35, 199, 275]), rank 0 
2024-05-14 05:21:25.279881: predicting 22842S_4_2 
2024-05-14 05:21:25.282676: 22842S_4_2, shape torch.Size([1, 42, 192, 278]), rank 0 
2024-05-14 05:21:25.736866: predicting 22853X_8_2 
2024-05-14 05:21:25.739846: 22853X_8_2, shape torch.Size([1, 46, 190, 275]), rank 0 
2024-05-14 05:21:26.201548: predicting 22855B_16_2 
2024-05-14 05:21:26.204517: 22855B_16_2, shape torch.Size([1, 48, 207, 275]), rank 0 
2024-05-14 05:21:27.090898: predicting 22860U_0_0 
2024-05-14 05:21:27.092112: 22860U_0_0, shape torch.Size([1, 46, 212, 279]), rank 0 
2024-05-14 05:21:27.973315: predicting 22862Y_4_3 
2024-05-14 05:21:27.976699: 22862Y_4_3, shape torch.Size([1, 50, 201, 281]), rank 0 
2024-05-14 05:21:29.733092: predicting 22865E_8_3 
2024-05-14 05:21:29.736407: 22865E_8_3, shape torch.Size([1, 50, 208, 267]), rank 0 
2024-05-14 05:21:31.492489: predicting 22871Z_8_3 
2024-05-14 05:21:31.495349: 22871Z_8_3, shape torch.Size([1, 44, 200, 268]), rank 0 
2024-05-14 05:21:32.382644: predicting 22873D_16_2 
2024-05-14 05:21:32.385540: 22873D_16_2, shape torch.Size([1, 51, 200, 280]), rank 0 
2024-05-14 05:21:34.143174: predicting 22893J_0_0 
2024-05-14 05:21:34.145559: 22893J_0_0, shape torch.Size([1, 49, 201, 277]), rank 0 
2024-05-14 05:21:35.904534: predicting 22900G_0_0 
2024-05-14 05:21:35.905907: 22900G_0_0, shape torch.Size([1, 45, 211, 268]), rank 0 
2024-05-14 05:21:36.786722: predicting 22915T_0_0 
2024-05-14 05:21:36.789841: 22915T_0_0, shape torch.Size([1, 44, 214, 271]), rank 0 
2024-05-14 05:21:37.678044: predicting 22934X_4_3 
2024-05-14 05:21:37.680865: 22934X_4_3, shape torch.Size([1, 51, 196, 276]), rank 0 
2024-05-14 05:21:39.438460: predicting 22937D_0_0 
2024-05-14 05:21:39.440766: 22937D_0_0, shape torch.Size([1, 44, 200, 269]), rank 0 
2024-05-14 05:21:40.329661: predicting 22955F_8_3 
2024-05-14 05:21:40.332405: 22955F_8_3, shape torch.Size([1, 48, 197, 282]), rank 0 
2024-05-14 05:21:41.219789: predicting 22977P_8_3 
2024-05-14 05:21:41.222549: 22977P_8_3, shape torch.Size([1, 45, 203, 275]), rank 0 
2024-05-14 05:21:42.110939: predicting 22986Q_4_2 
2024-05-14 05:21:42.113138: 22986Q_4_2, shape torch.Size([1, 48, 200, 274]), rank 0 
2024-05-14 05:21:42.992061: predicting 22990H_16_2 
2024-05-14 05:21:42.995132: 22990H_16_2, shape torch.Size([1, 47, 203, 278]), rank 0 
2024-05-14 05:21:43.885002: predicting 22999Z_8_3 
2024-05-14 05:21:43.888216: 22999Z_8_3, shape torch.Size([1, 42, 195, 269]), rank 0 
2024-05-14 05:21:44.775049: predicting 23006N_8_3 
2024-05-14 05:21:44.777984: 23006N_8_3, shape torch.Size([1, 50, 198, 268]), rank 0 
2024-05-14 05:21:46.534144: predicting 23007P_0_0 
2024-05-14 05:21:46.537096: 23007P_0_0, shape torch.Size([1, 50, 198, 268]), rank 0 
2024-05-14 05:21:48.293074: predicting 23045X_0_0 
2024-05-14 05:21:48.295329: 23045X_0_0, shape torch.Size([1, 44, 222, 282]), rank 0 
2024-05-14 05:21:49.185971: predicting 23060T_4_2 
2024-05-14 05:21:49.189200: 23060T_4_2, shape torch.Size([1, 46, 207, 262]), rank 0 
2024-05-14 05:21:50.076975: predicting 23074E_4_2 
2024-05-14 05:21:50.079915: 23074E_4_2, shape torch.Size([1, 50, 213, 270]), rank 0 
2024-05-14 05:21:51.837175: predicting 23099U_4_3 
2024-05-14 05:21:51.840454: 23099U_4_3, shape torch.Size([1, 48, 201, 288]), rank 0 
2024-05-14 05:21:52.727945: predicting 23106R_4_3 
2024-05-14 05:21:52.731329: 23106R_4_3, shape torch.Size([1, 44, 200, 271]), rank 0 
2024-05-14 05:21:53.621707: predicting 23120L_4_2 
2024-05-14 05:21:53.624031: 23120L_4_2, shape torch.Size([1, 48, 191, 268]), rank 0 
2024-05-14 05:21:54.078959: predicting 23126X_16_2 
2024-05-14 05:21:54.081833: 23126X_16_2, shape torch.Size([1, 47, 221, 277]), rank 0 
2024-05-14 05:21:54.972087: predicting 23133U_0_0 
2024-05-14 05:21:54.975723: 23133U_0_0, shape torch.Size([1, 47, 207, 277]), rank 0 
2024-05-14 05:21:55.875879: predicting 23139G_8_3 
2024-05-14 05:21:55.877184: 23139G_8_3, shape torch.Size([1, 47, 190, 264]), rank 0 
2024-05-14 05:21:56.323711: predicting 23146D_4_3 
2024-05-14 05:21:56.326801: 23146D_4_3, shape torch.Size([1, 42, 203, 275]), rank 0 
2024-05-14 05:21:57.215763: predicting 23150U_16_2 
2024-05-14 05:21:57.218679: 23150U_16_2, shape torch.Size([1, 48, 213, 265]), rank 0 
2024-05-14 05:21:58.109322: predicting 23151W_0_0 
2024-05-14 05:21:58.112545: 23151W_0_0, shape torch.Size([1, 48, 213, 265]), rank 0 
2024-05-14 05:21:59.004989: predicting 23165H_8_3 
2024-05-14 05:21:59.006857: 23165H_8_3, shape torch.Size([1, 44, 206, 269]), rank 0 
2024-05-14 05:21:59.887207: predicting 23166J_4_2 
2024-05-14 05:21:59.890028: 23166J_4_2, shape torch.Size([1, 44, 198, 283]), rank 0 
2024-05-14 05:22:00.779458: predicting 23175K_0_0 
2024-05-14 05:22:00.782041: 23175K_0_0, shape torch.Size([1, 48, 206, 264]), rank 0 
2024-05-14 05:22:01.669672: predicting 23198W_0_0 
2024-05-14 05:22:01.671236: 23198W_0_0, shape torch.Size([1, 50, 208, 265]), rank 0 
2024-05-14 05:22:03.420332: predicting 23201L_0_0 
2024-05-14 05:22:03.422666: 23201L_0_0, shape torch.Size([1, 49, 203, 263]), rank 0 
2024-05-14 05:22:05.176824: predicting 23208Z_8_2 
2024-05-14 05:22:05.179822: 23208Z_8_2, shape torch.Size([1, 44, 196, 269]), rank 0 
2024-05-14 05:22:06.067668: predicting 23215W_0_0 
2024-05-14 05:22:06.070178: 23215W_0_0, shape torch.Size([1, 44, 201, 285]), rank 0 
2024-05-14 05:22:06.960725: predicting 23218C_0_0 
2024-05-14 05:22:06.963610: 23218C_0_0, shape torch.Size([1, 46, 205, 278]), rank 0 
2024-05-14 05:22:07.853730: predicting 23231U_0_0 
2024-05-14 05:22:07.856201: 23231U_0_0, shape torch.Size([1, 52, 210, 279]), rank 0 
2024-05-14 05:22:09.614207: predicting 23232W_4_2 
2024-05-14 05:22:09.617070: 23232W_4_2, shape torch.Size([1, 50, 205, 275]), rank 0 
2024-05-14 05:22:11.375085: predicting 23234A_16_2 
2024-05-14 05:22:11.378075: 23234A_16_2, shape torch.Size([1, 45, 196, 271]), rank 0 
2024-05-14 05:22:12.266758: predicting 23236E_4_3 
2024-05-14 05:22:12.267686: 23236E_4_3, shape torch.Size([1, 42, 212, 272]), rank 0 
2024-05-14 05:22:13.147435: predicting 23247J_16_2 
2024-05-14 05:22:13.150492: 23247J_16_2, shape torch.Size([1, 48, 205, 279]), rank 0 
2024-05-14 05:22:14.031761: predicting 23273K_4_3 
2024-05-14 05:22:14.034267: 23273K_4_3, shape torch.Size([1, 44, 190, 282]), rank 0 
2024-05-14 05:22:14.489077: predicting 23279W_16_2 
2024-05-14 05:22:14.493353: 23279W_16_2, shape torch.Size([1, 49, 199, 279]), rank 0 
2024-05-14 05:22:16.248052: predicting 23294S_4_3 
2024-05-14 05:22:16.253862: 23294S_4_3, shape torch.Size([1, 52, 209, 273]), rank 0 
2024-05-14 05:22:18.017159: predicting 23295U_16_2 
2024-05-14 05:22:18.019521: 23295U_16_2, shape torch.Size([1, 45, 198, 275]), rank 0 
2024-05-14 05:22:18.908981: predicting 23312U_0_0 
2024-05-14 05:22:18.912169: 23312U_0_0, shape torch.Size([1, 42, 189, 265]), rank 0 
2024-05-14 05:22:19.366382: predicting 23315A_4_2 
2024-05-14 05:22:19.367661: 23315A_4_2, shape torch.Size([1, 49, 199, 267]), rank 0 
2024-05-14 05:22:21.117264: predicting 23320T_4_3 
2024-05-14 05:22:21.120429: 23320T_4_3, shape torch.Size([1, 49, 197, 274]), rank 0 
2024-05-14 05:22:22.876554: predicting 23337K_4_3 
2024-05-14 05:22:22.880487: 23337K_4_3, shape torch.Size([1, 52, 191, 272]), rank 0 
2024-05-14 05:22:23.771688: predicting 23349R_8_2 
2024-05-14 05:22:23.774422: 23349R_8_2, shape torch.Size([1, 42, 204, 269]), rank 0 
2024-05-14 05:22:24.661638: predicting 23374Q_16_2 
2024-05-14 05:22:24.664013: 23374Q_16_2, shape torch.Size([1, 51, 200, 282]), rank 0 
2024-05-14 05:22:26.423954: predicting 23381N_8_2 
2024-05-14 05:22:26.426363: 23381N_8_2, shape torch.Size([1, 48, 204, 274]), rank 0 
2024-05-14 05:22:27.311954: predicting 23386X_0_0 
2024-05-14 05:22:27.314718: 23386X_0_0, shape torch.Size([1, 48, 205, 274]), rank 0 
2024-05-14 05:22:28.201321: predicting 23389D_8_3 
2024-05-14 05:22:28.204312: 23389D_8_3, shape torch.Size([1, 37, 204, 268]), rank 0 
2024-05-14 05:22:29.089751: predicting 23411W_16_2 
2024-05-14 05:22:29.092650: 23411W_16_2, shape torch.Size([1, 38, 195, 267]), rank 0 
2024-05-14 05:22:29.977011: predicting 23428N_4_2 
2024-05-14 05:22:29.979760: 23428N_4_2, shape torch.Size([1, 50, 206, 274]), rank 0 
2024-05-14 05:22:31.738824: predicting 23440D_8_3 
2024-05-14 05:22:31.741955: 23440D_8_3, shape torch.Size([1, 50, 198, 272]), rank 0 
2024-05-14 05:22:33.497770: predicting 23453M_4_3 
2024-05-14 05:22:33.500860: 23453M_4_3, shape torch.Size([1, 44, 197, 277]), rank 0 
2024-05-14 05:22:34.388547: predicting 23466V_16_2 
2024-05-14 05:22:34.391636: 23466V_16_2, shape torch.Size([1, 45, 205, 267]), rank 0 
2024-05-14 05:22:35.280232: predicting 23491U_8_3 
2024-05-14 05:22:35.282763: 23491U_8_3, shape torch.Size([1, 44, 196, 271]), rank 0 
2024-05-14 05:22:36.170798: predicting 23496E_16_2 
2024-05-14 05:22:36.173674: 23496E_16_2, shape torch.Size([1, 43, 194, 270]), rank 0 
2024-05-14 05:22:37.061219: predicting 23497G_16_2 
2024-05-14 05:22:37.064281: 23497G_16_2, shape torch.Size([1, 49, 200, 274]), rank 0 
2024-05-14 05:22:38.821033: predicting 23520B_8_2 
2024-05-14 05:22:38.823931: 23520B_8_2, shape torch.Size([1, 46, 195, 273]), rank 0 
2024-05-14 05:22:39.714951: predicting 23574Y_8_3 
2024-05-14 05:22:39.717436: 23574Y_8_3, shape torch.Size([1, 46, 200, 291]), rank 0 
2024-05-14 05:22:40.607094: predicting 23609R_8_3 
2024-05-14 05:22:40.610486: 23609R_8_3, shape torch.Size([1, 44, 207, 274]), rank 0 
2024-05-14 05:22:41.498406: predicting 23615M_4_2 
2024-05-14 05:22:41.501628: 23615M_4_2, shape torch.Size([1, 46, 198, 271]), rank 0 
2024-05-14 05:22:42.389948: predicting 23627T_8_2 
2024-05-14 05:22:42.392966: 23627T_8_2, shape torch.Size([1, 45, 202, 271]), rank 0 
2024-05-14 05:22:43.281489: predicting 23636U_16_2 
2024-05-14 05:22:43.284292: 23636U_16_2, shape torch.Size([1, 46, 206, 289]), rank 0 
2024-05-14 05:22:44.174548: predicting 23638Y_0_0 
2024-05-14 05:22:44.177329: 23638Y_0_0, shape torch.Size([1, 46, 206, 289]), rank 0 
2024-05-14 05:22:45.068526: predicting 23641N_0_0 
2024-05-14 05:22:45.071272: 23641N_0_0, shape torch.Size([1, 48, 198, 274]), rank 0 
2024-05-14 05:22:45.958351: predicting 23653U_16_2 
2024-05-14 05:22:45.961079: 23653U_16_2, shape torch.Size([1, 42, 201, 273]), rank 0 
2024-05-14 05:22:46.848673: predicting 23667F_8_2 
2024-05-14 05:22:46.852048: 23667F_8_2, shape torch.Size([1, 42, 197, 272]), rank 0 
2024-05-14 05:22:47.746512: predicting 23669J_8_3 
2024-05-14 05:22:47.749537: 23669J_8_3, shape torch.Size([1, 48, 209, 280]), rank 0 
2024-05-14 05:22:48.635928: predicting 23682B_8_3 
2024-05-14 05:22:48.638881: 23682B_8_3, shape torch.Size([1, 42, 205, 279]), rank 0 
2024-05-14 05:22:49.526289: predicting 23683D_16_2 
2024-05-14 05:22:49.529372: 23683D_16_2, shape torch.Size([1, 44, 186, 275]), rank 0 
2024-05-14 05:22:49.983610: predicting 23686J_16_2 
2024-05-14 05:22:49.986699: 23686J_16_2, shape torch.Size([1, 36, 202, 273]), rank 0 
2024-05-14 05:22:50.872464: predicting 23696M_16_2 
2024-05-14 05:22:50.875412: 23696M_16_2, shape torch.Size([1, 46, 201, 272]), rank 0 
2024-05-14 05:22:51.761761: predicting 23701F_4_2 
2024-05-14 05:22:51.764000: 23701F_4_2, shape torch.Size([1, 44, 209, 267]), rank 0 
2024-05-14 05:22:52.650747: predicting 23725T_8_2 
2024-05-14 05:22:52.653385: 23725T_8_2, shape torch.Size([1, 46, 199, 288]), rank 0 
2024-05-14 05:22:53.542368: predicting 23727X_16_2 
2024-05-14 05:22:53.545103: 23727X_16_2, shape torch.Size([1, 45, 199, 266]), rank 0 
2024-05-14 05:22:54.432722: predicting 23743V_16_2 
2024-05-14 05:22:54.435438: 23743V_16_2, shape torch.Size([1, 49, 205, 276]), rank 0 
2024-05-14 05:22:56.190779: predicting 23789T_8_2 
2024-05-14 05:22:56.193681: 23789T_8_2, shape torch.Size([1, 44, 201, 265]), rank 0 
2024-05-14 05:22:57.081976: predicting 23803N_8_3 
2024-05-14 05:22:57.084207: 23803N_8_3, shape torch.Size([1, 44, 200, 273]), rank 0 
2024-05-14 05:22:57.964219: predicting 23814S_4_2 
2024-05-14 05:22:57.966393: 23814S_4_2, shape torch.Size([1, 43, 207, 279]), rank 0 
2024-05-14 05:22:58.855148: predicting 23815U_8_2 
2024-05-14 05:22:58.856418: 23815U_8_2, shape torch.Size([1, 50, 207, 271]), rank 0 
2024-05-14 05:23:00.606584: predicting 23832U_4_2 
2024-05-14 05:23:00.609655: 23832U_4_2, shape torch.Size([1, 46, 210, 272]), rank 0 
2024-05-14 05:23:01.499702: predicting 23842X_16_2 
2024-05-14 05:23:01.502278: 23842X_16_2, shape torch.Size([1, 46, 195, 275]), rank 0 
2024-05-14 05:23:02.386266: predicting 23851Y_0_0 
2024-05-14 05:23:02.389616: 23851Y_0_0, shape torch.Size([1, 44, 204, 279]), rank 0 
2024-05-14 05:23:03.279695: predicting 23871E_8_3 
2024-05-14 05:23:03.282413: 23871E_8_3, shape torch.Size([1, 50, 194, 270]), rank 0 
2024-05-14 05:23:05.037304: predicting 23872G_16_2 
2024-05-14 05:23:05.040402: 23872G_16_2, shape torch.Size([1, 50, 202, 273]), rank 0 
2024-05-14 05:23:06.797552: predicting 23874K_8_2 
2024-05-14 05:23:06.800802: 23874K_8_2, shape torch.Size([1, 52, 211, 289]), rank 0 
2024-05-14 05:23:08.559740: predicting 23875M_8_2 
2024-05-14 05:23:08.562210: 23875M_8_2, shape torch.Size([1, 52, 197, 268]), rank 0 
2024-05-14 05:23:10.310532: predicting 23882J_8_2 
2024-05-14 05:23:10.313152: 23882J_8_2, shape torch.Size([1, 46, 204, 283]), rank 0 
2024-05-14 05:23:11.203104: predicting 23887T_8_3 
2024-05-14 05:23:11.206031: 23887T_8_3, shape torch.Size([1, 40, 208, 269]), rank 0 
2024-05-14 05:23:12.092807: predicting 23891K_16_2 
2024-05-14 05:23:12.095934: 23891K_16_2, shape torch.Size([1, 46, 206, 283]), rank 0 
2024-05-14 05:23:12.986958: predicting 23917C_4_2 
2024-05-14 05:23:12.989450: 23917C_4_2, shape torch.Size([1, 46, 198, 272]), rank 0 
2024-05-14 05:23:13.878149: predicting 23922V_4_2 
2024-05-14 05:23:13.881168: 23922V_4_2, shape torch.Size([1, 44, 203, 266]), rank 0 
2024-05-14 05:23:14.770293: predicting 23932Y_4_3 
2024-05-14 05:23:14.772905: 23932Y_4_3, shape torch.Size([1, 41, 198, 281]), rank 0 
2024-05-14 05:23:15.660514: predicting 23934C_16_2 
2024-05-14 05:23:15.662924: 23934C_16_2, shape torch.Size([1, 46, 207, 276]), rank 0 
2024-05-14 05:23:16.554843: predicting 23945H_4_3 
2024-05-14 05:23:16.557871: 23945H_4_3, shape torch.Size([1, 40, 197, 267]), rank 0 
2024-05-14 05:23:17.459908: predicting 23950A_16_2 
2024-05-14 05:23:17.462421: 23950A_16_2, shape torch.Size([1, 48, 201, 271]), rank 0 
2024-05-14 05:23:18.349553: predicting 23966P_16_2 
2024-05-14 05:23:18.352945: 23966P_16_2, shape torch.Size([1, 50, 213, 275]), rank 0 
2024-05-14 05:23:20.112228: predicting 23970G_0_0 
2024-05-14 05:23:20.114817: 23970G_0_0, shape torch.Size([1, 49, 200, 273]), rank 0 
2024-05-14 05:23:21.875085: predicting 23994U_4_3 
2024-05-14 05:23:21.878075: 23994U_4_3, shape torch.Size([1, 49, 204, 279]), rank 0 
2024-05-14 05:23:23.647413: predicting 24005Q_4_3 
2024-05-14 05:23:23.649889: 24005Q_4_3, shape torch.Size([1, 49, 202, 269]), rank 0 
2024-05-14 05:23:25.406039: predicting 24007U_8_3 
2024-05-14 05:23:25.408870: 24007U_8_3, shape torch.Size([1, 50, 198, 279]), rank 0 
2024-05-14 05:23:27.164604: predicting 24013P_0_0 
2024-05-14 05:23:27.167531: 24013P_0_0, shape torch.Size([1, 48, 205, 265]), rank 0 
2024-05-14 05:23:28.054307: predicting 24017X_16_2 
2024-05-14 05:23:28.057135: 24017X_16_2, shape torch.Size([1, 52, 207, 268]), rank 0 
2024-05-14 05:23:29.816041: predicting 24029E_0_0 
2024-05-14 05:23:29.818292: 24029E_0_0, shape torch.Size([1, 46, 192, 271]), rank 0 
2024-05-14 05:23:30.273880: predicting 24049K_16_2 
2024-05-14 05:23:30.276878: 24049K_16_2, shape torch.Size([1, 48, 201, 269]), rank 0 
2024-05-14 05:23:31.163824: predicting 24079T_0_0 
2024-05-14 05:23:31.166675: 24079T_0_0, shape torch.Size([1, 47, 209, 267]), rank 0 
2024-05-14 05:23:32.057122: predicting 24080E_0_0 
2024-05-14 05:23:32.059497: 24080E_0_0, shape torch.Size([1, 47, 209, 267]), rank 0 
2024-05-14 05:23:32.950017: predicting 24084M_4_3 
2024-05-14 05:23:32.952163: 24084M_4_3, shape torch.Size([1, 50, 202, 283]), rank 0 
2024-05-14 05:23:34.708576: predicting 24092L_16_2 
2024-05-14 05:23:34.710797: 24092L_16_2, shape torch.Size([1, 44, 197, 270]), rank 0 
2024-05-14 05:23:35.599020: predicting 24097V_4_3 
2024-05-14 05:23:35.601175: 24097V_4_3, shape torch.Size([1, 46, 201, 279]), rank 0 
2024-05-14 05:23:36.491761: predicting 24105U_16_2 
2024-05-14 05:23:36.494392: 24105U_16_2, shape torch.Size([1, 49, 203, 270]), rank 0 
2024-05-14 05:23:38.250549: predicting 24106W_4_3 
2024-05-14 05:23:38.253779: 24106W_4_3, shape torch.Size([1, 46, 200, 265]), rank 0 
2024-05-14 05:23:39.141922: predicting 24113T_4_3 
2024-05-14 05:23:39.144370: 24113T_4_3, shape torch.Size([1, 46, 194, 264]), rank 0 
2024-05-14 05:23:40.032670: predicting 24116Z_4_2 
2024-05-14 05:23:40.033642: 24116Z_4_2, shape torch.Size([1, 46, 202, 263]), rank 0 
2024-05-14 05:23:40.914415: predicting 24119F_8_3 
2024-05-14 05:23:40.917589: 24119F_8_3, shape torch.Size([1, 50, 199, 264]), rank 0 
2024-05-14 05:23:42.672305: predicting 24120Q_8_3 
2024-05-14 05:23:42.674906: 24120Q_8_3, shape torch.Size([1, 50, 191, 266]), rank 0 
2024-05-14 05:23:43.564550: predicting 24122U_0_0 
2024-05-14 05:23:43.566660: 24122U_0_0, shape torch.Size([1, 50, 191, 266]), rank 0 
2024-05-14 05:23:44.456314: predicting 24130T_8_3 
2024-05-14 05:23:44.458687: 24130T_8_3, shape torch.Size([1, 50, 201, 268]), rank 0 
2024-05-14 05:23:46.214329: predicting 24143C_4_2 
2024-05-14 05:23:46.217350: 24143C_4_2, shape torch.Size([1, 46, 203, 265]), rank 0 
2024-05-14 05:23:47.104576: predicting 24150Z_0_0 
2024-05-14 05:23:47.107074: 24150Z_0_0, shape torch.Size([1, 46, 203, 265]), rank 0 
2024-05-14 05:23:47.994839: predicting 24195V_8_3 
2024-05-14 05:23:47.996952: 24195V_8_3, shape torch.Size([1, 44, 200, 266]), rank 0 
2024-05-14 05:23:48.877098: predicting 24209G_16_2 
2024-05-14 05:23:48.879757: 24209G_16_2, shape torch.Size([1, 44, 209, 267]), rank 0 
2024-05-14 05:23:49.763774: predicting 24220U_8_2 
2024-05-14 05:23:49.766615: 24220U_8_2, shape torch.Size([1, 52, 195, 278]), rank 0 
2024-05-14 05:23:51.523683: predicting 24229M_4_3 
2024-05-14 05:23:51.526704: 24229M_4_3, shape torch.Size([1, 52, 198, 272]), rank 0 
2024-05-14 05:23:53.281361: predicting 24230X_8_3 
2024-05-14 05:23:53.284296: 24230X_8_3, shape torch.Size([1, 46, 194, 274]), rank 0 
2024-05-14 05:23:54.172842: predicting 24231Z_0_0 
2024-05-14 05:23:54.175572: 24231Z_0_0, shape torch.Size([1, 46, 194, 274]), rank 0 
2024-05-14 05:23:55.064211: predicting 24235H_16_2 
2024-05-14 05:23:55.068073: 24235H_16_2, shape torch.Size([1, 48, 208, 270]), rank 0 
2024-05-14 05:23:55.956313: predicting 24242E_0_0 
2024-05-14 05:23:55.958376: 24242E_0_0, shape torch.Size([1, 46, 201, 278]), rank 0 
2024-05-14 05:23:56.841211: predicting 24262K_8_2 
2024-05-14 05:23:56.844203: 24262K_8_2, shape torch.Size([1, 41, 206, 273]), rank 0 
2024-05-14 05:23:57.732870: predicting 24267U_8_3 
2024-05-14 05:23:57.735252: 24267U_8_3, shape torch.Size([1, 48, 216, 275]), rank 0 
2024-05-14 05:23:58.623189: predicting 24268W_4_2 
2024-05-14 05:23:58.626583: 24268W_4_2, shape torch.Size([1, 46, 202, 280]), rank 0 
2024-05-14 05:23:59.515304: predicting 24274R_16_2 
2024-05-14 05:23:59.517860: 24274R_16_2, shape torch.Size([1, 44, 209, 268]), rank 0 
2024-05-14 05:24:00.407687: predicting 24298F_8_3 
2024-05-14 05:24:00.409432: 24298F_8_3, shape torch.Size([1, 50, 202, 277]), rank 0 
2024-05-14 05:24:02.158587: predicting 24307G_8_2 
2024-05-14 05:24:02.161551: 24307G_8_2, shape torch.Size([1, 48, 200, 270]), rank 0 
2024-05-14 05:24:03.047977: predicting 24309K_0_0 
2024-05-14 05:24:03.050083: 24309K_0_0, shape torch.Size([1, 48, 200, 270]), rank 0 
2024-05-14 05:24:03.929102: predicting 24329Q_16_2 
2024-05-14 05:24:03.932282: 24329Q_16_2, shape torch.Size([1, 50, 207, 273]), rank 0 
2024-05-14 05:24:05.689447: predicting 24336N_0_0 
2024-05-14 05:24:05.692132: 24336N_0_0, shape torch.Size([1, 50, 209, 281]), rank 0 
2024-05-14 05:24:07.452498: predicting 24350H_8_2 
2024-05-14 05:24:07.454696: 24350H_8_2, shape torch.Size([1, 46, 206, 266]), rank 0 
2024-05-14 05:24:08.344006: predicting 24357V_4_2 
2024-05-14 05:24:08.347848: 24357V_4_2, shape torch.Size([1, 50, 203, 267]), rank 0 
2024-05-14 05:24:10.111201: predicting 24361M_0_0 
2024-05-14 05:24:10.114191: 24361M_0_0, shape torch.Size([1, 42, 202, 261]), rank 0 
2024-05-14 05:24:11.000299: predicting 24368A_4_3 
2024-05-14 05:24:11.002885: 24368A_4_3, shape torch.Size([1, 49, 204, 281]), rank 0 
2024-05-14 05:24:12.760440: predicting 24370N_4_2 
2024-05-14 05:24:12.763190: 24370N_4_2, shape torch.Size([1, 46, 197, 280]), rank 0 
2024-05-14 05:24:13.652325: predicting 24381S_8_2 
2024-05-14 05:24:13.654758: 24381S_8_2, shape torch.Size([1, 50, 197, 282]), rank 0 
2024-05-14 05:24:15.412127: predicting 24391V_0_0 
2024-05-14 05:24:15.415380: 24391V_0_0, shape torch.Size([1, 44, 209, 262]), rank 0 
2024-05-14 05:24:16.303904: predicting 24408M_8_3 
2024-05-14 05:24:16.306387: 24408M_8_3, shape torch.Size([1, 45, 206, 275]), rank 0 
2024-05-14 05:24:17.196132: predicting 24431H_16_2 
2024-05-14 05:24:17.199120: 24431H_16_2, shape torch.Size([1, 50, 200, 271]), rank 0 
2024-05-14 05:24:18.955656: predicting 24441K_0_0 
2024-05-14 05:24:18.958863: 24441K_0_0, shape torch.Size([1, 46, 205, 273]), rank 0 
2024-05-14 05:24:19.848795: predicting 24450L_16_2 
2024-05-14 05:24:19.851732: 24450L_16_2, shape torch.Size([1, 47, 209, 279]), rank 0 
2024-05-14 05:24:20.741558: predicting 24462S_0_0 
2024-05-14 05:24:20.744112: 24462S_0_0, shape torch.Size([1, 52, 214, 285]), rank 0 
2024-05-14 05:24:22.501264: predicting 24469G_4_2 
2024-05-14 05:24:22.504351: 24469G_4_2, shape torch.Size([1, 47, 205, 275]), rank 0 
2024-05-14 05:24:23.392610: predicting 24471T_16_2 
2024-05-14 05:24:23.395944: 24471T_16_2, shape torch.Size([1, 48, 208, 274]), rank 0 
2024-05-14 05:24:24.284590: predicting 24496J_4_2 
2024-05-14 05:24:24.287843: 24496J_4_2, shape torch.Size([1, 44, 202, 265]), rank 0 
2024-05-14 05:24:25.182101: predicting 24514L_0_0 
2024-05-14 05:24:25.184531: 24514L_0_0, shape torch.Size([1, 48, 202, 265]), rank 0 
2024-05-14 05:24:26.072195: predicting 24517R_8_2 
2024-05-14 05:24:26.075135: 24517R_8_2, shape torch.Size([1, 48, 213, 285]), rank 0 
2024-05-14 05:24:26.963319: predicting 24520G_4_2 
2024-05-14 05:24:26.966211: 24520G_4_2, shape torch.Size([1, 45, 205, 295]), rank 0 
2024-05-14 05:24:27.856370: predicting 24528W_16_2 
2024-05-14 05:24:27.858959: 24528W_16_2, shape torch.Size([1, 41, 196, 269]), rank 0 
2024-05-14 05:24:28.747361: predicting 24544U_8_2 
2024-05-14 05:24:28.750011: 24544U_8_2, shape torch.Size([1, 46, 199, 269]), rank 0 
2024-05-14 05:24:29.639783: predicting 24547A_4_3 
2024-05-14 05:24:29.642664: 24547A_4_3, shape torch.Size([1, 52, 213, 282]), rank 0 
2024-05-14 05:24:31.402574: predicting 24556B_16_2 
2024-05-14 05:24:31.405463: 24556B_16_2, shape torch.Size([1, 44, 215, 281]), rank 0 
2024-05-14 05:24:32.293861: predicting 24583E_16_2 
2024-05-14 05:24:32.296743: 24583E_16_2, shape torch.Size([1, 47, 190, 266]), rank 0 
2024-05-14 05:24:32.751368: predicting 24626W_16_2 
2024-05-14 05:24:32.753426: 24626W_16_2, shape torch.Size([1, 45, 201, 267]), rank 0 
2024-05-14 05:24:33.639953: predicting 24633T_16_2 
2024-05-14 05:24:33.642590: 24633T_16_2, shape torch.Size([1, 50, 196, 275]), rank 0 
2024-05-14 05:24:35.396620: predicting 24679R_8_3 
2024-05-14 05:24:35.399531: 24679R_8_3, shape torch.Size([1, 50, 196, 275]), rank 0 
2024-05-14 05:24:37.157045: predicting 24682G_0_0 
2024-05-14 05:24:37.159543: 24682G_0_0, shape torch.Size([1, 50, 201, 275]), rank 0 
2024-05-14 05:24:38.917441: predicting 24706U_4_2 
2024-05-14 05:24:38.920498: 24706U_4_2, shape torch.Size([1, 47, 202, 277]), rank 0 
2024-05-14 05:24:39.809396: predicting 24713R_16_2 
2024-05-14 05:24:39.812434: 24713R_16_2, shape torch.Size([1, 44, 209, 274]), rank 0 
2024-05-14 05:24:40.700765: predicting 24727C_16_2 
2024-05-14 05:24:40.704204: 24727C_16_2, shape torch.Size([1, 44, 202, 279]), rank 0 
2024-05-14 05:24:41.594305: predicting 24729G_16_2 
2024-05-14 05:24:41.597096: 24729G_16_2, shape torch.Size([1, 43, 206, 271]), rank 0 
2024-05-14 05:24:42.485376: predicting 24737F_0_0 
2024-05-14 05:24:42.488036: 24737F_0_0, shape torch.Size([1, 50, 204, 268]), rank 0 
2024-05-14 05:24:44.246267: predicting 24750X_8_3 
2024-05-14 05:24:44.249186: 24750X_8_3, shape torch.Size([1, 45, 190, 265]), rank 0 
2024-05-14 05:24:44.702410: predicting 24761C_4_2 
2024-05-14 05:24:44.705250: 24761C_4_2, shape torch.Size([1, 51, 197, 272]), rank 0 
2024-05-14 05:24:46.462570: predicting 24771F_8_3 
2024-05-14 05:24:46.465412: 24771F_8_3, shape torch.Size([1, 48, 195, 269]), rank 0 
2024-05-14 05:24:47.351056: predicting 24773J_4_3 
2024-05-14 05:24:47.353493: 24773J_4_3, shape torch.Size([1, 50, 202, 276]), rank 0 
2024-05-14 05:24:49.110682: predicting 24792N_0_0 
2024-05-14 05:24:49.113729: 24792N_0_0, shape torch.Size([1, 46, 204, 280]), rank 0 
2024-05-14 05:24:50.002730: predicting 24804U_16_2 
2024-05-14 05:24:50.005545: 24804U_16_2, shape torch.Size([1, 37, 205, 262]), rank 0 
2024-05-14 05:24:50.890983: predicting 24805W_16_2 
2024-05-14 05:24:50.893242: 24805W_16_2, shape torch.Size([1, 41, 211, 270]), rank 0 
2024-05-14 05:24:51.780113: predicting 24817D_8_2 
2024-05-14 05:24:51.782969: 24817D_8_2, shape torch.Size([1, 49, 200, 283]), rank 0 
2024-05-14 05:24:53.539825: predicting 24825C_8_3 
2024-05-14 05:24:53.542216: 24825C_8_3, shape torch.Size([1, 50, 206, 277]), rank 0 
2024-05-14 05:24:55.300696: predicting 24850B_0_0 
2024-05-14 05:24:55.303318: 24850B_0_0, shape torch.Size([1, 46, 201, 274]), rank 0 
2024-05-14 05:24:56.190876: predicting 24873N_4_2 
2024-05-14 05:24:56.193455: 24873N_4_2, shape torch.Size([1, 37, 192, 276]), rank 0 
2024-05-14 05:24:56.646565: predicting 24921Y_0_0 
2024-05-14 05:24:56.649309: 24921Y_0_0, shape torch.Size([1, 48, 198, 277]), rank 0 
2024-05-14 05:24:57.536266: predicting 24931B_16_2 
2024-05-14 05:24:57.539579: 24931B_16_2, shape torch.Size([1, 44, 212, 271]), rank 0 
2024-05-14 05:24:58.438737: predicting 24936L_16_2 
2024-05-14 05:24:58.441561: 24936L_16_2, shape torch.Size([1, 46, 210, 274]), rank 0 
2024-05-14 05:24:59.331812: predicting 24937N_16_2 
2024-05-14 05:24:59.334774: 24937N_16_2, shape torch.Size([1, 43, 212, 280]), rank 0 
2024-05-14 05:25:00.224329: predicting 24986A_16_2 
2024-05-14 05:25:00.226243: 24986A_16_2, shape torch.Size([1, 51, 203, 272]), rank 0 
2024-05-14 05:25:01.976558: predicting 25012S_0_0 
2024-05-14 05:25:01.980098: 25012S_0_0, shape torch.Size([1, 48, 206, 280]), rank 0 
2024-05-14 05:25:02.870618: predicting 25023X_0_0 
2024-05-14 05:25:02.873703: 25023X_0_0, shape torch.Size([1, 44, 199, 274]), rank 0 
2024-05-14 05:25:03.761866: predicting 25024Z_0_0 
2024-05-14 05:25:03.764710: 25024Z_0_0, shape torch.Size([1, 44, 199, 274]), rank 0 
2024-05-14 05:25:04.652586: predicting 25031W_0_0 
2024-05-14 05:25:04.655315: 25031W_0_0, shape torch.Size([1, 41, 204, 267]), rank 0 
2024-05-14 05:25:05.541574: predicting 25041Z_0_0 
2024-05-14 05:25:05.543307: 25041Z_0_0, shape torch.Size([1, 51, 202, 275]), rank 0 
2024-05-14 05:25:07.294826: predicting 25081L_16_2 
2024-05-14 05:25:07.297805: 25081L_16_2, shape torch.Size([1, 46, 187, 257]), rank 0 
2024-05-14 05:25:07.751101: predicting 25114A_8_2 
2024-05-14 05:25:07.753949: 25114A_8_2, shape torch.Size([1, 48, 208, 274]), rank 0 
2024-05-14 05:25:08.641568: predicting 25122Z_16_2 
2024-05-14 05:25:08.644753: 25122Z_16_2, shape torch.Size([1, 47, 207, 283]), rank 0 
2024-05-14 05:25:09.534442: predicting 25129N_0_0 
2024-05-14 05:25:09.536956: 25129N_0_0, shape torch.Size([1, 50, 190, 275]), rank 0 
2024-05-14 05:25:10.425818: predicting 25142F_8_2 
2024-05-14 05:25:10.428861: 25142F_8_2, shape torch.Size([1, 37, 203, 278]), rank 0 
2024-05-14 05:25:11.314216: predicting 25150E_16_2 
2024-05-14 05:25:11.316926: 25150E_16_2, shape torch.Size([1, 46, 212, 282]), rank 0 
2024-05-14 05:25:12.207502: predicting 25158U_16_2 
2024-05-14 05:25:12.210136: 25158U_16_2, shape torch.Size([1, 51, 207, 273]), rank 0 
2024-05-14 05:25:13.968707: predicting 25171M_8_3 
2024-05-14 05:25:13.971174: 25171M_8_3, shape torch.Size([1, 50, 203, 278]), rank 0 
2024-05-14 05:25:15.728468: predicting 25176W_4_2 
2024-05-14 05:25:15.731278: 25176W_4_2, shape torch.Size([1, 50, 198, 276]), rank 0 
2024-05-14 05:25:17.485223: predicting 25177Y_8_2 
2024-05-14 05:25:17.488267: 25177Y_8_2, shape torch.Size([1, 48, 199, 275]), rank 0 
2024-05-14 05:25:18.387818: predicting 25180N_16_2 
2024-05-14 05:25:18.388826: 25180N_16_2, shape torch.Size([1, 48, 211, 285]), rank 0 
2024-05-14 05:25:19.268394: predicting 25182R_16_2 
2024-05-14 05:25:19.272636: 25182R_16_2, shape torch.Size([1, 52, 209, 276]), rank 0 
2024-05-14 05:25:21.040611: predicting 25209L_16_2 
2024-05-14 05:25:21.041933: 25209L_16_2, shape torch.Size([1, 46, 203, 273]), rank 0 
2024-05-14 05:25:21.922587: predicting 25218M_4_2 
2024-05-14 05:25:21.925341: 25218M_4_2, shape torch.Size([1, 44, 204, 270]), rank 0 
2024-05-14 05:25:22.814308: predicting 25222D_0_0 
2024-05-14 05:25:22.817208: 25222D_0_0, shape torch.Size([1, 44, 207, 268]), rank 0 
2024-05-14 05:25:23.704764: predicting 25234K_8_3 
2024-05-14 05:25:23.708157: 25234K_8_3, shape torch.Size([1, 46, 196, 273]), rank 0 
2024-05-14 05:25:24.605875: predicting 25235M_0_0 
2024-05-14 05:25:24.608271: 25235M_0_0, shape torch.Size([1, 46, 196, 273]), rank 0 
2024-05-14 05:25:25.496651: predicting 25251K_16_2 
2024-05-14 05:25:25.497992: 25251K_16_2, shape torch.Size([1, 52, 205, 266]), rank 0 
2024-05-14 05:25:27.247226: predicting 25280R_16_2 
2024-05-14 05:25:27.248536: 25280R_16_2, shape torch.Size([1, 48, 187, 274]), rank 0 
2024-05-14 05:25:27.694747: predicting 25304F_4_3 
2024-05-14 05:25:27.697616: 25304F_4_3, shape torch.Size([1, 45, 193, 269]), rank 0 
2024-05-14 05:25:28.584503: predicting 25307L_4_3 
2024-05-14 05:25:28.587240: 25307L_4_3, shape torch.Size([1, 44, 210, 280]), rank 0 
2024-05-14 05:25:29.476273: predicting 25309P_4_3 
2024-05-14 05:25:29.479354: 25309P_4_3, shape torch.Size([1, 46, 206, 284]), rank 0 
2024-05-14 05:25:30.368670: predicting 25313G_8_3 
2024-05-14 05:25:30.372096: 25313G_8_3, shape torch.Size([1, 50, 192, 265]), rank 0 
2024-05-14 05:25:31.259259: predicting 25326P_4_2 
2024-05-14 05:25:31.261755: 25326P_4_2, shape torch.Size([1, 47, 199, 274]), rank 0 
2024-05-14 05:25:32.151825: predicting 25327R_0_0 
2024-05-14 05:25:32.154306: 25327R_0_0, shape torch.Size([1, 47, 199, 274]), rank 0 
2024-05-14 05:25:33.043425: predicting 25336S_8_2 
2024-05-14 05:25:33.044725: 25336S_8_2, shape torch.Size([1, 52, 205, 274]), rank 0 
2024-05-14 05:25:34.793944: predicting 25337U_16_2 
2024-05-14 05:25:34.795645: 25337U_16_2, shape torch.Size([1, 44, 182, 266]), rank 0 
2024-05-14 05:25:35.240435: predicting 25350M_0_0 
2024-05-14 05:25:35.243528: 25350M_0_0, shape torch.Size([1, 48, 205, 281]), rank 0 
2024-05-14 05:25:36.131166: predicting 25358C_8_2 
2024-05-14 05:25:36.134202: 25358C_8_2, shape torch.Size([1, 44, 205, 264]), rank 0 
2024-05-14 05:25:37.022655: predicting 25359E_0_0 
2024-05-14 05:25:37.025040: 25359E_0_0, shape torch.Size([1, 44, 205, 264]), rank 0 
2024-05-14 05:25:37.911897: predicting 25360P_8_2 
2024-05-14 05:25:37.914831: 25360P_8_2, shape torch.Size([1, 52, 201, 276]), rank 0 
2024-05-14 05:25:39.672854: predicting 25369H_16_2 
2024-05-14 05:25:39.676019: 25369H_16_2, shape torch.Size([1, 48, 203, 271]), rank 0 
2024-05-14 05:25:40.562034: predicting 25370S_4_3 
2024-05-14 05:25:40.564287: 25370S_4_3, shape torch.Size([1, 50, 189, 262]), rank 0 
2024-05-14 05:25:41.456645: predicting 25384D_4_2 
2024-05-14 05:25:41.460392: 25384D_4_2, shape torch.Size([1, 48, 210, 264]), rank 0 
2024-05-14 05:25:42.353075: predicting 25422L_0_0 
2024-05-14 05:25:42.355920: 25422L_0_0, shape torch.Size([1, 46, 187, 269]), rank 0 
2024-05-14 05:25:42.813866: predicting 25437Y_16_2 
2024-05-14 05:25:42.817142: 25437Y_16_2, shape torch.Size([1, 42, 199, 267]), rank 0 
2024-05-14 05:25:43.711883: predicting 25441P_8_2 
2024-05-14 05:25:43.714561: 25441P_8_2, shape torch.Size([1, 46, 196, 275]), rank 0 
2024-05-14 05:25:44.606531: predicting 25477K_4_2 
2024-05-14 05:25:44.609348: 25477K_4_2, shape torch.Size([1, 48, 203, 268]), rank 0 
2024-05-14 05:25:45.496253: predicting 25482D_16_2 
2024-05-14 05:25:45.499597: 25482D_16_2, shape torch.Size([1, 42, 196, 261]), rank 0 
2024-05-14 05:25:46.396213: predicting 25498S_16_2 
2024-05-14 05:25:46.397499: 25498S_16_2, shape torch.Size([1, 50, 205, 266]), rank 0 
2024-05-14 05:25:48.146914: predicting 25514Q_8_2 
2024-05-14 05:25:48.150203: 25514Q_8_2, shape torch.Size([1, 45, 200, 286]), rank 0 
2024-05-14 05:25:49.036693: predicting 25521N_8_2 
2024-05-14 05:25:49.039548: 25521N_8_2, shape torch.Size([1, 50, 197, 283]), rank 0 
2024-05-14 05:25:50.796708: predicting 25576M_0_0 
2024-05-14 05:25:50.799711: 25576M_0_0, shape torch.Size([1, 43, 209, 266]), rank 0 
2024-05-14 05:25:51.687685: predicting 25583J_16_2 
2024-05-14 05:25:51.690454: 25583J_16_2, shape torch.Size([1, 49, 206, 271]), rank 0 
2024-05-14 05:25:53.446432: predicting 25595Q_8_2 
2024-05-14 05:25:53.449017: 25595Q_8_2, shape torch.Size([1, 46, 204, 265]), rank 0 
2024-05-14 05:25:54.337747: predicting 25604R_4_3 
2024-05-14 05:25:54.341128: 25604R_4_3, shape torch.Size([1, 49, 201, 277]), rank 0 
2024-05-14 05:25:56.105556: predicting 25618C_0_0 
2024-05-14 05:25:56.108046: 25618C_0_0, shape torch.Size([1, 46, 200, 265]), rank 0 
2024-05-14 05:25:56.996765: predicting 25622T_16_2 
2024-05-14 05:25:56.997768: 25622T_16_2, shape torch.Size([1, 51, 194, 265]), rank 0 
2024-05-14 05:25:58.746748: predicting 25626B_16_2 
2024-05-14 05:25:58.749508: 25626B_16_2, shape torch.Size([1, 42, 198, 275]), rank 0 
2024-05-14 05:25:59.635840: predicting 25680H_16_2 
2024-05-14 05:25:59.638398: 25680H_16_2, shape torch.Size([1, 45, 202, 272]), rank 0 
2024-05-14 05:26:00.526535: predicting 25685R_4_2 
2024-05-14 05:26:00.529431: 25685R_4_2, shape torch.Size([1, 46, 201, 273]), rank 0 
2024-05-14 05:26:01.418213: predicting 25689Z_4_3 
2024-05-14 05:26:01.421203: 25689Z_4_3, shape torch.Size([1, 49, 183, 266]), rank 0 
2024-05-14 05:26:02.309104: predicting 25691M_16_2 
2024-05-14 05:26:02.311651: 25691M_16_2, shape torch.Size([1, 36, 195, 265]), rank 0 
2024-05-14 05:26:03.195591: predicting 25694S_8_3 
2024-05-14 05:26:03.196805: 25694S_8_3, shape torch.Size([1, 45, 199, 263]), rank 0 
2024-05-14 05:26:04.077061: predicting 25698A_16_2 
2024-05-14 05:26:04.079821: 25698A_16_2, shape torch.Size([1, 46, 197, 270]), rank 0 
2024-05-14 05:26:04.968512: predicting 25703T_4_3 
2024-05-14 05:26:04.970695: 25703T_4_3, shape torch.Size([1, 42, 209, 278]), rank 0 
2024-05-14 05:26:05.858689: predicting 25716C_0_0 
2024-05-14 05:26:05.861599: 25716C_0_0, shape torch.Size([1, 35, 205, 273]), rank 0 
2024-05-14 05:26:06.745141: predicting 25754K_4_2 
2024-05-14 05:26:06.747829: 25754K_4_2, shape torch.Size([1, 50, 207, 273]), rank 0 
2024-05-14 05:26:08.504404: predicting 25758S_0_0 
2024-05-14 05:26:08.506923: 25758S_0_0, shape torch.Size([1, 50, 207, 273]), rank 0 
2024-05-14 05:26:10.262693: predicting 25762J_16_2 
2024-05-14 05:26:10.265445: 25762J_16_2, shape torch.Size([1, 50, 207, 269]), rank 0 
2024-05-14 05:26:12.021078: predicting 25771K_8_2 
2024-05-14 05:26:12.022513: 25771K_8_2, shape torch.Size([1, 50, 188, 272]), rank 0 
2024-05-14 05:26:12.904828: predicting 25777W_0_0 
2024-05-14 05:26:12.908251: 25777W_0_0, shape torch.Size([1, 50, 188, 272]), rank 0 
2024-05-14 05:26:13.798131: predicting 25778Y_0_0 
2024-05-14 05:26:13.801055: 25778Y_0_0, shape torch.Size([1, 50, 188, 272]), rank 0 
2024-05-14 05:26:14.689977: predicting 25782P_4_2 
2024-05-14 05:26:14.692283: 25782P_4_2, shape torch.Size([1, 48, 196, 281]), rank 0 
2024-05-14 05:26:15.579121: predicting 25793U_0_0 
2024-05-14 05:26:15.581924: 25793U_0_0, shape torch.Size([1, 48, 202, 276]), rank 0 
2024-05-14 05:26:16.468642: predicting 25804Z_16_2 
2024-05-14 05:26:16.471939: 25804Z_16_2, shape torch.Size([1, 52, 203, 266]), rank 0 
2024-05-14 05:26:18.232807: predicting 25806D_4_3 
2024-05-14 05:26:18.235412: 25806D_4_3, shape torch.Size([1, 46, 201, 271]), rank 0 
2024-05-14 05:26:19.122983: predicting 25820X_4_3 
2024-05-14 05:26:19.125785: 25820X_4_3, shape torch.Size([1, 47, 206, 267]), rank 0 
2024-05-14 05:26:20.014044: predicting 25822B_8_2 
2024-05-14 05:26:20.017365: 25822B_8_2, shape torch.Size([1, 48, 200, 270]), rank 0 
2024-05-14 05:26:20.904028: predicting 25831C_8_2 
2024-05-14 05:26:20.905409: 25831C_8_2, shape torch.Size([1, 51, 204, 278]), rank 0 
2024-05-14 05:26:22.653064: predicting 25833G_8_3 
2024-05-14 05:26:22.656551: 25833G_8_3, shape torch.Size([1, 39, 201, 273]), rank 0 
2024-05-14 05:26:23.546648: predicting 25841F_0_0 
2024-05-14 05:26:23.549449: 25841F_0_0, shape torch.Size([1, 46, 208, 275]), rank 0 
2024-05-14 05:26:24.438546: predicting 25849V_16_2 
2024-05-14 05:26:24.441637: 25849V_16_2, shape torch.Size([1, 40, 199, 271]), rank 0 
2024-05-14 05:26:25.328545: predicting 25859Y_4_3 
2024-05-14 05:26:25.330843: 25859Y_4_3, shape torch.Size([1, 47, 188, 273]), rank 0 
2024-05-14 05:26:25.785837: predicting 25892W_8_3 
2024-05-14 05:26:25.788778: 25892W_8_3, shape torch.Size([1, 42, 190, 273]), rank 0 
2024-05-14 05:26:26.241941: predicting 25896E_4_2 
2024-05-14 05:26:26.244627: 25896E_4_2, shape torch.Size([1, 48, 198, 278]), rank 0 
2024-05-14 05:26:27.130419: predicting 25910Y_16_2 
2024-05-14 05:26:27.133370: 25910Y_16_2, shape torch.Size([1, 36, 209, 262]), rank 0 
2024-05-14 05:26:28.016616: predicting 25913E_8_3 
2024-05-14 05:26:28.019222: 25913E_8_3, shape torch.Size([1, 42, 197, 265]), rank 0 
2024-05-14 05:26:28.907807: predicting 25917M_8_2 
2024-05-14 05:26:28.910476: 25917M_8_2, shape torch.Size([1, 48, 185, 260]), rank 0 
2024-05-14 05:26:29.365549: predicting 25923H_0_0 
2024-05-14 05:26:29.368434: 25923H_0_0, shape torch.Size([1, 48, 185, 260]), rank 0 
2024-05-14 05:26:29.822443: predicting 25943N_4_3 
2024-05-14 05:26:29.825426: 25943N_4_3, shape torch.Size([1, 49, 200, 266]), rank 0 
2024-05-14 05:26:31.582783: predicting 25953Q_16_2 
2024-05-14 05:26:31.585315: 25953Q_16_2, shape torch.Size([1, 40, 201, 275]), rank 0 
2024-05-14 05:26:32.473763: predicting 25958A_8_3 
2024-05-14 05:26:32.476188: 25958A_8_3, shape torch.Size([1, 42, 196, 264]), rank 0 
2024-05-14 05:26:33.364197: predicting 25973W_16_2 
2024-05-14 05:26:33.366174: 25973W_16_2, shape torch.Size([1, 46, 192, 269]), rank 0 
2024-05-14 05:26:33.811692: predicting 25976C_0_0 
2024-05-14 05:26:33.814066: 25976C_0_0, shape torch.Size([1, 52, 202, 264]), rank 0 
2024-05-14 05:26:35.563259: predicting 25987H_16_2 
2024-05-14 05:26:35.566197: 25987H_16_2, shape torch.Size([1, 51, 198, 279]), rank 0 
2024-05-14 05:26:37.323843: predicting 25988J_16_2 
2024-05-14 05:26:37.327022: 25988J_16_2, shape torch.Size([1, 52, 196, 278]), rank 0 
2024-05-14 05:26:39.081305: predicting 25991Y_8_2 
2024-05-14 05:26:39.084378: 25991Y_8_2, shape torch.Size([1, 46, 208, 273]), rank 0 
2024-05-14 05:26:39.973396: predicting 26015D_16_2 
2024-05-14 05:26:39.976578: 26015D_16_2, shape torch.Size([1, 44, 206, 268]), rank 0 
2024-05-14 05:26:40.864740: predicting 26021Y_8_3 
2024-05-14 05:26:40.867736: 26021Y_8_3, shape torch.Size([1, 46, 199, 275]), rank 0 
2024-05-14 05:26:41.756210: predicting 26074T_8_2 
2024-05-14 05:26:41.758452: 26074T_8_2, shape torch.Size([1, 51, 193, 276]), rank 0 
2024-05-14 05:26:43.514255: predicting 26083U_16_2 
2024-05-14 05:26:43.515590: 26083U_16_2, shape torch.Size([1, 45, 212, 278]), rank 0 
2024-05-14 05:26:44.398745: predicting 26093X_4_3 
2024-05-14 05:26:44.401276: 26093X_4_3, shape torch.Size([1, 48, 198, 264]), rank 0 
2024-05-14 05:26:45.287568: predicting 26104C_16_2 
2024-05-14 05:26:45.290573: 26104C_16_2, shape torch.Size([1, 46, 197, 278]), rank 0 
2024-05-14 05:26:46.179771: predicting 26112B_8_3 
2024-05-14 05:26:46.181083: 26112B_8_3, shape torch.Size([1, 45, 203, 269]), rank 0 
2024-05-14 05:26:47.061886: predicting 26118N_0_0 
2024-05-14 05:26:47.064010: 26118N_0_0, shape torch.Size([1, 46, 190, 265]), rank 0 
2024-05-14 05:26:47.519952: predicting 26121C_16_2 
2024-05-14 05:26:47.522503: 26121C_16_2, shape torch.Size([1, 48, 195, 272]), rank 0 
2024-05-14 05:26:48.409275: predicting 26142K_0_0 
2024-05-14 05:26:48.412187: 26142K_0_0, shape torch.Size([1, 46, 213, 269]), rank 0 
2024-05-14 05:26:49.301461: predicting 26148W_16_2 
2024-05-14 05:26:49.304555: 26148W_16_2, shape torch.Size([1, 42, 193, 278]), rank 0 
2024-05-14 05:26:50.197961: predicting 26175Z_16_2 
2024-05-14 05:26:50.199270: 26175Z_16_2, shape torch.Size([1, 35, 199, 272]), rank 0 
2024-05-14 05:26:51.076765: predicting 26183Y_0_0 
2024-05-14 05:26:51.079828: 26183Y_0_0, shape torch.Size([1, 42, 194, 277]), rank 0 
2024-05-14 05:26:51.972587: predicting 26185C_4_2 
2024-05-14 05:26:51.975341: 26185C_4_2, shape torch.Size([1, 50, 190, 265]), rank 0 
2024-05-14 05:27:01.929867: Validation complete 
2024-05-14 05:27:01.929967: Mean Validation Dice:  0.9350958105272807 
